% Encoding: UTF-8

@Article{abbeel2010autonomous,
  author    = {Abbeel, Pieter and Coates, Adam and Ng, Andrew Y.},
  journal   = {The International Journal of Robotics Research},
  title     = {Autonomous helicopter aerobatics through apprenticeship learning},
  year      = {2010},
  number    = {13},
  pages     = {1608--1639},
  volume    = {29},
  groups    = {RL},
  publisher = {SAGE Publications Sage UK: London, England},
  timestamp = {2020-08-06},
}

@Article{Abdellaoui2006pt,
  author    = {Abdellaoui, Mohammed and Han, Bleichrodt and Paraschiv, Corina},
  journal   = {Management Science},
  title     = {Loss aversion under prospect theory: {A} parameter-free measurement},
  year      = {2006},
  number    = {10},
  pages     = {1659--1674},
  volume    = {53},
  groups    = {prospect theory},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@InProceedings{abdi2010designing,
  author       = {Abdi, Hamid and Nahavandi, Saeid},
  booktitle    = {2010 IEEE/ASME International Conference on Advanced Intelligent Mechatronics},
  title        = {Designing optimal fault tolerant {Jacobian} for robotic manipulators},
  year         = {2010},
  organization = {IEEE},
  pages        = {426--431},
  groups       = {parallel manipulator},
  timestamp    = {2020-08-06},
}

@InProceedings{abdi2011optimal,
  author       = {Abdi, Hamid and Nahavandi, Saeid and Maciejewski, Anthony A.},
  booktitle    = {2011 IEEE International Conference on Robotics and Automation},
  title        = {Optimal fault-tolerant {Jacobian} matrix generators for redundant manipulators},
  year         = {2011},
  organization = {IEEE},
  pages        = {4688--4693},
  groups       = {parallel manipulator},
  timestamp    = {2020-08-06},
}

@Article{Abonyi2001,
  author    = {Abonyi, J. and Babuska, R. and Szeifert, F.},
  journal   = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  title     = {Fuzzy modeling with multivariate membership functions: {Gray-box} identification and control design},
  year      = {2001},
  issn      = {1941-0492},
  month     = {10},
  number    = {5},
  pages     = {755--767},
  volume    = {31},
  abstract  = {A novel framework for fuzzy modeling and model-based control design is described. The fuzzy model is of the Takagi-Sugeno (TS) type with constant consequents. It uses multivariate antecedent membership functions obtained by Delaunay triangulation of their characteristic points. The number and position of these points are determined by an iterative insertion algorithm. Constrained optimization is used to estimate the consequent parameters, where the constraints are based on control-relevant a priori knowledge about the modeled process. Finally, methods for control design through linearization and inversion of this model are developed. The proposed techniques are demonstrated by means of two benchmark examples: identification of the well-known Box-Jenkins gas furnace and inverse model-based control of a pH process. The obtained results are compared with results from the literature.},
  doi       = {10.1109/3477.956037},
  file      = {:FILES/2001 - Abonyi2001 - Fuzzy modeling with multivariate membership functions- gray-box identification and control design.pdf:PDF},
  groups    = {interesting articles},
  keywords  = {mesh generation;fuzzy logic;model-based reasoning;fuzzy control;fuzzy modeling;multivariate membership functions;gray-box identification;control design;model-based control design;Takagi-Sugeno type;multivariate antecedent membership functions;Delaunay triangulation;iterative insertion algorithm;control-relevant a priori knowledge;Box-Jenkins gas furnace;inverse model-based control;pH process;Fuzzy control;Control design;Fuzzy systems;Fuzzy sets;Parameter estimation;Inverse problems;Space technology;Input variables;Scattering;Piecewise linear approximation},
  timestamp = {2020-08-06},
}

@InCollection{abrams1980projection,
  author    = {Abrams, R. A. and Wu, C. T.},
  booktitle = {Advances in Geometric Programming},
  publisher = {Springer},
  title     = {Projection and restriction methods in geometric programming and related problems},
  year      = {1980},
  pages     = {165--182},
  groups    = {SGP},
  timestamp = {2020-07-16},
}

@InProceedings{abtahi2011deep,
  author    = {Abtahi, Farnaz and Fasel, Ian},
  booktitle = {Workshops at the Twenty-Fifth AAAI Conference on Artificial Intelligence},
  title     = {Deep belief nets as function approximators for reinforcement learning},
  year      = {2011},
  groups    = {RL},
}

@Article{abual2004wideband,
  author   = {Abu-Al-Saud, W. A. and Stuber, G. L.},
  journal  = {IEEE Transactions on Signal Processing},
  title    = {Efficient wideband channelizer for software radio systems using modulated {PR} filterbanks},
  year     = {2004},
  issn     = {1941-0476},
  month    = {10},
  number   = {10},
  pages    = {2807--2820},
  volume   = {52},
  abstract = {An efficient method is proposed for channelizing frequency division multiplexed (FDM) channels in wideband software radio (SWR) received signals that do not satisfy the conditions required for polyphase decomposition of the discrete filterbank (DFB) channelizer. The proposed method, which uses modulated perfect reconstruction (PR) filterbanks, requires fewer computations than DFBs for channelizing wideband signals that are composed of FDM channels of nonequal bandwidths, especially when a large number of channels are extracted. The proposed channelizer, if applied in the reverse direction, can be used to synthesize a set of channels with nonequal bandwidths into a single wideband signal in SWR transmitters. A method is also proposed for efficiently designing the modulated PR filterbanks, which have a large number of subchannels and prototype filters with high stopband attenuations that are used in the proposed channelizer. The computational complexity of the proposed channelizer is compared with the complexity of the DFB channelizer for channelizing the wideband and high-dynamic-range signals that are typical of SWR systems, and simulation results of the proposed channelization method are discussed.},
  doi      = {10.1109/TSP.2004.834242},
  groups   = {DSP},
  keywords = {software radio;channel bank filters;frequency division multiplexing;computational complexity;radio transmitters;signal reconstruction;channel allocation;efficient wideband channelizer;software radio systems;modulated perfect reconstruction filterbanks;frequency division multiplexed channels;polyspace decomposition;discrete filterbank channelizer;SWR transmitters;computational complexity;Wideband;Software radio;Frequency division multiplexing;Bandwidth;RF signals;Signal synthesis;Radio transmitters;Prototypes;Filters;Attenuation},
}

@Article{adali1997canonical,
  author    = {Adali, T\"{u}lay and Liu, Xiao},
  journal   = {Signal Processing},
  title     = {Canonical piecewise linear network for nonlinear filtering and its application to blind equalization},
  year      = {1997},
  number    = {2},
  pages     = {145--155},
  volume    = {61},
  file      = {:FILES/1997 - adali1997canonical - Canonical piecewise linear network for nonlinear filtering and its application to blind equalization.pdf:PDF},
  groups    = {application, DSP},
  publisher = {Elsevier},
}

@Article{adams1993mixed,
  author    = {Adams, Warren P. and Sherali, Hanif D.},
  journal   = {Mathematical Programming},
  title     = {Mixed-integer bilinear programming problems},
  year      = {1993},
  number    = {1-3},
  pages     = {279--305},
  volume    = {59},
  groups    = {MILP},
  publisher = {Springer},
}

@Article{adams2004comparisons,
  author    = {Adams, Warren P. and Forrester, Richard J. and Glover, Fred W.},
  journal   = {Discrete Optimization},
  title     = {Comparisons and enhancement strategies for linearizing mixed 0-1 quadratic programs},
  year      = {2004},
  number    = {2},
  pages     = {99--120},
  volume    = {1},
  groups    = {MILP},
  publisher = {Elsevier},
}

@Article{adams2012base,
  author    = {Adams, Warren P. and Henry, Stephen M.},
  journal   = {Operations research},
  title     = {Base-2 expansions for linearizing products of functions of discrete variables},
  year      = {2012},
  number    = {6},
  pages     = {1477--1490},
  volume    = {60},
  groups    = {MILP},
  publisher = {INFORMS},
}

@Article{adhya1999lagrangian,
  author    = {Adhya, Nilanjan and Tawarmalani, Mohit and Sahinidis, Nikolaos V.},
  journal   = {Industrial \& Engineering Chemistry Research},
  title     = {A lagrangian approach to the pooling problem},
  year      = {1999},
  number    = {5},
  pages     = {1956--1972},
  volume    = {38},
  groups    = {global optimization},
  publisher = {ACS Publications},
}

@Article{adjiman1998global,
  author    = {Adjiman, Claire S. and Dallwig, Stefan and Floudas, Christodoulos A. and Neumaier, Arnold},
  journal   = {Computers \& Chemical Engineering},
  title     = {A global optimization method, $\alpha$bb, for general twice-differentiable constrained {NLPs}-{I.} theoretical advances},
  year      = {1998},
  number    = {9},
  pages     = {1137--1158},
  volume    = {22},
  groups    = {global optimization},
  publisher = {Elsevier},
}

@Article{adjiman2000global,
  author    = {Adjiman, Claire S. and Androulakis, Ioannis P. and Floudas, Christodoulos A.},
  journal   = {AIChE Journal},
  title     = {Global optimization of mixed-integer nonlinear problems},
  year      = {2000},
  number    = {9},
  pages     = {1769--1797},
  volume    = {46},
  groups    = {global optimization},
  publisher = {Wiley Online Library},
}

@Article{Afriat1971,
  author    = {Afriat, S. N.},
  journal   = {SIAM Journal on Applied Mathematics},
  title     = {Theory of maxima and the method of {Lagrange}},
  year      = {1971},
  number    = {3},
  pages     = {343--357},
  volume    = {20},
  doi       = {https://doi.org/10.1137/0120037},
  file      = {:FILES/1971 - Afriat1971 - Theory of maxima and the method of Lagrange.pdf:PDF},
  groups    = {global optimization},
  timestamp = {2020-08-31},
  url       = {https://doi.org/10.1137/0120037},
}

@Article{Aggarwal20192D,
  author   = {Aggarwal, A. and Kumar, M. and Kumar Rawat, T.},
  journal  = {IET Signal Processing},
  title    = {Design of two-dimensional {FIR} filters with quadrantally symmetric properties using the {2D} l1-method},
  year     = {2019},
  issn     = {1751-9683},
  number   = {3},
  pages    = {262--272},
  volume   = {13},
  abstract = {The mathematical formulation of the two-dimensional (2D) $L_1$L1-method for designing of the 2D-finite impulse response (FIR) filter is introduced in this study. It features the 2D-FIR filter with narrow transition width and flatter passband and stopband response. The 2D complexity is reduced using the quadrant symmetricity concept for the reduction of filter coefficients to be evaluated. Here, the unique features of the 2D $L_1$L1-method are exploited for the efficient design of the 2D-FIR filter. To study the effectiveness of the 2D-FIR filter using the proposed method, its performance is compared with other existing 2D-FIR filter methods. Simulation results for five design example of 2D lowpass, highpass, bandpass, bandstop filters and 2D differentiator are presented to prove the efficacy of the proposed design in terms of passband ripple, stopband ripple, passband error, stopband error and magnitude response.},
  doi      = {10.1049/iet-spr.2018.5353},
  file     = {:FILES/2019 - Aggarwal20192D - Design of two-dimensional FIR filters with quadrantally symmetric properties using the 2D L1-method.pdf:PDF},
  groups   = {two-dimensional FIR},
  keywords = {low-pass filters;FIR filters;band-pass filters;computational complexity;high-pass filters;two-dimensional FIR filters;quadrantally symmetric properties;2D L1-method;two-dimensional L1-method;mathematical formulation;2D-finite impulse response filter;2D-FIR filter;narrow transition width;flatter passband response;flatter stopband response;2D complexity;filter coefficient reduction;2D lowpass filter;2D highpass filter;2D bandpass filter;2D bandstop filter;2D differentiator;passband ripple;stopband ripple;passband error;stopband error;magnitude response},
}

@InProceedings{Ahmadi2013pwlPower,
  author    = {Ahmadi, Hamed and Mart\'{i}, Jos\'{e} R. and Moshref, Ali},
  booktitle = {2013 IEEE Power Energy Society General Meeting},
  title     = {Piecewise linear approximation of generators cost functions using max-affine functions},
  year      = {2013},
  month     = {7},
  pages     = {1--5},
  doi       = {10.1109/PESMG.2013.6672353},
  file      = {:FILES/2013 - Ahmadi2013pwlPower - Piecewise linear approximation of generators cost functions using max-affine functions.pdf:PDF},
  groups    = {identification},
  issn      = {1932-5517},
  keywords  = {approximation theory;electric generators;linearisation techniques;nonlinear functions;optimisation;piecewise linear techniques;power generation economics;bounded domain;multivariate function linearisation;linear function series;PWL technique;power system optimization;nonlinear function linearisation;max-affine function;generator cost function;piecewise linear approximation;Linear approximation;Piecewise linear approximation;Generators;Power systems;Cost function},
}

@ARTICLE{akan2012broader,
 AUTHOR = {Akan, Mustafa and Alagoz, Oguzhan and Ata, Baris and Erenay, Fatih Safa and Said, Adnan},
 JOURNAL = {Operations research},
 NUMBER = {4},
 PAGES = {757--770},
 PUBLISHER = {INFORMS},
 TITLE = {A broader view of designing the liver allocation system},
 VOLUME = {60},
 YEAR = {2012}
}

@Article{akrotirianakis2004computational,
  author    = {Akrotirianakis, Ioannis G. and Floudas, Christodoulos A.},
  journal   = {Journal of Global Optimization},
  title     = {Computational experience with a new class of convex underestimators: {Box-constrained} {NLP} problems},
  year      = {2004},
  number    = {3},
  pages     = {249--264},
  volume    = {29},
  groups    = {global optimization},
  publisher = {Springer},
}

@Article{akrotirianakis2004new,
  author    = {Akrotirianakis, Ioannis G. and Floudas, Christodoulos A.},
  journal   = {Journal of Global Optimization},
  title     = {A new class of improved convex underestimators for twice continuously differentiable constrained nlps},
  year      = {2004},
  number    = {4},
  pages     = {367--390},
  volume    = {30},
  groups    = {global optimization},
  publisher = {Springer},
}

@Article{al1983jointly,
  author    = {Al-Khayyal, Faiz A. and Falk, James E.},
  journal   = {Mathematics of Operations Research},
  title     = {Jointly constrained biconvex programming},
  year      = {1983},
  number    = {2},
  pages     = {273--286},
  volume    = {8},
  groups    = {global optimization},
  publisher = {INFORMS},
}

@Article{al1990jointly,
  author    = {Al-Khayyal, Faiz A.},
  journal   = {Computers \& Mathematics with Applications},
  title     = {Jointly constrained bilinear programs and related problems: {An} overview},
  year      = {1990},
  number    = {11},
  pages     = {53--62},
  volume    = {19},
  groups    = {bilinear},
  publisher = {Elsevier},
}

@Article{al1992generalized,
  author    = {Al-Khayyal, Faiz A.},
  journal   = {European Journal of Operational Research},
  title     = {Generalized bilinear programming: {Part} {I}. models, applications and linear programming relaxation},
  year      = {1992},
  number    = {3},
  pages     = {306--314},
  volume    = {60},
  abstract  = {The evolution of the bilinear programming problem is reviewed and a new, more general model is discussed. The model involves two decision vectors and reduces to a linear program when one of the decision vectors is fixed. The class of problems under consideration contains traditional bilinear programs, general quadratic programs, and bilinearly constrained and quadratically constrained extensions of these problems. We describe how several important applications from the literature, including the multiple modular design problem, can be modeled as generalized bilinear programs. Finally, we derive a linear programming relaxation that can be used as a subproblem in algorithmic solution schemes based on outer approximation and branch and bound.},
  doi       = {10.1016/0377-2217(92)90082-K},
  file      = {:FILES/1992 - al1992generalized - Generalized bilinear programming- {Part} i. models, applications and linear programming relaxation.pdf:PDF},
  groups    = {bilinear},
  publisher = {Elsevier},
  url       = {https://www.sciencedirect.com/science/article/abs/pii/037722179290082K},
}

@Article{alarie2001concavity,
  author    = {Alarie, St\'{e}phane and Audet, Charles and Jaumard, Brigitte and Savard, Gilles},
  journal   = {Mathematical Programming},
  title     = {Concavity cuts for disjoint bilinear programming},
  year      = {2001},
  number    = {2},
  pages     = {373--398},
  volume    = {90},
  groups    = {bilinear},
  publisher = {Springer},
}

@Article{alejandre2004general,
  author    = {Alejandre, J. L. and Allueva, Ana and Gonzalez, Jose Miguel},
  journal   = {Computational Optimization and Applications},
  title     = {A general alternative procedure for solving negative degree of difficulty problems in geometric programming},
  year      = {2004},
  number    = {1},
  pages     = {83--93},
  volume    = {27},
  file      = {:FILES/2004 - alejandre2004general - A general alternative procedure for solving negative degree of difficulty problems in geometric programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-07-16},
}

@Article{Alesina1998,
  author    = {Alesina, Alberto Claudio and Galuzzi, Massimo},
  journal   = {L’Enseignement Math\'{e}matique.},
  title     = {A new proof of {Vincent's} theorem},
  year      = {1998},
  month     = {01},
  pages     = {219--256},
  volume    = {IIe S{\'{e}}rie 44},
  doi       = {10.5169/seals-63903},
  groups    = {mathematical basis},
  timestamp = {2020-08-06},
}

@Article{Alexander2004var,
  author    = {Alexander, Gordon J. and Baptista, Alexandre M.},
  journal   = {Management Science},
  title     = {A comparison of {VaR} and {CVaR} constraints on portfolio selection with the mean-variance model},
  year      = {2004},
  number    = {9},
  pages     = {1261--1273},
  volume    = {50},
  file      = {:FILES/2004 - Alexander2004var - A comparison of {VaR} and {CVaR} constraints on portfolio selection with the mean-variance model_supplement.pdf:PDF;:FILES/2004 - Alexander2004var - A comparison of {VaR} and {CVaR} constraints on portfolio selection with the mean-variance model.pdf:PDF},
  groups    = {VaR, cvar, mean variance},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{Alexander2006,
  author    = {Alexander, Siddharth and Coleman, Thomas F. and Li, Yuying},
  journal   = {Journal of Banking \& Finance},
  title     = {Minimizing {CVaR} and {VaR} for a portfolio of derivatives},
  year      = {2006},
  number    = {2},
  pages     = {583--605},
  volume    = {30},
  file      = {:FILES/2006 - Alexander2006 - Minimizing CVaR and VaR for a portfolio of derivatives.pdf:PDF},
  groups    = {VaR, cvar, TEC},
  timestamp = {2020-09-05},
}

@Article{ali2016sdp,
  author    = {Ali, Elaf J. and Gao, David Y.},
  journal   = {arXiv preprint arXiv:1609.04675},
  title     = {On {SDP} method for solving canonical dual problem in post buckling of large deformed elastic beam},
  year      = {2016},
  abstract  = {This paper presents a new methodology and algorithm for solving post buckling problems of a large deformed elastic beam. The total potential energy of this beam is a nonconvex functional, which can be used to model both pre- and post-buckling phenomena. By using a canonical dual finite element method, a new primal-dual semi-definite programming (PD-SDP) algorithm is presented, which can be used to obtain all possible post-buckled solutions. Applications are illustrated by several numerical examples with different boundary conditions. We find that the global minimum solution of the nonconvex potential leads to a stable configuration of the buckled beam, the local maximum solution leads to the unbuckled state, and both of these two solutions are numerically stable. However, the local minimum solution leads to an unstable buckled state, which is very sensitive to axial compressive forces, thickness of beam, numerical precision, and the size of finite elements. The method and algorithm proposed in this paper can be used for solving general nonconvex variational problems in engineering and sciences.},
  file      = {:FILES/2016 - ali2016sdp -  On SDP method for solving canonical dual problem in post buckling of large deformed elastic beam.pdf:PDF},
  groups    = {mathematical basis},
  timestamp = {2020-08-31},
}

@Article{Aliabadi2019inventory,
  author    = {Aliabadi, Leyla and Yazdanparast, Reza and Nasiri, Mohammad Mahdi},
  journal   = {International Journal of Management Science and Engineering Management},
  title     = {An inventory model for non-instantaneous deteriorating items with credit period and carbon emission sensitive demand: {A} signomial geometric programming approach},
  year      = {2019},
  number    = {2},
  pages     = {124--136},
  volume    = {14},
  abstract  = {This study considers sustainability issues and default risks in the context of joint inventory control and trade credit financing for Non-Instantaneous Deteriorating Items (NIDIs) in a supplier-retailer-customer system, in which the supplier offers an upstream full trade credit to the retailer and the retailer, in turn, provides a downstream partial trade credit to her/his customers. Demand rate is sensitive to the amount of carbon emissions, the length of the credit period suggested by the retailer to its customers and selling price. The main objective of this study is to optimize credit period, order quantity, and replenishment cycle time in order to maximize retailer’s total profit and minimize carbon emissions at the same time. For solving the proposed problem, we apply an approximation method to simplify the profit function and transform the problem into a constrained Signomial Geometric Programming (SGP) problem, then a global optimization approach is used for solving the model.Finally, a numerical illustration and sensitivity analysis are performed to demonstrate the problem and the solution procedure. Some useful managerial insights are obtained from computational results. The results show that the retailer will increase its total profit by considering trade credit policy and non-instantaneous deteriorating phenomenon.},
  doi       = {10.1080/17509653.2018.1504331},
  groups    = {SGP},
  publisher = {Taylor \& Francis},
  timestamp = {2020-07-16},
  url       = {https://doi.org/10.1080/17509653.2018.1504331},
}

@Article{Althofer1991TA,
  author  = {Alth\"{o}fer, Ingo and Koschnick, Klaus Uwe},
  journal = {Applied Mathematics \& Optimization},
  title   = {On the convergence of ``{Threshold Accepting}''},
  year    = {1991},
  number  = {1},
  pages   = {183--195},
  volume  = {24},
  groups  = {convergence},
  type    = {Journal Article},
}

@Article{Anderson1970risk,
  author    = {Anderson, Norman H. and Shanteau, James C.},
  journal   = {Journal of Experimental Psychology},
  title     = {Information integration in risky decision making},
  year      = {1970},
  number    = {3},
  pages     = {441--451},
  volume    = {84},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{Andersson2001,
  author    = {Andersson, Fredrik and Mausser, Helmut and Rosen, Dan and Uryasev, Stanislav},
  journal   = {Mathematical Programming},
  title     = {Credit risk optimization with conditional value-at-risk criterion},
  year      = {2001},
  number    = {2},
  pages     = {273--291},
  volume    = {89},
  groups    = {cvar, TEC},
  timestamp = {2020-09-05},
  type      = {Journal Article},
}

@InCollection{Ankenbrandt1991,
  author    = {Ankenbrandt, Carol A.},
  booktitle = {Foundations of Genetic Algorithms},
  publisher = {Elsevier},
  title     = {An extension to the theory of convergence and a proof of the time complexity of genetic algorithms},
  year      = {1991},
  editor    = {RAWLINS, GREGORY J.E.},
  pages     = {53--68},
  volume    = {1},
  abstract  = {Genetic algorithms, search procedures modelled after the mechanics of natural selection, are difficult to analyze because their time complexity is related to characteristics of the application problem domain. The standard recurrence relation for binary and nonbinary genetic algorithms is solved using an inductive proof and a proof using linear finite difference equations. This result is used to estimate the average and worst case time complexity for genetic algorithms. The resulting equations define the relationship between estimated run time, problem size, fitness ratio and the complexity of the domain specific evaluation function for domains with constant fitness ratio for binary and nonbinary GAs. The fitness ratio is a characteristic of the problem domain reflecting the relative merit of some candidate solutions over others.},
  doi       = {https://doi.org/10.1016/B978-0-08-050684-5.50007-0},
  groups    = {genetic algorithms},
  issn      = {1081-6593},
  keywords  = {convergence, complexity, implementation parameters, fitness ratio},
  timestamp = {2020-06-13},
  url       = {http://www.sciencedirect.com/science/article/pii/B9780080506845500070},
}

@ARTICLE{antoniou1982acce,
 ABSTRACT = {Two techniques are described which can be used in the design of weighted-Chebyshev nonrecursive digital filters. The first technique is a new initialization scheme for 3-band filters which improves convergence in the design of bandstop filters. The second technique is an improved search algorithm which can be used to locate the maxima of the error function. It incorporates cubic interpolation with a selective step-by-step search and it replaces the exhaustive step-by-step search proposed by Rabiner, McClellan, and Parks in the past as well as the selective step-by-step search proposed by Antoniou recently. The two techniques as well as an improved technique for the rejection of superfluous maxima of the error function, proposed recently by Antoniou, are used to construct a filter-design package which can be used for the design of equiripple nonrecursive filters. When applied for the design of a large number of low-pass, high-pass, bandpass, and bandstop filters, the new design method leads to an average saving in the amount of computation of about 87 percent relative to the amount required by the Rabiner, McClellan, and Parks method. It is demonstrated that this improvement is achieved without degrading the robustness of the Remez exchange algorithm to a significant extent.},
 AUTHOR = {Antoniou, A.},
 DOI = {10.1109/TCS.1983.1085296},
 GROUPS = {FIR filter design},
 ISSN = {1558-1276},
 JOURNAL = {IEEE Transactions on Circuits and Systems},
 KEYWORDS = {Bandstop filters;Chebyshev filters;Digital filters;Nonrecursive digital filters;Design methodology;Chebyshev approximation;Digital filters;Band pass filters;Convergence;Low pass filters;Design optimization;Interpolation;Packaging;Degradation},
 MONTH = {10},
 NUMBER = {10},
 PAGES = {740--750},
 TITLE = {New improved method for the design of weighted- chebyshev, nonrecursive, digital filters},
 VOLUME = {30},
 YEAR = {1983}
}

@Article{antoniou1983improve,
  author   = {Antoniou, A.},
  journal  = {IEE Proceedings G - Electronic Circuits and Systems},
  title    = {Accelerated procedure for the design of equiripple nonrecursive digital filters},
  year     = {1982},
  issn     = {0143-7089},
  month    = feb,
  number   = {1},
  pages    = {1},
  volume   = {129},
  abstract = {An accelerated procedure for the design of equiripple nonrecursive digital filters is described. The new procedure entails two techniques. The first technique is a selective search for the maxima of the error function, and it replaces the exhaustive search proposed by Rabiner, McClellan and Parks. It leads to a large saving in the number of function evaluations. The second technique is a more effective approach for the rejection of superfluous maxima of the error function. It can lead to a significant reduction in the number of iterations. The two techniques together lead to an overall saving in the amount of computation in the range 55 to 83\%, depending on the filter specifications.},
  doi      = {10.1049/ip-g-1.1982.0001},
  groups   = {FIR filter design},
  keywords = {circuit CAD;digital filters;low-pass filters;network synthesis;error function maxima;low-pass filter;digital filter design;CAD;equiripple nonrecursive digital filters;accelerated procedure;rejection of superfluous maxima},
}

@Article{aronszajn1950theory,
  author    = {Aronszajn, Nachman},
  journal   = {Transactions of the American Mathematical Society},
  title     = {Theory of reproducing kernels},
  year      = {1950},
  number    = {3},
  pages     = {337--404},
  volume    = {68},
  groups    = {SVM},
  publisher = {JSTOR},
  timestamp = {2020-08-30},
}

@Article{Arram2019,
  author    = {Arram, Anas and Ayob, Masri},
  journal   = {Computers \& Industrial Engineering},
  title     = {A novel multi-parent order crossover in genetic algorithm for combinatorial optimization problems},
  year      = {2019},
  issn      = {0360-8352},
  pages     = {267--274},
  volume    = {133},
  abstract  = {Many multi-parent crossovers have been proposed to solve specific combinatorial optimization problem and not applicable to solve other problems (i.e. cannot produce feasible solution). Only multi-parent partially mapped crossover (MPPMX) and adjacency-based crossover (ABC) have been proposed to work over different combinatorial problems. However, both MPPMX and ABC suffered from a very high computational time or poor performance. Therefore, this work proposes a novel multi-parent order crossover (MPOX) for solving several combinatorial optimization problems with reasonable amount of time. The MPOX extends the two-parent order crossover by modifying the recombination operator to recombine more than two parents and generates a new offspring. MPOX at first selects the crossover points and divides the parents into n substrings based on these points (where n is the number of parents). Then, MPOX copies a predefined number of elements from each parent into the offspring based on their order while checking the feasibility of the offspring. The performance of MPOX is tested on the traveling salesman problems and berth allocation problems, which are widely studied in the literature. Experimental results demonstrated that the MPOX significantly improves the OX in both problem domains and outperforms both ABC and MPPMX over the travelling salesman problem and the berth allocation problem with less computational time. These results indicate the effectiveness of MPOX over OX, ABC and MPPMX, and its capability for solving both problems.},
  doi       = {https://doi.org/10.1016/j.cie.2019.05.012},
  file      = {:FILES/2019 - Arram2019 - A novel multi-parent order crossover in genetic algorithm for combinatorial optimization problems.pdf:PDF},
  groups    = {genetic algorithms, TEC},
  keywords  = {Genetic algorithm, Multi-parent crossover, Order crossover, Traveling salesman problem, Berth allocation problem},
  timestamp = {2020-09-05},
  url       = {http://www.sciencedirect.com/science/article/pii/S0360835219302773},
}

@Article{Artzner1999,
  author    = {Artzner, Philippe and Delbaen, Freddy and Eber, Jean-Marc and Heath, David},
  journal   = {Mathematical Finance},
  title     = {Coherent measures of risk},
  year      = {1999},
  number    = {3},
  pages     = {203--228},
  volume    = {9},
  file      = {:FILES/1999 - Artzner1999 - Coherent measures of risk.pdf:PDF},
  groups    = {VaR},
  publisher = {Blackwell Publishers Inc},
  timestamp = {2020-09-04},
}

@Article{Arulkumaran2017survey,
  author   = {Arulkumaran, K. and Deisenroth, M. P. and Brundage, M. and Bharath, A. A.},
  journal  = {IEEE Signal Processing Magazine},
  title    = {Deep reinforcement learning: {A} brief survey},
  year     = {2017},
  issn     = {1558-0792},
  month    = {11},
  number   = {6},
  pages    = {26--38},
  volume   = {34},
  abstract = {Deep reinforcement learning (DRL) is poised to revolutionize the field of artificial intelligence (AI) and represents a step toward building autonomous systems with a higher-level understanding of the visual world. Currently, deep learning is enabling reinforcement learning (RL) to scale to problems that were previously intractable, such as learning to play video games directly from pixels. DRL algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera inputs in the real world. In this survey, we begin with an introduction to the general field of RL, then progress to the main streams of value-based and policy-based methods. Our survey will cover central algorithms in deep RL, including the deep Q-network (DQN), trust region policy optimization (TRPO), and asynchronous advantage actor critic. In parallel, we highlight the unique advantages of deep neural networks, focusing on visual understanding via RL. To conclude, we describe several current areas of research within the field.},
  doi      = {10.1109/MSP.2017.2743240},
  groups   = {RL},
  keywords = {cameras;learning (artificial intelligence);mobile robots;neural nets;deep reinforcement learning;artificial intelligence;autonomous systems;robot control policies;camera inputs;value-based method;policy-based method;central algorithms;deep Q-network;trust region policy optimization;asynchronous advantage actor critic;deep neural networks;Artificial intelligence;Signal processing algorithms;Visualization;Machine learning;Learning (artificial intelligence);Neural networks},
}

@InProceedings{atkeson1997comparison,
  author       = {Atkeson, Christopher G. and Santamaria, Juan Carlos},
  booktitle    = {Proceedings of International Conference on Robotics and Automation},
  title        = {A comparison of direct and model-based reinforcement learning},
  year         = {1997},
  organization = {IEEE},
  pages        = {3557--3564},
  volume       = {4},
  groups       = {RL},
}

@InCollection{atkeson1997locally,
  author    = {Atkeson, Christopher G. and Moore, Andrew W. and Schaal, Stefan},
  booktitle = {Lazy learning},
  publisher = {Springer},
  title     = {Locally weighted learning},
  year      = {1997},
  pages     = {11--73},
  groups    = {machine learning},
  timestamp = {2020-08-06},
}

@Article{Attouch2020,
  author    = {Attouch, Hedy and Chbani, Zaki and Riahi, Hassan},
  journal   = {Optimization},
  title     = {Fast convex optimization via a third-order in time evolution equation},
  year      = {2020},
  issn      = {0233-1934},
  pages     = {1--30},
  abstract  = {In a Hilbert space $H$, we develop fast convex optimization methods which are based on an evolution system of the third-order in time. The function to minimize $f:H \to R$ is convex, continuously differentiable, with $argmin f \neq \emptyset$, and enters the dynamic via its gradient. On the basis of Lyapunov's analysis and temporal scaling techniques, we show a convergence rate of the values of the order $1/t_3$, and obtain the convergence of the trajectories towards optimal solutions. When f is strongly convex, an exponential rate of convergence is obtained. We complete the study of the continuous dynamic by introducing a damping term induced by the Hessian of $F$. This allows the oscillations to be controlled and attenuated. Then, we analyse the convergence of the proximal-based algorithms obtained by temporal discretization of this system, and obtain similar convergence rates. The algorithmic results are valid for a general convex, lower semicontinuous and proper function $f:H \to R \cup \{ + \infty\}$.},
  doi       = {10.1080/02331934.2020.1764953},
  file      = {:FILES/2020 - Attouch2020 - Fast convex optimization via a third-order in time evolution equation.pdf:PDF},
  groups    = {global optimization},
  timestamp = {2020-08-06},
  url       = {https://www.tandfonline.com/doi/full/10.1080/02331934.2020.1764953},
}

@Article{audet1999symmetrical,
  author    = {Audet, Charles and Hansen, Pierre and Jaumard, Brigitte and Savard, Gilles},
  journal   = {Mathematical Programming},
  title     = {A symmetrical linear maxmin approach to disjoint bilinear programming},
  year      = {1999},
  number    = {3},
  pages     = {573--592},
  volume    = {85},
  groups    = {bilinear},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{audet2000branch,
  author    = {Audet, Charles and Hansen, Pierre and Jaumard, Brigitte and Savard, Gilles},
  journal   = {Mathematical Programming},
  title     = {A branch and cut algorithm for nonconvex quadratically constrained quadratic programming},
  year      = {2000},
  month     = jan,
  number    = {1},
  pages     = {131--152},
  volume    = {87},
  abstract  = {We present a branch and cut algorithm that yields in finite time, a globally ε-optimal solution (with respect to feasibility and optimality) of the nonconvex quadratically constrained quadratic programming problem. The idea is to estimate all quadratic terms by successive linearizations within a branching tree using Reformulation-Linearization Techniques (RLT). To do so, four classes of linearizations (cuts), depending on one to three parameters, are detailed. For each class, we show how to select the best member with respect to a precise criterion. The cuts introduced at any node of the tree are valid in the whole tree, and not only within the subtree rooted at that node. In order to enhance the computational speed, the structure created at any node of the tree is flexible enough to be used at other nodes. Computational results are reported that include standard test problems taken from the literature. Some of these problems are solved for the first time with a proof of global optimality.},
  doi       = {10.1007/s101079900106},
  file      = {:FILES/2000 - audet2000branch - A branch and cut algorithm for nonconvex quadratically constrained quadratic programming.pdf:PDF},
  groups    = {global optimization},
  publisher = {Springer},
  timestamp = {2020-08-06},
  url       = {https://link.springer.com/article/10.1007/s101079900106},
}

@Article{audet2008exact,
  author    = {Audet, Charles and Hansen, Pierre and Karam, Alejandro and Ng, Chi To and Perron, Sylvain},
  journal   = {Optimization Letters},
  title     = {Exact {$L_2$}-norm plane separation},
  year      = {2008},
  number    = {4},
  pages     = {483--495},
  volume    = {2},
  file      = {:FILES/2008 - audet2008exact - Exact L2-norm plane.pdf:PDF},
  groups    = {SVM},
  publisher = {Springer},
  timestamp = {2020-08-30},
}

@ARTICLE{avriel1970complementary,
 AUTHOR = {Avriel, Mu and Williams, AC},
 GROUPS = {SGP},
 JOURNAL = {SIAM Journal on Applied Mathematics},
 NUMBER = {1},
 PAGES = {125--141},
 PUBLISHER = {SIAM},
 TIMESTAMP = {2020-07-16},
 TITLE = {Complementary geometric programming},
 VOLUME = {19},
 YEAR = {1970}
}

@ARTICLE{avriel1971extension,
 AUTHOR = {Avriel, M and Williams, AC},
 GROUPS = {SGP},
 JOURNAL = {Journal of Engineering Mathematics},
 NUMBER = {2},
 PAGES = {187--194},
 PUBLISHER = {Springer},
 TIMESTAMP = {2020-07-16},
 TITLE = {An extension of geometric programming with applications in engineering optimization},
 VOLUME = {5},
 YEAR = {1971}
}

@ARTICLE{avriel1975solution,
 AUTHOR = {Avriel, M and Dembo, R and Passy, U},
 GROUPS = {SGP},
 JOURNAL = {International journal for numerical methods in engineering},
 NUMBER = {1},
 PAGES = {149--168},
 PUBLISHER = {Wiley Online Library},
 TIMESTAMP = {2020-07-16},
 TITLE = {Solution of generalized geometric programs},
 VOLUME = {9},
 YEAR = {1975}
}

@Article{BabaeizadehFTCK2016,
  author        = {Babaeizadeh, Mohammad and Frosio, Iuri and Tyree, Stephen and Clemons, Jason and Kautz, Jan},
  journal       = {CoRR},
  title         = {{ga3c: {}} gpu-based {A3C} for deep reinforcement learning},
  year          = {2016},
  volume        = {abs/1611.06256},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/BabaeizadehFTCK16.bib},
  eprint        = {1611.06256},
  groups        = {RL},
  timestamp     = {2020-08-06},
  url           = {http://arxiv.org/abs/1611.06256},
}

@InBook{Bagirov2014,
  author    = {Bagirov, Adil and Karmitsa, Napsu and M\"{a}kel\"{a}, Marko M.},
  pages     = {305--310},
  publisher = {Springer International Publishing},
  title     = {Bundle methods},
  year      = {2014},
  address   = {Cham},
  isbn      = {978-3-319-08114-4},
  abstract  = {At the moment, bundle methods are regarded as the most effective and reliable methods for nonsmooth optimization. They are based on the subdifferential theory developed by Rockafellar and Clarke, where the classical differential theory is generalized for convex and locally Lipschitz continuous functions, respectively. The basic idea of bundle methods is to approximate the subdifferential (that is, the set of subgradients) of the objective function by gathering subgradients from previous iterations into a bundle. In this way, more information about the local behavior of the function is obtained than what an individual arbitrary subgradient can yield. In this chapter, we first introduce the most frequently used bundle methods, that is, the proximal bundle and the bundle trust methods, and then we describe the basic ideas of the second order bundle-Newton method.},
  booktitle = {Introduction to Nonsmooth Optimization: Theory, Practice and Software},
  doi       = {10.1007/978-3-319-08114-4_12},
  file      = {:FILES/2014 - BBagirov2014 - undle methods.pdf:PDF},
  groups    = {global optimization, proximal bundle method},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1007/978-3-319-08114-4_12},
}

@Book{bagirov2014introduction,
  author    = {Bagirov, Adil and Karmitsa, Napsu and M\"{a}kel\"{a}, Marko M.},
  publisher = {Springer},
  title     = {Introduction to nonsmooth optimization: {Theory,} practice and software},
  year      = {2014},
  abstract  = {This book is the first easy-to-read text on nonsmooth optimization (NSO, not necessarily diﬀerentiable optimization). Solving these kinds of problems plays a critical role in many industrial applications and real-world modeling systems, for example in the context of image denoising, optimal control, neural network training, data mining, economics, and computational chemistry and physics. The book covers both the theory and the numerical methods used in NSO, and provides an overview of diﬀerent problems arising in the ﬁeld. It is organized into three parts:

1.convex and nonconvex analysis and the theory of NSO;

2.test problems and practical applications;

3.a guide to NSO software.

The book is ideal for anyone teaching or attending NSO courses. As an accessible introduction to the ﬁeld, it is also well suited as an independent learning guide for practitioners already familiar with the basics of optimization.},
  file      = {:FILES/2014 - bagirov2014introduction - Introduction to Nonsmooth Optimization【book】.pdf:PDF},
  groups    = {nonsmooth optimization},
  timestamp = {2020-09-04},
}

@Article{Bai2017,
  author    = {Bai, Yu and Xu, Zhiming and Xi, Xiangming and Wang, Shuning},
  journal   = {Tsinghua Science and Technology},
  title     = {Objective variation simplex algorithm for continuous piecewise linear programming},
  year      = {2017},
  issn      = {1007-0214},
  month     = {2},
  number    = {01},
  pages     = {73--82},
  volume    = {22},
  abstract  = {This paper works on a modified simplex algorithm for the local optimization of Continuous PieceWise Linear (CPWL) programming with generalization of hinging hyperplane objective and linear constraints. CPWL programming is popular since it can be equivalently transformed into difference of convex functions programming or concave optimization. Inspired by the concavity of the concave CPWL functions, we propose an Objective Variation Simplex Algorithm (OVSA), which is able to find a local optimum in a reasonable time. Computational results are presented for further insights into the performance of the OVSA compared with two other algorithms on random test problems.},
  author+an = {3=highlight},
  doi       = {10.1109/TST.2017.7830897},
  file      = {:FILES/2017 - Bai2017 - Objective variation simplex algorithm for continuous piecewise linear programming.pdf:PDF},
  groups    = {my paper, Wang's Work},
  keywords  = {linear programming;piecewise linear techniques;objective variation simplex algorithm;continuous piecewise linear programming;local optimization;hyperplane objective;linear constraints;CPWL programming;convex functions programming;concave optimization;OVSA;Programming;Optimization;Linear programming;Indexes;Convex functions;Linearity;Approximation algorithms;local optimization;continuous piecewise linear programming;modified simplex algorithm},
  timestamp = {2020-06-20},
}

@Article{balakrishnan1989composite,
  author    = {Balakrishnan, Anantharam and Graves, Stephen C.},
  journal   = {Networks},
  title     = {A composite algorithm for a concave-cost network flow problem},
  year      = {1989},
  number    = {2},
  pages     = {175--202},
  volume    = {19},
  file      = {:FILES/1989 - balakrishnan1989composite - A Composite Algorithm for a Concave-Cost Network Flow Problem.pdf:PDF},
  groups    = {global optimization},
  publisher = {Wiley Online Library},
  timestamp = {2020-08-06},
}

@Article{balas1971intersection,
  author    = {Balas, Egon},
  journal   = {Operations Research},
  title     = {Intersection cuts-a new type of cutting planes for integer programming},
  year      = {1971},
  number    = {1},
  pages     = {19--39},
  volume    = {19},
  groups    = {MILP},
  publisher = {INFORMS},
  timestamp = {2020-08-06},
}

@Article{Balduzzi2015CompatibleVG,
  author    = {Balduzzi, David and Ghifary, Muhammad},
  journal   = {ArXiv},
  title     = {Compatible value gradients for reinforcement learning of continuous deep policies},
  year      = {2015},
  volume    = {abs/1509.03005},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@Article{Ban2016,
  author     = {Ban, Jung-Chao and Chang, Chih-Hung},
  journal    = {Neural Networks},
  title      = {When are two multi-layer cellular neural networks the same?},
  year       = {2016},
  issn       = {0893-6080},
  bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S0893608016300016},
  bdsk-url-2 = {http://dx.doi.org/10.1016/j.neunet.2016.03.005},
  doi        = {http://dx.doi.org/10.1016/j.neunet.2016.03.005},
  groups     = {Neural Network},
  timestamp  = {2020-08-06},
  url        = {http://www.sciencedirect.com/science/article/pii/S0893608016300016},
}

@Article{Banichuk1976,
  author    = {Banichuk, N. V.},
  journal   = {Journal of Optimization Theory and Applications},
  title     = {Minimax approach to structural optimization problems},
  year      = {1976},
  number    = {1},
  pages     = {111--127},
  volume    = {20},
  file      = {:FILES/1976 - Banichuk1976 - Minimax approach to structural optimization problems.pdf:PDF},
  groups    = {application},
  publisher = {Springer},
  timestamp = {2020-08-31},
}

@Article{Baran2010fir,
  author     = {Baran, T. and Wei, D. and Oppenheim, A. V.},
  journal    = {IEEE Transactions on Signal Processing},
  title      = {Linear programming algorithms for sparse filter design},
  year       = {2010},
  issn       = {1941-0476},
  month      = {3},
  number     = {3},
  pages      = {1605--1617},
  volume     = {58},
  abstract   = {In designing discrete-time filters, the length of the impulse response is often used as an indication of computational cost. In systems where the complexity is dominated by arithmetic operations, the number of nonzero coefficients in the impulse response may be a more appropriate metric to consider instead, and computational savings are realized by omitting arithmetic operations associated with zero-valued coefficients. This metric is particularly relevant to the design of sensor arrays, where a set of array weights with many zero-valued entries allows for the elimination of physical array elements, resulting in a reduction of data acquisition and communication costs. However, designing a filter with the fewest number of nonzero coefficients subject to a set of frequency-domain constraints is a computationally difficult optimization problem. This paper describes several approximate polynomial-time algorithms that use linear programming to design filters having a small number of nonzero coefficients, i.e., filters that are sparse. Specifically, we present two approaches that have different computational complexities in terms of the number of required linear programs. The first technique iteratively thins the impulse response of a non-sparse filter until frequency-domain constraints are violated. The second minimizes the 1-norm of the impulse response of the filter, using the resulting design to determine the coefficients that are constrained to zero in a subsequent re-optimization stage. The algorithms are evaluated within the contexts of array design and acoustic equalization.},
  doi        = {10.1109/TSP.2009.2036471},
  file       = {:FILES/2010 - Baran2010fir - Linear Programming Algorithms for Sparse Filter Design.pdf:PDF},
  groups     = {sparse},
  keywords   = {computational complexity;data acquisition;discrete time filters;linear programming;optimisation;polynomials;sensor arrays;transient response;sparse filter;discrete-time filters;linear programming algorithms;impulse response;sensor arrays;physical array elements;data acquisition;communication costs;frequency-domain constraints;optimization;polynomial time algorithms;computational complexity;Linear programming;Nonlinear filters;Algorithm design and analysis;Sensor arrays;Arithmetic;Iterative algorithms;Computational efficiency;Data acquisition;Costs;Constraint optimization;Sparse filters;linear programming;FIR digital filters;linear arrays, read},
  readstatus = {read},
}

@Article{barberis2001prospect,
  author    = {Barberis, Nicholas and Huang, Ming and Santos, Tano},
  journal   = {Quarterly Journal of Economics},
  title     = {Prospect theory and asset prices},
  year      = {2001},
  number    = {1},
  pages     = {1--53},
  volume    = {116},
  file      = {:FILES/2001 - barberis2001prospect - Prospect theory and asset prices.pdf:PDF},
  groups    = {asset allocation, prospect theory},
  timestamp = {2020-09-04},
}

@Article{Bartlett2003,
  author    = {Bartlett, Peter L. and Mendelson, Shahar},
  journal   = {Journal of Machine Learning Research},
  title     = {Rademacher and {Gussian} complexities: {Risk} bounds and structural results},
  year      = {2003},
  pages     = {463--482},
  volume    = {3},
  acmid     = {944944},
  groups    = {Portfolio Selection},
  numpages  = {20},
  timestamp = {2020-09-04},
}

@Article{barto1983neuronlike,
  author    = {Barto, Andrew G and Sutton, Richard S and Anderson, Charles W},
  journal   = {IEEE transactions on systems, man, and cybernetics},
  title     = {Neuronlike adaptive elements that can solve difficult learning control problems},
  year      = {1983},
  number    = {5},
  pages     = {834--846},
  groups    = {Heuristics},
  publisher = {IEEE},
  timestamp = {2020-08-06},
}

@Article{bawa1975optimal,
  author    = {Bawa, Vijay S},
  journal   = {Journal of Financial Economics},
  title     = {Optimal rules for ordering uncertain prospects},
  year      = {1975},
  number    = {1},
  pages     = {95--121},
  volume    = {2},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
}

@ARTICLE{beck1975modified,
 AUTHOR = {Beck, PA and Ecker, JG},
 GROUPS = {SGP},
 JOURNAL = {Journal of Optimization Theory and Applications},
 NUMBER = {2},
 PAGES = {189--202},
 PUBLISHER = {Springer},
 TIMESTAMP = {2020-07-16},
 TITLE = {A modified concave simplex algorithm for geometric programming},
 VOLUME = {15},
 YEAR = {1975}
}

@InProceedings{bellemare2016increasing,
  author    = {Bellemare, Marc G and Ostrovski, Georg and Guez, Arthur and Thomas, Philip S and Munos, R\'{e}mi},
  booktitle = {Thirtieth AAAI Conference on Artificial Intelligence},
  title     = {Increasing the action gap: {New} operators for reinforcement learning},
  year      = {2016},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@InProceedings{bellemare2017distributional,
  author       = {Bellemare, Marc G and Dabney, Will and Munos, R\'{e}mi},
  booktitle    = {Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  title        = {A distributional perspective on reinforcement learning},
  year         = {2017},
  organization = {JMLR. org},
  pages        = {449--458},
  groups       = {RL},
  timestamp    = {2020-08-06},
}

@Book{bellman1957DP,
  author    = {Bellman, Richard},
  publisher = {Princeton Univ Press},
  title     = {Dynamic programming},
  year      = {1957},
  groups    = {MILP},
  timestamp = {2020-08-06},
}

@Article{bellman1957MDP,
  author    = {BELLMAN, RICHARD},
  journal   = {Journal of Mathematics and Mechanics},
  title     = {A markovian decision process},
  year      = {1957},
  issn      = {00959057, 19435274},
  number    = {5},
  pages     = {679--684},
  volume    = {6},
  groups    = {machine learning},
  publisher = {Indiana University Mathematics Department},
  timestamp = {2020-08-06},
  url       = {http://www.jstor.org/stable/24900506},
}

@Article{bellotti2020sparse,
  author     = {Bellotti, Maja Jurisic and Vucic, Mladen},
  journal    = {Elektronika ir Elektrotechnika},
  title      = {Sparse {FIR} filter design based on signomial programming},
  year       = {2020},
  number     = {1},
  pages      = {40--45},
  volume     = {26},
  file       = {:FILES/2020 - bellotti2020sparse - Sparse fir filter design based on signomial Programming.pdf:PDF},
  groups     = {SGP, sparse},
  keywords   = {read},
  readstatus = {read},
  timestamp  = {2020-07-16},
}

@Article{ben1994global,
  author    = {Ben-Tal, Aharon and Eiger, Gideon and Gershovitz, Vladimir},
  journal   = {Mathematical programming},
  title     = {Global minimization by reducing the duality gap},
  year      = {1994},
  number    = {1-3},
  pages     = {193--212},
  volume    = {63},
  groups    = {global optimization},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{benartzi1995myopic,
  author        = {Benartzi, Shlomo and Thaler, Richard H},
  journal       = {The Quarterly Journal of Economics},
  title         = {Myopic loss aversion and the equity premium puzzle},
  year          = {1995},
  number        = {1},
  pages         = {73--92},
  volume        = {110},
  date-modified = {2016-04-05 02:52:48 +0000},
  groups        = {Portfolio Selection},
  publisher     = {Citeseer},
  timestamp     = {2020-09-04},
}

@Article{benati2004computation,
  author    = {Benati, Stefano},
  journal   = {European Journal of Operational Research},
  title     = {The computation of the worst conditional expectation},
  year      = {2004},
  number    = {2},
  pages     = {414--425},
  volume    = {155},
  abstract  = {Recent advances in risk theory identify risk as a measure related to the tail of a probability distribution function, since it represents the “worst” outcomes of the random variable. Measures like value-at-risk (VaR), conditional VaR, expected shortfall and so on have become familiar operational tools for many financial applications. In this paper, one of these measures, the worst conditional expectation with threshold α of a discrete random variable Z, shortly WCEα(Z), is considered. It has been found that its computation can be formulated as a fractional integer programming problem with a single linear constraint, but its complexity is NP-hard, therefore it must be solved by implicit enumeration. Due to its similarity with the knapsack problem, it has been found that a good upper bound and a sharp data structure allow the implementation of a branch\&bound that is able to solve realistic size problems in less than one hundredth of a second.},
  doi       = {10.1016/S0377-2217(02)00905-0},
  file      = {:FILES/2004 - benati2004computation - The computation of the worst conditional expectation.pdf:PDF},
  groups    = {utility theory},
  publisher = {Elsevier},
  timestamp = {2020-09-04},
  url       = {https://www.sciencedirect.com/science/article/pii/S0377221702009050},
}

@Article{BENATI2007milp,
  author     = {Benati, Stefano and Rizzi, Romeo},
  journal    = {European Journal of Operational Research},
  title      = {A mixed integer linear programming formulation of the optimal mean/value-at-risk portfolio problem},
  year       = {2007},
  issn       = {0377-2217},
  number     = {1},
  pages      = {423 -- 434},
  volume     = {176},
  abstract   = {In this paper, we consider an extension of the Markovitz model, in which the variance has been replaced with the Value-at-Risk. So a new portfolio optimization problem is formulated. We showed that the model leads to an NP-hard problem, but if the number of past observation T or the number of assets K are low, e.g. fixed to a constant, polynomial time algorithms exist. Furthermore, we showed that the problem can be formulated as an integer programming instance. When K and T are large and αVaR is small-as common in financial practice-the computational results show that the problem can be solved in a reasonable amount of time.},
  comment    = {solved by CPLEX},
  doi        = {https://doi.org/10.1016/j.ejor.2005.07.020},
  file       = {:FILES/2007 - BENATI2007milp - A mixed integer linear programming formulation of the optimal mean value-at-risk portfolio problem.pdf:PDF},
  groups     = {VaR, algorithms, TEC},
  keywords   = {Portfolio optimization, Complexity theory, Linear integer programming, skimmed},
  readstatus = {skimmed},
  timestamp  = {2020-09-05},
  url        = {http://www.sciencedirect.com/science/article/pii/S0377221705005813},
}

@InCollection{benjio2015error,
  author    = {Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
  booktitle = {Advances in Neural Information Processing Systems 28},
  publisher = {Curran Associates, Inc.},
  title     = {Scheduled sampling for sequence prediction with recurrent neural networks},
  year      = {2015},
  editor    = {Cortes, C. and Lawrence, N. D. and Lee, D. D. and Sugiyama, M. and Garnett, R.},
  pages     = {1171--1179},
  groups    = {Neural Network},
  timestamp = {2020-08-06},
  url       = {http://papers.nips.cc/paper/5956-scheduled-sampling-for-sequence-prediction-with-recurrent-neural-networks.pdf},
}

@ARTICLE{bergamini2005logic,
 AUTHOR = {Bergamini, Maria Lorena and Aguirre, Pio and Grossmann, Ignacio},
 JOURNAL = {Computers \& chemical engineering},
 NUMBER = {9},
 PAGES = {1914--1933},
 PUBLISHER = {Elsevier},
 TITLE = {Logic-based outer approximation for globally optimal synthesis of process networks},
 VOLUME = {29},
 YEAR = {2005}
}

@Article{Berkelaar2009loss,
  author    = {Berkelaar, Arjan and Kouwenberg, Roy},
  journal   = {Journal of Banking \& Finance},
  title     = {From boom `til bust: {How} loss aversion affects asset prices},
  year      = {2009},
  number    = {6},
  pages     = {1005--1013},
  volume    = {33},
  groups    = {asset allocation, Portfolio Selection},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{Bernard2010cpt,
  author    = {Bernard, Carole and Ghossoub, Mario},
  journal   = {Mathematics and financial economics},
  title     = {Static portfolio choice under cumulative prospect theory},
  year      = {2010},
  number    = {4},
  pages     = {277--306},
  volume    = {2},
  groups    = {prospect theory},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@InBook{Bertsekas2009,
  author    = {Bertsekas, Dimitri P.},
  editor    = {Floudas, Christodoulos A. and Pardalos, Panos M.},
  pages     = {2555--2560},
  publisher = {Springer US},
  title     = {Neuro-dynamic programmingneuro-dynamic programming},
  year      = {2009},
  address   = {Boston, MA},
  isbn      = {978-0-387-74759-0},
  abstract  = {Keywords},
  booktitle = {Encyclopedia of Optimization},
  doi       = {10.1007/978-0-387-74759-0_440},
  groups    = {RL},
  timestamp = {2020-08-06},
  url       = {https://doi.org/10.1007/978-0-387-74759-0_440},
}

@Article{Beyer2001,
  author    = {Beyer, H.-G. and Deb, K.},
  journal   = {IEEE Transactions on Evolutionary Computation},
  title     = {On self-adaptive features in real-parameter evolutionary algorithms},
  year      = {2001},
  issn      = {1941-0026},
  month     = {6},
  number    = {3},
  pages     = {250--270},
  volume    = {5},
  abstract  = {Due to the flexibility in adapting to different fitness landscapes, self-adaptive evolutionary algorithms (SA-EAs) have been gaining popularity in the recent past. In this paper, we postulate the properties that SA-EA operators should have for successful applications in real-valued search spaces. Specifically, population mean and variance of a number of SA-EA operators such as various real-parameter crossover operators and self-adaptive evolution strategies are calculated for this purpose. Simulation results are shown to verify the theoretical calculations. The postulations and population variance calculations explain why self-adaptive genetic algorithms and evolution strategies have shown similar performance in the past and also suggest appropriate strategy parameter values, which must be chosen while applying and comparing different SA-EAs.},
  date      = {June 2001},
  doi       = {10.1109/4235.930314},
  file      = {:FILES/2001 - Beyer2001 - On self-adaptive features in real-parameter evolutionary algorithms.pdf:PDF},
  groups    = {Evolutionary Algorithms},
  issue     = {3},
  keywords  = {Evolutionary computation, Genetic mutations, Genetic algorithms, Electronic switching systems, Genetic programming, Automatic testing, Helium, Government, Computer science, Laboratories},
  publisher = {IEEE},
}

@Article{Beyer2002,
  author   = {Beyer, Hans-Georg and Schwefel, Hans-Paul},
  journal  = {Natural Computing},
  title    = {Evolution strategies -- a comprehensive introduction},
  year     = {2002},
  issn     = {1572-9796},
  month    = {3},
  number   = {1},
  pages    = {3--52},
  volume   = {1},
  abstract = {This article gives a comprehensive introduction into one of the main branches of evolutionary computation -- the evolution strategies (ES) the history of which dates back to the 1960s in Germany. Starting from a survey of history the philosophical background is explained in order to make understandable why ES are realized in the way they are. Basic ES algorithms and design principles for variation and selection operators as well as theoretical issues are presented, and future branches of ES research are discussed.},
  day      = {01},
  doi      = {10.1023/A:1015059928466},
  file     = {:FILES/2002 - Beyer2002 - Evolution strategies -- A comprehensive introduction.pdf:PDF},
  groups   = {Evolution Strategy},
  url      = {https://doi.org/10.1023/A:1015059928466},
}

@Article{bjork2003some,
  author    = {Bj\"{o}rk, Kaj-Mikael and Lindberg, Per Olov and Westerlund, Tapio},
  journal   = {Computers \& Chemical Engineering},
  title     = {Some convexifications in global optimization of problems containing signomial terms},
  year      = {2003},
  number    = {5},
  pages     = {669--679},
  volume    = {27},
  file      = {:FILES/2003 - bjork2003some - Some convexifications in global optimization of problems containing signomial terms.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@TechReport{bjorn2007,
  author      = {Hagstr\"{o}mer, Bj\"{o}rn and Anderson, Richard G. and Binner, Jane M. and Elger, Thomas and Nilsson, Birger},
  institution = {Federal Reserve Bank of St. Louis},
  title       = {Mean-variance vs. full-scale optimization: {Broad} evidence for the {U.K}},
  year        = {2007},
  type        = {Working Papers},
  file        = {:FILES/2007 - bjorn2007 - Mean-Variance vs. Full-Scale Optimization- Broad Evidence for the UK.pdf:PDF},
  groups      = {VaR, mean variance},
  timestamp   = {2020-09-04},
}

@Article{blanchard2019accurate,
  author    = {Blanchard, Pierre and Higham, Desmond J. and Higham, Nicholas J.},
  journal   = {arXiv preprint arXiv:1909.03469},
  title     = {Accurate computation of the log-sum-exp and softmax functions},
  year      = {2019},
  abstract  = {Evaluating the log-sum-exp function or the softmax function is a key step in many modern data science algorithms, notably in inference and classification. Because of the exponentials that these functions contain, the evaluation is prone to overflow and underflow, especially in low precision arithmetic. Software implementations commonly use alternative formulas that avoid overflow and reduce the chance of harmful underflow, employing a shift or another rewriting. Although mathematically equivalent, these variants behave differently in floating-point arithmetic. We give rounding error analyses of different evaluation algorithms and interpret the error bounds using condition numbers for the functions. We conclude, based on the analysis and numerical experiments, that the shifted formulas are of similar accuracy to the unshifted ones and that the shifted softmax formula is typically more accurate than a division-free variant.},
  file      = {:FILES/2019 - blanchard2019accurate - Accurate computation of the log-sum-exp and softmax functions.pdf:PDF},
  groups    = {LSEO},
  timestamp = {2020-08-06},
}

@Article{blau1969generalized,
  author    = {Blau, Gary E and Wilde, Douglass J},
  journal   = {The Canadian Journal of Chemical Engineering},
  title     = {Generalized polynomial programming},
  year      = {1969},
  number    = {4},
  pages     = {317--326},
  volume    = {47},
  groups    = {SGP},
  publisher = {Wiley Online Library},
  timestamp = {2020-08-06},
}

@Article{blau1971lagrangian,
  author    = {Blau, Gary E and Wilde, Douglass J},
  journal   = {AIChE Journal},
  title     = {A lagrangian algorithm for equality constrained generalized polynomial optimization},
  year      = {1971},
  number    = {1},
  pages     = {235--240},
  volume    = {17},
  groups    = {SGP},
  publisher = {Wiley Online Library},
  timestamp = {2020-08-06},
}

@Article{Bonnans1997TrustRegion,
  author    = {Bonnans, J. Fr\'{e}d\'{e}ric and Pola, Cecilia},
  journal   = {SIAM Journal on Optimization},
  title     = {A trust region interior point algorithm for linearly constrained optimization},
  year      = {1997},
  number    = {3},
  pages     = {717--731},
  volume    = {7},
  address   = {Philadelphia, PA, USA},
  groups    = {global optimization},
  keywords  = {interior points, linesearch, quadratic model, trust region},
  numpages  = {15},
  publisher = {Society for Industrial and Applied Mathematics},
  timestamp = {2020-08-06},
}

@INPROCEEDINGS{bonzanigo1982improve,
 ABSTRACT = {Some methods are proposed which try to improve the execution of FIR filter design programs based on the Remez algorithm. The number of evaluations of the Lagrange interpolation formula needed for finding the extrema of the error function can be reduced by searching for the zeros of the derivative. The derivative of the Lagrange interpolation polynomial can be computed together with the Lagrange interpolation itself with little additional effort. The precision of the evaluation of the Lagrange interpolation can be improved by utilizing all the points resulting from the Remez algorithm. A couple of other minor improvements are given, too.},
 AUTHOR = {Bonzanigo, F.},
 BOOKTITLE = {ICASSP '82. IEEE International Conference on Acoustics, Speech, and Signal Processing},
 DOI = {10.1109/ICASSP.1982.1171739},
 GROUPS = {FIR filter design},
 KEYWORDS = {Finite impulse response filter;Lagrangian functions;Interpolation;Frequency;Algorithm design and analysis;Polynomials;Central Processing Unit;Prototypes;Equations;Linear systems},
 MONTH = {5},
 PAGES = {274--277},
 TITLE = {Some improvements to the design programs for equiripple {FIR} filters},
 VOLUME = {7},
 YEAR = {1982}
}

@BOOK{Borch1974,
 AUTHOR = {Borch, Karl Henrik},
 PUBLISHER = {Lexington Books},
 TITLE = {The mathematical theory of insurance: {An} annotated selection of papers on insurance published 1960-1972},
 TYPE = {Book},
 YEAR = {1974}
}

@Book{Borch2014,
  author    = {Borch, Karl Henrik and Sandmo, Agnar and Aase, Knut Kristian},
  publisher = {Elsevier},
  title     = {Economics of insurance},
  year      = {2014},
  address   = {Amsterdam},
  volume    = {29},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
  type      = {Book},
}

@InProceedings{boser1992training,
  author    = {Boser, Bernhard E. and Guyon, Isabelle M. and Vapnik, Vladimir N.},
  booktitle = {Proceedings of the Fifth Annual Workshop on Computational Learning Theory},
  title     = {A training algorithm for optimal margin classifiers},
  year      = {1992},
  address   = {New York, NY, USA},
  pages     = {144--152},
  publisher = {ACM},
  series    = {COLT '92},
  groups    = {machine learning},
  location  = {Pittsburgh, Pennsylvania, USA},
  numpages  = {9},
  timestamp = {2020-08-06},
}

@Article{boualam2019proximal,
  author    = {Boualam, Hssaine and Roubi, Ahmed},
  journal   = {Journal of Global Optimization},
  title     = {Proximal bundle methods based on approximate subgradients for solving {Lagrangian} duals of minimax fractional programs},
  year      = {2019},
  number    = {2},
  pages     = {255--284},
  volume    = {74},
  file      = {:FILES/2019 - boualam2019proximal - Proximal bundle methods based on approximate subgradients for solving Lagrangian duals of minimax fractional programs.pdf:PDF},
  groups    = {global optimization, proximal bundle method},
  publisher = {Springer},
  timestamp = {2020-09-04},
}

@ARTICLE{Bouman1996,
 AUTHOR = {Bouman, Charles A. and Sauer, Ken},
 JOURNAL = {IEEE Transactions on Image Processing},
 NUMBER = {3},
 PAGES = {480--492},
 TITLE = {A unified approach to statistical tomography using coordinate descent optimization},
 VOLUME = {5},
 YEAR = {1996}
}

@Book{boyd2004convex,
  author    = {Boyd, Stephen P and Vandenberghe, Lieven},
  publisher = {Cambridge university press},
  title     = {Convex optimization},
  year      = {2004},
  groups    = {global optimization},
  timestamp = {2020-08-06},
}

@Article{boyd2007tutorial,
  author    = {Boyd, Stephen and Kim, Seung-Jean and Vandenberghe, Lieven and Hassibi, Arash},
  journal   = {Optimization and Engineering},
  title     = {A tutorial on geometric programming},
  year      = {2007},
  number    = {1},
  pages     = {67},
  volume    = {8},
  file      = {:FILES/2007 - boyd2007tutorial - A tutorial on geometric programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-07-16},
}

@ARTICLE{bradley1973algorithm,
 AUTHOR = {Bradley, J},
 GROUPS = {SGP},
 JOURNAL = {Institute of Industrial Research and Standards, Dublin, Ireland},
 TIMESTAMP = {2020-07-16},
 TITLE = {An algorithm for the numerical solution of prototype geometric programs},
 YEAR = {1973}
}

@Article{bradley1997clustering,
  author    = {Bradley, Paul S. and Mangasarian, Olvi L. and Street, W. Nick},
  journal   = {Advances in neural information processing systems},
  title     = {Clustering via concave minimization},
  year      = {1997},
  pages     = {368--374},
  file      = {:FILES/1997 - bradley1997clustering - Clustering via concave minimization.pdf:PDF},
  groups    = {machine learning},
  publisher = {MORGAN KAUFMANN PUBLISHERS},
  timestamp = {2020-08-06},
}

@InProceedings{bradley1998feature,
  author    = {Bradley, Paul S. and Mangasarian, Olvi L.},
  booktitle = {ICML},
  title     = {Feature selection via concave minimization and support vector machines.},
  year      = {1998},
  pages     = {82--90},
  volume    = {98},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@InProceedings{bramlette1991,
  author    = {Bramlette, Mark F.},
  booktitle = {Proceedings of the Fourth International Conference on Genetic Algorithms},
  title     = {Initialization, mutation and selection methods in genetic algorithms for function optimization},
  year      = {1991},
  pages     = {100--107},
  groups    = {genetic algorithms},
}

@Article{Breheny2011FS,
  author        = {Breheny, Patrick and Huang, Jian},
  journal       = {The annals of applied statistics},
  title         = {Coordinate descent algorithms for nonconvex penalized regression, with applications to biological feature selection},
  year          = {2011},
  number        = {1},
  pages         = {232--253},
  volume        = {5},
  date-modified = {2016-04-05 02:50:29 +0000},
  groups        = {global optimization},
  timestamp     = {2020-08-06},
}

@Article{Breiman1993,
  author    = {Breiman, L.},
  journal   = {IEEE Transactions on Information Theory},
  title     = {Hinging hyperplanes for regression, classification, and function approximation},
  year      = {1993},
  number    = {3},
  pages     = {999--1013},
  volume    = {39},
  file      = {:FILES/1993 - Breiman1993 - Hinging hyperplanes for regression, classification and function approximation.pdf:PDF},
  groups    = {identification},
  timestamp = {2020-08-06},
}

@Article{bricker1993geometric,
  author    = {Bricker, Dennis L. and Choi, Jae Chul and Rajgopal, Jayant},
  journal   = {European Journal of Operational Research},
  title     = {On geometric programming problems having negative degrees of difficulty},
  year      = {1993},
  month     = aug,
  number    = {3},
  pages     = {427--430},
  volume    = {68},
  abstract  = {The dual of a geometric programming problem with negative degree of difficulty is often infeasible. It has been suggested that such problems be solved by finding a dual ‘approximate’ solution which minimizes a measure of the infeasibility, e.g., the summed squares of the infeasibilities in the dual constraints. We point out the shortcomings in that approach, and suggest a simple technique to ensure dual feasibility, namely the addition of a constant term to the primal objective.},
  doi       = {10.1016/0377-2217(93)90199-W},
  file      = {:FILES/1993 - bricker1993geometric - On geometric programming problems having negative degrees of difficulty.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
  url       = {https://www.sciencedirect.com/science/article/abs/pii/037722179390199W},
}

@Article{brooks2011support,
  author    = {Brooks, J. Paul},
  journal   = {Operations Research},
  title     = {Support vector machines with the ramp loss and the hard margin loss},
  year      = {2011},
  number    = {2},
  pages     = {467--479},
  volume    = {59},
  groups    = {SVM},
  publisher = {INFORMS},
  timestamp = {2020-08-30},
}

@Misc{brown2014hessian,
  author    = {Brown, David E},
  title     = {The {Hessian} matrix: {Eigenvalues,} concavity, and curvature},
  year      = {2014},
  groups    = {mathematical basis},
  journal   = {BYU Idaho Department of Mathematics},
  timestamp = {2020-08-06},
}

@Article{burer2012non,
  author    = {Burer, Samuel and Letchford, Adam N.},
  journal   = {Surveys in Operations Research and Management Science},
  title     = {Non-convex mixed-integer nonlinear programming: {A} survey},
  year      = {2012},
  number    = {2},
  pages     = {97--106},
  volume    = {17},
  file      = {:FILES/2012 - burer2012non - Non-convex mixed-integer nonlinear programming- A survey.pdf:PDF},
  groups    = {MINLP},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@Article{Burlacu2019,
  author    = {Burlacu, Robert and Gei{\ss}ler, Bj\"{o}rn and Schewe, Lars},
  journal   = {Optimization Methods and Software},
  title     = {Solving mixed-integer nonlinear programmes using adaptively refined mixed-integer linear programmes},
  year      = {2019},
  pages     = {1--28},
  file      = {:FILES/2019 - Burlacu2019 - Solving mixed-integer nonlinear programmes using adaptively refined mixed-integer linear programmes.pdf:PDF},
  groups    = {MINLP},
  publisher = {Taylor \& Francis},
  timestamp = {2020-08-06},
}

@Article{byrd1994representations,
  author    = {Byrd, Richard H and Nocedal, Jorge and Schnabel, Robert B},
  journal   = {Mathematical Programming},
  title     = {Representations of quasi-newton matrices and their use in limited memory methods},
  year      = {1994},
  number    = {1-3},
  pages     = {129--156},
  volume    = {63},
  groups    = {mathematical basis},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{Byrd2003nlp,
  author     = {Byrd, Richard H. and Gould, Nicholas I. M. and Nocedal, Jorge and Waltz, Richard A.},
  journal    = {Math. Program.},
  title      = {An algorithm for nonlinear optimization using linear programming and equality constrained subproblems},
  year       = {2004},
  issn       = {0025-5610},
  month      = {5},
  number     = {1},
  pages      = {27--48},
  volume     = {100},
  address    = {Berlin, Heidelberg},
  doi        = {10.1007/s10107-003-0485-4},
  groups     = {global optimization},
  issue_date = {May 2004},
  numpages   = {22},
  publisher  = {Springer-Verlag},
  timestamp  = {2020-08-06},
  url        = {https://doi.org/10.1007/s10107-003-0485-4},
}

@Article{Byrd2016,
  author    = {Byrd, Richard H. and Hansen, Samantha L. and Nocedal, Jorge and Singer, Yoram},
  journal   = {SIAM Journal on Optimization},
  title     = {A stochastic quasi-newton method for large-scale optimization},
  year      = {2016},
  number    = {2},
  pages     = {1008--1031},
  volume    = {26},
  file      = {:FILES/2016 - Byrd2016 - A stochastic quasi-Newton method for large-scale optimization.pdf:PDF},
  groups    = {stochastic programming},
  publisher = {SIAM},
  timestamp = {2020-08-31},
}

@Article{Calafiore2020lse,
  author    = {Calafiore, G. C. and Gaubert, S. and Possieri, C.},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  title     = {Log-sum-exp neural networks and posynomial models for convex and log-log-convex data},
  year      = {2020},
  issn      = {2162-2388},
  month     = {3},
  number    = {3},
  pages     = {827--838},
  volume    = {31},
  abstract  = {In this paper, we show that a one-layer feedforward neural network with exponential activation functions in the inner layer and logarithmic activation in the output neuron is a universal approximator of convex functions. Such a network represents a family of scaled log-sum exponential functions, here named log-sum-exp ( $\mathrm {LSE}_{T}$ ). Under a suitable exponential transformation, the class of $\mathrm {LSE}_{T}$ functions maps to a family of generalized posynomials $\mathrm {GPOS}_{T}$ , which we similarly show to be universal approximators for log-log-convex functions. A key feature of an $\mathrm {LSE}_{T}$ network is that, once it is trained on data, the resulting model is convex in the variables, which makes it readily amenable to efficient design based on convex optimization. Similarly, once a $\mathrm {GPOS}_{T}$ model is trained on data, it yields a posynomial model that can be efficiently optimized with respect to its variables by using geometric programming (GP). The proposed methodology is illustrated by two numerical examples, in which, first, models are constructed from simulation data of the two physical processes (namely, the level of vibration in a vehicle suspension system, and the peak power generated by the combustion of propane), and then optimization-based design is performed on these models.},
  doi       = {10.1109/TNNLS.2019.2910417},
  file      = {:FILES/2020 - Calafiore2020lse - Log-Sum-Exp Neural Networks and Posynomial Models for Convex and Log-Log-Convex Data.pdf:PDF},
  groups    = {SGP, LSEO, structure},
  keywords  = {Data models;Biological system modeling;Convex functions;Numerical models;Context modeling;Neural networks;Transforms;Convex optimization;data-driven optimization;feedforward neural networks (FFNNs);function approximation;geometric programming (GP);surrogate models;tropical polynomials},
  timestamp = {2020-07-16},
}

@Article{Campbell2001,
  author    = {Campbell, Rachel and Huisman, Ronald and Koedijk, Kees},
  journal   = {Journal of Banking \& Finance},
  title     = {Optimal portfolio selection in a value-at-risk framework},
  year      = {2001},
  number    = {9},
  pages     = {1789--1804},
  volume    = {25},
  file      = {:FILES/2001 - Campbell2001 - Optimal portfolio selection in a value-at-risk framework.pdf:PDF},
  groups    = {VaR},
  timestamp = {2020-09-04},
}

@Article{canutescu2003cyclic,
  author    = {Canutescu, Adrian A and Dunbrack, Roland L},
  journal   = {Protein science},
  title     = {Cyclic coordinate descent: {A} robotics algorithm for protein loop closure},
  year      = {2003},
  number    = {5},
  pages     = {963--972},
  volume    = {12},
  groups    = {global optimization},
  timestamp = {2020-08-06},
}

@MastersThesis{caodaoyou2010,
  author    = {曹道友},
  school    = {安徽大学},
  title     = {基于改进遗传算法的应用研究},
  year      = {2010},
  address   = {安徽},
  groups    = {genetic algorithms},
  timestamp = {2020-08-06},
}

@Article{Caplin2001ut,
  author    = {Caplin, Andrew and Leahy, John},
  journal   = {Quarterly Journal of economics},
  title     = {Psychological expected utility theory and anticipatory feelings},
  year      = {2001},
  pages     = {55--79},
  volume    = {116},
  groups    = {utility theory},
  issue     = {1},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@ARTICLE{caratzoulas2005trigonometric,
 AUTHOR = {Caratzoulas, S and Floudas, CA},
 JOURNAL = {Journal of optimization theory and applications},
 NUMBER = {2},
 PAGES = {339--362},
 PUBLISHER = {Springer},
 TITLE = {Trigonometric convex underestimator for the base functions in fourier space},
 VOLUME = {124},
 YEAR = {2005}
}

@Article{carrizosa2013heuristic,
  author    = {Carrizosa, Emilio and Nogales-G\'{o}mez, Amaya and Romero Morales, Dolores},
  journal   = {Optimization Letters},
  title     = {Heuristic approaches for support vector machines with the ramp loss},
  year      = {2014},
  number    = {3},
  pages     = {1125--1135},
  volume    = {8},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@Article{castro2014optimality,
  author    = {Castro, Pedro M. and Grossmann, Ignacio E.},
  journal   = {Journal of Global Optimization},
  title     = {Optimality-based bound contraction with multiparametric disaggregation for the global optimization of mixed-integer bilinear problems},
  year      = {2014},
  number    = {2-3},
  pages     = {277--306},
  volume    = {59},
  file      = {:FILES/2014 - castro2014optimality - Optimality-based bound contraction with multiparametric disaggregation for the global optimization of mixed-integer bilinear problems.pdf:PDF},
  groups    = {bilinear},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{castro2015tightening,
  author    = {Castro, Pedro M.},
  journal   = {Computers \& Chemical Engineering},
  title     = {Tightening piecewise {McCormick} relaxations for bilinear problems},
  year      = {2015},
  pages     = {300--311},
  volume    = {72},
  file      = {:FILES/2015 - castro2015tightening - Tightening piecewise McCormick relaxations for bilinear problems.pdf:PDF},
  groups    = {bilinear},
  publisher = {Elsevier},
  timestamp = {2020-08-31},
}

@Article{CC01a,
  author    = {Chang, Chih-Chung and Lin, Chih-Jen},
  journal   = {ACM Transactions on Intelligent Systems and Technology},
  title     = {{libsvm}: {A} library for support vector machines},
  year      = {2011},
  note      = {Software available at \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm}},
  pages     = {27:1--27:27},
  volume    = {2},
  groups    = {SVM},
  issue     = {3},
  timestamp = {2020-08-30},
}

@Article{Cenci2006eut,
  author    = {Cenci, Marisa and Corradini, Massimiliano and Gheno, Andrea},
  journal   = {Astin Bulletin},
  title     = {Dynamic portfolio selection in a dual expected utility theory framework},
  year      = {2006},
  number    = {2},
  pages     = {505--520},
  volume    = {36},
  file      = {:FILES/2006 - Cenci2006eut - Dynamic portfolio selection in a dual expected utility theory framework.pdf:PDF},
  groups    = {utility theory},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{CenterMeishengZheng2003,
  author    = {Zheng, Meisheng and Chen, Ning and Song, Chao},
  journal   = {Machinery Design and Manufacture},
  title     = {An algorithm for determining the largest internal circle in arbitrary polygons},
  year      = {2003},
  number    = {005},
  pages     = {84--85},
  groups    = {mathematical basis},
  timestamp = {2020-08-06},
}

@Article{Cervantes2003,
  author    = {Cervantes, Ania Luss\'{o}n and Agamennoni, Osvaldo E. and Figueroa, Jos\'{e} L.},
  journal   = {Journal of Process Control},
  title     = {A nonlinear model predictive control system based on {Wiener} piecewise linear models},
  year      = {2003},
  number    = {7},
  pages     = {655--666},
  volume    = {13},
  abstract  = {In this paper a nonlinear model predictive control (NMPC) based on a Wiener model with a piecewise linear gain is presented. This approach retains all the interested properties of the classical linear model predictive control (MPC) and keeps computations easy to solve due to the canonical structure of the nonlinear gain. Some guidelines for the identification of the nominal model as well as the uncertainty bounds are discussed, and two examples that show the possibility of application of this control scheme to real life problems are presented.},
  file      = {:FILES/2003 - Cervantes2003 - A nonlinear model predictive control system based on Wiener piecewise linear models.pdf:PDF},
  groups    = {application},
  timestamp = {2020-08-06},
}

@Article{chang2008coordinate,
  author    = {Chang, Kai-Wei and Hsieh, Cho-Jui and Lin, Chih-Jen},
  journal   = {Journal of Machine Learning Research},
  title     = {Coordinate descent method for large-scale {L2}-loss linear support vector machines},
  year      = {2008},
  pages     = {1369--1398},
  volume    = {9},
  groups    = {SVM},
  numpages  = {30},
  timestamp = {2020-08-30},
}

@Article{ChangWookAhn2003,
  author    = {Ahn, Chang Wook and Ramakrishna, R. S.},
  journal   = {IEEE Transactions on Evolutionary Computation},
  title     = {Elitism-based compact genetic algorithms},
  year      = {2003},
  issn      = {1941-0026},
  month     = {8},
  number    = {4},
  pages     = {367--385},
  volume    = {7},
  abstract  = {This paper describes two elitism-based compact genetic algorithms (cGAs)-persistent elitist compact genetic algorithm (pe-cGA), and nonpersistent elitist compact genetic algorithm (ne-cGA). The aim is to design efficient cGAs by treating them as estimation of distribution algorithms (EDAs) for solving difficult optimization problems without compromising on memory and computation costs. The idea is to deal with issues connected with lack of memory by allowing a selection pressure that is high enough to offset the disruptive effect of uniform crossover. The pe-cGA finds a near optimal solution (i.e., a winner) that is maintained as long as other solutions generated from probability vectors are no better. The ne-cGA further improves the performance of the pe-cGA by avoiding strong elitism that may lead to premature convergence. It also maintains genetic diversity. This paper also proposes an analytic model for investigating convergence enhancement.},
  doi       = {10.1109/TEVC.2003.814633},
  file      = {:FILES/2003 - ChangWookAhn2003 - Elitism-based compact genetic algorithms.pdf:PDF},
  groups    = {genetic algorithms, TEC},
  keywords  = {genetic algorithms;computational complexity;elitism-based compact genetic algorithms;GA;persistent elitist compact genetic algorithm;pe-cGA;nonpersistent elitist compact genetic algorithm;ne-cGA;distribution estimation algorithms;EDA;memory costs;computation costs;uniform crossover;genetic diversity;Genetic algorithms;Equations;Electronic design automation and methodology;Computational efficiency;Genetic mutations;Algorithm design and analysis;Design optimization;Distributed computing;Cost function;Electronic switching systems},
  timestamp = {2020-09-05},
}

@Article{charles2016expected,
  author    = {Charles-Cadogan, G},
  journal   = {Journal of Mathematical Economics},
  title     = {Expected utility theory and inner and outer measures of loss aversion},
  year      = {2016},
  pages     = {10--20},
  volume    = {63},
  groups    = {utility theory},
  publisher = {Elsevier},
  timestamp = {2020-09-04},
}

@Article{charnes1954minimization,
  author    = {Charnes, Abraham and Lemke, Carlton E.},
  journal   = {Naval Research Logistics Quarterly},
  title     = {Minimization of non-linear separable convex functionals},
  year      = {1954},
  number    = {4},
  pages     = {301--312},
  volume    = {1},
  file      = {:FILES/1954 - charnes1954minimization - Minimization of non-linear separable convex functionals.pdf:PDF},
  groups    = {global optimization},
  publisher = {Wiley Online Library},
  timestamp = {2020-08-06},
}

@Article{chauhdry2012nested,
  author    = {Chauhdry, Majid H. M. and Luh, Peter B.},
  journal   = {Control Engineering Practice},
  title     = {Nested partitions for global optimization in nonlinear model predictive control},
  year      = {2012},
  number    = {9},
  pages     = {869--881},
  volume    = {20},
  file      = {:FILES/2012 - chauhdry2012nested - Nested partitions for global optimization in nonlinear model predictive control.pdf:PDF},
  groups    = {global optimization},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@InProceedings{Chebotar2017,
  author    = {Chebotar, Y. and Kalakrishnan, M. and Yahya, A. and Li, A. and Schaal, S. and Levine, S.},
  booktitle = {2017 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Path integral guided policy search},
  year      = {2017},
  month     = {5},
  pages     = {3381--3388},
  abstract  = {We present a policy search method for learning complex feedback control policies that map from high-dimensional sensory inputs to motor torques, for manipulation tasks with discontinuous contact dynamics. We build on a prior technique called guided policy search (GPS), which iteratively optimizes a set of local policies for specific instances of a task, and uses these to train a complex, high-dimensional global policy that generalizes across task instances. We extend GPS in the following ways: (1) we propose the use of a model-free local optimizer based on path integral stochastic optimal control (PI2), which enables us to learn local policies for tasks with highly discontinuous contact dynamics; and (2) we enable GPS to train on a new set of task instances in every iteration by using on-policy sampling: this increases the diversity of the instances that the policy is trained on, and is crucial for achieving good generalization. We show that these contributions enable us to learn deep neural network policies that can directly perform torque control from visual input. We validate the method on a challenging door opening task and a pick-and-place task, and we demonstrate that our approach substantially outperforms the prior LQR-based local policy optimizer on these tasks. Furthermore, we show that on-policy sampling significantly increases the generalization ability of these policies.},
  doi       = {10.1109/ICRA.2017.7989384},
  groups    = {RL},
  keywords  = {feedback;learning (artificial intelligence);manipulator dynamics;neural nets;optimal control;path planning;sampled data systems;torque control;path integral guided policy search;path integral GPS;complex feedback control policy learning;motor torques;manipulation tasks;discontinuous contact dynamics;iterative optimization;model-free local optimizer;path integral stochastic optimal control;PI2;on-policy sampling;deep neural network policy learning;torque control;door opening task;pick-and-place task;LQR-based local policy optimizer;vision-based robotic manipulation skills;Global Positioning System;Robots;Trajectory;Visualization;Training;Search methods;Stochastic processes},
  timestamp = {2020-08-06},
}

@Article{Chen2013,
  author     = {Chen, Shih-Hsin and Chen, Min-Chih and Chang, Pei-Chann and Mani, V.},
  journal    = {Applied Mathematical Modelling},
  title      = {Multiple parents crossover operators: {A} new approach removes the overlapping solutions for sequencing problems},
  year       = {2013},
  issn       = {0307-904X},
  number     = {5},
  pages      = {2737 -- 2746},
  volume     = {37},
  abstract   = {Maintaining population diversity throughout generations of Genetic Algorithms (GAs) is key to avoid premature convergence. Redundant solutions is one cause for the decreasing population diversity. To prevent the negative effect of redundant solutions, we propose a framework that is based on the multi-parents crossover (MPX) operator embedded in GAs. Because MPX generates diversified chromosomes with good solution quality, when a pair of redundant solutions is found, we would generate a new offspring by using the MPX to replace the redundant chromosome. Three schemes of MPX will be examined and will be compared against some algorithms in literature when we solve the permutation flowshop scheduling problems, which is a strong NP-Hard sequencing problem. The results indicate that our approach significantly improves the solution quality. This study is useful for researchers who are trying to avoid premature convergence of evolutionary algorithms by solving the sequencing problems.},
  doi        = {https://doi.org/10.1016/j.apm.2012.06.005},
  file       = {:FILES/2013 - Chen2013 - Multiple parents crossover operators- A new approach removes the overlapping solutions for sequencing problems.pdf:PDF},
  groups     = {genetic algorithms, TEC},
  keywords   = {Diversity, Removing redundant solutions, Multi-parents crossover operator, Flowshop scheduling problems, read},
  readstatus = {read},
  timestamp  = {2020-09-05},
  url        = {http://www.sciencedirect.com/science/article/pii/S0307904X12003617},
}

@Article{chen2016global,
  author    = {Chen, Yi and Gao, David Y.},
  journal   = {Journal of Global Optimization},
  title     = {Global solutions to nonconvex optimization of 4th-order polynomial and log-sum-exp functions},
  year      = {2016},
  number    = {3},
  pages     = {417--431},
  volume    = {64},
  file      = {:FILES/2016 - chen2016global - Global solutions to nonconvex optimization of 4th-order polynomial and log-sum-exp functions.pdf:PDF},
  groups    = {LSEO},
  publisher = {Springer},
  timestamp = {2020-08-31},
}

@Article{Chen2019ACW,
  author    = {Chen, Tianfei and Sun, Lijun},
  journal   = {Journal of Sensors},
  title     = {A connectivity weighting dv_hop localization algorithm using modified artificial bee colony optimization},
  year      = {2019},
  pages     = {1464513:1--1464513:14},
  volume    = {2019},
  groups    = {ABC},
  timestamp = {2020-08-06},
}

@Article{Chen2019fir,
  author     = {Chen, W. and Huang, M. and Lou, X.},
  journal    = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title      = {Design of sparse {FIR} filters with reduced effective length},
  year       = {2019},
  issn       = {1558-0806},
  month      = {4},
  number     = {4},
  pages      = {1496--1506},
  volume     = {66},
  abstract   = {In this paper, an exchange algorithm is proposed to design sparse linear phase finite impulse response (FIR) filters with reduced effective length. The sparse FIR filter design problem is formally an l0-norm minimization problem. This original design problem is re-formulated by encoding the filter coefficients using a binary encoding vector, which represents the locations of the zero and non-zero filter coefficients. An iterative 0-1 exchange process with proper direction control is proposed to propel the minimax approximation error toward the specified upper bound of error for sparsity maximization. The effective length is optimized with a lower priority than sparsity in the proposed algorithm. Simulation results show that the proposed algorithm is superior to the existing algorithms in terms of both sparsity and/or effective length in most cases.},
  doi        = {10.1109/TCSI.2018.2883965},
  file       = {:FILES/2019 - Chen2019fir - Design of Sparse FIR Filters With Reduced Effective Length.pdf:PDF},
  groups     = {sparse},
  keywords   = {approximation theory;FIR filters;iterative methods;minimax techniques;reduced effective length FIR filter;sparse linear phase finite impulse response filters;minimization problem;zero filter coefficients;minimax approximation error;sparsity maximization;nonzero filter coefficients;binary encoding vector;exchange algorithm;Finite impulse response filters;Approximation algorithms;Encoding;Approximation error;Minimization;Optimization;Signal processing algorithms;Finite impulse response (FIR) filter;sparse filter design;l₀-norm minimization;effective length, read},
  readstatus = {read},
}

@Article{chen2020cascaded,
  author     = {Chen, Wangqian and Huang, Mo and Ye, Wenbin and Lou, Xin},
  journal    = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title      = {Cascaded form sparse {FIR} filter design},
  year       = {2020},
  file       = {:FILES/2020 - chen2020cascaded - Cascaded Form Sparse FIR Filter Design.pdf:PDF},
  groups     = {sparse},
  keywords   = {read},
  publisher  = {IEEE},
  readstatus = {read},
}

@Book{cheney1982appr,
  author    = {Cheney, Elliott Ward},
  publisher = {AMS Chelsea Publishing},
  title     = {Introduction to approximation theory},
  year      = {2000},
  edition   = {2nd},
  groups    = {identification},
  timestamp = {2020-08-06},
}

@Article{Cheng2010,
  author   = {Cheng, Hui and Yang, Shengxiang},
  journal  = {Engineering Applications of Artificial Intelligence},
  title    = {Genetic algorithms with immigrants schemes for dynamic multicast problems in mobile ad hoc networks},
  year     = {2010},
  issn     = {0952-1976},
  note     = {Advances in metaheuristics for hard optimization: new trends and case studies},
  number   = {5},
  pages    = {806 -- 819},
  volume   = {23},
  abstract = {In this paper, the problem of dynamic quality-of-service (QoS) multicast routing in mobile ad hoc networks is investigated. Lots of interesting works have been done on multicast since it is proved to be a NP-hard problem. However, most of them consider the static network scenarios only and the multicast tree cannot adapt to the topological changes. With the advancement in communication technologies, more and more wireless mobile networks appear, e.g., mobile ad hoc networks (MANETs). In a MANET, the network topology keeps changing due to its inherent characteristics such as the node mobility and energy conservation. Therefore, an effective multicast algorithm should track the topological changes and adapt the best multicast tree to the changes accordingly. In this paper, we propose to use genetic algorithms with immigrants schemes to solve the dynamic QoS multicast problem in MANETs. MANETs are considered as target systems because they represent a new generation of wireless networks. In the construction of the dynamic network environments, two models are proposed and investigated. One is named as the general dynamics model in which the topologies are changed due to that the nodes are scheduled to sleep or wake up. The other is named as the worst dynamics model, in which the topologies are altered because some links on the current best multicast tree are removed. Extensive experiments are conducted based on both of the dynamic network models. The experimental results show that these immigrants based genetic algorithms can quickly adapt to the environmental changes (i.e., the network topology changes) and produce high quality solutions following each change.},
  doi      = {https://doi.org/10.1016/j.engappai.2010.01.021},
  file     = {:FILES/2010 - Cheng2010 - Genetic algorithms with immigrants schemes for dynamic multicast problems in mobile ad hoc networks.pdf:PDF},
  groups   = {genetic algorithms},
  keywords = {Mobile ad hoc network, Dynamic multicast, Genetic algorithm, Immigrants scheme, Dynamic optimization},
  url      = {http://www.sciencedirect.com/science/article/pii/S0952197610000394},
}

@Article{chiang2004geometric,
  author    = {Chiang, Mung and Boyd, Stephen},
  journal   = {IEEE Transactions on Information Theory},
  title     = {Geometric programming duals of channel capacity and rate distortion},
  year      = {2004},
  number    = {2},
  pages     = {245--258},
  volume    = {50},
  file      = {:FILES/2004 - chiang2004geometric - Geometric programming duals of channel capacity and rate distortion.pdf:PDF},
  groups    = {SGP},
  publisher = {IEEE},
  timestamp = {2020-07-16},
}

@Article{chiang2005geometric,
  author    = {Chiang, Mung and others},
  journal   = {Foundations and Trends{\textregistered} in Communications and Information Theory},
  title     = {Geometric programming for communication systems},
  year      = {2005},
  number    = {1--2},
  pages     = {1--154},
  volume    = {2},
  file      = {:FILES/2005 - chiang2005geometric - Geometric programming for communication systems.pdf:PDF},
  groups    = {SGP},
  publisher = {Now Publishers, Inc.},
  timestamp = {2020-07-16},
}

@ARTICLE{chiang2005power,
 AUTHOR = {Chiang, Mung and Tan, Chee Wei and Palomar, Daniel P and O\'neill, Daniel and Julian, David},
 GROUPS = {SGP},
 JOURNAL = {IEEE transactions on wireless communications},
 NUMBER = {7},
 PAGES = {2640--2651},
 PUBLISHER = {IEEE},
 TIMESTAMP = {2020-07-16},
 TITLE = {Power control by geometric programming},
 VOLUME = {6},
 YEAR = {2007}
}

@Article{Chikkula1998,
  author    = {Chikkula, Yugender and Lee, Jay H. and Ogunnaike, B. A.},
  journal   = {AIChE Journal},
  title     = {Dynamically scheduled {MPC} of nonlinear processes using hinging hyperplane models},
  year      = {1998},
  number    = {12},
  pages     = {2658--2674},
  volume    = {44},
  file      = {:FILES/1998 - Chikkula1998 - dynamically scheduled mpc of nonlinear processes using hinging hyperplane models.pdf:PDF},
  groups    = {application},
  publisher = {Wiley Subscription Services, Inc., A Wiley Company},
  timestamp = {2020-08-06},
}

@Article{choi2018contingency,
  author    = {Choi, Jongwook and Guo, Yijie and Moczulski, Marcin and Oh, Junhyuk and Wu, Neal and Norouzi, Mohammad and Lee, Honglak},
  journal   = {arXiv preprint arXiv:1811.01483},
  title     = {Contingency-aware exploration in reinforcement learning},
  year      = {2018},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@Article{chua1971efficient,
  author    = {Chua, Leon},
  journal   = {IEEE Transactions on Circuit Theory},
  title     = {Efficient computer algorithms for piecewise-linear analysis of resistive nonlinear networks},
  year      = {1971},
  number    = {1},
  pages     = {73--85},
  volume    = {18},
  file      = {:FILES/1971 - chua1971efficient - Efficient Computer Algorithms for Piecewise-Linear Analysis of Resistive Nonlinear Networks.pdf:PDF},
  groups    = {application},
  publisher = {IEEE},
  timestamp = {2020-08-06},
}

@Article{chua1977section,
  author    = {Chua, L.O. and Kang, S.M.},
  journal   = {Proceedings of the IEEE},
  title     = {Section-wise piecewise-linear functions: {Canonical} representation, properties, and applications},
  year      = {1977},
  number    = {6},
  pages     = {915--929},
  volume    = {65},
  groups    = {identification},
  publisher = {IEEE},
  timestamp = {2020-08-06},
}

@Article{Chua1988,
  author    = {Chua, L.O. and Deng, A.C.},
  journal   = {IEEE Transactions on Circuits and Systems},
  title     = {Canonical piecewise-linear representation},
  year      = {1988},
  number    = {1},
  pages     = {101--111},
  volume    = {35},
  groups    = {identification},
  timestamp = {2020-08-06},
}

@InProceedings{chua2018deep,
  author    = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  year      = {2018},
  pages     = {4754--4765},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@Article{clasen1984solution,
  author    = {Clasen, Richard J},
  journal   = {Operations Research},
  title     = {The solution of the chemical equilibrium programming problem with generalized benders decomposition},
  year      = {1984},
  number    = {1},
  pages     = {70--79},
  volume    = {32},
  groups    = {global optimization},
  publisher = {INFORMS},
  timestamp = {2020-08-06},
}

@InProceedings{clavera2018model,
  author    = {Clavera, Ignasi and Rothfuss, Jonas and Schulman, John and Fujita, Yasuhiro and Asfour, Tamim and Abbeel, Pieter},
  booktitle = {Conference on Robot Learning},
  title     = {Model-based reinforcement learning via meta-policy optimization},
  year      = {2018},
  pages     = {617--629},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@InProceedings{cleghorn2012piecewise,
  author       = {Cleghorn, Christopher Wesley and Engelbrecht, Andries P.},
  booktitle    = {International Conference on Swarm Intelligence},
  title        = {Piecewise linear approximation of n-dimensional parametric curves using particle swarms},
  year         = {2012},
  organization = {Springer},
  pages        = {292--299},
  file         = {:FILES/2012 - cleghorn2012piecewise - Piecewise linear approximation of n-dimensional parametric curves using particle swarms.pdf:PDF},
  groups       = {identification},
  timestamp    = {2020-08-06},
}

@InProceedings{Collins1991,
  author    = {Collins, Robert J. and Jefferson, David R.},
  booktitle = {PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS},
  title     = {Selection in massively parallel genetic algorithms},
  year      = {1991},
  pages     = {249--256},
  publisher = {Morgan Kaufmann},
  file      = {:FILES/1991 - Collins1991 - Selection in massively parallel genetic algorithms.pdf:PDF},
  groups    = {genetic algorithms},
  timestamp = {2020-06-13},
}

@InProceedings{collobert2006trading,
  author       = {Collobert, Ronan and Sinz, Fabian and Weston, Jason and Bottou, L\'{e}on},
  booktitle    = {Proceedings of the 23rd international conference on Machine learning},
  title        = {Trading convexity for scalability},
  year         = {2006},
  organization = {ACM},
  pages        = {201--208},
  groups       = {Portfolio Selection},
  timestamp    = {2020-09-04},
}

@Article{Conn1998discontinuous,
  author    = {Conn, Andrew R. and Mongeau, Marcel},
  journal   = {Mathematical Programming},
  title     = {Discontinuous piecewise linear optimization},
  year      = {1998},
  number    = {3},
  pages     = {315--380},
  volume    = {80},
  groups    = {optimization},
  timestamp = {2020-08-06},
}

@Book{coombs1974portfolio,
  author    = {Coombs, Clyde Hamilton},
  publisher = {University of Michigan, Department of Psychology},
  title     = {Portfolio theory and the measurement of risk},
  year      = {1974},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
}

@Article{cordella2004sub,
  author    = {Cordella, Luigi P. and Foggia, Pasquale and Sansone, Carlo and Vento, Mario},
  journal   = {IEEE transactions on pattern analysis and machine intelligence},
  title     = {A (sub)graph isomorphism algorithm for matching large graphs},
  year      = {2004},
  month     = aug,
  number    = {10},
  pages     = {1367--1372},
  volume    = {26},
  doi       = {10.1109/TPAMI.2004.75},
  file      = {:FILES/2004 - cordella2004sub - A (sub)graph isomorphism algorithm for matching large graphs.pdf:PDF},
  publisher = {IEEE},
  url       = {https://ieeexplore.ieee.org/document/1323804},
}

@Article{cortes1995support,
  author    = {Cortes, Corinna and Vapnik, Vladimir},
  journal   = {Machine Learning},
  title     = {Support-vector networks},
  year      = {1995},
  number    = {3},
  pages     = {273--297},
  volume    = {20},
  groups    = {Neural Network},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2020-08-06},
}

@INCOLLECTION{Cortes2015,
 AUTHOR = {Schulman, John and Heess, Nicolas and Weber, Theophane and Abbeel, Pieter},
 BOOKTITLE = {Advances in Neural Information Processing Systems 28},
 EDITOR = {Cortes, C. and Lawrence, N. D. and Lee, D. D. and Sugiyama, M. and Garnett, R.},
 PAGES = {3528--3536},
 PUBLISHER = {Curran Associates, Inc.},
 TITLE = {Gradient estimation using stochastic computation graphs},
 URL = {http://papers.nips.cc/paper/5899-gradient-estimation-using-stochastic-computation-graphs.pdf},
 YEAR = {2015}
}

@Article{cox1970bracketing,
  author    = {Cox, M. G.},
  journal   = {The Computer Journal},
  title     = {A bracketing technique for computing a zero of a function},
  year      = {1970},
  number    = {1},
  pages     = {101--102},
  volume    = {13},
  file      = {:FILES/1970 - cox1970bracketing - A bracketing technique for computing a zero of a function.pdf:PDF},
  groups    = {mathematical basis},
  publisher = {Oxford University Press},
  timestamp = {2020-08-06},
}

@Article{cox1971algorithm,
  author    = {Cox, Morris G.},
  journal   = {The Computer Journal},
  title     = {An algorithm for approximating convex functions by means by first degree splines},
  year      = {1971},
  number    = {3},
  pages     = {272--275},
  volume    = {14},
  file      = {:FILES/1971 - cox1971algorithm - An algorithm for approximating convex functions by means by first degree splines.pdf:PDF},
  groups    = {Approximation},
  publisher = {Oxford University Press},
  timestamp = {2020-08-06},
}

@Article{cremers2005,
  author        = {Cremers, Jan-Hein and Kritzman, Mark and Page, S\'{e}bastien},
  journal       = {Journal of Portfolio Management},
  title         = {Optimal hedge fund allocations},
  year          = {2005},
  pages         = {78--81},
  volume        = {31},
  date-modified = {2016-03-03 05:25:40 +0000},
  groups        = {Portfolio Selection},
  issue         = {3},
  timestamp     = {2020-09-04},
}

@Article{croxton2003comparison,
  author    = {Croxton, Keely L. and Gendron, Bernard and Magnanti, Thomas L.},
  journal   = {Management Science},
  title     = {A comparison of mixed-integer programming models for nonconvex piecewise linear cost minimization problems},
  year      = {2003},
  number    = {9},
  pages     = {1268--1273},
  volume    = {49},
  file      = {:FILES/2003 - croxton2003comparison - A Comparison of Mixed-Integer Programming Models for Nonconvex Piecewise Linear Cost Minimization Problems.pdf:PDF},
  groups    = {optimization},
  publisher = {INFORMS},
  timestamp = {2020-08-06},
}

@Article{croxton2003models,
  author  = {Croxton, Keely L. and Gendron, Bernard and Magnanti, Thomas L.},
  journal = {Transportation Science},
  title   = {Models and methods for merge-in-transit operations},
  year    = {2003},
  number  = {1},
  pages   = {1--22},
  volume  = {37},
  file    = {:FILES/2003 - croxton2003models - MODELS AND METHODS FOR MERGE-IN-TRANSIT OPERATIONS.pdf:PDF},
}

@Article{cryer1971solution,
  author    = {Cryer, Colin W},
  journal   = {SIAM Journal on Control},
  title     = {The solution of a quadratic programming problem using systematic overrelaxation},
  year      = {1971},
  number    = {3},
  pages     = {385--392},
  volume    = {9},
  groups    = {global optimization},
  publisher = {SIAM},
  timestamp = {2020-08-06},
}

@Article{Cui2020b,
  author    = {Cui, Haijuan and Luo, Xiaochuan and Wang, Yuan},
  journal   = {Computers \& Industrial Engineering},
  title     = {Scheduling of steelmaking-continuous casting process using deflected surrogate {Lagrangian} relaxation approach and {DC} algorithm},
  year      = {2020},
  issn      = {0360-8352},
  pages     = {106271},
  abstract  = {This paper investigates a hybrid flowshop scheduling (HFS) problem in the steelmaking continuous casting (SCC) process. Firstly, a mathematical model is built for the SCC scheduling problem. By relaxing the machine capacity constraint, the SCC scheduling problem can be transformed into a DC (difference of convex functions) programming problem, which can solved by using DC algorithm. Under some reasonable assumptions, the convergence of the DC algorithm is analyzed. Secondly, we propose an effective and efficient deflected surrogate subgradient method with global convergence to solve the Lagrangian dual (LD) problem. Thirdly, a simple heuristic method is designed to obtain a feasible scheduling. Lastly, we report some computational experiments to demonstrate the effectiveness of the proposed surrogate subgradient method by comparing with other similar surrogate subgradient methods.},
  doi       = {10.1016/j.cie.2020.106271},
  file      = {:FILES/2020 - Cui2020b - Scheduling of steelmaking-continuous casting process using deflected surrogate {Lagrangian} relaxation approach and {DC} algorithm.pdf:PDF},
  groups    = {global optimization},
  keywords  = {Lagrangian relaxation, Steelmaking continuous casting, Scheduling problem, DC programming problem, Surrogate subgradient method},
  timestamp = {2020-08-06},
  url       = {http://www.sciencedirect.com/science/article/pii/S036083522030005X},
}

@InProceedings{d2010experiments,
  author       = {{D’Ambrosio}, Claudia and Frangioni, Antonio and Liberti, Leo and Lodi, Andrea},
  booktitle    = {International Symposium on Experimental Algorithms},
  title        = {Experiments with a feasibility pump approach for nonconvex {MINLP}},
  year         = {2010},
  organization = {Springer},
  pages        = {350--360},
  file         = {:FILES/2010 - d2010experiments - Experiments with a feasibility pump approach for nonconvex MINLPs.pdf:PDF},
  groups       = {MILP},
  timestamp    = {2020-08-06},
}

@Article{DAmbrosio2010,
  author    = {D’Ambrosio, Claudia and Lodi, Andrea and Martello, Silvano},
  journal   = {Operations Research Letters},
  title     = {Piecewise linear approximation of functions of two variables in {MILP} models},
  year      = {2010},
  number    = {1},
  pages     = {39--46},
  volume    = {38},
  file      = {:FILES/2010 - DAmbrosio2010 - Piecewise linear approximation of functions of two variables in MILP models.pdf:PDF},
  groups    = {MILP, Approximation},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@InProceedings{dam2012iterative,
  author       = {Dam, Samiran and Mandal, Pradip},
  booktitle    = {2012 25th International Conference on VLSI Design},
  title        = {Iterative performance model upgradation in geometric programming based analog circuit sizing for improved design accuracy},
  year         = {2012},
  organization = {IEEE},
  pages        = {376--381},
  file         = {:FILES/2012 - dam2012iterative - Iterative performance model upgradation in geometric programming based analog circuit sizing for improved design accuracy.pdf:PDF},
  groups       = {SGP},
  timestamp    = {2020-07-16},
}

@Article{Dantzig1960,
  author    = {Dantzig, George B.},
  journal   = {Econometrica},
  title     = {On the significance of solving linear programming problems with some integer variables},
  year      = {1960},
  number    = {1},
  pages     = {30--44},
  volume    = {28},
  file      = {:FILES/1960 - Dantzig1960 - On the Significance of Solving Linear Programming Problems with Some Integer Variables.pdf:PDF},
  groups    = {MILP},
  timestamp = {2020-08-06},
}

@Book{davis1975interpolation,
  author    = {Davis, Philip J.},
  publisher = {Courier Corporation},
  title     = {Interpolation and approximation},
  year      = {1975},
  file      = {:FILES/1975 - davis1975interpolation - Interpolation and Approximation.pdf:PDF},
  groups    = {identification},
  timestamp = {2020-08-06},
}

@InProceedings{Davis1985,
  author    = {Davis, Lawrence},
  booktitle = {Proceedings of the 9th International Joint Conference on Artificial Intelligence},
  title     = {Applying adaptive algorithms to epistatic domains},
  year      = {1985},
  address   = {Los Angeles, CA, USA},
  editor    = {Joshi, Aravind K.},
  month     = aug,
  pages     = {162--164},
  publisher = {Morgan Kaufmann},
  abstract  = {John Holland has shown that when adaptive algorithms are used to search certain kinds of extremely large problem spaces, they will converge on a "good" solution fairly quickly. Such problem spaces are characterized by a low degree of epistasis. A host of classical search problems, however, are epistatic in nature. The present paper describes some new techniques for applying adaptive algorithms to epistatic domains, while retaining some of the strength of Holland's convergence proof. These techniques are described for two-dimensional bin-packing problems, and summarized for graph coloring problems. What makes these problems amenable to an adaptive approach is a two-stage evaluation procedure. Encodings of solutions are mutated and reproduced as they are in non-epistatic domains, but their evaluation is carried out after a decoding process. Using the techniques described, convergence is promoted in two ways: one of the natural mutation operators is a weaker version of Holland's crossover, and domain knowledge may be built into decoding processes so that the size of the search space is radically cut down.},
  file      = {:FILES/1985 - Davis1985 - Applying Adaptive Algorithms to Epistatic Domains.pdf:PDF},
  groups    = {genetic algorithms},
  url       = {http://ijcai.org/Proceedings/85-1/Papers/029.pdf},
}

@Article{de2007computational,
  author    = {De Giorgi, Enrico and Hens, Thorsten and Mayer, J\'{a}nos},
  journal   = {Computational Economics},
  title     = {Computational aspects of prospect theory with asset pricing applications},
  year      = {2007},
  number    = {3},
  pages     = {267--281},
  volume    = {29},
  file      = {:FILES/2007 - de2007computational - Computational Aspects of Prospect Theory with Asset Pricing Applications.pdf:PDF},
  groups    = {prospect theory, asset allocation},
  timestamp = {2020-09-04},
}

@Article{Deb1995,
  author    = {Deb, Kalyanmoy and Agrawal, Ram Bhushan},
  journal   = {Complex Systems},
  title     = {Simulated binary crossover for continuous search space},
  year      = {1995},
  number    = {2},
  volume    = {9},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/journals/compsys/DebA95.bib},
  file      = {:FILES/1995 - Deb1995 - Simulated Binary Crossover for Continuous Search Space.pdf:PDF},
  groups    = {genetic algorithms, TEC},
  timestamp = {2020-09-05},
  url       = {http://www.complex-systems.com/abstracts/v09_i02_a02.html},
}

@Article{Deb2002,
  author     = {Deb, K. and Pratap, A. and Agarwal, S. and Meyarivan, T.},
  journal    = {IEEE Transactions on Evolutionary Computation},
  title      = {A fast and elitist multiobjective genetic algorithm: {NSGA-II}},
  year       = {2002},
  issn       = {1941-0026},
  pages      = {182--197},
  volume     = {6},
  abstract   = {Multi-objective evolutionary algorithms (MOEAs) that use non-dominated sorting and sharing have been criticized mainly for: (1) their O(MN/sup 3/) computational complexity (where M is the number of objectives and N is the population size); (2) their non-elitism approach; and (3) the need to specify a sharing parameter. In this paper, we suggest a non-dominated sorting-based MOEA, called NSGA-II (Non-dominated Sorting Genetic Algorithm II), which alleviates all of the above three difficulties. Specifically, a fast non-dominated sorting approach with O(MN/sup 2/) computational complexity is presented. Also, a selection operator is presented that creates a mating pool by combining the parent and offspring populations and selecting the best N solutions (with respect to fitness and spread). Simulation results on difficult test problems show that NSGA-II is able, for most problems, to find a much better spread of solutions and better convergence near the true Pareto-optimal front compared to the Pareto-archived evolution strategy and the strength-Pareto evolutionary algorithm - two other elitist MOEAs that pay special attention to creating a diverse Pareto-optimal front. Moreover, we modify the definition of dominance in order to solve constrained multi-objective problems efficiently. Simulation results of the constrained NSGA-II on a number of test problems, including a five-objective, seven-constraint nonlinear problem, are compared with another constrained multi-objective optimizer, and the much better performance of NSGA-II is observed.},
  date       = {April 2002},
  doi        = {10.1109/4235.996017},
  file       = {:FILES/2002 - Deb2002 - A Fast and Elitist Multiobjective Genetic Algorithm- NSGA-II.pdf:PDF},
  groups     = {genetic algorithms},
  issue      = {2},
  keywords   = {Genetic algorithms, Sorting, Computational complexity, Evolutionary computation, Computational modeling, Testing, Decision making, Associate members, Diversity reception, Constraint optimization, skimmed},
  publisher  = {IEEE},
  readstatus = {skimmed},
  timestamp  = {2020-06-05},
}

@Article{Deb2002a,
  author     = {Deb, Kalyanmoy and Anand, Ashish and Joshi, Dhiraj},
  journal    = {Evolutionary Computation},
  title      = {A computationally efficient evolutionary algorithm for real-parameter optimization},
  year       = {2002},
  issn       = {1063-6560},
  month      = {12},
  number     = {4},
  pages      = {371--395},
  volume     = {10},
  abstract   = {Due to increasing interest in solving real-world optimization problems using evolutionary algorithms (EAs), researchers have recently developed a number of real-parameter genetic algorithms (GAs). In these studies, the main research effort is spent on developing an efficient recombination operator. Such recombination operators use probability distributions around the parent solutions to create an offspring. Some operators emphasize solutions at the center of mass of parents and some around the parents. In this paper, we propose a generic parent-centric recombination operator (PCX) and a steady-state, elite-preserving, scalable, and computationally fast population-alteration model (we call the G3 model). The performance of the G3 model with the PCX operator is investigated on three commonly used test problems and is compared with a number of evolutionary and classical optimization algorithms including other real-parameter GAs with the unimodal normal distribution crossover (UNDX) and the simplex crossover (SPX) operators, the correlated self-adaptive evolution strategy, the covariance matrix adaptation evolution strategy (CMA-ES), the differential evolution technique, and the quasi-Newton method. The proposed approach is found to consistently and reliably perform better than all other methods used in the study. A scale-up study with problem sizes up to 500 variables shows a polynomial computational complexity of the proposed approach. This extensive study clearly demonstrates the power of the proposed technique in tackling real-parameter optimization problems.},
  doi        = {10.1162/106365602760972767},
  file       = {:FILES/2002 - Deb2002a - A Computationally Efficient Evolutionary Algorithm for Real-Parameter Optimization.pdf:PDF},
  groups     = {Evolutionary Algorithms, TEC},
  issue      = {4},
  keywords   = {Real-parameter optimization, simulated binary crossover, self-adaptive evolution strategy, covariance matrix adaptation, differential evolution, quasi-Newton method, parent-centric recombination, scalable evolutionary algorithms, skimmed},
  publisher  = {MITP},
  readstatus = {skimmed},
  timestamp  = {2020-09-05},
}

@Article{Deep2007,
  author    = {Deep, Kusum and Thakur, Manoj},
  journal   = {Applied Mathematics and Computation},
  title     = {A new mutation operator for real coded genetic algorithms},
  year      = {2007},
  issn      = {0096-3003},
  number    = {1},
  pages     = {211 -- 230},
  volume    = {193},
  abstract  = {In this paper, a new mutation operator called power mutation (PM) is introduced for real coded genetic algorithms (RCGA). The performance of PM is compared with two other existing real coded mutation operators taken from literature namely: non-uniform mutation (NUM) and Makinen, Periaux and Toivanen mutation (MPTM). Using the various combinations of two crossovers (Laplace crossover [Kusum Deep, Manoj Thakur, A new crossover operator for real coded genetic algorithms, Applied Mathematics and Computations, accepted for publication, doi:10.1016/j.amc.2006.10.047] and Heuristic crossover [Z. Michalewicz, Genetic Algorithms+Data Structures=Evolution Programs, Springer-Verlag, New York, 1992; A.H. Wright, Genetic algorithms for real parameter optimization, in: G.J.E. Rawlins (Ed.), Foundations of Genetic Algorithms I, Morgan Kaufmann, San Mateo, 1991, pp. 205-218]) and three mutation operators (the newly defined mutation in this paper, PM, NUM and MPTM) six generational real coded GAs are compared on a set of 20 benchmark global optimization test problems. Various performance criterion are used to judge the efficiency, accuracy and reliability of all the RCGAs. The results show that the RCGA using the proposed power mutation, when used in conjunction with the earlier defined Laplace crossover, outperforms all other GAs considered in this study.},
  doi       = {https://doi.org/10.1016/j.amc.2007.03.046},
  file      = {:FILES/2007 - Deep2007 - A new mutation operator for real coded genetic algorithms.pdf:PDF},
  groups    = {genetic algorithms, TEC},
  keywords  = {Genetic algorithms, Global optimization, Real coded mutation operator},
  timestamp = {2020-09-05},
  url       = {http://www.sciencedirect.com/science/article/pii/S0096300307003918},
}

@InProceedings{degris2012ac,
  author    = {Degris, T. and Pilarski, P. M. and Sutton, R. S.},
  booktitle = {2012 American Control Conference (ACC)},
  title     = {Model-free reinforcement learning with continuous action in practice},
  year      = {2012},
  month     = {6},
  pages     = {2177--2182},
  abstract  = {Reinforcement learning methods are often considered as a potential solution to enable a robot to adapt to changes in real time to an unpredictable environment. However, with continuous action, only a few existing algorithms are practical for real-time learning. In such a setting, most effective methods have used a parameterized policy structure, often with a separate parameterized value function. The goal of this paper is to assess such actor-critic methods to form a fully specified practical algorithm. Our specific contributions include 1) developing the extension of existing incremental policy-gradient algorithms to use eligibility traces, 2) an empirical comparison of the resulting algorithms using continuous actions, 3) the evaluation of a gradient-scaling technique that can significantly improve performance. Finally, we apply our actor-critic algorithm to learn on a robotic platform with a fast sensorimotor cycle (10ms). Overall, these results constitute an important step towards practical real-time learning control with continuous action.},
  doi       = {10.1109/ACC.2012.6315022},
  groups    = {RL},
  issn      = {0743-1619},
  keywords  = {gradient methods;learning (artificial intelligence);real-time systems;robots;model-free reinforcement learning;continuous action;robot;parameterized policy structure;incremental policy-gradient algorithms;actor-critic algorithm;sensorimotor cycle;real-time learning control;Real-time systems;Vectors;Learning;Robot sensing systems;Mobile robots;Standards},
  timestamp = {2020-08-06},
}

@InProceedings{deisenroth2011pilco,
  author    = {Deisenroth, Marc and Rasmussen, Carl E},
  booktitle = {Proceedings of the 28th International Conference on machine learning (ICML-11)},
  title     = {Pilco: {A} model-based and data-efficient approach to policy search},
  year      = {2011},
  pages     = {465--472},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@Article{deisenroth2013gaussian,
  author    = {Deisenroth, M. P. and Fox, D. and Rasmussen, C. E.},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title     = {Gaussian processes for data-efficient learning in robotics and control},
  year      = {2015},
  issn      = {1939-3539},
  month     = {2},
  number    = {2},
  pages     = {408--423},
  volume    = {37},
  abstract  = {Autonomous learning has been a promising direction in control and robotics for more than a decade since data-driven learning allows to reduce the amount of engineering knowledge, which is otherwise required. However, autonomous reinforcement learning (RL) approaches typically require many interactions with the system to learn controllers, which is a practical limitation in real systems, such as robots, where many interactions can be impractical and time consuming. To address this problem, current learning approaches typically require task-specific knowledge in form of expert demonstrations, realistic simulators, pre-shaped policies, or specific knowledge about the underlying dynamics. In this paper, we follow a different approach and speed up learning by extracting more information from data. In particular, we learn a probabilistic, non-parametric Gaussian process transition model of the system. By explicitly incorporating model uncertainty into long-term planning and controller learning our approach reduces the effects of model errors, a key problem in model-based learning. Compared to state-of-the art RL our model-based policy search method achieves an unprecedented speed of learning. We demonstrate its applicability to autonomous learning in real robot and control tasks.},
  doi       = {10.1109/TPAMI.2013.218},
  groups    = {machine learning},
  keywords  = {Computational modeling;Probabilistic logic;Approximation methods;Robots;Uncertainty;Data models;Predictive models;Policy search;robotics;control;Gaussian processes;Bayesian inference;reinforcement learning},
  timestamp = {2020-08-06},
}

@ARTICLE{dembo1976set,
 AUTHOR = {Dembo, Ron S},
 GROUPS = {SGP},
 JOURNAL = {Mathematical Programming},
 NUMBER = {1},
 PAGES = {192--213},
 PUBLISHER = {Springer},
 TIMESTAMP = {2020-07-16},
 TITLE = {A set of geometric programming test problems and their solutions},
 VOLUME = {10},
 YEAR = {1976}
}

@ARTICLE{dembo1978current,
 AUTHOR = {Dembo, RS},
 GROUPS = {SGP},
 JOURNAL = {Journal of Optimization theory and Applications},
 NUMBER = {2},
 PAGES = {149--183},
 PUBLISHER = {Springer},
 TIMESTAMP = {2020-07-16},
 TITLE = {Current state of the art of algorithms and computer software for geometric programming},
 VOLUME = {26},
 YEAR = {1978}
}

@Article{dembo1978optimal,
  author    = {Dembo, Ron S and Avriel, Mordecai},
  journal   = {Mathematical Programming},
  title     = {Optimal design of a membrane separation process using signomial programming},
  year      = {1978},
  number    = {1},
  pages     = {12--25},
  volume    = {15},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{dempe2001bundle,
  author    = {Dempe, Stephan and Bard, Jonathan F},
  journal   = {Journal of Optimization Theory and Applications},
  title     = {Bundle trust-region algorithm for bilinear bilevel programming},
  year      = {2001},
  number    = {2},
  pages     = {265--288},
  volume    = {110},
  groups    = {bilinear},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@ARTICLE{dempster1995,
 ABSTRACT = {The computational complexity of VLSI digital filters using fixed point binary multiplier coefficients is normally dominated by the number of adders used in the implementation of the multipliers. It has been shown that using multiplier blocks to exploit redundancy across the coefficients results in significant reductions in complexity over methods using canonic signed-digit (CSD) representation, which in turn are less complex than standard binary representation. Three new algorithms for the design of multiplier blocks are described: an efficient modification to an existing algorithm, a new algorithm giving better results, and a hybrid of these two which trades off performance against computation time. Significant savings in filter implementation cost over existing techniques result in all three cases. For a given wordlength, it was found that a threshold set size exists above which the multiplier block is extremely likely to be optimal. In this region, design computation time is substantially reduced.<>},
 AUTHOR = {Dempster, A. G. and Macleod, M. D.},
 DOI = {10.1109/82.466647},
 GROUPS = {FIR filter design},
 ISSN = {1558-125X},
 JOURNAL = {IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing},
 KEYWORDS = {adders;multiplying circuits;FIR filters;digital filters;computational complexity;VLSI;digital arithmetic;redundancy;minimum-adder multiplier blocks;FIR digital filters;computational complexity;VLSI;fixed point binary multiplier coefficients;redundancy;computation time;filter implementation cost;threshold set size;Finite impulse response filter;Digital filters;Adders;Cost function;Computational complexity;Very large scale integration;Algorithm design and analysis;Microprocessors;Bridge circuits},
 MONTH = {9},
 NUMBER = {9},
 PAGES = {569--577},
 TITLE = {Use of minimum-adder multiplier blocks in {FIR} digital filters},
 VOLUME = {42},
 YEAR = {1995}
}

@Article{desages1996matching,
  author    = {Desages, A. C. and Colantonio, M. C. and Chen, G.},
  journal   = {Mathematical and computer modelling},
  title     = {Matching conditions for stability analysis of nonlinear feedback control systems},
  year      = {1996},
  number    = {10},
  pages     = {1--10},
  volume    = {23},
  file      = {:FILES/1996 - desages1996matching - Matching conditions for stability analysis of nonlinear feedback control systems.pdf:PDF},
  publisher = {Elsevier},
}

@Article{ding2007accelerating,
  author    = {Ding, Xiaosong and Al-Khayyal, Faiz},
  journal   = {Journal of Global Optimization},
  title     = {Accelerating convergence of cutting plane algorithms for disjoint bilinear programming},
  year      = {2007},
  number    = {3},
  pages     = {421--436},
  volume    = {38},
  groups    = {bilinear},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{Dinuzzo2011convergence,
  author    = {Dinuzzo, F.},
  journal   = {IEEE Transactions on Neural Network},
  title     = {Analysis of fixed-point and coordinate descent algorithms for regularized kernel methods},
  year      = {2011},
  number    = {10},
  pages     = {1576--87},
  volume    = {22},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@InProceedings{Doersch2015,
  author    = {Doersch, C. and Gupta, A. and Efros, A. A.},
  booktitle = {2015 IEEE International Conference on Computer Vision (ICCV)},
  title     = {Unsupervised visual representation learning by context prediction},
  year      = {2015},
  month     = {12},
  pages     = {1422--1430},
  doi       = {10.1109/ICCV.2015.167},
  groups    = {machine learning},
  issn      = {2380-7504},
  keywords  = {feature extraction;image representation;object recognition;prediction theory;unsupervised learning;unsupervised visual representation learning;context prediction;spatial context;supervisory signal;unlabeled image collection;image patches extraction;convolutional neural net;position prediction;objects recognition;feature representation;within-image context;visual similarity;unsupervised visual discovery;Pascal VOC 2011 detection dataset;ConvNet;R-CNN framework;Visualization;Context;Training;Semantics;Data mining;Predictive models;Image representation},
  timestamp = {2020-08-06},
}

@Article{Tien2020,
  author    = {Tien, {Meng-Hsuan} and {D’Souza}, Kiran},
  journal   = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  title     = {Method for controlling vibration by exploiting piecewise-linear nonlinearity in energy harvesters},
  year      = {2020},
  number    = {2233},
  pages     = {20190491},
  volume    = {476},
  abstract  = {Vibration energy is becoming a significant alternative solution for energy generation. Recently, a great deal of research has been conducted on how to harvest energy from vibration sources ranging from ocean waves to human motion to microsystems. In this paper, a theoretical model of a piecewise-linear (PWL) nonlinear vibration harvester that has potential applications in variety of fields is proposed and numerically investigated. This new technique enables automatic frequency tunability in the energy harvester by controlling the gap size in the PWL oscillator so that it is able to adapt to changes in excitations. To optimize the performance of the proposed system, a control method combining the response prediction, signal measurement and gap adjustment mechanism is proposed in this paper. This new energy harvester not only overcomes the limitation of traditional linear energy harvesters that can only provide the maximum power generation efficiency over a narrow frequency range but also improves the performance of current nonlinear energy harvesters that are not as efficient as linear energy harvesters at resonance. The proposed system is demonstrated in several case studies to illustrate its effectiveness for a number of different excitations.},
  doi       = {10.1098/rspa.2019.0491},
  eprint    = {https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.2019.0491},
  file      = {:FILES/2020 - Tien2020 - Method for controlling vibration by exploiting piecewise-linear nonlinearity in energy harvesters.pdf:PDF},
  groups    = {application},
  timestamp = {2020-08-06},
  url       = {https://royalsocietypublishing.org/doi/abs/10.1098/rspa.2019.0491},
}

@Article{Dong2020,
  author   = {Dong, Jing and Zhao, Yuxin and Liu, Chang},
  journal  = {Neural Processing Letters},
  title    = {Constrained {PSO} based center selection for {RBF} networks under concurrent fault situation},
  year     = {2020},
  issn     = {1573-773X},
  month    = {6},
  number   = {3},
  pages    = {2437--2451},
  volume   = {51},
  abstract = {In the training of radial basis function (RBF) networks, one important issue is to select RBF centers before constructing the networks. Most existing center selection methods are designed for the fault-free situation only. However, as the implementation of the networks may be perturbed by faults, these algorithms may lead to networks with degraded performance. This paper considers the center selection problem for RBF networks under the concurrent fault situation where multiplicative weight noise and open weight fault exist simultaneously. In particular, we introduce a binary label vector indicating the centers selected from training samples. Using the label vector, the fault-tolerant RBF model under the concurrent fault situation is reformulated as a constrained optimization problem, so that fault-tolerance can be considered in the procedure of center selection. To solve this constrained optimization problem, a constrained particle swarm optimization based algorithm is developed to select centers and train the network simultaneously. Simulation results show that the proposed algorithm is superior than state-of-the-art center selection algorithms.},
  day      = {01},
  doi      = {10.1007/s11063-020-10202-1},
  file     = {:FILES/2020 - Dong2020 - Constrained PSO Based Center Selection for RBF Networks Under Concurrent Fault Situation.pdf:PDF},
  groups   = {interesting articles, PSO},
  url      = {https://doi.org/10.1007/s11063-020-10202-1},
}

@Article{Dueck1992,
  author    = {Dueck, Gunter and Winker, Peter},
  journal   = {Applied Stochastic Models and Data Analysis},
  title     = {New concepts and algorithms for portfolio choice},
  year      = {1992},
  number    = {3},
  pages     = {159--178},
  volume    = {8},
  comment   = {first attempt to solve portfolio via heuristics, i.e., threshold accepting},
  groups    = {VaR, Portfolio Selection, TEC},
  keywords  = {prio2},
  priority  = {prio2},
  timestamp = {2020-09-12},
}

@Article{Duffie1997,
  author    = {Duffie, Darrell and Pan, Jun},
  journal   = {The Journal of Derivatives},
  title     = {An overview of value at risk},
  year      = {1997},
  number    = {3},
  pages     = {7--49},
  volume    = {4},
  file      = {:FILES/1997 - Duffie1997 - An overview of value at risk.pdf:PDF},
  groups    = {VaR, TEC},
  publisher = {Springer},
  timestamp = {2020-09-05},
}

@ARTICLE{duffin1962cost,
 AUTHOR = {Duffin, Ro Jo},
 GROUPS = {SGP},
 JOURNAL = {Operations Research},
 NUMBER = {5},
 PAGES = {668--675},
 PUBLISHER = {INFORMS},
 TIMESTAMP = {2020-07-16},
 TITLE = {Cost minimization problems treated by geometric means},
 VOLUME = {10},
 YEAR = {1962}
}

@ARTICLE{duffin1966duality,
 AUTHOR = {Duffin, RJ and Peterson, Elmor L},
 GROUPS = {SGP},
 JOURNAL = {SIAM Journal on Applied Mathematics},
 NUMBER = {6},
 PAGES = {1307--1349},
 PUBLISHER = {SIAM},
 TIMESTAMP = {2020-07-16},
 TITLE = {Duality theory for geometric programming},
 VOLUME = {14},
 YEAR = {1966}
}

@ARTICLE{duffin1970linearizing,
 AUTHOR = {Duffin, Richard James},
 GROUPS = {SGP},
 JOURNAL = {SIAM review},
 NUMBER = {2},
 PAGES = {211--227},
 PUBLISHER = {SIAM},
 TIMESTAMP = {2020-07-16},
 TITLE = {Linearizing geometric programs},
 VOLUME = {12},
 YEAR = {1970}
}

@ARTICLE{duffin1972reversed,
 AUTHOR = {Duffin, Richard James and Peterson, Elmor L},
 GROUPS = {SGP},
 JOURNAL = {Indiana University Mathematics Journal},
 NUMBER = {6},
 PAGES = {531--550},
 PUBLISHER = {JSTOR},
 TIMESTAMP = {2020-07-16},
 TITLE = {Reversed geometric programs treated by harmonic means},
 VOLUME = {22},
 YEAR = {1972}
}

@ARTICLE{duffin1973geometric,
 AUTHOR = {Duffin, Richard James and Peterson, Elmor L},
 GROUPS = {SGP},
 JOURNAL = {Journal of Optimization Theory and Applications},
 NUMBER = {1},
 PAGES = {3--35},
 PUBLISHER = {Springer},
 TIMESTAMP = {2020-07-16},
 TITLE = {Geometric programming with signomials},
 VOLUME = {11},
 YEAR = {1973}
}

@Article{dyer1988,
  author    = {Dyer, M. E. and Frieze, A. M.},
  journal   = {SIAM Journal on Computing},
  title     = {On the complexity of computing the volume of a polyhedron},
  year      = {1988},
  number    = {5},
  pages     = {967--974},
  volume    = {17},
  doi       = {10.1137/0217060},
  eprint    = {https://doi.org/10.1137/0217060},
  groups    = {mathematical basis},
  timestamp = {2020-08-06},
  url       = {https://doi.org/10.1137/0217060},
}

@ARTICLE{ecker1980geometric,
 AUTHOR = {Ecker, Joseph G},
 GROUPS = {SGP},
 JOURNAL = {SIAM review},
 NUMBER = {3},
 PAGES = {338--362},
 PUBLISHER = {SIAM},
 TIMESTAMP = {2020-07-16},
 TITLE = {Geometric programming: {Methods,} computations and applications},
 VOLUME = {22},
 YEAR = {1980}
}

@ARTICLE{edwards1962,
 AUTHOR = {Edwards, Ward},
 ISSUE = {2},
 JOURNAL = {Psychological Review},
 TITLE = {Subjective probabilities inferred from decisions},
 VOLUME = {69},
 YEAR = {1962}
}

@Article{effati2015efficient,
  author    = {Effati, Sohrab and Mansoori, Amin and Eshaghnezhad, Mohammad},
  journal   = {Neurocomputing},
  title     = {An efficient projection neural network for solving bilinear programming problems},
  year      = {2015},
  pages     = {1188--1197},
  volume    = {168},
  file      = {:FILES/2015 - effati2015efficient - An efficient projection neural network for solving bilinear programming problems.pdf:PDF},
  groups    = {bilinear, Neural Network},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@InProceedings{Eiben1995,
  author    = {Eiben, A. E. and Kemenade, C. H. M. and Kok, J. N.},
  booktitle = {Advances in Artificial Life},
  title     = {Orgy in the computer: {Multi-parent} reproduction in genetic algorithms},
  year      = {1995},
  address   = {Berlin, Heidelberg},
  editor    = {Mor\'{a}n, Federico and Moreno, Alvaro and Merelo, Juan Juli\'{a}n and Chac\'{o}n, Pablo},
  pages     = {934--945},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {In this paper we investigate the phenomenon of multi-parent reproduction, i.e. we study recombination mechanisms where an arbitrary n>1 number of parents participate in creating children. In particular, we discuss scanning crossover that generalizes the standard uniform crossover and diagonal crossover that generalizes 1-point crossover, and study the effects of different number of parents on the GA behavior. We conduct experiments on tough function optimization problems and observe that by multi-parent operators the performance of GAs can be enhanced significantly. We also give a theoretical foundation by showing how these operators work on distributions.},
  file      = {:FILES/1995 - Eiben1995 - Orgy in the computer- multi-parent reproduction in genetic algorithms.pdf:PDF},
  groups    = {genetic algorithms},
  isbn      = {978-3-540-49286-3},
}

@InProceedings{Eiben1996,
  author    = {Eiben, A. E. and Schippers, C. A.},
  booktitle = {Parallel Problem Solving from Nature -- PPSN IV},
  title     = {Multi-parent's niche: {N-ary} crossovers on {nk-landscapes}},
  year      = {1996},
  address   = {Berlin, Heidelberg},
  editor    = {Voigt, Hans-Michael and Ebeling, Werner and Rechenberg, Ingo and Schwefel, Hans-Paul},
  pages     = {319--328},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Using the multi-parent diagonal and scanning crossover in GAs reproduction operators obtain an adjustable arity. Hereby sexuality becomes a graded feature instead of a Boolean one. Our main objective is to relate the performance of GAs to the extent of sexuality used for reproduction on less arbitrary functions then those reported in the current literature. We investigate GA behaviour on Kauffman's NK-landscapes that allow for systematic characterization and user control of ruggedness of the fitness landscape. We test GAs with a varying extent of sexuality, ranging from asexual to 'very sexual'. Our tests were performed on two types of NK-landscapes: landscapes with random and landscapes with nearest neighbour epistasis. For both landscape types we selected landscapes from a range of ruggednesses. The results confirm the superiority of (very) sexual recombination on mildly epistatic problems.},
  file      = {:FILES/1996 - Eiben1996 - Multi-parent's niche- N-ary crossovers on NK-landscapes.pdf:PDF},
  groups    = {genetic algorithms},
  isbn      = {978-3-540-70668-7},
}

@Article{Eiben1997,
  author    = {Eiben, Agoston E. and B\"{a}ck, Thomas},
  journal   = {Evolutionary Computation},
  title     = {Empirical investigation of multiparent recombination operators in evolution strategies},
  year      = {1997},
  issn      = {1063-6560},
  number    = {3},
  pages     = {347--365},
  volume    = {5},
  abstract  = {An extension of evolution strategies to multiparent recombination involving a variable number of parents to create an offspring individual is proposed. The extension is experimentally evaluated on a test suite of functions differing in their modality and separability and the regular/irregular arrangement of their local optima. Multiparent diagonal crossover and uniform scanning crossover and a multiparent version of intermediary recombination are considered in the experiments. The performance of the algorithm is observed to depend on the particular combination of recombination operator and objective function. In most of the cases a significant increase in performance is observed as the number of parents increases. However, there might also be no significant impact of recombination at all, and for one of the unimodal objective functions, the performance is observed to deteriorate over the course of evolution for certain choices of the recombination operator and the number of parents. Additional experiments with a skewed initialization of the population clarify that intermediary recombination does not cause a search bias toward the origin of the coordinate system in the case of domains of variables that are symmetric around zero.},
  date      = {Sept. 1997},
  doi       = {10.1162/evco.1997.5.3.347},
  file      = {:FILES/1997 - Eiben1997 - Empirical Investigation of Multiparent Recombination Operators in Evolution Strategies.pdf:PDF},
  groups    = {Evolution Strategy},
  keywords  = {Evolution strategies, parameter optimization, multiparent recombination, skewed initialization},
  publisher = {MITP},
}

@Article{Eiben2015,
  author   = {Eiben, Agoston E. and Smith, Jim},
  journal  = {Nature},
  title    = {From evolutionary computation to the evolution of things},
  year     = {2015},
  issn     = {1476-4687},
  month    = {5},
  number   = {7553},
  pages    = {476--482},
  volume   = {521},
  abstract = {Evolution has provided a source of inspiration for algorithm designers since the birth of computers. The resulting field, evolutionary computation, has been successful in solving engineering tasks ranging in outlook from the molecular to the astronomical. Today, the field is entering a new phase as evolutionary algorithms that take place in hardware are developed, opening up new avenues towards autonomous machines that can adapt to their environment. We discuss how evolutionary computation compares with natural evolution and what its benefits are relative to other computing approaches, and we introduce the emerging area of artificial evolution in physical systems.},
  day      = {01},
  doi      = {10.1038/nature14544},
  file     = {:FILES/2015 - Eiben2015 - From evolutionary computation to evolution of things.pdf:PDF},
  groups   = {genetic algorithms},
  url      = {https://doi.org/10.1038/nature14544},
}

@InProceedings{Eiden1994,
  author    = {Eiden, A. E. and Rau\'{e}, P.E. and Ruttkay, Z.},
  booktitle = {Parallel Problem Solving from Nature -- PPSN III},
  title     = {Genetic algorithms with multi-parent recombination},
  year      = {1994},
  address   = {Berlin, Heidelberg},
  editor    = {Y., Davidor and HP., Schwefel and R, M\"{a}nner},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  volume    = {886},
  abstract  = {We investigate genetic algorithms where more than two parents are involved in the recombination operation. We introduce two multi-parent recombination mechanisms: gene scanning and diagonal crossover that generalize uniform, respecively n-point crossovers. In this paper we concentrate on the gene scanning mechanism and we perform extensive tests to observe the effect of different numbers of parents on the performance of the GA. We consider different problem types, such as numerical optimization, constrained optimization (TSP) and constraint satisfaction (graph coloring). The experiments show that 2-parent recombination is inferior on the classical DeJong functions. For the other problems the results are not conclusive, in some cases 2 parents are optimal, while in some others more parents are better.},
  file      = {:FILES/1994 - Eiden1994 - Genetic algorithms with multi-parent recombination.pdf:PDF},
  groups    = {genetic algorithms},
}

@Article{el2010cooperative,
  author    = {{El-Abd}, Mohammed and Kamel, Mohamed S.},
  journal   = {Swarm Intelligence},
  title     = {A cooperative particle swarm optimizer with migration of heterogeneous probabilistic models},
  year      = {2010},
  number    = {1},
  pages     = {57--89},
  volume    = {4},
  file      = {:FILES/2010 - el2010cooperative - A cooperative particle swarm optimizer with migration of heterogeneous probabilistic models.pdf:PDF},
  groups    = {PSO},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{elal2010alpha,
  author    = {Elal-Olivero, David},
  journal   = {Proyecciones (Antofagasta)},
  title     = {Alpha-skew-normal distribution},
  year      = {2010},
  number    = {3},
  pages     = {224--240},
  volume    = {29},
  groups    = {mathematical basis},
  publisher = {Universidad Cat{\'o}lica del Norte, Departamento de Matem{\'a}ticas},
  timestamp = {2020-08-06},
}

@Article{Elfeky2008,
  author    = {Elfeky, Ehab Z. and Sarker, Ruhul A. and Essam, Daryl L.},
  journal   = {Journal of Computer Science and Technology},
  title     = {Analyzing the simple ranking and selection process for constrained evolutionary optimization},
  year      = {2008},
  issn      = {1860-4749},
  month     = {1},
  number    = {1},
  pages     = {19--34},
  volume    = {23},
  abstract  = {Many optimization problems that involve practical applications have functional constraints, and some of these constraints are active, meaning that they prevent any solution from improving the objective function value to the one that is better than any solution lying beyond the constraint limits. Therefore, the optimal solution usually lies on the boundary of the feasible region. In order to converge faster when solving such problems, a new ranking and selection scheme is introduced which exploits this feature of constrained problems. In conjunction with selection, a new crossover method is also presented based on three parents. When comparing the results of this new algorithm with six other evolutionary based methods, using 12 benchmark problems from the literature, it shows very encouraging performance. T-tests have been applied in this research to show if there is any statistically significance differences between the algorithms. A study has also been carried out in order to show the effect of each component of the proposed algorithm.},
  day       = {01},
  doi       = {10.1007/s11390-008-9109-z},
  file      = {:FILES/2008 - Elfeky2008 - Analyzing the Simple Ranking and Selection Process for Constrained Evolutionary Optimization.pdf:PDF},
  groups    = {genetic algorithms},
  timestamp = {2020-06-14},
  url       = {https://doi.org/10.1007/s11390-008-9109-z},
}

@InProceedings{Elsayed2010,
  author     = {Elsayed, Saber M. and Sarker, Ruhul A. and Essam, Daryl L.},
  booktitle  = {Simulated Evolution and Learning. SEAL 2010. Lecture Notes in Computer Science},
  title      = {A comparative study of different variants of genetic algorithms for constrained optimization},
  year       = {2010},
  address    = {Berlin, Heidelberg},
  editor     = {al., Deb K.},
  publisher  = {Springer},
  volume     = {6457},
  abstract   = {Over the last few decades, many different variants of Genetic Algorithms (GAs) have been introduced for solving Constrained Optimization Problems (COPs). However, a comparative study of their performances is rare. In this paper, our objective is to analyze different variants of GA and compare their performances by solving the 36 CEC benchmark problems by using, a new scoring scheme introduced in this paper and, a nonparametric test procedure. The insights gain in this study will help researchers and practitioners to decide which variant to use for their problems.},
  file       = {:FILES/2010 - Elsayed2010 - A Comparative Study of Different Variants of Genetic Algorithms for Constrained Optimization .pdf:PDF},
  groups     = {genetic algorithms},
  keywords   = {read},
  readstatus = {read},
}

@Article{Elsayed2011,
  author   = {Elsayed, Saber M. and Sarker, Ruhul A. and Essam, Daryl L.},
  journal  = {Computers \& Operations Research},
  title    = {Multi-operator based evolutionary algorithms for solving constrained optimization problems},
  year     = {2011},
  issn     = {0305-0548},
  number   = {12},
  pages    = {1877 -- 1896},
  volume   = {38},
  abstract = {Over the last two decades, many sophisticated evolutionary algorithms have been introduced for solving constrained optimization problems. Due to the variability of characteristics in different COPs, no single algorithm performs consistently over a range of problems. In this paper, for a better coverage of the problem characteristics, we introduce an algorithm framework that uses multiple search operators in each generation. The appropriate mix of the search operators, for any given problem, is determined adaptively. The framework is tested by implementing two different algorithms. The performance of the algorithms is judged by solving 60 test instances taken from two constrained optimization benchmark sets from specialized literature. The first algorithm, which is a multi-operator based genetic algorithm (GA), shows a significant improvement over different versions of GA (each with a single one of these operators). The second algorithm, using differential evolution (DE), also confirms the benefit of the multi-operator algorithm by providing better and consistent solutions. The overall results demonstrated that both GA and DE based algorithms show competitive, if not better, performance as compared to the state of the art algorithms.},
  doi      = {https://doi.org/10.1016/j.cor.2011.03.003},
  file     = {:FILES/2011 - Elsayed2011 - Multi-operator based evolutionary algorithms for solving constrained optimization problems.pdf:PDF},
  groups   = {genetic algorithms, Evolutionary Algorithms},
  keywords = {Genetic algorithm, Constrained optimization, Differential evolution, Operator ensemble},
  url      = {http://www.sciencedirect.com/science/article/pii/S030505481100075X},
}

@InProceedings{Elsayed2011a,
  author          = {Elsayed, Saber M. and Sarker, Ruhul A. and Essam, Daryl L.},
  booktitle       = {2011 IEEE Congress of Evolutionary Computation (CEC)},
  title           = {{GA} with a new multi-parent crossover for constrained optimization},
  year            = {2011},
  pages           = {857--864},
  publisher       = {IEEE},
  abstract        = {Over the last two decades, many Genetic Algorithms have been introduced for solving Constrained Optimization Problems (COPs). Due to the variability of the characteristics in different COPs, none of these algorithms performs consistently over a range of problems. In this paper, we introduce a Genetic Algorithm with a new multi-parent crossover for solving a variety of COPs. The proposed algorithm also uses a randomized operator instead of mutation and maintains an archive of good solutions. The algorithm has been tested by solving the 36 test instances, introduced in the CEC2010 constrained optimization competition session. The results show that the proposed algorithm performs better than the state-of-the-art algorithms.},
  date            = {5-8 June 2011},
  doi             = {10.1109/CEC.2011.5949708},
  eventdate       = {5-8 June 2011},
  eventtitleaddon = {New Orleans, LA},
  file            = {:FILES/2011 - Elsayed2011a - GA with a new multi-parent crossover for constrained optimization .pdf:PDF},
  groups          = {genetic algorithms, TEC},
  isbn            = {978-1-4244-7833-0},
  issn            = {1089-778X},
  keywords        = {Genetic algorithms, Optimization, Algorithm design and analysis, Gaussian distribution, Equations, Robustness, Evolutionary computation, Constrained optimization, genetic algorithms, read},
  location        = {New Orleans, LA},
  readstatus      = {read},
  timestamp       = {2020-09-05},
}

@Article{Emmanuel2008sparsity,
  author    = {Cand\`{e}s, Emmanuel and Wakin, Michael and Boyd, Stephen},
  journal   = {Journal of Fourier Analysis and Applications},
  title     = {Enhancing sparsity by reweighted {L1} minimization},
  year      = {2008},
  month     = {11},
  pages     = {877--905},
  volume    = {14},
  abstract  = {It is now well understood that (1) it is possible to reconstruct sparse signals
exactly from what appear to be highly incomplete sets of linear measurements and
(2) that this can be done by constrained 1 minimization. In this paper, we study a
novel method for sparse signal recovery that in many situations outperforms 1 minimization in the sense that substantially fewer measurements are needed for exact
recovery. The algorithm consists of solving a sequence of weighted 1-minimization
problems where the weights used for the next iteration are computed from the value
of the current solution. We present a series of experiments demonstrating the remarkable performance and broad applicability of this algorithm in the areas of sparse
signal recovery, statistical estimation, error correction and image processing. Interestingly, superior gains are also achieved when our method is applied to recover signals
with assumed near-sparsity in overcomplete representations—not by reweighting the
1 norm of the coefficient sequence as is common, but by reweighting the 1 norm of
the transformed object. An immediate consequence is the possibility of highly effi-
cient data acquisition protocols by improving on a technique known as Compressive
Sensing.},
  doi       = {10.1007/s00041-008-9045-x},
  file      = {:FILES/2008 - Emmanuel2008sparsity - Enhancing Sparsity by Reweighted ℓ 1 Minimization.pdf:PDF},
  groups    = {machine learning},
  timestamp = {2020-08-31},
}

@InProceedings{Ernst1998hinging,
  author       = {Ernst, S.},
  booktitle    = {Proceedings of the 37th IEEE Conference on Decision and Control},
  title        = {Hinging hyperplane trees for approximation and identification},
  year         = {1998},
  organization = {IEEE},
  pages        = {1266--1271},
  volume       = {2},
  groups       = {identification},
  timestamp    = {2020-08-06},
}

@INCOLLECTION{Eshelman1993,
 ABSTRACT = {In this paper we introduce interval-schemata as a tool for analyzing real-coded genetic algorithms (GAs). We show how interval-schemata are analogous to Holland's symbol-schemata and provide a key to understanding the implicit parallelism of real-valued GAs. We also show how they support the intuition that real-coded GAs should have an advantage over binary coded GAs in exploiting local continuities in function optimization. On the basis of our analysis we predict some failure modes for real-coded GAs using several different crossover operators and present some experimental results that support these predictions. We also introduce a crossover operator for real-coded GAs that is able to avoid some of these failure modes.},
 AUTHOR = {Eshelman, Larry J. and Schaffer, J. David},
 BOOKTITLE = {Foundations of Genetic Algorithms},
 COMMENT = {this can not be downloaded.},
 DOI = {https://doi.org/10.1016/B978-0-08-094832-4.50018-0},
 EDITOR = {WHITLEY, L. DARRELL},
 GROUPS = {genetic algorithms},
 ISSN = {1081-6593},
 PAGES = {187 -- 202},
 PUBLISHER = {Elsevier},
 SERIES = {Foundations of Genetic Algorithms},
 TIMESTAMP = {2020-06-10},
 TITLE = {Real-coded genetic algorithms and interval-schemata},
 URL = {http://www.sciencedirect.com/science/article/pii/B9780080948324500180},
 VOLUME = {2},
 YEAR = {1993}
}

@TechReport{falk1973global,
  author      = {Falk, James E},
  institution = {GEORGE WASHINGTON UNIVersity, PROGRAM IN LOGISTICS},
  title       = {Global solutions of signomial programs},
  year        = {1973},
  groups      = {SGP},
  timestamp   = {2020-08-06},
}

@Article{falk1973linear,
  author    = {Falk, James E},
  journal   = {Mathematical Programming},
  title     = {A linear max-min problem},
  year      = {1973},
  number    = {1},
  pages     = {169--188},
  volume    = {5},
  groups    = {optimization},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{faria2011novel,
  author    = {Faria, D\'{e}bora C and Bagajewicz, Miguel J},
  journal   = {Computers \& chemical engineering},
  title     = {Novel bound contraction procedure for global optimization of bilinear {MINLP} problems with applications to water management problems},
  year      = {2011},
  number    = {3},
  pages     = {446--455},
  volume    = {35},
  groups    = {bilinear},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@Article{faria2012new,
  author    = {Faria, D\'{e}bora C and Bagajewicz, Miguel J},
  journal   = {AIChE Journal},
  title     = {A new approach for global optimization of a class of {MINLP} problems with applications to water management and pooling problems},
  year      = {2012},
  number    = {8},
  pages     = {2320--2335},
  volume    = {58},
  groups    = {MILP},
  publisher = {Wiley Online Library},
  timestamp = {2020-08-06},
}

@ARTICLE{farley2954,
 ABSTRACT = {A general discussion of ideas and definitions relating to self-organizing systems and their synthesis is given, together with remarks concerning their simulation by digital computer. Synthesis and simulation of an actual system is then described. This system, initially randomly organized within wide limits, organizes itself to perform a simple prescribed task.},
 AUTHOR = {Farley, B. and Clark, W.},
 DOI = {10.1109/TIT.1954.1057468},
 ISSN = {2168-2704},
 JOURNAL = {Transactions of the IRE Professional Group on Information Theory},
 KEYWORDS = {Computational modeling;Computer simulation;Time measurement;Laboratories;Information systems;Mechanical factors;Organizing;Transforms;TV;Contracts},
 MONTH = {9},
 NUMBER = {4},
 PAGES = {76--84},
 TITLE = {Simulation of self-organizing systems by digital computer},
 VOLUME = {4},
 YEAR = {1954}
}

@Article{Feldman1992,
  author    = {Feldman, Keith},
  journal   = {Journal of the Institute of Actuaries},
  title     = {Portfolio selection, efficient diversification of investments by {Harry M. Markowitz}},
  year      = {1992},
  number    = {1},
  pages     = {165--166},
  volume    = {119},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{Feldstein1969MV,
  author    = {Feldstein, Martin S.},
  journal   = {The Review of Economic Studies},
  title     = {Mean-variance analysis in the theory of liquidity preference and portfolio selection},
  year      = {1969},
  number    = {1},
  pages     = {5--12},
  volume    = {36},
  groups    = {mean variance},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Book{fellner1965probability,
  author    = {Fellner, William},
  publisher = {Irwin},
  title     = {Probability and profit: {A} study of economic behavior along bayesian lines},
  year      = {1965},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
}

@Article{Feng2018Design,
  author    = {Feng, Zhi Guo and Yiu, Ka Fai Cedric and Wu, Soon Yi},
  journal   = {Circuits Systems \& Signal Processing},
  title     = {Design of sparse filters by a discrete filled function technique},
  year      = {2018},
  pages     = {4279--4294},
  file      = {:FILES/2018 - Feng2018Design - Design of Sparse Filters by a Discrete Filled Function Technique.pdf:PDF},
  groups    = {sparse},
  timestamp = {2020-08-06},
  volumn    = {37},
}

@Book{Fiacco1968nonlinear,
  author    = {Fiacco, Anthony V. and Garth P, McCormick},
  publisher = {Wiley},
  title     = {Nonlinear programming: {Sequential} unconstrained minimization techniques},
  year      = {1968},
  address   = {New York, USA},
  groups    = {global optimization},
  timestamp = {2020-08-06},
}

@Article{figueroa1998use,
  author    = {Figueroa, Jos\'{e} L. and Desages, Alfredo C.},
  journal   = {Optimal Control Applications and Methods},
  title     = {Use of piecewise linear approximations for steady-state back-off analysis},
  year      = {1998},
  number    = {2},
  pages     = {93--110},
  volume    = {19},
  file      = {:FILES/1998 - figueroa1998use - Use of piecewise linear approximations for steady-state back-off analysis.pdf:PDF},
  groups    = {application},
  publisher = {Wiley Online Library},
  timestamp = {2020-08-06},
}

@Article{filip2016robust,
  author    = {Filip, Silviu-Ioan},
  journal   = {ACM Transactions on Mathematical Software (TOMS)},
  title     = {A robust and scalable implementation of the parks-mcclellan algorithm for designing {FIR} filters},
  year      = {2016},
  number    = {1},
  pages     = {1--24},
  volume    = {43},
  file      = {:FILES/2016 - filip2016robust - A robust and scalable implementation of the Parks-McClellan algorithm for designing FIR filters .pdf:PDF},
  groups    = {FIR filter design},
  publisher = {ACM New York, NY, USA},
}

@InProceedings{finn2016guided,
  author    = {Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  booktitle = {International conference on machine learning},
  title     = {Guided cost learning: {Deep} inverse optimal control via policy optimization},
  year      = {2016},
  pages     = {49--58},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@Article{fishburn1977mean,
  author    = {Fishburn, Peter C},
  journal   = {The American Economic Review},
  title     = {Mean-risk analysis with risk associated with below-target returns},
  year      = {1977},
  number    = {2},
  pages     = {116--126},
  volume    = {67},
  groups    = {Portfolio Selection},
  publisher = {JSTOR},
  timestamp = {2020-09-04},
}

@Article{fishburn1979two,
  author    = {Fishburn, Peter C. and Kochenberger, Gary A.},
  journal   = {Decision Sciences},
  title     = {Two-piece {von Neumann-Morgenstern} utility functions},
  year      = {1979},
  number    = {4},
  pages     = {503--518},
  volume    = {10},
  groups    = {utility theory},
  publisher = {Wiley Online Library},
  timestamp = {2020-09-04},
}

@Article{Florian1995,
  author        = {Florian, Michael and Chen, Yang},
  journal       = {International Transactions in Operational Research},
  title         = {A coordinate descent method for the bi-level {o--d} matrix adjustment problem},
  year          = {1995},
  number        = {2},
  pages         = {165--179},
  volume        = {2},
  date-modified = {2016-03-31 12:42:10 +0000},
  groups        = {bilevel},
  timestamp     = {2020-08-06},
}

@Article{floudas1990global,
  author    = {Floudas, Christodoulos A. and Visweswaran, V.},
  journal   = {Computers \& chemical engineering},
  title     = {A global optimization algorithm ({GOP}) for certain classes of nonconvex {NLPs}-{I}. theory},
  year      = {1990},
  number    = {12},
  pages     = {1397--1417},
  volume    = {14},
  file      = {:FILES/1990 - floudas1990global - A global optimization algorithm (GOP) for certain classes of nonconvex NLPs—I. Theory.pdf:PDF},
  groups    = {global optimization},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@Article{floudas1993primal,
  author    = {Floudas, Christodoulos A and Visweswaran, Vishy},
  journal   = {Journal of Optimization Theory and Applications},
  title     = {Primal-relaxed dual global optimization approach},
  year      = {1993},
  number    = {2},
  pages     = {187--225},
  volume    = {78},
  groups    = {global optimization},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Book{floudas1999handbook,
  author    = {Floudas, Christodoulos A and Pardalos, Panos M and Adjiman, Claire and Esposito, William R and G\"{u}m\"{u}s, Zeynep H and Harding, Stephen T and Klepeis, John L and Meyer, Clifford A and Schweiger, Carl A},
  publisher = {Springer Science \& Business Media},
  title     = {Handbook of test problems in local and global optimization},
  year      = {1999},
  volume    = {33},
  groups    = {global optimization},
  timestamp = {2020-08-06},
}

@Article{floudas2000deterministic,
  author    = {Floudas, Christodoulos A},
  journal   = {Methods and Applications},
  title     = {Deterministic global optimization: {Theory}},
  year      = {2000},
  groups    = {global optimization},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2020-08-06},
}

@Article{floudas2005global,
  author    = {Floudas, Christodoulos A. and Akrotirianakis, Ioannis G. and Caratzoulas, S. and Meyer, Clifford A. and Kallrath, Josef},
  journal   = {Computers \& Chemical Engineering},
  title     = {Global optimization in the 21st century: {Advances} and challenges},
  year      = {2005},
  number    = {6},
  pages     = {1185--1202},
  volume    = {29},
  file      = {:FILES/2005 - floudas2005global - Global optimization in the 21st century- Advances and challenges.pdf:PDF},
  groups    = {global optimization},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@Article{floudas2009review,
  author    = {Floudas, Christodoulos A. and Gounaris, Chrysanthos E.},
  journal   = {Journal of Global Optimization},
  title     = {A review of recent advances in global optimization},
  year      = {2009},
  number    = {1},
  pages     = {3--38},
  volume    = {45},
  file      = {:FILES/2009 - floudas2009review - A review of recent advances in global optimization.pdf:PDF},
  groups    = {global optimization},
  numpages  = {36},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2020-08-06},
}

@Book{fogel1966,
  author    = {Fogel, L.J. and Owens, A.J. and Walsh, M.J.},
  publisher = {Wiley},
  title     = {Artificial intelligence through simulated evolution},
  year      = {1966},
  address   = {New York},
  groups    = {Heuristics},
  timestamp = {2020-08-06},
}

@Article{Forsgren2002Interior,
  author    = {Forsgren, Anders and Gill, Philip E. and Wright, Margaret H.},
  journal   = {SIAM Review},
  title     = {Interior methods for nonlinear optimization},
  year      = {2002},
  number    = {4},
  pages     = {525--597},
  volume    = {44},
  groups    = {global optimization},
  publisher = {Society for Industrial and Applied Mathematics},
  timestamp = {2020-08-06},
}

@Article{fortunato2017noisy,
  author    = {Fortunato, Meire and Azar, Mohammad Gheshlaghi and Piot, Bilal and Menick, Jacob and Osband, Ian and Graves, Alex and Mnih, Vlad and Munos, Remi and Hassabis, Demis and Pietquin, Olivier and others},
  journal   = {arXiv preprint arXiv:1706.10295},
  title     = {Noisy networks for exploration},
  year      = {2017},
  groups    = {Neural Network},
  timestamp = {2020-08-06},
}

@Article{Fourer1985simplex,
  author    = {Fourer, Robert},
  journal   = {Mathematical Programming},
  title     = {A simplex algorithm for piecewise-linear programming {i}: {Derivation} and proof},
  year      = {1985},
  number    = {2},
  pages     = {204--233},
  volume    = {33},
  groups    = {optimization},
  timestamp = {2020-08-06},
}

@Article{Fourer1988simplex,
  author    = {Fourer, Robert},
  journal   = {Mathematical Programming},
  title     = {A simplex algorithm for piecewise-linear programming {ii}: {Finiteness,} feasibility and degeneracy},
  year      = {1988},
  number    = {1},
  pages     = {281--315},
  volume    = {41},
  groups    = {optimization},
  timestamp = {2020-08-06},
}

@Article{Fourer1992simplex,
  author    = {Fourer, Robert},
  journal   = {Mathematical Programming},
  title     = {A simplex algorithm for piecewise-linear programming {iii}: {Computational} analysis and applications},
  year      = {1992},
  number    = {1},
  pages     = {213--235},
  volume    = {53},
  groups    = {optimization},
  timestamp = {2020-08-06},
}

@Article{Fourer1992solving,
  author    = {Fourer, Robert and Marsten, Roy E.},
  journal   = {ORSA Journal on Computing},
  title     = {Solving piecewise-linear programs: {Experiments} with a simplex approach},
  year      = {1992},
  number    = {1},
  pages     = {16--31},
  volume    = {4},
  groups    = {optimization},
  timestamp = {2020-08-06},
}

@InProceedings{franccois2015discount,
  author    = {Fran\c{c}ois-Lavet, Vincent and Fonteneau, Rapha\"{e}l and Ernst, Damien},
  booktitle = {NIPS 2015 Workshop on Deep Reinforcement Learning},
  title     = {How to discount deep reinforcement learning: {Towards} new dynamic strategies},
  year      = {2015},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@ARTICLE{Frangioni2009,
 AUTHOR = {Frangioni, A. and Gentile, C. and Lacalandra, F.},
 DOI = {10.1109/TPWRS.2008.2004744},
 ISSN = {1558-0679},
 JOURNAL = {IEEE Transactions on Power Systems},
 KEYWORDS = {hydrothermal power systems;integer programming;linear programming;piecewise linear techniques;power generation dispatch;power generation scheduling;MILP formulations;unit commitment problems;hydrothermal power generation;mixed-integer nonlinear program;nonlinear objective function;piecewise-linear functions;mixed-integer linear program;valid inequalities;perspective cuts;standard piecewise linearizations;dynamic formulations;iterative approximation;Cost function;Reservoirs;Large-scale systems;Steady-state;Hydroelectric-thermal power generation;Piecewise linear techniques;Standards development;Load forecasting;Delay effects;Production;Hydrothermal unit commitment;mixed-integer linear program formulations;valid inequalities},
 MONTH = {2},
 NUMBER = {1},
 PAGES = {105--113},
 TITLE = {Tighter approximated milp formulations for unit commitment problems},
 VOLUME = {24},
 YEAR = {2009}
}

@Article{friedman1981projection,
  author    = {Friedman, Jerome H. and Stuetzle, Werner},
  journal   = {Journal of the American statistical Association},
  title     = {Projection pursuit regression},
  year      = {1981},
  number    = {376},
  pages     = {817--823},
  volume    = {76},
  file      = {:FILES/1981 - friedman1981projection - PROJECTION PURSUIT REGRESSION.pdf:PDF},
  groups    = {machine learning},
  publisher = {Taylor \& Francis Group},
  timestamp = {2020-08-06},
}

@Article{friedman1991multivariate,
  author    = {Friedman, Jerome H.},
  journal   = {The annals of statistics},
  title     = {Multivariate adaptive regression splines},
  year      = {1991},
  pages     = {1--67},
  file      = {:FILES/1991 - friedman1991multivariate - multivariate adaptive regression splines.pdf:PDF},
  groups    = {machine learning},
  publisher = {JSTOR},
  timestamp = {2020-08-06},
}

@Article{Friedman2008,
  author    = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  journal   = {Biostatistics},
  title     = {Sparse inverse covariance estimation with the graphical lasso},
  year      = {2008},
  number    = {3},
  pages     = {432--441},
  volume    = {9},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@ARTICLE{friedman2010regularization,
 AUTHOR = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Rob},
 JOURNAL = {Journal of Statistical Software},
 NUMBER = {1},
 PAGES = {1},
 PUBLISHER = {NIH Public Access},
 TITLE = {Regularization paths for generalized linear models via coordinate descent},
 VOLUME = {33},
 YEAR = {2010}
}

@InProceedings{friess1998kernel,
  author    = {Frie\ss, Thilo-Thomas and Cristianini, Nello and Campbell, Colin},
  booktitle = {Proceedings of the Fifteenth International Conference on Machine Learning},
  title     = {The kernel-adatron algorithm: {A} fast and simple learning procedure for support vector machines},
  year      = {1998},
  pages     = {188--196},
  series    = {ICML '98},
  groups    = {SVM},
  numpages  = {9},
  timestamp = {2020-08-30},
}

@Article{FU2009711,
  author    = {Fu, Yan and Zhou, Bingfeng},
  journal   = {Computer Aided Geometric Design},
  title     = {Direct sampling on surfaces for high quality remeshing},
  year      = {2009},
  issn      = {0167-8396},
  note      = {Solid and Physical Modeling 2008},
  number    = {6},
  pages     = {711 -- 723},
  volume    = {26},
  abstract  = {Isotropic point distribution is crucial in remeshing process to generate a high-quality mesh. In this paper, we present a novel algorithm of isotropic sampling on two-manifold mesh surface. Our main contribution lies in the successful generalization of a 2D fast Poisson disk sampling algorithm, which makes it able to sample directly 3D mesh surfaces, including feature edges. We adopt geodesic distance as the distance metric for sampling algorithm in 3D to better capture the geometry information. Given a density function over the surface, we derive a close analytic form of the available boundary, which makes our algorithm support efficient adaptive sampling. To further improve the isotropy of point distribution, Lloyd relaxation is performed locally to optimize the location of sampling points. The whole process guarantees that new vertices lie on the original surface. Mutual tessellation is utilized to reconstruct the connectivity of new vertices, which guarantees the fidelity and validity of topology. Experiments show that our algorithm is able to remesh an arbitrary closed manifold into a high-quality mesh with large minimal angles and small number of irregular vertices.},
  doi       = {http://eproxy2.lib.tsinghua.edu.cn:80/rwt/33/https/MSYXTLUQPJUB/10.1016/j.cagd.2009.03.007},
  groups    = {mathematical basis},
  keywords  = {Poisson-disk, Sampling, Remeshing},
  timestamp = {2020-08-06},
  url       = {http://eproxy2.lib.tsinghua.edu.cn:80/rwt/33/http/P75YPLUUMNVXK5UDMWTGT6UFMN4C6Z5QNF/science/article/pii/S0167839609000430},
}

@Article{fuduli2004dc,
  author    = {Fuduli, Antonio and Gaudioso, Manlio and Giallombardo, Giovanni},
  journal   = {Optimization Methods and Software},
  title     = {A {DC} piecewise affine model and a bundling technique in nonconvex nonsmooth minimization},
  year      = {2004},
  number    = {1},
  pages     = {89--102},
  volume    = {19},
  file      = {:FILES/2004 - fuduli2004dc - A DC piecewise affine model and a bundling technique in nonconvex nonsmooth minimization.pdf:PDF},
  groups    = {nonsmooth optimization, proximal bundle method},
  publisher = {Taylor \& Francis},
  timestamp = {2020-09-04},
}

@Article{fuduli2004minimizing,
  author    = {Fuduli, Antonio and Gaudioso, Manlio and Giallombardo, Giovanni},
  journal   = {SIAM Journal on Optimization},
  title     = {Minimizing nonconvex nonsmooth functions via cutting planes and proximity control},
  year      = {2004},
  number    = {3},
  pages     = {743--756},
  volume    = {14},
  abstract  = {We describe an extension of the classical cutting plane algorithm to tackle the unconstrained minimization of a nonconvex, not necessarily differentiable function of several variables.

The method is based on the construction of both a lower and an upper polyhedral approximation to the objective function and is related to the use of the concept of proximal trajectory.

Convergence to a stationary point is proved for weakly semismooth functions.},
  file      = {:FILES/2004 - fuduli2004minimizing - Minimizing nonconvex nonsmooth functions via cutting planes and proximity control.pdf:PDF},
  groups    = {nonsmooth optimization, proximal bundle method},
  publisher = {SIAM},
  timestamp = {2020-09-04},
}

@Article{fung2004feature,
  author    = {Fung, Glenn M. and Mangasarian, Olvi L.},
  journal   = {Computational Optimization and Applications},
  title     = {A feature selection {Newton} method for support vector machine classification},
  year      = {2004},
  number    = {2},
  pages     = {185--202},
  volume    = {28},
  groups    = {SVM},
  language  = {English},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2020-08-30},
}

@Article{Gabriel2015,
  author        = {Dulac-Arnold, Gabriel and Evans, Richard and Sunehag, Peter and Coppin, Ben},
  journal       = {CoRR},
  title         = {Reinforcement learning in large discrete action spaces},
  year          = {2015},
  volume        = {abs/1512.07679},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/Dulac-ArnoldESC15.bib},
  eprint        = {1512.07679},
  groups        = {RL},
  timestamp     = {2020-08-06},
  url           = {http://arxiv.org/abs/1512.07679},
}

@Article{Gaivoronski2005,
  author    = {Gaivoronski, Alexei A. and Pflug, Georg},
  journal   = {Journal of Risk},
  title     = {Value-at-risk in portfolio optimization: {Properties} and computational approach},
  year      = {2005},
  number    = {2},
  pages     = {1--31},
  volume    = {7},
  file      = {:FILES/2005 - Gaivoronski2005 - Value-at-risk in portfolio optimization- Properties and computational approach.pdf:PDF},
  groups    = {VaR, TEC},
  timestamp = {2020-09-05},
}

@InProceedings{gal2016improving,
  author    = {Gal, Yarin and McAllister, Rowan and Rasmussen, Carl Edward},
  booktitle = {Data-Efficient Machine Learning workshop, International Conference on Machine Learning},
  title     = {Improving {pilco} with {b}ayesian neural network dynamics models},
  year      = {2016},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@Article{gallo1977bilinear,
  author    = {Gallo, Giorgio and \"{U}lk\"{u}c\"{u}, Aydin},
  journal   = {Mathematical Programming},
  title     = {Bilinear programming: {An} exact algorithm},
  year      = {1977},
  number    = {1},
  pages     = {173--194},
  volume    = {12},
  groups    = {bilinear},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@InProceedings{gamboa2018pilco,
  author    = {Gamboa Higuera, J. C. and Meger, D. and Dudek, G.},
  booktitle = {2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Synthesizing neural network controllers with probabilistic model-based reinforcement learning},
  year      = {2018},
  month     = {10},
  pages     = {2538--2544},
  abstract  = {We present an algorithm for rapidly learning neural network policies for robotics systems. The algorithm follows the model-based reinforcement learning paradigm and improves upon existing algorithms: PILeO and a sample-based version of PILeo with neural network dynamics (Deep-PILeO). To improve convergence, we propose a model-based algorithm that uses fixed random numbers and clips gradients during optimization. We propose training a neural network dynamics model using variational dropout with truncated Log-Normal noise. These improvements enable data-efficient synthesis of complex neural network policies. We test our approach on a variety of benchmark tasks, demonstrating data-efficiency that is competitive with that of PILeO, while being able to optimize complex neural network controllers. Finally, we assess the performance of the algorithm for learning motor controllers for a six legged autonomous underwater vehicle. This demonstrates the potential of the algorithm for scaling up the dimensionality and dataset sizes, in more complex tasks.},
  doi       = {10.1109/IROS.2018.8594018},
  groups    = {RL},
  issn      = {2153-0858},
  keywords  = {learning (artificial intelligence);mobile robots;neurocontrollers;underwater vehicles;complex neural network controllers;motor controllers;probabilistic model-based reinforcement learning;robotics systems;sample-based version;Deep-PILeO;model-based algorithm;random numbers;clips gradients;neural network dynamics model;data-efficient synthesis;complex neural network policies;data-efficiency;truncated log-normal noise;Robots;Optimization;Vehicle dynamics;Task analysis;Heuristic algorithms;Neural networks;Stochastic processes},
  timestamp = {2020-08-06},
}

@InCollection{gao1998minimax,
  author    = {Gao, David Yang},
  booktitle = {Reformulation: Nonsmooth, Piecewise Smooth, Semismooth and Smoothing Methods},
  publisher = {Springer},
  title     = {Minimax and triality theory in nonsmooth variational problems},
  year      = {1998},
  pages     = {161--179},
  file      = {:FILES/1998 - gao1998minimax - Minimax and triality theory in nonsmooth variational problems.pdf:PDF},
  groups    = {nonsmooth optimization},
  timestamp = {2020-08-31},
}

@InCollection{geissler2012using,
  author    = {Gei{\ss}ler, Bj\"{o}rn and Martin, Alexander and Morsi, Antonio and Schewe, Lars},
  booktitle = {Mixed integer nonlinear programming},
  publisher = {Springer},
  title     = {Using piecewise linear functions for solving {MINLPs}},
  year      = {2012},
  pages     = {287--314},
  file      = {:FILES/2012 - geissler2012using - Using Piecewise Linear Functions for Solving MINLPs.pdf:PDF},
  groups    = {MILP, application},
  timestamp = {2020-08-06},
}

@Article{geoffrion1977objective,
  author    = {Geoffrion, Arthur M},
  journal   = {Mathematical Programming},
  title     = {Objective function approximations in mathematical programming},
  year      = {1977},
  number    = {1},
  pages     = {23--37},
  volume    = {13},
  groups    = {global optimization},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{Gerber1998UF,
  author    = {Gerber, Hans U. and Pafum, G\'{e}rard},
  journal   = {North American Actuarial Journal},
  title     = {Utility functions: {From} risk theory to finance},
  year      = {1998},
  number    = {3},
  pages     = {74--91},
  volume    = {2},
  groups    = {utility theory},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{geyer2009life,
  author    = {Geyer, Alois and Hanke, Michael and Weissensteiner, Alex},
  journal   = {Journal of Computational Finance},
  title     = {Life-cycle asset allocation and consumption using stochastic linear programming},
  year      = {2009},
  number    = {4},
  pages     = {29--50},
  volume    = {12},
  groups    = {stochastic programming},
  timestamp = {2020-08-06},
}

@Article{GhiasiShirazi2019,
  author    = {Ghiasi-Shirazi, Kamaledin},
  journal   = {Neural Processing Letters},
  title     = {Competitive cross-entropy loss: {A} study on training single-layer neural networks for solving nonlinearly separable classification problems},
  year      = {2019},
  issn      = {1573-773X},
  month     = {10},
  number    = {2},
  pages     = {1115--1122},
  volume    = {50},
  abstract  = {After Minsky and Papert (Perceptrons, MIT Press, Cambridge, 1969) showed the inability of perceptrons in solving nonlinearly separable problems, for several decades people misinterpreted it as an inherent weakness that is common to all single-layer neural networks. The introduction of the backpropagation algorithm reinforced this misinterpretation as its success in solving nonlinearly separable problems passed through the training of multilayer neural networks. Recently, Conaway and Kurtz (Neural Comput 29(3):861--866, 2017) proposed a single-layer network in which the number of output units for each class is the same as input units and showed that it could solve some nonlinearly separable problems. They used the MSE (Mean Square Error) between the input units and the output units of the actual class as the objective function for training the network. They showed that their method could solve the XOR and M{\&}S'81 problems, but it could not do any better than random guessing on the 3-bit parity problem. In this paper, we use a soft competitive approach to generalize the CE (Cross-Entropy) loss, which is a widely accepted criterion for multiclass classification, to networks that have several output units for each class, calling the resulting measure the CCE (Competitive cross-entropy) loss. In contrast to Conaway and Kurtz (2017), in our method, the number of output units for each class can be chosen arbitrarily. We show that the proposed method can successfully solve the 3-bit parity problem, in addition to the XOR and M{\&}S'81 problems. Furthermore, we perform experiments on several datasets for multiclass classification, comparing a single-layer network trained with the proposed CCE loss against LVQ, linear SVM, a single-layer network trained with the CE loss, and the method of Conaway and Kurtz (2017). The results show that the CCE loss performs remarkably better than existing algorithms for training single-layer neural networks.},
  day       = {01},
  doi       = {10.1007/s11063-018-9906-5},
  file      = {:FILES/2019 - GhiasiShirazi2019 - Competitive Cross-Entropy Loss- A Study on Training Single-Layer Neural Networks for Solving Nonlinearly Separable Classification Problems.pdf:PDF},
  groups    = {Neural Network},
  timestamp = {2020-08-31},
  url       = {https://doi.org/10.1007/s11063-018-9906-5},
}

@InProceedings{gidaris2018,
  author    = {Gidaris, Spyros and Singh, Praveer and Komodakis, Nikos},
  booktitle = {Proceedings of 6th International Conference on Learning Representations (ICLR) 2018},
  title     = {Unsupervised representation learning by predicting image rotations},
  year      = {2018},
  address   = {Vancouver, Canada},
  month     = apr,
  pages     = {1--16},
  abstract  = {Abstract : Over the last years, deep convolutional neural networks (ConvNets) have transformed the field of computer vision thanks to their unparalleled capacity to learn high level semantic image features. However, in order to successfully learn those features, they usually require massive amounts of manually labeled data, which is both expensive and impractical to scale. Therefore, unsupervised semantic feature learning, i.e., learning without requiring manual annotation effort, is of crucial importance in order to successfully harvest the vast amount of visual data that are available today. In our work we propose to learn image features by training Con-vNets to recognize the 2d rotation that is applied to the image that it gets as input. We demonstrate both qualitatively and quantitatively that this apparently simple task actually provides a very powerful supervisory signal for semantic feature learning. We exhaustively evaluate our method in various unsupervised feature learning benchmarks and we exhibit in all of them state-of-the-art performance. Specifically, our results on those benchmarks demonstrate dramatic improvements w.r.t. prior state-of-the-art approaches in unsupervised representation learning and thus significantly close the gap with supervised feature learning. For instance, in PASCAL VOC 2007 detection task our unsupervised pre-trained AlexNet model achieves the state-of-the-art (among unsupervised methods) mAP of 54.4\% that is only 2.4 points lower from the supervised case. We get similarly striking results when we transfer our unsupervised learned features on various other tasks, such as ImageNet classification, PASCAL classification, PASCAL segmentation, and CIFAR-10 classification. The code and models of our paper will be published on: \url{https://github.com/gidariss/FeatureLearningRotNet}.},
  file      = {:FILES/2018 - gidaris2018 - Unsupervised representation learning by predicting image rotations.pdf:PDF},
  groups    = {machine learning},
  timestamp = {2020-08-06},
  url       = {https://hal-enpc.archives-ouvertes.fr/hal-01864755},
}

@Article{gill1986projected,
  author    = {Gill, Philip E and Murray, Walter and Saunders, Michael A and Tomlin, John A and Wright, Margaret H},
  journal   = {Mathematical programming},
  title     = {On projected {Newton} barrier methods for linear programming and an equivalence to karmarkar's projective method},
  year      = {1986},
  number    = {2},
  pages     = {183--209},
  volume    = {36},
  groups    = {global optimization},
  timestamp = {2020-08-06},
}

@Article{gilli1993strange,
  author    = {Gilli, Marco},
  journal   = {IEEE transactions on circuits and systems. 1, Fundamental theory and applications},
  title     = {Strange attractors in delayed cellular neural networks},
  year      = {1993},
  number    = {11},
  pages     = {849--853},
  volume    = {40},
  file      = {:FILES/1993 - gilli1993strange - Strange attractors in delayed cellular neural networks.pdf:PDF},
  groups    = {Neural Network},
  publisher = {Institute of Electrical and Electronics Engineers},
  timestamp = {2020-08-06},
}

@TechReport{Gilli2000TA,
  author      = {Gilli, Manfred and K\"{e}llezi, Evis},
  institution = {International Center for Financial Asset Management and Engineering},
  title       = {A heuristic approach to portfolio optimization},
  year        = {2000},
  month       = {10},
  number      = {rp20},
  type        = {FAME Research Paper Series},
  bdsk-url-1  = {https://ideas.repec.org/p/fam/rpseri/rp20.html},
  groups      = {Portfolio Selection},
  timestamp   = {2020-09-04},
  url         = {https://ideas.repec.org/p/fam/rpseri/rp20.html},
}

@InBook{Gilli2002TA,
  author        = {Gilli, Manfred and K\"{e}llezi, Evis},
  editor        = {Pardalos, Panos M. and Tsitsiringos, Vassilis K.},
  pages         = {1--18},
  publisher     = {Springer US},
  title         = {The threshold accepting heuristic for index tracking},
  year          = {2002},
  address       = {Boston, MA},
  abstract      = {We investigate the performance of the threshold accepting heuristic for the index tracking problem. The index tracking problem consists in minimizing the tracking error between a portfolio and a benchmark. The objective is to replicate the performance of a given index upon the condition that the number of stocks allowed in the portfolio is smaller than the number of stocks in the benchmark index. Transaction costs are incurred each time that the portfolio is rebalanced.

We find the composition of a portfolio that tracks the performance of the benchmark during a given period in the past and compare it with the performance of the portfolio in a subsequent period. We report computational results in the cases where the benchmarks are market indices tracked by a small number of assets. We find that the threshold accepting heuristic is an efficient optimization technique for this problem.},
  booktitle     = {Financial engineering, e-commerce and supply chain},
  date-modified = {2016-03-03 05:28:16 +0000},
  file          = {:FILES/2002 - Gilli2002TA - The threshold accepting heuristic for index tracking.pdf:PDF},
  groups        = {VaR, TEC},
  timestamp     = {2020-09-05},
}

@InBook{Gilli2002varAndESF,
  author    = {Gilli, Manfred and K\"{e}llezi, Evis},
  editor    = {Kontoghiorghes, Erricos John and Rustem, Berc and Siokos, Stavros},
  pages     = {167--183},
  publisher = {Springer US},
  title     = {A global optimization heuristic for portfolio choice with {VaR} and expected shortfall},
  year      = {2002},
  address   = {Boston, MA},
  booktitle = {Computational methods in decision-making, economics and finance},
  file      = {:FILES/2002 - Gilli2002varAndESF - A Global Optimization Heuristic for Portfolio Choice with VaR and Expected Shortfall.pdf:PDF},
  groups    = {VaR},
  timestamp = {2020-09-04},
}

@Article{ginsberg1971semi,
  author    = {Ginsberg, Ralph B},
  journal   = {Journal of Mathematical Sociology},
  title     = {Semi-markov processes and mobility},
  year      = {1971},
  number    = {2},
  pages     = {233--262},
  volume    = {1},
  groups    = {machine learning},
  publisher = {Taylor \& Francis},
  timestamp = {2020-08-06},
}

@Article{glover1975surrogate,
  author    = {Glover, Fred},
  journal   = {Operations Research},
  title     = {Surrogate constraint duality in mathematical programming},
  year      = {1975},
  number    = {3},
  pages     = {434--451},
  volume    = {23},
  groups    = {global optimization},
  publisher = {INFORMS},
  timestamp = {2020-08-06},
}

@Article{glover1986future,
  author    = {Glover, Fred},
  journal   = {Computers \& operations research},
  title     = {Future paths for integer programming and links to artificial intelligence},
  year      = {1986},
  number    = {5},
  pages     = {533--549},
  volume    = {13},
  file      = {:FILES/1986 - glover1986future - FUTURE PATHS FOR INTEGER PROGRAMMING AND LINKS TO ARTIFICIAL INTELLIGENCE.pdf:PDF},
  groups    = {MILP},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@INPROCEEDINGS{Goldberg1985,
 ADDRESS = {USA},
 AUTHOR = {Goldberg, David E. and Lingle, Robert},
 BOOKTITLE = {Proceedings of the 1st International Conference on Genetic Algorithms},
 COMMENT = {couldn't find the paper},
 GROUPS = {genetic algorithms},
 ISBN = {0805804269},
 NUMPAGES = {6},
 PAGES = {154--159},
 PUBLISHER = {L. Erlbaum Associates Inc.},
 TITLE = {Alleles, loci, and the traveling salesman problem},
 YEAR = {1985}
}

@INPROCEEDINGS{Goldberg1987,
 ADDRESS = {USA},
 AUTHOR = {Goldberg, David E. and Richardson, Jon},
 BOOKTITLE = {Proceedings of the Second International Conference on Genetic Algorithms on Genetic Algorithms and Their Application},
 COMMENT = {not downloadable.},
 GROUPS = {genetic algorithms},
 ISBN = {0805801588},
 LOCATION = {Cambridge, Massachusetts, USA},
 NUMPAGES = {9},
 PAGES = {41--49},
 PUBLISHER = {L. Erlbaum Associates Inc.},
 TITLE = {Genetic algorithms with sharing for multimodal function optimization},
 YEAR = {1987}
}

@Article{Goldberg1988,
  author  = {Goldberg, David E. and Holland, John H.},
  journal = {Machine Learning},
  title   = {Genetic algorithms and machine learning},
  year    = {1988},
  issn    = {1573-0565},
  month   = {10},
  number  = {2},
  pages   = {95--99},
  volume  = {3},
  day     = {01},
  doi     = {10.1023/A:1022602019183},
  file    = {:FILES/1988 - Goldberg1988 - Genetic Algorithms and Machine Learning.pdf:PDF},
  groups  = {genetic algorithms, machine learning},
  url     = {https://doi.org/10.1023/A:1022602019183},
}

@Article{Goldberg1990,
  author    = {Goldberg, David E.},
  journal   = {Complex Systems},
  title     = {A note on {Boltzmann} tournament selection for genetic algorithms and population-oriented simulated annealing},
  year      = {1990},
  volume    = {4},
  file      = {:FILES/1990 - Goldberg1990 - A note on Boltzmann tournament selection for genetic algorithms and population-oriented simulated annealing.pdf:PDF},
  groups    = {genetic algorithms},
  timestamp = {2020-06-13},
}

@Book{Goldberg1989ga,
  author    = {Goldberg, David E.},
  publisher = {Addison-Wesley Longman Publishing Co., Inc.},
  title     = {Genetic algorithms in search, optimization and machine learning},
  year      = {1989},
  address   = {Boston, MA, USA},
  edition   = {1st},
  groups    = {genetic algorithms, machine learning},
}

@Article{Gomory1958cutting,
  author    = {Gomory, Ralph},
  journal   = {Bulletin of the American Mathematical Society},
  title     = {Outline of an algorithm for integer solutions to linear programs},
  year      = {1958},
  month     = {09},
  pages     = {275--278},
  volume    = {64},
  doi       = {10.1090/S0002-9904-1958-10224-4},
  groups    = {MILP},
  timestamp = {2020-08-06},
}

@Article{gondzio2012interior,
  author    = {Gondzio, Jacek},
  journal   = {European Journal of Operational Research},
  title     = {Interior point methods 25 years later},
  year      = {2012},
  month     = may,
  number    = {3},
  pages     = {587--601},
  volume    = {218},
  abstract  = {Interior point methods for optimization have been around for more than 25 years now. Their presence has shaken up the field of optimization. Interior point methods for linear and (convex) quadratic programming display several features which make them particularly attractive for very large scale optimization. Among the most impressive of them are their low-degree polynomial worst-case complexity and an unrivalled ability to deliver optimal solutions in an almost constant number of iterations which depends very little, if at all, on the problem dimension. Interior point methods are competitive when dealing with small problems of dimensions below one million constraints and variables and are beyond competition when applied to large problems of dimensions going into millions of constraints and variables.

In this survey we will discuss several issues related to interior point methods including the proof of the worst-case complexity result, the reasons for their amazingly fast practical convergence and the features responsible for their ability to solve very large problems. The ever-growing sizes of optimization problems impose new requirements on optimization methods and software. In the final part of this paper we will therefore address a redesign of interior point methods to allow them to work in a matrix-free regime and to make them well-suited to solving even larger problems.},
  doi       = {10.1016/j.ejor.2011.09.017},
  file      = {:FILES/2012 - gondzio2012interior - Interior point methods 25 years later.pdf:PDF},
  groups    = {convergence},
  timestamp = {2020-08-06},
  url       = {https://www.sciencedirect.com/science/article/pii/S0377221711008204},
}

@InProceedings{Gong2004,
  author     = {Gong, Daoxiong and Ruan, Xiaogang},
  booktitle  = {Fifth World Congress on Intelligent Control and Automation},
  title      = {A new multi-parent recombination genetic algorithm},
  year       = {2004},
  address    = {Hangzhou, China},
  month      = {6},
  pages      = {2099--2103},
  volume     = {3},
  abstract   = {This paper proposes a new Multi-parent Recombination Genetic Algorithm, which introduces a new Fitness-Weighted Crossover (FWX) and adopts a random threshold based mechanism to determine the parent-number of multi-parent recombination. FWX is the generalization of Single-point Crossover, Two-point Crossover, Multi-point Crossover, Uniform Crossover, Arithmetic Crossover and Multi-parent Occurrence Based Scanning Crossover. It endures the fitter parent a bigger influencing factor, which is used to determine the contribution of parents to their offspring. The new GA approach guarantees the validity of the offspring by the fact that FWX is a convex combination of parents. Experiment on a suit of benchmark functions validated the advantages of our approach.},
  doi        = {10.1109/WCICA.2004.1341955},
  file       = {:FILES/2004 - Gong2004 - A new Multi-parent Recombination Genetic Algorithm .pdf:PDF},
  groups     = {genetic algorithms},
  keywords   = {genetic algorithms;genetics;multiparent recombination genetic algorithm;fitness weighted crossover;random threshold based mechanism;parent number;single point crossover;two point crossover;multipoint crossover;uniform crossover;arithmetic crossover;multiparent occurrence based scanning crossover;fitter parent;benchmark functions;Biological cells;Biological system modeling;Genetic mutations;Computational biology;Organisms, read},
  readstatus = {read},
  timestamp  = {2020-06-10},
}

@Article{Gong2018,
  author    = {Gong, Chao and Xu, Chunhui and Ando, Masakazu and Xi, Xiangming},
  journal   = {Tsinghua Science and Technology},
  title     = {A new method of portfolio optimization under cumulative prospect theory},
  year      = {2018},
  issn      = {1007-0214},
  month     = {2},
  number    = {1},
  pages     = {75--86},
  volume    = {23},
  abstract  = {In this paper, the portfolio selection problem under Cumulative Prospect Theory (CPT) is investigated and a model of portfolio optimization is presented. This model is solved by coupling scenario generation techniques with a genetic algorithm. Moreover, an Adaptive Real-Coded Genetic Algorithm (ARCGA) is developed to find the optimal solution for the proposed model. Computational results show that the proposed method solves the portfolio selection model and that ARCGA is an effective and stable algorithm. We compare the portfolio choices of CPT investors based on various bootstrap techniques for scenario generation and empirically examine the effect of reference points on investment behavior.},
  author+an = {4=highlight},
  comment   = {1.696},
  doi       = {10.26599/TST.2018.9010057},
  file      = {:FILES/2018 - Gong2018 - A new method of portfolio optimization under cumulative prospect theory.pdf:PDF},
  groups    = {my paper, TEC},
  keywords  = {concave programming;genetic algorithms;investment;portfolio optimization;cumulative prospect theory;portfolio selection problem;scenario generation techniques;Real-Coded Genetic Algorithm;ARCGA;portfolio selection model;portfolio choices;CPT investors;investment behavior;Portfolios;Genetic algorithms;Investment;Optimization;Adaptation models;Computational modeling;Linear programming;portfolio choice;cumulative prospect theory;bootstrap method;adaptive real-coded genetic algorithm},
  timestamp = {2020-09-05},
}

@Article{gounaris2008convexity,
  author    = {Gounaris, C. E. and Floudas, C. A.},
  journal   = {Journal of Optimization Theory and Applications},
  title     = {Convexity of products of univariate functions and convexification transformations for geometric programming},
  year      = {2008},
  number    = {3},
  pages     = {407},
  volume    = {138},
  file      = {:FILES/2008 - gounaris2008convexity - Convexity of products of univariate functions and convexification transformations for geometric programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-07-16},
}

@Article{gounaris2008tight,
  author    = {Gounaris, Chrysanthos E. and Floudas, Christodoulos A.},
  journal   = {Journal of Global Optimization},
  title     = {Tight convex underestimators for $\mathcal{C}^2$-continuous problems: {I.} univariate functions},
  year      = {2008},
  number    = {1},
  pages     = {51--67},
  volume    = {42},
  file      = {:FILES/2008 - gounaris2008tight - Tight convex underestimators for C2 -continuous problems- I. univariate functions.pdf:PDF},
  groups    = {global optimization, identification},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{gounaris2009computational,
  author    = {Gounaris, Chrysanthos E and Misener, Ruth and Floudas, Christodoulos A},
  journal   = {Industrial \& Engineering Chemistry Research},
  title     = {Computational comparison of piecewise- linear relaxations for pooling problems},
  year      = {2009},
  number    = {12},
  pages     = {5742--5766},
  volume    = {48},
  groups    = {application},
  publisher = {ACS Publications},
  timestamp = {2020-08-06},
}

@InProceedings{greco1994new,
  author       = {Greco, L and Iwaniec, Tadeusz},
  booktitle    = {Annales de l'Institut Henri Poincare (C) Non Linear Analysis},
  title        = {New inequalities for the {Jacobian}},
  year         = {1994},
  number       = {1},
  organization = {Elsevier},
  pages        = {17--35},
  volume       = {11},
  groups       = {mathematical basis},
  timestamp    = {2020-08-06},
}

@InProceedings{Grefenstette1985,
  author    = {Grefenstette, John J. and Gopal, Rajeev and Rosmaita, Brian J. and Gucht, Dirk Van},
  booktitle = {Proceedings of the 1st International Conference on Genetic Algorithms},
  title     = {Genetic algorithms for the traveling salesman problem},
  year      = {1985},
  address   = {USA},
  pages     = {160--168},
  publisher = {L. Erlbaum Associates Inc.},
  file      = {:FILES/1985 - Grefenstette1985 - Genetic Algorithms for the Traveling Salesman Problem.pdf:PDF},
  groups    = {genetic algorithms},
  isbn      = {0805804269},
  numpages  = {9},
}

@InProceedings{Grefenstette1989,
  author    = {Grefenstette, John J. and Baker, James E.},
  booktitle = {Proceedings of the Third International Conference on Genetic Algorithms},
  title     = {How genetic algorithms work: {A} critical look at implicit parallelism},
  year      = {1989},
  address   = {San Francisco, CA, USA},
  pages     = {20--27},
  publisher = {Morgan Kaufmann Publishers Inc.},
  groups    = {genetic algorithms},
  location  = {George Mason University, USA},
  numpages  = {8},
  timestamp = {2020-06-13},
}

@Article{grishina2017prospect,
  author    = {Grishina, N. and Lucas, C. A. and Date, P.},
  journal   = {Quantitative Finance},
  title     = {Prospect theory--based portfolio optimization: {An} empirical study and analysis using intelligent algorithms},
  year      = {2017},
  number    = {3},
  pages     = {353--367},
  volume    = {17},
  groups    = {prospect theory},
  publisher = {Taylor \& Francis},
  timestamp = {2020-09-04},
}

@Article{grondman2012,
  author    = {Grondman, Ivo and Busoniu, Lucian and Lopes, Gabriel and Babuska, Robert},
  journal   = {IEEE Transactions on Systems Man and Cybernetics Part B-Cybernetics},
  title     = {A survey of actor-critic reinforcement learning: {Standard} and natural policy gradients},
  year      = {2012},
  month     = {11},
  pages     = {1291--1307},
  volume    = {42},
  doi       = {10.1109/TSMCC.2012.2218595},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@InProceedings{Gu2016,
  author    = {Gu, Lei and Xi, Xiangming and Liu, Kuangyu and Wang, Shuning},
  booktitle = {2016 12th World Congress on Intelligent Control and Automation (WCICA)},
  title     = {Cost effectiveness model and optimization of weapon system based on cost as an independent variable},
  year      = {2016},
  address   = {Guilin, China},
  month     = {6},
  pages     = {2455--2459},
  abstract  = {Cost effectiveness analysis is to select the best alternative based on the value of effectiveness, which can be obtained by the life cycle cost. Inspired by the thought of cost as an independent variable (CAIV), this paper attempts to turn the evaluation and decision problem into a programming problem. We estabilish the system effectiveness model with the logarithm method and the cost model with the logistic curve. Then according to the cost effectiveness decision-making criteria, we estabilish cost effectiveness model of the weapon system, which can be approximated by a continuous piecewise linear (CPWL) surrogate model. To solve the obtained problem, we utilize CPWL programming methods. The feasibility of model and optimization is validated by an example of cost effectiveness model of armed helicopter.},
  author+an = {2=highlight},
  doi       = {10.1109/WCICA.2016.7578503},
  file      = {:FILES/2016 - Gu2016 - Cost effectiveness model and optimization of weapon system based on cost as an independent variable.pdf:PDF},
  groups    = {my paper, Wang's Work},
  keywords  = {decision making;life cycle costing;military aircraft;optimisation;piecewise linear techniques;weapons;weapon system optimization;life cycle cost;cost as an independent variable;CAIV;decision problem;logarithm method;cost model;logistic curve;cost effectiveness decision making criteria;continuous piecewise linear surrogate model;CPWL programming method;armed helicopter cost effectiveness model;Weapons;Helicopters;Automation;Optimization;Economics;Analytical models;Programming},
}

@Article{guder1994optimal,
  author    = {G\"{u}der, Faruk and Morris, James G},
  journal   = {Mathematical programming},
  title     = {Optimal objective function approximation for separable convex quadratic programming},
  year      = {1994},
  number    = {1-3},
  pages     = {133--142},
  volume    = {67},
  groups    = {global optimization},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{guisewite1990minimum,
  author    = {Guisewite, Geoffrey M and Pardalos, Panos M},
  journal   = {Annals of Operations Research},
  title     = {Minimum concave-cost network flow problems: {Applications,} complexity, and algorithms},
  year      = {1990},
  number    = {1},
  pages     = {75--99},
  volume    = {25},
  groups    = {global optimization},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{Gulli2000,
  author    = {Gilli, M and K\"{e}llezi, E},
  journal   = {Atti del XXIV Convegno AMASES, Padenghe, Italy},
  title     = {Heuristic optimization in finance: {An} application to portfolio selection},
  year      = {2000},
  groups    = {Portfolio Selection, TEC},
  timestamp = {2020-09-05},
}

@Article{gupte2013solving,
  author    = {Gupte, Akshay and Ahmed, Shabbir and Cheon, Myun Seok and Dey, Santanu},
  journal   = {SIAM Journal on Optimization},
  title     = {Solving mixed integer bilinear problems using {MILP} formulations},
  year      = {2013},
  number    = {2},
  pages     = {721--744},
  volume    = {23},
  groups    = {MILP},
  publisher = {SIAM},
  timestamp = {2020-08-06},
}

@InProceedings{Gustafsson2007fir,
  author     = {Gustafsson, O. and DeBrunner, L. S. and DeBrunner, V. and Johansson, H.},
  booktitle  = {2007 Conference Record of the Forty-First Asilomar Conference on Signals, Systems and Computers},
  title      = {On the design of sparse half-band like {FIR} filters},
  year       = {2007},
  month      = {11},
  pages      = {1098--1102},
  abstract   = {In this work we consider the design of sparse FIR filters, i.e. filters with few non-zero multiplications. The considered filters have half-band like properties, but with slightly relaxed specifications compared with actual half-band filters. We propose a filter design technique where the number of non-zero filter coefficients is minimized. It is shown by examples that it is possible to take advantage of an increased passband ripple only to obtain a half-band like solution with fewer non-zero multiplications. Decreasing the passband edge only does not give such a direct improvement.},
  doi        = {10.1109/ACSSC.2007.4487392},
  file       = {:FILES/2007 - Gustafsson2007fir - On the design of sparse half-band like FIR filters.pdf:PDF},
  groups     = {sparse},
  issn       = {1058-6393},
  keywords   = {band-pass filters;filtering theory;FIR filters;sparse FIR filters;half-band like properties;filter design technique;passband ripple;Finite impulse response filter;Passband;Minimax techniques;Nonlinear filters;Transfer functions;Frequency response;Design engineering;Least squares methods;Chebyshev approximation;Digital signal processing, read},
  readstatus = {read},
}

@Article{Guzelis1991,
  author    = {Guzelis, C. and Goknar, I.C.},
  journal   = {IEEE Transactions on Circuits and Systems},
  title     = {A canonical representation for piecewise-affine maps and its applications to circuit analysis},
  year      = {1991},
  number    = {11},
  pages     = {1342--1354},
  volume    = {38},
  groups    = {identification},
  timestamp = {2020-08-06},
}

@InCollection{ha2018rnn,
  author    = {Ha, David and Schmidhuber, J\"{u}rgen},
  booktitle = {Advances in Neural Information Processing Systems 31},
  publisher = {Curran Associates, Inc.},
  title     = {Recurrent world models facilitate policy evolution},
  year      = {2018},
  editor    = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
  pages     = {2450--2462},
  groups    = {RL},
  timestamp = {2020-08-06},
  url       = {http://papers.nips.cc/paper/7512-recurrent-world-models-facilitate-policy-evolution.pdf},
}

@Article{haarhoff1970new,
  author    = {Haarhoff, PC and Buys, JD},
  journal   = {The Computer Journal},
  title     = {A new method for the optimization of a nonlinear function subject to nonlinear constraints},
  year      = {1970},
  number    = {2},
  pages     = {178--184},
  volume    = {13},
  groups    = {global optimization},
  publisher = {Oxford University Press},
  timestamp = {2020-08-06},
}

@Article{hafner2011reinforcement,
  author    = {Hafner, Roland and Riedmiller, Martin},
  journal   = {Machine learning},
  title     = {Reinforcement learning in feedback control},
  year      = {2011},
  number    = {1-2},
  pages     = {137--169},
  volume    = {84},
  groups    = {RL},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{Hager2020,
  author    = {Hager, William W. and Zhang, Hongchao},
  journal   = {Computational Optimization and Applications},
  title     = {Convergence rates for an inexact {ADMM} applied to separable convex optimization},
  year      = {2020},
  month     = aug,
  abstract  = {Convergence rates are established for an inexact accelerated alternating direction method of multipliers (I-ADMM) for general separable convex optimization with a linear constraint. Both ergodic and non-ergodic iterates are analyzed. Relative to the iteration number k, the convergence rate is O(1/k) in a convex setting and O(1/k2) in a strongly convex setting. When an error bound condition holds, the algorithm is 2-step linearly convergent. The I-ADMM is designed so that the accuracy of the inexact iteration preserves the global convergence rates of the exact iteration, leading to better numerical performance in the test problems.},
  doi       = {https://doi.org/10.1007/s10589-020-00221-y},
  file      = {:FILES/2018 - Hager2020 - Convergence rates for an inexact ADMM applied to separable convex optimization.pdf:PDF},
  groups    = {global optimization},
  keywords  = {Separable convex optimization,Alternating direction method of multipliers,ADMM,Accelerated gradient method,Inexact methods,Global convergence,Convergence rates},
  timestamp = {2020-08-06},
}

@Article{hansen1992new,
  author    = {Hansen, Pierre and Jaumard, Brigitte and Savard, Gilles},
  journal   = {SIAM Journal on scientific and Statistical Computing},
  title     = {New branch-and-bound rules for linear bilevel programming},
  year      = {1992},
  number    = {5},
  pages     = {1194--1217},
  volume    = {13},
  groups    = {bilevel},
  publisher = {SIAM},
  timestamp = {2020-08-06},
}

@Article{hansen1992reduction,
  author    = {Hansen, Pierre and Jaumard, Brigitte},
  journal   = {Journal of Global optimization},
  title     = {Reduction of indefinite quadratic programs to bilinear programs},
  year      = {1992},
  number    = {1},
  pages     = {41--60},
  volume    = {2},
  groups    = {bilinear},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{hasan2010piecewise,
  author    = {Hasan, M. M. Faruque and Karimi, I. A.},
  journal   = {AIChE journal},
  title     = {Piecewise linear relaxation of bilinear programs using bivariate partitioning},
  year      = {2010},
  number    = {7},
  pages     = {1880--1893},
  volume    = {56},
  file      = {:FILES/2010 - hasan2010piecewise - Piecewise linear relaxation of bilinear programs using bivariate partitioning.pdf:PDF},
  groups    = {bilinear, application},
  publisher = {Wiley Online Library},
  timestamp = {2020-08-06},
}

@Article{hassan2010pak,
  author    = {Hassan, Mohamed Y. and Hijazi, Rafiq H.},
  journal   = {Pakistan Journal of Statistics},
  title     = {A bimodal exponential power distribution},
  year      = {2010},
  number    = {2},
  pages     = {379--396},
  volume    = {26},
  file      = {:FILES/2010 - hassan2010pak - A bimodal exponential power distribution.pdf:PDF},
  groups    = {mathematical basis},
  timestamp = {2020-08-06},
}

@Article{hassan2016bimodal,
  author    = {Hassan, MY and El-Bassiouni, MY},
  journal   = {Communications in Statistics-Theory and Methods},
  title     = {Bimodal skew-symmetric normal distribution},
  year      = {2016},
  number    = {5},
  pages     = {1527--1541},
  volume    = {45},
  groups    = {mathematical basis},
  publisher = {Taylor \& Francis},
  timestamp = {2020-08-06},
}

@Article{Hasuike2015,
  author    = {Hasuike, Takashi and Katagiri, Hideki and Tsubaki, Hiroe},
  journal   = {Procedia Computer Science},
  title     = {A constructing algorithm for appropriate piecewise linear membership function based on statistics and information theory},
  year      = {2015},
  issn      = {1877-0509},
  note      = {Knowledge-Based and Intelligent Information \& Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings},
  pages     = {994 -- 1003},
  volume    = {60},
  abstract  = {This paper proposes a constructing algorithm for an appropriate membership function to integrate the fuzzy Shannon entropy with a piecewise linear function into subjective intervals estimation by the heuristic method based on the human cognitive behavior and subjectivity under a given probability density function. It is important to set a membership function appropriately in real-world decision making. The main parts of our proposed approach are to give membership values a decision maker confidently set, and to obtain the others by solving a nonlinear mathematical programming problem objectively. It is difficult to solve the initial mathematical programming problem efficiently using previous constructing approaches. In this paper, introducing some natural assumptions in the real-world and performing deterministic equivalent transformations to the initial problem using nonlinear programming, an efficient algorithm to obtain the optimal condition of each appropriate membership value is developed.},
  doi       = {10.1016/j.procs.2015.08.140},
  file      = {:FILES/2015 - Hasuike2015 - A constructing algorithm for appropriate piecewise linear membership function based on statistics and information theory.pdf:PDF},
  groups    = {identification},
  keywords  = {Membership function, Fuzzy entropy, Smoothing function, Mathematical programming},
  timestamp = {2020-08-06},
}

@InProceedings{hausknecht2015deep,
  author    = {Hausknecht, Matthew and Stone, Peter},
  booktitle = {2015 AAAI Fall Symposium Series},
  title     = {Deep recurrent {Q-learning} for partially observable mdps},
  year      = {2015},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@InProceedings{Hausknecht2016,
  author    = {Hausknecht, Matthew J. and Stone, Peter},
  booktitle = {Proceedings of 4th International Conference on Learning Representations (ICLR)},
  title     = {Deep reinforcement learning in parameterized action space},
  year      = {2016},
  editor    = {Bengio, Yoshua and LeCun, Yann},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/journals/corr/HausknechtS15a.bib},
  groups    = {RL},
  timestamp = {2020-08-06},
  url       = {http://arxiv.org/abs/1511.04143},
}

@Article{he2011portfolio,
  author    = {He, Xue Dong and Zhou, Xun Yu},
  journal   = {Management Science},
  title     = {Portfolio choice under cumulative prospect theory: {An} analytical treatment},
  year      = {2011},
  number    = {2},
  pages     = {315--331},
  volume    = {57},
  groups    = {prospect theory},
  publisher = {INFORMS},
  timestamp = {2020-09-04},
}

@ARTICLE{hees2017ddpo,
 ARCHIVEPREFIX = {arXiv},
 AUTHOR = {Heess, Nicolas and TB, Dhruva and Sriram, Srinivasan and Lemmon, Jay and Merel, Josh and Wayne, Greg and Tassa, Yuval and Erez, Tom and Wang, Ziyu and Eslami, S. M. Ali and Riedmiller, Martin A. and Silver, David},
 BIBSOURCE = {dblp computer science bibliography, https://dblp.org},
 BIBURL = {https://dblp.org/rec/journals/corr/HeessTSLMWTEWER17.bib},
 EPRINT = {1707.02286},
 JOURNAL = {CoRR},
 TIMESTAMP = {Mon, 22 Jul 2019 16:19:02 +0200},
 TITLE = {Emergence of locomotion behaviours in rich environments},
 URL = {http://arxiv.org/abs/1707.02286},
 VOLUME = {abs/1707.02286},
 YEAR = {2017}
}

@InProceedings{heess2012actor,
  author    = {Heess, Nicolas and Silver, David and Teh, Yee Whye},
  booktitle = {EWRL},
  title     = {Actor-critic reinforcement learning with energy-based policies.},
  year      = {2012},
  pages     = {43--58},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@InProceedings{heess2015learning,
  author    = {Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Timothy and Erez, Tom and Tassa, Yuval},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Learning continuous control policies by stochastic value gradients},
  year      = {2015},
  pages     = {2944--2952},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@Article{heess2015rnn,
  author        = {Heess, Nicolas and Hunt, Jonathan J. and Lillicrap, Timothy P. and Silver, David},
  journal       = {CoRR},
  title         = {Memory-based control with recurrent neural networks},
  year          = {2015},
  volume        = {abs/1512.04455},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/HeessHLS15.bib},
  eprint        = {1512.04455},
  groups        = {Neural Network},
  timestamp     = {2020-08-06},
  url           = {http://arxiv.org/abs/1512.04455},
}

@INPROCEEDINGS{heinrich2015fictitious,
 AUTHOR = {Heinrich, Johannes and Lanctot, Marc and Silver, David},
 BOOKTITLE = {International Conference on Machine Learning},
 PAGES = {805--813},
 TITLE = {Fictitious self-play in extensive-form games},
 YEAR = {2015}
}

@Article{heinrich2016self,
  author        = {Heinrich, Johannes and Silver, David},
  journal       = {CoRR},
  title         = {Deep reinforcement learning from self-play in imperfect-information games},
  year          = {2016},
  volume        = {abs/1603.01121},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/HeinrichS16.bib},
  eprint        = {1603.01121},
  groups        = {RL},
  timestamp     = {2020-08-06},
  url           = {http://arxiv.org/abs/1603.01121},
}

@InProceedings{hessel2018rainbow,
  author    = {Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle = {Thirty-Second AAAI Conference on Artificial Intelligence},
  title     = {Rainbow: {Combining} improvements in deep reinforcement learning},
  year      = {2018},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@Misc{hester2017deep,
  author        = {Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Dulac-Arnold, Gabriel and Osband, Ian and Agapiou, John and Leibo, Joel Z. and Gruslys, Audrunas},
  title         = {Deep {Q-learning} from demonstrations},
  year          = {2017},
  archiveprefix = {arXiv},
  eprint        = {1704.03732},
  groups        = {RL},
  primaryclass  = {cs.AI},
  timestamp     = {2020-08-06},
}

@Article{hildreth1957quadratic,
  author    = {Hildreth, Clifford},
  journal   = {Naval Research Logistics Quarterly},
  title     = {A quadratic programming procedure},
  year      = {1957},
  number    = {1},
  pages     = {79--85},
  volume    = {4},
  groups    = {global optimization},
  publisher = {Wiley Subscription Services, Inc., A Wiley Company},
  timestamp = {2020-08-06},
}

@InProceedings{Hinterding1995,
  author    = {Hinterding, R.},
  booktitle = {Proceedings of 1995 IEEE International Conference on Evolutionary Computation},
  title     = {Gaussian mutation and self-adaption for numeric genetic algorithms},
  year      = {1995},
  month     = {11},
  pages     = {384--},
  volume    = {1},
  doi       = {10.1109/ICEC.1995.489178},
  file      = {:FILES/1995 - Hinterding1995 - Gaussian mutation and self-adaption for numeric genetic algorithms.pdf:PDF},
  groups    = {genetic algorithms, TEC},
  keywords  = {Genetic mutations;Genetic algorithms;Electronic switching systems;Genetic programming;Decoding;Testing;Gaussian distribution;Computational modeling;Gaussian noise;Evolutionary computation},
  timestamp = {2020-09-05},
}

@TechReport{hinton1984boltzmann,
  author      = {Hinton, Geoffrey E. and Sejnowski, Terrence J. and Ackley, David H.},
  institution = {Carnegie Mellon University},
  title       = {Boltzmann machines: {Constraint} satisfaction networks that learn},
  year        = {1984},
  address     = {Pittsburgh, PA},
  month       = may,
  number      = {CMU-CS-84-119},
  file        = {:FILES/1984 - hinton1984boltzmann - Boltzmann machines  Constraint satisfaction networks that learn.pdf:PDF},
  groups      = {Neural Network},
  publisher   = {Carnegie-Mellon University, Department of Computer Science},
  timestamp   = {2020-08-06},
}

@Article{ho2009designing,
  author    = {Ho, Yuen-Hong Alvin and Kwan, Hing-Kit and Wong, Ngai and Ho, Ka-Leung},
  journal   = {International Journal of Circuit Theory and Applications},
  title     = {Designing globally optimal delta--sigma modulator topologies via signomial programming},
  year      = {2009},
  number    = {3},
  pages     = {453--472},
  volume    = {37},
  groups    = {SGP},
  publisher = {Wiley Online Library},
  timestamp = {2020-08-06},
}

@Book{holland1975adaptation,
  author    = {Holland, John H.},
  publisher = {MIT Press},
  title     = {Adaptation in natural and artificial systems: {An} introductory analysis with applications to biology, control and artificial intelligence},
  year      = {1992},
  address   = {Cambridge, MA, USA},
  isbn      = {9780262275552},
  abstract  = {Genetic algorithms are playing an increasingly important role in studies of complex adaptive systems, ranging from adaptive agents in economic theory to the use of machine learning techniques in the design of complex devices such as aircraft turbines and integrated circuits. Adaptation in Natural and Artificial Systems is the book that initiated this field of study, presenting the theoretical foundations and exploring applications.In its most familiar form, adaptation is a biological process, whereby organisms evolve by rearranging genetic material to survive in environments confronting them. In this now classic work, Holland presents a mathematical model that allows for the nonlinearity of such complex interactions. He demonstrates the model's universality by applying it to economics, physiological psychology, game theory, and artificial intelligence and then outlines the way in which this approach modifies the traditional views of mathematical genetics.Initially applying his concepts to simply defined artificial systems with limited numbers of parameters, Holland goes on to explore their use in the study of a wide range of complex, naturally occuring processes, concentrating on systems having multiple factors that interact in nonlinear ways. Along the way he accounts for major effects of coadaptation and coevolution: the emergence of building blocks, or schemata, that are recombined and passed on to succeeding generations to provide, innovations and improvements.John H. Holland is Professor of Psychology and Professor of Electrical Engineering and Computer Science at the University of Michigan. He is also Maxwell Professor at the Santa Fe Institute and is Director of the University of Michigan/Santa Fe Institute Advanced Research Program.},
  file      = {:FILES/1992 - Adaptation in Natural and Artificial Systems_ An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence (1992, The MIT Press) - libgen.lc.pdf:PDF},
  groups    = {genetic algorithms, TEC},
  timestamp = {2020-09-05},
}

@Article{Holland1992a,
  author    = {Holland, John H.},
  journal   = {Scientific American},
  title     = {Genetic algorithms},
  year      = {1992},
  issn      = {00368733, 19467087},
  number    = {1},
  pages     = {66--73},
  volume    = {267},
  file      = {:FILES/1992 - Holland1992a - Genetic Algorithms.pdf:PDF},
  groups    = {genetic algorithms},
  publisher = {Scientific American, a division of Nature America, Inc.},
  url       = {http://www.jstor.org/stable/24939139},
}

@Article{Hong1986UT,
  author    = {Hong, Chew Soo and Waller, William S.},
  journal   = {Journal of Mathematical Psychology},
  title     = {Empirical tests of weighted utility theory},
  year      = {1986},
  number    = {1},
  pages     = {55--72},
  volume    = {30},
  groups    = {utility theory},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@InProceedings{hong2014fir,
  author    = {Hong, T. and Bai, H. and Wei, Y. and Yang, J. and Zhu, Z.},
  booktitle = {2014 7th International Congress on Image and Signal Processing},
  title     = {Sparse two-dimensional {FIR} digital filters design using {FISTA}},
  year      = {2014},
  month     = {10},
  pages     = {815--819},
  abstract  = {An efficient algorithm described in this brief is proposed for designing two-dimensional (2D) linear-phase finite impulse response (FIR) digital filters. This algorithm is inspired by the methods described in [11], [14]. The proposed algorithm handles the problem on L1-L2 formula directly and does not recast the problem to Quadratic Programming (QP) shown in [11]. Moreover, the choice of trade-off parameter arises in L1-L2 is studied in this paper. Two examples are presented to illustrate our new algorithm.},
  doi       = {10.1109/CISP.2014.7003889},
  file      = {:FILES/2014 - hong2014fir - Sparse two-dimensional FIR digital filters design using FISTA.pdf:PDF},
  groups    = {two-dimensional FIR, sparse},
  keywords  = {FIR filters;iterative methods;quadratic programming;two-dimensional digital filters;sparse two-dimensional fir digital filter;2D linear-phase finite impulse response digital filter;L1-L2 formula;quadratic programming;QP;fast iterative shrinkage-thresholding algorithm;Algorithm design and analysis;Finite impulse response filters;Signal processing algorithms;Vectors;Frequency response;Optimization;L1-L2;sparse;2D;FIR;linear-phase},
}

@Article{hopfield1982neural,
  author    = {Hopfield, John J.},
  journal   = {Proceedings of the national academy of sciences},
  title     = {Neural networks and physical systems with emergent collective computational abilities},
  year      = {1982},
  number    = {8},
  pages     = {2554--2558},
  volume    = {79},
  file      = {:FILES/1982 - hopfield1982neural - Neural networks and physical systems with emergent collective computational abilities.pdf:PDF},
  groups    = {Neural Network},
  publisher = {National Acad Sciences},
  timestamp = {2020-08-06},
}

@Book{Horst1990global,
  author    = {Horst, Reiner and Tuy, Hoang},
  publisher = {Springer Verlag},
  title     = {Global optimization: {Deterministic} approaches},
  year      = {1995},
  address   = {Berlin Heidelberg},
  file      = {:FILES/1995 - Horst1990global - global optimizaion - deterministic approaches.pdf:PDF},
  groups    = {global optimization},
  timestamp = {2020-08-06},
}

@Book{horst2000introduction,
  author    = {Horst, R. and Pardalos, P.M. and Thoai, N.V.},
  publisher = {Springer},
  title     = {Introduction to global optimization},
  year      = {2000},
  groups    = {global optimization},
  timestamp = {2020-08-06},
}

@Book{horst2013global,
  author    = {Horst, Reiner and Tuy, Hoang},
  publisher = {Springer Science \& Business Media},
  title     = {Global optimization: {Deterministic} approaches},
  year      = {2013},
  groups    = {global optimization},
  timestamp = {2020-08-06},
}

@InProceedings{hsieh2008dual,
  author    = {Hsieh, Cho-Jui and Chang, Kai-Wei and Lin, Chih-Jen and Keerthi, S. Sathiya and Sundararajan, S.},
  booktitle = {Proceedings of the 25th International Conference on Machine Learning},
  title     = {A dual coordinate descent method for large-scale linear {SVM}},
  year      = {2008},
  address   = {New York, NY, USA},
  pages     = {408--415},
  publisher = {ACM},
  series    = {ICML '08},
  acmid     = {1390208},
  groups    = {SVM},
  location  = {Helsinki, Finland},
  numpages  = {8},
  timestamp = {2020-08-30},
}

@InProceedings{Hsieh2011Matrix,
  author    = {Hsieh, Cho-Jui and Dhillon, Inderjit S.},
  booktitle = {Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining},
  title     = {Fast coordinate descent methods with variable selection for non-negative matrix factorization},
  year      = {2011},
  pages     = {1064--1072},
  publisher = {ACM},
  groups    = {machine learning},
  timestamp = {2020-08-06},
}

@InProceedings{Hu2007,
  author    = {Hu, X. B. and Di Paolo, E.},
  booktitle = {2007 IEEE Congress on Evolutionary Computation},
  title     = {An efficient genetic algorithm with uniform crossover for the multi-objective airport gate assignment problem},
  year      = {2007},
  month     = {9},
  pages     = {55--62},
  abstract  = {Genetic Algorithms (GAs) have a good potential of solving the Gate Assignment Problem (GAP) at airport terminals, and the design of feasible and efficient evolutionary operators, particularly, the crossover operator, is crucial to successful implementations. This paper reports an application of GAs to the multi-objective GAP. The relative positions between aircraft rather than their absolute positions in the queues to gates is used to construct chromosomes in a novel encoding scheme, and a new uniform crossover operator, free of feasibility problems, is then proposed, which is effective and efficient to identify, inherit and protect useful common sub-queues to gates during evolution. Extensive simulation studies illustrate the advantages of the proposed GA scheme with uniform crossover operator.},
  doi       = {10.1109/CEC.2007.4424454},
  file      = {:FILES/2007 - Hu2007 - An efficient Genetic Algorithm with uniform crossover for the multi-objective Airport Gate Assignment Problem.pdf:PDF},
  groups    = {genetic algorithms, TEC},
  issn      = {1941-0026},
  keywords  = {airports;genetic algorithms;queueing theory;genetic algorithm;multiobjective airport gate assignment problem;airport terminals;evolutionary operators;crossover operator;sub-queues;Genetic algorithms;Airports;Evolutionary computation},
  timestamp = {2020-09-05},
}

@Article{Hu2017bp,
  author    = {Hu, Qian and Zhu, Wenbin and Qin, Hu and Lim, Andrew},
  journal   = {European Journal of Operational Research},
  title     = {A branch-and-price algorithm for the two-dimensional vector packing problem with piecewise linear cost function},
  year      = {2017},
  issn      = {0377-2217},
  number    = {1},
  pages     = {70 -- 80},
  volume    = {260},
  abstract  = {The two-dimensional vector packing problem with piecewise linear cost function (2DVPP-PLC) models a practical packing problem faced by many companies that use courier services. We propose a branch-and-price algorithm to solve the 2DVPP-PLC exactly. The column generation procedure is a key component that affects the performance of a branch-and-price algorithm. The pricing problem exhibits an interesting structure that allows us to decompose it into subproblems that form a lattice. We explore dominance relations on the lattice and design an efficient algorithm for the pricing problem. Experimental results show that our branch-and-price algorithm is capable of solving 2DVPP-PLC test instances effectively.},
  doi       = {10.1016/j.ejor.2016.12.021},
  file      = {:FILES/2017 - Hu2017bp - A branch-and-price algorithm for the two-dimensional vector packing problem with piecewise linear cost function.pdf:PDF},
  groups    = {optimization},
  keywords  = {Packing, 2D vector packing, Piecewise linear cost function, Branch-and-price, Column generation},
  timestamp = {2020-08-06},
}

@InProceedings{huang2010operation,
  author       = {Huang, Xiaolin and Xu, Jun and Wang, Shuning},
  booktitle    = {2010 IEEE International Conference on Systems Man and Cybernetics (SMC)},
  title        = {Operation optimization for centrifugal chiller plants using continuous piecewise linear programming},
  year         = {2010},
  organization = {IEEE},
  pages        = {1121--1126},
  file         = {:FILES/2010 - huang2010operation - Operation optimization for centrifugal chiller plants using continuous piecewise linear programming.pdf:PDF},
  groups       = {application, Wang's Work},
  timestamp    = {2020-08-06},
}

@PhdThesis{Huang2011thesis,
  author        = {黄晓霖},
  school        = {清华大学},
  title         = {基于连续分片线性模型的非线性系统建模与优化},
  year          = {2011},
  date-added    = {2016-03-31 09:21:17 +0000},
  date-modified = {2016-03-31 09:22:32 +0000},
  groups        = {identification},
  timestamp     = {2020-08-06},
}

@Article{Huang2012Minimization,
  author     = {Huang, Xiaolin and Xu, Jun and Wang, Shuning and Xu, Chunhui},
  journal    = {Journal of the Operational Research Society},
  title      = {Minimization of the $k$-th maximum and its application on {LMS} regression and {VaR} optimization},
  year       = {2012},
  issn       = {01605682, 14769360},
  number     = {11},
  pages      = {1479--1491},
  volume     = {63},
  abstract   = {Motivated by two important problems, the least median of squares (LMS) regression and value-at-risk (VaR) optimization, this paper considers the problem of minimizing the K-th maximum for linear functions. For this study, a sufficient and necessary condition of local optimality is given. From this condition and other properties, we propose an algorithm that uses linear programming technique. The algorithm is assessed on real data sets and the experiments for LMS regression and VaR optimization both show its effectiveness.},
  file       = {:FILES/2012 - Huang2012Minimization - Minimization of the k-th maximum and its application on LMS regression and VaR optimization.pdf:PDF},
  groups     = {VaR, algorithms, Wang's Work, LMS, TEC},
  keywords   = {prio1, read},
  priority   = {prio1},
  publisher  = {[Operational Research Society, Palgrave Macmillan Journals]},
  readstatus = {read},
  timestamp  = {2020-09-05},
  url        = {http://www.jstor.org/stable/41680019},
}

@Article{Huang2013RampL1,
  author    = {Huang, Xiaolin and Shi, Lei and Suykens, Johan A. K.},
  journal   = {Journal of Machine Learning Research},
  title     = {Ramp loss linear programming support vector machine},
  year      = {2014},
  pages     = {2185--2211},
  volume    = {15},
  groups    = {SVM},
  timestamp = {2020-09-17},
}

@MISC{huang2020nfsc,
 ADDRESS = {National Natural Science Foundation of China (NSFC)(51975155). China. Participatant},
 GROUPS = {projects},
 KEYWORDS = {project},
 TIMESTAMP = {2020-06-20},
 TITLE = {Machining method of liquid metal electrode micro-edm shaped-controlled by strong electric field and rotating magnetic field},
 YEAR = {{2020/01$\sim$2023/12}},
 note = {600k RMB}
}

@MISC{huang2020nfscCN,
 ADDRESS = {国家自然科学基金（面上项目）51975155，参与},
 GROUPS = {projects},
 KEYWORDS = {project},
 TIMESTAMP = {2020-06-20},
 TITLE = {基于强电场和旋转磁场控形的液体金属电极微细电火花加工方法},
 YEAR = {{2020/01$\sim$2023/12}},
 note = {60万元}
}

@Article{HuangHill,
  author    = {Huang, Xiaolin and Xu, Jun and Mu, Xiaomu and Wang, Shuning},
  journal   = {Computers \& Operations Research},
  title     = {The hill detouring method for minimizing hinging hyperplanes functions},
  year      = {2012},
  number    = {7},
  pages     = {1763--1770},
  volume    = {39},
  file      = {:FILES/2012 - HuangHill - The hill detouring method for minimizing hinging hyperplanes functions.pdf:PDF},
  groups    = {optimization, Wang's Work},
  timestamp = {2020-08-06},
}

@Article{HuangSubregion,
  author    = {Huang, Xiaolin and Xu, Jun and Wang, Shuning},
  journal   = {Journal of Optimization Theory and Applications},
  title     = {Exact penalty and optimality condition for nonseparable continuous piecewise linear programming},
  year      = {2012},
  issn      = {1573-2878},
  month     = {10},
  number    = {1},
  pages     = {145--164},
  volume    = {155},
  abstract  = {Utilizing compact representations for continuous piecewise linear functions, this paper discusses some theoretical properties for nonseparable continuous piecewise linear programming. The existence of exact penalty for continuous piecewise linear programming is proved, which allows us to concentrate on unconstrained problems. For unconstrained problems, we give a sufficient and necessary local optimality condition, which is based on a model with universal representation capability and hence applicable to arbitrary continuous piecewise linear programming. From the gained optimality condition, an algorithm is proposed and evaluated by numerical experiments, where the theoretical properties are illustrated as well.},
  day       = {01},
  doi       = {10.1007/s10957-012-0032-7},
  file      = {:FILES/2012 - HuangSubregion - Exact Penalty and Optimality Condition for Nonseparable Continuous Piecewise Linear Programming.pdf:PDF},
  groups    = {optimization, Wang's Work, TEC},
  keywords  = {Piecewise linear; Nonlinear programming; Exact penalty; Local optimality condition},
  language  = {English},
  publisher = {Springer US},
  timestamp = {2020-09-05},
  url       = {https://doi.org/10.1007/s10957-012-0032-7},
}

@Article{hunter2004tutorial,
  author    = {Hunter, David R. and Lange, Kenneth},
  journal   = {The American Statistician},
  title     = {A tutorial on {MM} algorithms},
  year      = {2004},
  number    = {1},
  pages     = {30--37},
  volume    = {58},
  file      = {:FILES/2004 - hunter2004tutorial - A tutorial on MM algorithms.pdf:PDF},
  groups    = {mathematical basis},
  publisher = {Taylor \& Francis},
  timestamp = {2020-08-06},
}

@Article{Hussain2017,
  author     = {Hussain, Abid and Muhammad, Yousaf Shad and Nauman Sajid, M. and Hussain, Ijaz and Mohamd Shoukry, Alaa and Gani, Showkat},
  journal    = {Computational Intelligence and Neuroscience},
  title      = {Genetic algorithm for traveling salesman problem with modified cycle crossover operator},
  year       = {2017},
  issn       = {1687-5265},
  month      = {10},
  pages      = {7430125},
  volume     = {2017},
  abstract   = {Genetic algorithms are evolutionary techniques used for optimization purposes according to survival of the fittest idea. These methods do not ensure optimal solutions; however, they give good approximation usually in time. The genetic algorithms are useful for NP-hard problems, especially the traveling salesman problem. The genetic algorithm depends on selection criteria, crossover, and mutation operators. To tackle the traveling salesman problem using genetic algorithms, there are various representations such as binary, path, adjacency, ordinal, and matrix representations. In this article, we propose a new crossover operator for traveling salesman problem to minimize the total distance. This approach has been linked with path representation, which is the most natural way to represent a legal tour. Computational results are also reported with some traditional path representation methods like partially mapped and order crossovers along with new cycle crossover operator for some benchmark TSPLIB instances and found improvements.},
  comment    = {the journal asks for APC $2050},
  day        = {25},
  doi        = {10.1155/2017/7430125},
  file       = {:FILES/2017 - Hussain2017 - Genetic Algorithm for traveling salesman problem with modified cycle crossover operator.pdf:PDF},
  groups     = {genetic algorithms},
  keywords   = {skimmed},
  publisher  = {Hindawi},
  readstatus = {skimmed},
  url        = {https://doi.org/10.1155/2017/7430125},
}

@InProceedings{Hutter2002,
  author    = {Hutter, M.},
  booktitle = {Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600)},
  title     = {Fitness uniform selection to preserve genetic diversity},
  year      = {2002},
  month     = {5},
  pages     = {783--788 vol.1},
  volume    = {1},
  abstract  = {In evolutionary algorithms, the fitness of a population increases with time by mutating and recombining individuals and by a biased selection of more fit individuals. The right selection pressure is critical in ensuring sufficient optimization progress on the one hand and in preserving genetic diversity to be able to escape from local optima on the other. We propose a new selection scheme, which is uniform in the fitness values. It generates selection pressure towards sparsely populated fitness regions, not necessarily towards higher fitness, as is the case for all other selection schemes. We show that the new selection scheme can be more effective than standard selection schemes.},
  doi       = {10.1109/CEC.2002.1007025},
  file      = {:FILES/2002 - Hutter2002 - Fitness uniform selection to preserve genetic diversity.pdf:PDF},
  groups    = {genetic algorithms},
  keywords  = {evolutionary computation;fitness uniform selection;genetic diversity preservation;evolutionary algorithms;population fitness;optimization;local optima;fitness values;sparsely populated fitness regions;Evolutionary computation;Genetic mutations;Steady-state},
  timestamp = {2020-06-13},
}

@Article{Hwang2010loss,
  author    = {Hwang, Soosung and Satchell, Steve E.},
  journal   = {Journal of Banking \& Finance},
  title     = {How loss averse are investors in financial markets?},
  year      = {2010},
  number    = {10},
  pages     = {2425--2438},
  volume    = {34},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@InProceedings{Imamoto2008PWL,
  author    = {Imamoto, Alyson and Tang, Benjamim},
  booktitle = {Advances in Electrical and Electronics Engineering - IAENG Special Edition of the World Congress on Engineering and Computer Science 2008},
  title     = {A recursive descent algorithm for finding the optimal minimax piecewise linear approximation of convex functions},
  year      = {2008},
  month     = {10},
  pages     = {287--293},
  doi       = {10.1109/WCECS.2008.42},
  file      = {:FILES/2008 - Imamoto2008PWL - A Recursive Descent Algorithm for Finding the Optimal Minimax Piecewise Linear Approximation of Convex Functions.pdf:PDF},
  groups    = {Approximation},
  issn      = {null},
  keywords  = {convex programming;differential equations;function approximation;minimax techniques;piecewise linear techniques;recursive functions;convex differentiable function;recursive descent algorithm;optimal minimax piecewise linear approximation;Approximation algorithms;Minimax techniques;Piecewise linear approximation;Function approximation;Piecewise linear techniques;Joining processes;Computer science;Hardware;Computer applications;Application software;optimal;minimax;piecewise;linear;approximation},
  timestamp = {2020-08-06},
}

@Article{Ishibuchi2004,
  author    = {Ishibuchi, Hisao and Yamamoto, Takashi},
  journal   = {Fuzzy Sets and Systems},
  title     = {Fuzzy rule selection by multi-objective genetic local search algorithms and rule evaluation measures in data mining},
  year      = {2004},
  issn      = {0165-0114},
  note      = {Genetic Fuzzy Systems: New Developments},
  number    = {1},
  pages     = {59 -- 88},
  volume    = {141},
  abstract  = {This paper shows how a small number of simple fuzzy if-then rules can be selected for pattern classification problems with many continuous attributes. Our approach consists of two phases: candidate rule generation by rule evaluation measures in data mining and rule selection by multi-objective evolutionary algorithms. In our approach, first candidate fuzzy if-then rules are generated from numerical data and prescreened using two rule evaluation measures (i.e., confidence and support) in data mining. Then a small number of fuzzy if-then rules are selected from the prescreened candidate rules using multi-objective evolutionary algorithms. In rule selection, we use three objectives: maximization of the classification accuracy, minimization of the number of selected rules, and minimization of the total rule length. Thus the task of multi-objective evolutionary algorithms is to find a number of non-dominated rule sets with respect to these three objectives. The main contribution of this paper is to propose an idea of utilizing the two rule evaluation measures as prescreening criteria of candidate rules for fuzzy rule selection. An arbitrarily specified number of candidate rules can be generated from numerical data for high-dimensional pattern classification problems. Through computer simulations, we demonstrate that such a prescreening procedure improves the efficiency of our approach to fuzzy rule selection. We also extend a multi-objective genetic algorithm (MOGA) in our former studies to a multi-objective genetic local search (MOGLS) algorithm where a local search procedure adjusts the selection (i.e., inclusion or exclusion) of each candidate rule. Furthermore, a learning algorithm of rule weights (i.e., certainty factors) is combined with our MOGLS algorithm. Such extensions to our MOGA for fuzzy rule selection are another contribution of this paper.},
  doi       = {https://doi.org/10.1016/S0165-0114(03)00114-3},
  file      = {:FILES/2004 - Ishibuchi2004 - Fuzzy rule selection by multi-objective genetic local search algorithms and rule evaluation measures in data mining.pdf:PDF},
  groups    = {genetic algorithms},
  keywords  = {Data mining, Pattern classification, Fuzzy rule selection, Evolutionary multi-criterion optimization, Hybrid genetic algorithms},
  timestamp = {2020-06-13},
  url       = {http://www.sciencedirect.com/science/article/pii/S0165011403001143},
}

@Article{islam2005modified,
  author    = {Islam, Sahidul and Roy, Tapan Kumar},
  journal   = {Journal of Applied Mathematics and Computing},
  title     = {Modified geometric programming problem and its applications},
  year      = {2005},
  number    = {1-2},
  pages     = {121--144},
  volume    = {17},
  file      = {:FILES/2005 - islam2005modified - Modified geometric programming problem and its applications.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-07-16},
}

@Article{Jadaan2008,
  author    = {Jadaan, Omar Al and Rajamani, Lakishmi and Rao, C. R.},
  journal   = {Journal of Theoretical and Applied Information Technology},
  title     = {Improved selection operator for {GA}},
  year      = {2008},
  month     = {01},
  pages     = {269--277},
  volume    = {4},
  file      = {:FILES/2008 - Jadaan2008 - Improved Selection  Operator for GA.pdf:PDF},
  groups    = {genetic algorithms},
  timestamp = {2020-06-13},
}

@Article{JAKOVCEVICSTOR201562,
  author    = {Stor], Nevena [Jakov\v{c}evi\'{c} and Slapni\v{c}ar, Ivan and Barlow, Jesse L.},
  journal   = {Linear Algebra and its Applications},
  title     = {Accurate eigenvalue decomposition of real symmetric arrowhead matrices and applications},
  year      = {2015},
  issn      = {0024-3795},
  note      = {Special issue on eigenvalue problems},
  pages     = {62 -- 89},
  volume    = {464},
  abstract  = {We present a new algorithm for solving the eigenvalue problem for an n×n real symmetric arrowhead matrix. The algorithm computes all eigenvalues and all components of the corresponding eigenvectors with high relative accuracy in O(n2) operations under certain circumstances. The algorithm is based on a shift-and-invert approach. Only a single element of the inverse of the shifted matrix eventually needs to be computed with double the working precision. Each eigenvalue and the corresponding eigenvector can be computed separately, which makes the algorithm adaptable for parallel computing. Our results extend to Hermitian arrowhead matrices, real symmetric diagonal-plus-rank-one matrices and singular value decomposition of real triangular arrowhead matrices.},
  doi       = {https://doi.org/10.1016/j.laa.2013.10.007},
  groups    = {mathematical basis},
  keywords  = {Eigenvalue decomposition, Arrowhead matrix, High relative accuracy, Singular value decomposition},
  timestamp = {2020-08-06},
  url       = {http://www.sciencedirect.com/science/article/pii/S0024379513006265},
}

@Article{Jarrow2006,
  author    = {Jarrow, Robert and Zhao, Feng},
  journal   = {Management Science},
  title     = {Downside loss aversion and portfolio management},
  year      = {2006},
  number    = {4},
  pages     = {558--566},
  volume    = {52},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{Jebari2013,
  author     = {Jebari, Khalid and Madiafi, Mohammed},
  journal    = {International Journal of Emerging Sciences},
  title      = {Selection methods for genetic algorithms},
  year       = {2013},
  number     = {4},
  pages      = {333},
  volume     = {3},
  abstract   = {Based on a study of six well known selection methods often used in genetic algorithms, this paper presents a technique that benefits their advantages in terms of the quality of solutions and the genetic diversity. The numerical results show the extent to which the quality of solution depends on the choice of the selection method. The proposed technique, that can help reduce this dependence, is presented and its efficiency is numerically illustrated.},
  file       = {:FILES/2013 - Jebari2013 - Selection Methods for Genetic Algorithms.pdf:PDF},
  groups     = {genetic algorithms, TEC},
  keywords   = {read},
  readstatus = {read},
  timestamp  = {2020-09-05},
}

@ARTICLE{jefferson1978generalized,
 AUTHOR = {Jefferson, TR and Scott, CH},
 GROUPS = {SGP},
 JOURNAL = {Journal of Optimization Theory and Applications},
 NUMBER = {1},
 PAGES = {117--129},
 PUBLISHER = {Springer},
 TIMESTAMP = {2020-07-16},
 TITLE = {Generalized geometric programming applied to problems of optimal control: {I.} theory},
 VOLUME = {26},
 YEAR = {1978}
}

@Article{jha1995geometric,
  author    = {Jha, Nand K.},
  journal   = {Computers \& Industrial Engineering},
  title     = {Geometric programming based robot control design},
  year      = {1995},
  number    = {1-4},
  pages     = {631--635},
  volume    = {29},
  file      = {:FILES/1995 - jha1995geometric - Geometric programming based robot control design.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@Article{Jiang2012firPeak,
  author   = {Jiang, Aimin and Kwan, Hon Keung and Zhu, Yanping},
  journal  = {IEEE Transactions on Signal Processing},
  title    = {Peak-error-constrained sparse {FIR} filter design using iterative {SOCP}},
  year     = {2012},
  issn     = {1941-0476},
  month    = {8},
  number   = {8},
  pages    = {4035--4044},
  volume   = {60},
  abstract = {In this paper, a novel algorithm is proposed to design sparse FIR filters. It is known that this design problem is highly nonconvex due to the existence of -norm of a filter coefficient vector in its objective function. To tackle this difficulty, an iterative procedure is developed to search a potential sparsity pattern, which is then used to compute the final solution by solving a convex optimization problem. In each iterative step, the original sparse filter design problem is successively transformed to a simpler subproblem. It can be proved that under a weak condition, globally optimal solutions of these subproblems can be attained by solving their dual problems. In this case, the overall iterative procedure converges to a locally optimal solution of the original design problem. The design procedure described above can be repeated for several times to further improve the sparsity of design results. The output of the previous stage can be used as the initial point of the subsequent design. The performance of the proposed algorithm is evaluated by two sets of design examples, and compared to other sparse FIR filter design algorithms.},
  doi      = {10.1109/TSP.2012.2199316},
  file     = {:FILES/2012 - Jiang2012firPeak - Peak-Error-Constrained Sparse FIR Filter Design Using Iterative SOCP.pdf:PDF},
  groups   = {sparse},
  keywords = {convergence of numerical methods;convex programming;FIR filters;iterative methods;peak-error-constrained sparse FIR filter design;iterative SOCP;filter coefficient vector;l0-norm;objective function;potential sparsity pattern;convex optimization problem;global optimal solutions;iterative procedure;local optimal solution;design sparsity;design sets;Finite impulse response filters;Signal processing algorithms;Matching pursuit algorithms;Approximation algorithms;Iterative algorithms;Linear programming;Optimization;Finite impulse response (FIR) filters;second-order cone programming (SOCP);sparse filter design},
}

@InProceedings{Jiang2012minimaxfir,
  author    = {Jiang, Aimin and Kwan, Hon Keung and Zhu, Yanping and Liu, X.},
  booktitle = {2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Minimax design of sparse {FIR} digital filters},
  year      = {2012},
  month     = {3},
  pages     = {3497--3500},
  abstract  = {In this paper, we present a novel algorithm to design sparse FIR digital filters in the minimax sense. To tackle the nonconvexity of the design problem, an efficient iterative procedure is developed to find a potential sparsity pattern. In each iteration, a subproblem in a simpler form is constructed. Instead of directly resolving these nonconvex subproblems, we resort to their respective dual problems. It can be proved that under a weak condition, globally optimal solutions of these subproblems can be attained by solving their dual problems. In this case, the overall iterative procedure can converge to a locally optimal solution of the original design problem. The real minimax design can then be achieved by refining the FIR filter obtained by the iterative procedure. The design procedure described above can be repeated for several times to further improve the sparsity of design results. The output of the previous stage can be used as the initial point of the subsequent design. Simulation results demonstrate the effectiveness of our proposed algorithm.},
  doi       = {10.1109/ICASSP.2012.6288670},
  file      = {:FILES/2012 - Jiang2012minimaxfir - Minimax design of sparse FIR digital filters.pdf:PDF},
  groups    = {sparse},
  issn      = {2379-190X},
  keywords  = {concave programming;FIR filters;iterative methods;minimax techniques;minimax design;sparse FIR digital filter;nonconvex design subproblem;iterative procedure;Algorithm design and analysis;Finite impulse response filter;Approximation algorithms;Filtering algorithms;Signal processing algorithms;Matching pursuit algorithms;Finite impulse response (FIR) digital filter;sparse filter design;minimax},
}

@InProceedings{jiang2012wls,
  author    = {Jiang, Aimin and Kwan, Hon Keung},
  booktitle = {2012 IEEE International Symposium on Circuits and Systems (ISCAS)},
  title     = {Efficient design of sparse {FIR} filters in {WLS} sense},
  year      = {2012},
  month     = {5},
  pages     = {41--44},
  abstract  = {A novel algorithm is presented in this paper to design sparse FIR filters in the weighted least-squares (WLS) sense. The original design problem is cast as a constrained l0-norm optimization problem. To tackle the nonconvexity, an efficient iterative procedure is developed. In each iterative step, a subproblem in a simpler form is constructed. It can be demonstrated that in each iteration an optimal solution to each subproblem can be efficiently and reliably attained by the successive activation algorithm proposed in this paper, such that the overall design algorithm can converge to a local solution of the original design problem. Since its major part only involves scalar operations, compared with other sparse filter design approaches, the proposed design algorithm is computationally efficient. The effectiveness of the proposed design algorithm is demonstrated by numerical examples.},
  doi       = {10.1109/ISCAS.2012.6272050},
  file      = {:FILES/2012 - jiang2012wls - Efficient design of sparse FIR filters in WLS sense.pdf:PDF},
  groups    = {sparse},
  issn      = {2158-1525},
  keywords  = {FIR filters;iterative methods;sparse matrices;sparse FIR filters;WLS sense;weighted least squares sense;nonconvexity;iterative procedure;iterative step;simpler form;optimal solution;successive activation algorithm;sparse filter design;design algorithm;Finite impulse response filter;Algorithm design and analysis;Signal processing algorithms;Approximation algorithms;Filtering algorithms;Approximation error;Passband},
}

@Article{jiang2013firWLS,
  author     = {Jiang, Aimin and Kwan, Hon Keung},
  journal    = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title      = {{WLS} design of sparse {FIR} digital filters},
  year       = {2013},
  issn       = {1558-0806},
  month      = {1},
  number     = {1},
  pages      = {125--135},
  volume     = {60},
  abstract   = {In this paper, we propose a novel algorithm for sparse finite impulse response (FIR) filter designs. The objective of the sparse digital filter design problem considered in this paper is to reduce the number of nonzero-valued filter coefficients, subject to a weighted least-squares (WLS) approximation error constraint imposed on the frequency domain. The proposed design method is inspired by the iterative shrinkage/thresholding (IST) algorithms, which are used in sparse and redundant representation for signals. The basic idea of the proposed design algorithm is to successively transform the original nonconvex problem to a series of constrained subproblems in a simpler form. Despite of their nonconvexity, these subproblems can be efficiently and reliably solved in each iterative step by a numerical approach developed in this paper. Furthermore, it can be demonstrated that the obtained solutions are essentially optimal to their respective subproblems. Since its major part only involves scalar operations, the proposed algorithm is computationally efficient. Three sets of numerical examples are presented in this paper to illustrate the effectiveness of the proposed design algorithm.},
  doi        = {10.1109/TCSI.2012.2215742},
  file       = {:FILES/2013 - jiang2013firWLS - WLS design of sparse FIR digital filters.pdf:PDF},
  groups     = {sparse},
  keywords   = {approximation theory;FIR filters;frequency-domain analysis;iterative methods;least squares approximations;signal representation;WLS design;sparse FIR digital filters;sparse finite impulse response filter designs;weighted least-squares approximation error constraint;frequency domain;iterative shrinkage-thresholding algorithms;IST algorithm;nonzero-valued filter coefficients;sparse signal representation;redundant signal representation;nonconvex problem;constrained subproblems;numerical approach;scalar operations;Finite impulse response (FIR) digital filter;iterative shrinkage/thresholding (IST);sparse filter design;weighted least-squares (WLS), read},
  readstatus = {read},
}

@InProceedings{Jiang2014firsparse,
  author     = {Jiang, Aimin and Kwan, Hon Keung and Tang, Y. and Zhu, Yanping},
  booktitle  = {2014 IEEE International Symposium on Circuits and Systems (ISCAS)},
  title      = {Efficient design of sparse {FIR} filters with optimized filter length},
  year       = {2014},
  month      = {6},
  pages      = {966--969},
  abstract   = {A large number of experiments have demonstrated that for an FIR filter the sparsity of filter coefficients is highly related to its filter order. However, traditional sparse FIR filter design methods focus on how to increase the number of zero-valued coefficients, but overlook the impact of filter orders on design performance. As an attempt to jointly optimize filter length and sparsity of an FIR filter, a novel method is proposed in this paper to design sparse linear-phase FIR filters. With peak error constraints, the objective function of the design problem is formulated as a combination of the sparsity of filter coefficients and a measure of the effective filter order. Then, the design problem is then recast as a weighted l0-norm optimization problem, which is solved by an efficient numerical method based on the iterative-reweighted-least-squares (IRLS) algorithms. Experimental results illustrate that the proposed method can efficiently reduce the effective filter order while enhancing the sparsity of an FIR filter.},
  doi        = {10.1109/ISCAS.2014.6865298},
  file       = {:FILES/2014 - Jiang2014firsparse - Efficient design of sparse FIR filters with optimized filter length.pdf:PDF},
  groups     = {sparse},
  issn       = {2158-1525},
  keywords   = {FIR filters;iterative methods;least squares approximations;logic design;optimisation;optimized filter length;filter coefficients;filter order;zero-valued coefficients;sparse linear-phase FIR filters;peak error constraints;l0-norm optimization problem;iterative-reweighted-least-squares algorithms;Finite impulse response filters;Design methodology;Optimization;Algorithm design and analysis;Linear programming;Complexity theory;Passband;Iterative-reweighted-least-squares (IRLS);l0 norm;quadratic programming;linear programming;sparse FIR filter, read},
  readstatus = {read},
}

@Article{Jiang2015fir,
  author     = {Jiang, Aimin and Kwan, Hon Keung and Zhu, Yanping and Liu, X. and Xu, N. and Tang, Y.},
  journal    = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title      = {Design of sparse {FIR} filters with joint optimization of sparsity and filter order},
  year       = {2015},
  issn       = {1558-0806},
  month      = {1},
  number     = {1},
  pages      = {195--204},
  volume     = {62},
  abstract   = {In this paper, two novel algorithms are developed to design sparse linear-phase (LP) FIR filters. Compared to traditional design methods, they can jointly optimize coefficient sparsity and order of an LP FIR filter, so as to achieve a balance between filtering performance and implementation efficiency. The design problem under consideration is formally cast as a regularized l0-norm minimization problem, which is then tackled by two different design algorithms. In the first proposed algorithm, the objective function of the original design problem is replaced by its upper bound, which leads to a weighted l0-norm minimization problem, while in the second one a group of auxiliary variables are introduced such that the original design problem can be equivalently transformed to another weighted l0-norm minimization problem. The iterative-reweighted-least-squares (IRLS) algorithm is employed with appropriate modifications to solve both weighted l0-norm minimization problems. Simulation results show that, compared to traditional approaches, the proposed algorithms can achieve comparable or better design results in terms of both sparsity and effective filter order.},
  doi        = {10.1109/TCSI.2014.2354771},
  file       = {:FILES/2015 - Jiang2015fir - Design of Sparse FIR Filters With Joint Optimization of Sparsity and Filter Order.pdf:PDF},
  groups     = {sparse},
  keywords   = {FIR filters;iterative methods;least squares approximations;linear phase filters;minimisation;finite impulse response filters;IRLS algorithm;iterative-reweighted-least-squares algorithm;original design problem;auxiliary variables;weighted-norm minimization problem;objective function;regularized-norm minimization problem;implementation efficiency;filtering performance;coefficient sparsity;LP FIR filter design;sparse linear-phase FIR filter order design;joint optimization;Quadratic programming;Sparse matrices;Filter order;Least squares methods;Filter order;iterative-reweighted-least-squares (IRLS);linear phase;quadratic programming (QP);sparse FIR filter;weighted $l_{0}$-norm minimization, read},
  readstatus = {read},
}

@InBook{jiang2015sparseFirTrends,
  author    = {Jiang, Aimin and Kwan, Hon Keung},
  editor    = {Lim, Yong Ching and Kwan, Hon Keung and Siu, Wan-Chi},
  pages     = {145--176},
  publisher = {Jenny Stanford Publishing},
  title     = {Recent advances in sparse {FIR} filter design using $\ell_0$ and $\ell_1$ optimization techniques},
  year      = {2015},
  address   = {Singapore},
  series    = {Jenny Stanford Series on Digital Signal Processing},
  booktitle = {Trends in Digital Signal Processing - A Festschrift in Honour of A. G. Constantinides},
  groups    = {sparse},
}

@InProceedings{Jiang2016firpeak,
  author     = {Jiang, Aimin and Kwan, Hon Keung and Zhu, Yanping and Liu, Xiaofeng and Xu, Ning and Yao, Xiao},
  booktitle  = {2016 24th European Signal Processing Conference (EUSIPCO)},
  title      = {Peak-error-constrained sparse {FIR} filter design using iterative {L1} optimization},
  year       = {2016},
  month      = {8},
  pages      = {180--184},
  abstract   = {In this paper, a novel algorithm is presented for the design of sparse linear-phase FIR filters. Compared to traditional l1-optimization-based methods, the proposed algorithm minimizes l1 norm of a portion (instead of all) of nonzero coefficients. In this way, some nonzero coefficients at crucial positions are not affected by l1 norm utilized in the objective function. The proposed algorithm employs an iterative procedure and the index set of these crucial coefficients is updated in each iteration. Simulation results demonstrate that the proposed algorithm can achieve better design results than both greedy methods and traditional l1-optimization-based methods.},
  doi        = {10.1109/EUSIPCO.2016.7760234},
  file       = {:FILES/2016 - Jiang2016firpeak - Peak-error-constrained sparse FIR filter design using iterative L1 optimization.pdf:PDF},
  groups     = {sparse},
  issn       = {2076-1465},
  keywords   = {FIR filters;iterative methods;minimisation;peak-error-constrained sparse FIR filter design;iterative L1 optimization;sparse linear-phase FIR filter;L1 norm minimization;nonzero coefficient;objective function;greedy method;Finite impulse response filters;Algorithm design and analysis;Signal processing algorithms;Optimization;Approximation error;Indexes;Approximation algorithms;FIR filters;iterative l1 optimization;l0 norm;linear program;sparsity, read},
  readstatus = {read},
}

@Article{Jiang2019partial,
  author     = {Jiang, Aimin and Kwan, Hon Keung and Tang, Yibin and Zhu, Yanping},
  journal    = {IEEE Transactions on Circuits and Systems II: Express Briefs},
  title      = {Sparse {FIR} filter design via partial 1-norm optimization},
  year       = {2020},
  issn       = {1558-3791},
  month      = aug,
  number     = {8},
  pages      = {1482--1486},
  volume     = {67},
  abstract   = {In this paper, we consider a sparse linear-phase FIR filter design problem. Recent methods assume that all the coefficients can be nullified and, thus, various 0 or 1-norm-based optimization techniques are applied on each of them. In contrast, the proposed algorithm is based on two important observations: 1) Given design specifications, some coefficients cannot be nullified, otherwise the specifications cannot be satisfied. 2) Impulse responses on neighboring positions of an FIR filter cannot vary dramatically so as to guarantee the smoothness of the corresponding magnitude responses over most of frequencies. In view of these facts, several rules are adopted in the proposed algorithm to select indices of potential zero coefficients to be used in 1-norm optimization. Simulation results have demonstrated the effectiveness of the proposed design algorithm.},
  doi        = {10.1109/TCSII.2019.2937343},
  file       = {:FILES/2020 - Jiang2019partial - Sparse FIR Filter Design via Partial 1-Norm Optimization.pdf:PDF},
  groups     = {sparse},
  keywords   = {Finite impulse response filters;Optimization;Heuristic algorithms;Indexes;Filtering theory;Approximation error;Sparse FIR filter design;1-norm optimization;linear-phase FIR filters;digital filter design;sparsity., read},
  readstatus = {read},
  timestamp  = {2020-08-07},
}

@Article{Jin2017,
  author    = {Jin, Zhong and Gao, David Y.},
  journal   = {Applied Mathematics and Computation},
  title     = {On modeling and global solutions for {DC} optimization problems by canonical duality theory},
  year      = {2017},
  pages     = {168--181},
  volume    = {296},
  file      = {:FILES/2017 - Jin2017 - On modeling and global solutions for dc optimization problems by canonical duality theory.pdf:PDF},
  groups    = {SGP, mathematical basis},
  publisher = {Elsevier},
  timestamp = {2020-08-31},
}

@MISC{johan2013nfsc,
 ADDRESS = {Bilateral Project between Tsinghua University and KU Leuven. Participatant},
 GROUPS = {projects},
 KEYWORDS = {project},
 TIMESTAMP = {2020-06-20},
 TITLE = {Piecewise linear technique of support vector machines and its application},
 YEAR = {{2013/01$\sim$2014/12}}
}

@Article{jorge2005bilinear,
  author    = {Jorge, Jes\'{u}s M.},
  journal   = {Journal of Global Optimization},
  title     = {A bilinear algorithm for optimizing a linear function over the efficient set of a multiple objective linear programming problem},
  year      = {2005},
  month     = jan,
  number    = {1},
  pages     = {1--16},
  volume    = {31},
  doi       = {10.1007/s10898-003-3784-7},
  file      = {:FILES/2005 - jorge2005bilinear - A bilinear algorithm for optimizing a linear function over the efficient set of a multiple objective linear programming problem.pdf:PDF},
  groups    = {bilinear},
  publisher = {Springer},
  timestamp = {2020-08-06},
  url       = {https://link.springer.com/article/10.1007/s10898-003-3784-7#citeas},
}

@Article{BurkhardtJr2013,
  author    = {Burkhardt Jr., Richard W.},
  journal   = {Genetics},
  title     = {Lamarck, evolution, and the inheritance of acquired characters},
  year      = {2013},
  issn      = {1943-2631},
  month     = {8},
  note      = {23908372[pmid]},
  number    = {4},
  pages     = {793--805},
  volume    = {194},
  abstract  = {Scientists are not always remembered for the ideas they cherished most. In the case of the French biologist Jean-Baptiste Lamarck, his name since the end of the nineteenth century has been tightly linked to the idea of the inheritance of acquired characters. This was indeed an idea that he endorsed, but he did not claim it as his own nor did he give it much thought. He took pride instead in advancing the ideas that (1) nature produced successively all the different forms of life on earth, and (2) environmentally induced behavioral changes lead the way in species change. This article surveys Lamarck's ideas about organic change, identifies several ironies with respect to how his name is commonly remembered, and suggests that some historical justice might be done by using the adjective "Lamarckian" to denote something more (or other) than a belief in the inheritance of acquired characters.},
  doi       = {10.1534/genetics.113.151852},
  file      = {:FILES/2013 - BurkhardtJr2013 - Lamarck, Evolution, and the Inheritance of Acquired Characters.pdf:PDF},
  groups    = {genetic algorithms},
  keywords  = {*Biological Evolution; Botany/history; France; History, 18th Century; History, 19th Century; Zoology/*history},
  language  = {eng},
  publisher = {Genetics Society of America},
  timestamp = {2020-06-05},
  url       = {https://pubmed.ncbi.nlm.nih.gov/23908372},
}

@Article{judice1991computational,
  author    = {J\'{u}dice, JJ and Faustino, Ana M},
  journal   = {Computers \& operations research},
  title     = {A computational analysis of {LCP} methods for bilinear and concave quadratic programming},
  year      = {1991},
  number    = {8},
  pages     = {645--654},
  volume    = {18},
  groups    = {bilinear},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@Article{Julian1998CS,
  author        = {Juli\'{a}n, P. and Jordan, M. and Desages, A.},
  journal       = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title         = {Canonical piecewise-linear approximation of smooth functions},
  year          = {1998},
  number        = {5},
  pages         = {567--571},
  volume        = {45},
  date-modified = {2016-04-05 02:46:48 +0000},
  file          = {:FILES/1998 - Julian1998CS - Canonical piecewise-linear approximation of smooth functions.pdf:PDF},
  groups        = {identification},
  timestamp     = {2020-08-06},
}

@Article{Julian1999CS,
  author        = {Juli\'{a}n, P. and Desages, A. and Agamennoni, O.},
  journal       = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title         = {High-level canonical piecewise linear representation using a simplicial partition},
  year          = {1999},
  number        = {4},
  pages         = {463--480},
  volume        = {46},
  date-modified = {2016-04-05 02:46:19 +0000},
  file          = {:FILES/1999 - Julian1999CS - High-level canonical piecewise linear representation using a simplicial partition.pdf:PDF},
  groups        = {identification},
  timestamp     = {2020-08-06},
}

@Article{julian1999parametrization,
  author        = {Juli\'{a}n, Pedro and Guivant, Jose and Desages, Alfredo},
  journal       = {International Journal of Control},
  title         = {A parametrization of piecewise linear {Lyapunov} functions via linear programming},
  year          = {1999},
  number        = {7-8},
  pages         = {702--715},
  volume        = {72},
  date-modified = {2016-04-05 02:46:55 +0000},
  file          = {:FILES/1999 - julian1999parametrization - A parametrization of piecewise linear Lyapunov functions via linear programming.pdf:PDF},
  groups        = {application},
  publisher     = {Taylor \& Francis},
  timestamp     = {2020-08-06},
}

@PhdThesis{Julian1999phd,
  author        = {Juli\'{a}n, P.},
  title         = {A high level canonical piecewise linear representation: {Theory} and applications},
  year          = {1999},
  date-modified = {2016-04-05 02:47:02 +0000},
  groups        = {identification},
  timestamp     = {2020-08-06},
  university    = {Universidad Nacional del Sur, Bahia Blanca, Argentina},
}

@Article{Julian2000CS,
  author        = {Juli\'{a}n, P. and Desages, A. and D\'Amico, B.},
  journal       = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title         = {Orthonormal high-level canonical {PWL} functions with applications to model reduction},
  year          = {2000},
  number        = {5},
  pages         = {702--712},
  volume        = {47},
  abstract      = {An inner product is defined for the linear vector space PWL/sub H/[S] of all the piecewise linear (PWL) continuous mappings defined over a rectangular compact set S, using a simplicial partition H. This permits us to assure that PWL/sub H/[S] is a Hilbert space. Then, the notion of orthogonality is introduced and orthonormal bases of PWL functions are formulated. A relevant consequence of the approach is that the problem of function approximation can be translated to the more studied field of approximation in Hilbert spaces of finite dimension. As will be shown, this powerful theoretical framework can be used to generate an optimal scheme for model reduction.},
  date-modified = {2016-04-05 02:46:34 +0000},
  file          = {:FILES/2000 - Julian2000CS - Orthonormal high-level canonical {PWL} functions with applications to model reduction.pdf:PDF},
  groups        = {identification},
  timestamp     = {2020-09-04},
}

@Article{Julian2003CS,
  author        = {Juli\'{a}n, P.},
  journal       = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title         = {The complete canonical piecewise-linear representation: {Functional} form for minimal degenerate intersections},
  year          = {2003},
  number        = {3},
  pages         = {387--396},
  volume        = {50},
  date-modified = {2016-04-05 02:46:41 +0000},
  groups        = {identification},
  timestamp     = {2020-08-06},
}

@Article{Jung2007lms,
  author    = {Jung, Kang-Mo},
  journal   = {Journal of Applied Statistics},
  title     = {Least trimmed squares estimator in the errors-in-variables model},
  year      = {2007},
  number    = {3},
  pages     = {331--338},
  volume    = {34},
  abstract  = {Abstract We propose a robust estimator in the errors-in-variables model using the least trimmed squares estimator. We call this estimator the orthogonal least trimmed squares (OLTS) estimator. We show that the OLTS estimator has the high breakdown point and appropriate equivariance properties. We develop an algorithm for the OLTS estimate. Simulations are performed to compare the efficiencies of the OLTS estimates with the total least squares (TLS) estimates and a numerical example is given to illustrate the effectiveness of the estimate.},
  doi       = {10.1080/02664760601004973},
  eprint    = {https://doi.org/10.1080/02664760601004973},
  file      = {:FILES/2007 - Jung2007lms - Least Trimmed Squares Estimator in the Errors-in-Variables Model.pdf:PDF},
  groups    = {LMS},
  publisher = {Taylor & Francis},
  url       = {https://doi.org/10.1080/02664760601004973},
}

@Article{Kahlert1990CS,
  author    = {Kahlert, C. and Chua, L. O.},
  journal   = {IEEE Transactions on Circuits and Systems},
  title     = {A generalized canonical piecewise-linear representation},
  year      = {1990},
  number    = {3},
  pages     = {373--383},
  volume    = {37},
  file      = {:FILES/1990 - Kahlert1990CS - A generalized canonical piecewise-linear representation.pdf:PDF},
  groups    = {identification},
  timestamp = {2020-08-06},
}

@Article{Kahlert1992,
  author    = {Kahlert, C. and Chua, L.O.},
  journal   = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title     = {The complete canonical piecewise-linear representation. {i}. the geometry of the domain space},
  year      = {1992},
  number    = {3},
  pages     = {222--236},
  volume    = {39},
  groups    = {identification},
  timestamp = {2020-08-06},
}

@Article{Kahneman1979,
  author    = {Kahneman, Daniel and Tversky, Amos},
  journal   = {Econometrica},
  title     = {Prospect theory: {An} analysis of decision under risk},
  year      = {1979},
  number    = {2},
  pages     = {263--292},
  volume    = {47},
  groups    = {prospect theory},
  timestamp = {2020-09-04},
}

@Article{kaiser2020rl,
  author        = {Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H. and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and Sepassi, Ryan and Tucker, George and Michalewski, Henryk},
  journal       = {CoRR},
  title         = {Model-based reinforcement learning for {Atari}},
  year          = {2019},
  volume        = {abs/1903.00374},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1903-00374.bib},
  eprint        = {1903.00374},
  groups        = {RL},
  timestamp     = {2020-08-06},
  url           = {http://arxiv.org/abs/1903.00374},
}

@InCollection{kallrath2004exact,
  author    = {Kallrath, Josef},
  booktitle = {Frontiers in global optimization},
  publisher = {Springer},
  title     = {Exact computation of global minima of a nonconvex portfolio optimization problem},
  year      = {2004},
  pages     = {237--254},
  abstract  = {The goal of this project was to compute minimal cost solutions satisfying the demand of pre-given product portfolios and to investigate the dependence of the fix costs and investment costs on the product portfolio.

The most important parameters characterizing the production facilities are the number and the size of the reactors. The production is subject to shelf-life constraints, i.e., products cannot be stored longer than one week.

Even if we analyze this problem under the simple assumption of constant batch sizes and limit ourself to only one time period covering one week, the computation of minimum cost scenarios requires that we determine global minima of a nonconvex MINLP problem. An objective function built up by the sum of concave functions and trilinear products terms involving the variables describing the number of batches, the utilization rates and the volume of the reactor are the nonlinear features in the model.

We have successfully applied four different solution techniques to solve this problem. (1) An exact transformation allows us to represent the nonlinear constraints by MILP constraints. Using piecewise linear approximations for the objective function the problem is solved with XPress-MP, a commercial MILP solver. (2) The local MINLP Branch-and-Bound solver SBB which is part of the modeling system GAMS. (3) The Branch\&Reduce Optimization Navigator (BARON) also called from GAMS. (4) A taylorized Branch\&Bound approach based on the construction of a lower bounding problem by underestimating the concave objective function with piecewise linear approximations described in a forecoming paper.

Our overall conclusion from a detailed analysis of specific portfolio cases is that the problem, for some cases, can be solved with nowadays standard solvers’ capacities but it requires a lot of CPU time. Therefore, in order not to cover only special cases and also to cope with the scaling properties of this problem suffering from weak lower bounds, we recommend to use taylorized approaches in addition.},
  file      = {:FILES/2004 - kallrath2004exact - Exact Computation of Global Minima of a Nonconvex Portfolio Optimization Problem.pdf:PDF},
  groups    = {global optimization, VaR, Portfolio Selection},
  timestamp = {2020-09-04},
}

@InCollection{kallrath2014computing,
  author    = {Kallrath, Josef and Rebennack, Steffen},
  booktitle = {Optimization in Science and Engineering},
  publisher = {Springer},
  title     = {Computing area-tight piecewise linear overestimators, underestimators and tubes for univariate functions},
  year      = {2014},
  pages     = {273--292},
  file      = {:FILES/2014 - kallrath2014computing - Computing area-tight piecewise linear overestimators, underestimators and tubes for univariate functions.pdf:PDF},
  groups    = {Approximation},
  timestamp = {2020-08-06},
}

@Article{kamthe2017data,
  author    = {Kamthe, Sanket and Deisenroth, Marc Peter},
  journal   = {arXiv preprint arXiv:1706.06491},
  title     = {Data-efficient reinforcement learning with probabilistic model predictive control},
  year      = {2017},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@Article{Kang1978Chua,
  author    = {Kang, S. and Chua, L. O.},
  journal   = {IEEE Transactions on Circuits and Systems},
  title     = {A global representation of multidimensional piecewise-linear functions with linear partitions},
  year      = {1978},
  number    = {11},
  pages     = {938=--940},
  volume    = {25},
  file      = {:FILES/1978 - Kang1978Chua - A global representation of multidimensional piecewise-linear functions with linear partitions.pdf:PDF},
  groups    = {identification},
  timestamp = {2020-08-06},
}

@Article{Karniel2001polyhedral,
  author    = {Karniel, A. and Meir, R. and Inbar, G.F.},
  journal   = {Neurocomputing},
  title     = {Polyhedral mixture of linear experts for many-to-one mapping inversion and multiple controllers},
  year      = {2001},
  pages     = {31--49},
  volume    = {37},
  groups    = {mathematical basis},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@Article{karuppiah2006global,
  author    = {Karuppiah, Ramkumar and Grossmann, Ignacio E},
  journal   = {Computers \& Chemical Engineering},
  title     = {Global optimization for the synthesis of integrated water systems in chemical processes},
  year      = {2006},
  number    = {4},
  pages     = {650--673},
  volume    = {30},
  groups    = {global optimization},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@Article{katzenelson1965algorithm,
  author    = {Katzenelson, Jacob},
  journal   = {Bell System Technical Journal},
  title     = {An algorithm for solving nonlinear resistor networks},
  year      = {1965},
  number    = {8},
  pages     = {1605--1620},
  volume    = {44},
  file      = {:FILES/1965 - katzenelson1965algorithm - An algorithm for solving nonlinear resistor networks.pdf:PDF},
  groups    = {global optimization},
  timestamp = {2020-08-06},
}

@Article{Kavenaar1992CS,
  author    = {Kevenaar, T.A.M. and Leenaerts, D.M.W.},
  journal   = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title     = {A comparison of piecewise-linear model descriptions},
  year      = {1992},
  number    = {12},
  pages     = {996--1004},
  volume    = {39},
  abstract  = {Current methods for storing piecewise-linear mappings are discussed and compared. To do so, the model descriptions are all transformed into a general form. Among the aspects compared are the ease of modeling, the class of functions that can be modeled using a certain model description, and the suitability of using the models in simulators. No best model description is found, but it is made apparent that some models are better suited for certain applications than others},
  doi       = {10.1109/81.207720},
  file      = {:FILES/1992 - Kavenaar1992CS - A comparison of piecewise-linear model descriptions.pdf:PDF},
  groups    = {identification},
  timestamp = {2020-08-06},
  url       = {https://ieeexplore.ieee.org/document/207720/},
}

@TechReport{Ke2009,
  author      = {Ke, Tang and Xiaodong, Li and N., Suganthan P. and Zhenyu, Yang and Thomas, Weise},
  institution = {University of Science and Technology of China},
  title       = {Benchmark functions for the cec’2010 special session and competition on large scale global optimization},
  year        = {2009},
  file        = {:FILES/2009 - Ke2009 - Benchmark functions for the CEC’2010 special session and competition on large scale global optimization.pdf:PDF},
  groups      = {benchmark},
  timestamp   = {2020-06-08},
}

@ARTICLE{Keating2002,
 AUTHOR = {Keating, Con and Shadwick, William F.},
 ISSUE = {3},
 JOURNAL = {Journal of Performance Measurement},
 PAGES = {1--42},
 TITLE = {A universal performance measure},
 TYPE = {Journal Article},
 VOLUME = {6},
 YEAR = {2002}
}

@Article{Keha2004models,
  author    = {Keha, A.B. and Farias, I.R. and Nemhauser, G.L.},
  journal   = {Operations Research Letters},
  title     = {Models for representing piecewise linear cost functions},
  year      = {2004},
  number    = {1},
  pages     = {44--48},
  volume    = {32},
  groups    = {identification},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@Article{Keha2006branch,
  author    = {Keha, Ahmet B. and Farias, Ismael R. and Nemhauser, George L.},
  journal   = {Operations Research},
  title     = {A branch-and-cut algorithm without binary variables for nonconvex piecewise linear optimization},
  year      = {2006},
  number    = {5},
  pages     = {847--858},
  volume    = {54},
  groups    = {optimization},
  timestamp = {2020-08-06},
}

@InProceedings{Kennedy1995,
  author    = {Kennedy, J. and Eberhart, R.},
  booktitle = {Proceedings of IEEE International Conference on Neural Networks},
  title     = {Particle swarm optimization},
  year      = {1995},
  pages     = {1942--1948},
  volume    = {4},
  file      = {:FILES/1995 - Kennedy1995 - Particle swarm optimization.pdf:PDF},
  groups    = {PSO},
  timestamp = {2020-08-06},
}

@Article{kettani1990equivalent,
  author    = {Kettani, Ossama and Oral, Muhittin},
  journal   = {Management Science},
  title     = {Equivalent formulations of nonlinear integer problems for efficient optimization},
  year      = {1990},
  number    = {1},
  pages     = {115--119},
  volume    = {36},
  groups    = {MILP},
  publisher = {INFORMS},
  timestamp = {2020-08-06},
}

@Article{Kevenaar1994CS,
  author    = {Kevenaar, T. A. M. and Leenaerts, D. M. W. and Bokhoven, W. M. G.},
  journal   = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title     = {Extensions to {Chua's} explicit piecewise-linear function descriptions},
  year      = {1994},
  number    = {4},
  pages     = {308--314},
  volume    = {41},
  abstract  = {In this paper, we extend the class of explicit piecewise linear descriptions in the modulus form that was recently introduced by Chua cum suis. This is achieved by transforming a special form of a more general implicit description given by Van Bokhoven (1981) using the modulus transformation. This results in a set of base functions that can be used to compose the more general explicit description. It is shown that with this set all previously presented explicit PL descriptions can be covered. Furthermore, we pose some problems that occur when trying to construct an even more general description},
  file      = {:FILES/1994 - Kevenaar1994CS - Extensions to {Chua's} explicit piecewise-linear function descriptions.pdf:PDF},
  groups    = {identification},
  timestamp = {2020-09-04},
}

@Article{kibzun2015comparison,
  author    = {Kibzun, Andrey},
  journal   = {Applied Stochastic Models in Business and Industry},
  title     = {Comparison of two algorithms for solving a two-stage bilinear stochastic programming problem with quantile criterion},
  year      = {2015},
  number    = {6},
  pages     = {862--874},
  volume    = {31},
  groups    = {bilinear},
  publisher = {Wiley Online Library},
  timestamp = {2020-08-06},
}

@Article{Kim2000,
  author    = {Kim, Dukwon and Pardalos, PanosM.},
  journal   = {Journal of Global Optimization},
  title     = {A dynamic domain contraction algorithm for nonconvex piecewise linear network flow problems},
  year      = {2000},
  number    = {1-4},
  pages     = {225--234},
  volume    = {17},
  groups    = {optimization},
  language  = {English},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2020-08-06},
}

@Article{kim2006firLP,
  author     = {Kim, Joon Tae and Oh, Woo Jin and Lee, Yong Hoon},
  journal    = {IEEE Transactions on Signal Processing},
  title      = {Design of nonuniformly spaced linear-phase {FIR} filters using mixed integer linear programming},
  year       = {1996},
  issn       = {1941-0476},
  month      = {1},
  number     = {1},
  pages      = {123--126},
  volume     = {44},
  abstract   = {An optimization problem for designing a nonuniformly spaced linear-phase FIR filter with minimal complexity is formulated and solved by mixed integer linear programming (MILP). Examples illustrate that the proposed method is useful for designing a wide range of filter types and can outperform subset selection-based design methods.},
  doi        = {10.1109/78.482018},
  file       = {:FILES/1996 - kim2006firLP - Design of nonuniformly spaced linear-phase FIR filters using mixed integer linear programming.pdf:PDF},
  groups     = {sparse, MILP},
  keywords   = {FIR filters;linear programming;integer programming;optimisation;delay circuits;design;nonuniformly spaced linear-phase FIR filters;mixed integer linear programming;optimization problem;minimal complexity;Finite impulse response filter;Nonlinear filters;Mixed integer linear programming;Costs;Design optimization;Design methodology;Arithmetic;Delay;Narrowband;Wideband, read},
  readstatus = {read},
}

@Article{kirkpatrick1983,
  author    = {Kirkpatrick, A. and Gelatt, S. D. and Vecchi, M. P.},
  journal   = {Science},
  title     = {Optimization by simulated annealing},
  year      = {1983},
  number    = {4598},
  pages     = {671--680},
  volume    = {220},
  file      = {:FILES/1983 - kirkpatrick1983 - Optimization by Simulated Annealing.pdf:PDF},
  groups    = {Simulated Annealing},
  timestamp = {2020-08-06},
}

@Book{kiwiel1985methods,
  author    = {Kiwiel, Krzysztof C.},
  editor    = {Bold, A. and Eckmann, B.},
  publisher = {Springer-Verlag},
  title     = {Methods of descent for nondifferentiable optimization},
  year      = {1985},
  address   = {Berlin Heidelberg New York Tokyo},
  series    = {Lecture Notes in Mathematics},
  volume    = {1133},
  file      = {:FILES/1985 - kiwiel1985methods - Methods of Descent for Nondifferentiable Optimization.pdf:PDF},
  groups    = {nonsmooth optimization},
  timestamp = {2020-08-06},
}

@TechReport{Klopf1972BrainFA,
  author    = {Klopf, A. Harry},
  title     = {Brain function and adaptive systems: {A} heterostatic theory},
  year      = {1972},
  groups    = {genetic algorithms},
  institute = {United States Air Force},
  timestamp = {2020-08-06},
}

@Article{kobberling2005index,
  author    = {K\"{o}bberling, Veronika and Wakker, Peter P},
  journal   = {Journal of Economic Theory},
  title     = {An index of loss aversion},
  year      = {2005},
  number    = {1},
  pages     = {119--131},
  volume    = {122},
  groups    = {Portfolio Selection},
  publisher = {Elsevier},
  timestamp = {2020-09-04},
}

@ARTICLE{kochenberger1973solution,
 AUTHOR = {Kochenberger, Gary A and Woolsey, RED and McCarl, Bruce A},
 GROUPS = {SGP},
 JOURNAL = {Journal of the Operational Research Society},
 NUMBER = {2},
 PAGES = {285--294},
 PUBLISHER = {Taylor \& Francis},
 TIMESTAMP = {2020-07-16},
 TITLE = {On the solution of geometric programs via separable programming},
 VOLUME = {24},
 YEAR = {1973}
}

@Article{kohonen1982self,
  author    = {Kohonen, Teuvo},
  journal   = {Biological cybernetics},
  title     = {Self-organized formation of topologically correct feature maps},
  year      = {1982},
  number    = {1},
  pages     = {59--69},
  volume    = {43},
  file      = {:FILES/1982 - kohonen1982self - Self-Organized Formation of Topologically Correct Feature Maps.pdf:PDF},
  groups    = {machine learning},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{kolodziej2013global,
  author    = {Kolodziej, Scott and Castro, Pedro M. and Grossmann, Ignacio E.},
  journal   = {Journal of Global Optimization},
  title     = {Global optimization of bilinear programs with a multiparametric disaggregation technique},
  year      = {2013},
  number    = {4},
  pages     = {1039--1063},
  volume    = {57},
  file      = {:FILES/2013 - kolodziej2013global - Global Optimization of Bilinear Programs with a Multiparametric Disaggregation Technique.pdf:PDF},
  groups    = {bilinear},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@TechReport{konno1971bilinear,
  author      = {Konno, Hiroshi},
  institution = {STANFORD UNIV CALIF DEPT OF OPERATIONS RESEARCH},
  title       = {Bilinear programming: {Part} i. algorithm for solving bilinear programs.},
  year        = {1971},
  groups      = {bilinear},
  timestamp   = {2020-08-06},
}

@Article{konno1976cutting,
  author    = {Konno, Hiroshi},
  journal   = {Mathematical Programming},
  title     = {A cutting plane algorithm for solving bilinear programs},
  year      = {1976},
  number    = {1},
  pages     = {14--27},
  volume    = {11},
  groups    = {bilinear},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{konno1990piecewise,
  author    = {Konno, Hiroshi},
  journal   = {Journal of the Operations Research Society of Japan},
  title     = {Piecewise linear risk function and portfolio optimization},
  year      = {1990},
  number    = {2},
  pages     = {139--156},
  volume    = {33},
  groups    = {application, Portfolio Selection},
  timestamp = {2020-09-04},
}

@Article{konno1991meanabsolute,
  author    = {Konno, Hiroshi and Yamazaki, Hiroaki},
  journal   = {Management Science},
  title     = {Mean-absolute deviation portfolio optimization model and its applications to {Tokyo} stock market},
  year      = {1991},
  number    = {5},
  pages     = {519--531},
  volume    = {37},
  groups    = {mean variance},
  timestamp = {2020-09-04},
}

@InProceedings{Kort1972,
  author    = {Kort, B. W. and Bertsekas, D. P.},
  booktitle = {Proceedings of the 1972 IEEE Conference on Decision and Control and 11th Symposium on Adaptive Processes},
  title     = {A new penalty function method for constrained minimization},
  year      = {1972},
  month     = {12},
  pages     = {162--166},
  doi       = {10.1109/CDC.1972.268971},
  file      = {:FILES/1972 - Kort1972 - A new penalty function algorithm for constrained minimization.pdf:PDF},
  groups    = {global optimization},
  issn      = {null},
  keywords  = {Minimization methods;Functional programming;Mathematical programming;Lagrangian functions;Convergence},
  timestamp = {2020-08-31},
}

@Article{Kortanek1997,
  author    = {Kortanek, K. O. and Xu, Xiaojie and Ye, Yinyu},
  journal   = {Mathematical Programming},
  title     = {An infeasible interior-point algorithm for solving primal and dual geometric programs},
  year      = {1997},
  issn      = {1436-4646},
  month     = {1},
  number    = {1},
  pages     = {155--181},
  volume    = {76},
  day       = {01},
  doi       = {10.1007/BF02614382},
  file      = {:FILES/1997 - Kortanek1997 - An infeasible interior-point algorithm for solving primal and dual geometric programs.pdf:PDF},
  groups    = {SGP},
  timestamp = {2020-07-16},
}

@InProceedings{koutnik2014online,
  author       = {Koutnik, Jan and Schmidhuber, J\"{u}rgen and Gomez, Faustino},
  booktitle    = {International conference on simulation of adaptive behavior},
  title        = {Online evolution of deep convolutional network for vision-based reinforcement learning},
  year         = {2014},
  organization = {Springer},
  pages        = {260--269},
  groups       = {Neural Network},
  timestamp    = {2020-08-06},
}

@Misc{Kovalsky2020,
  author    = {Kovalsky, Shahar Z. and Aigerman, Noam and Daubechies, Ingrid and Kazhdan, Michael and Lu, Jianfeng and Steinerberger, Stefan},
  title     = {Non-convex planar harmonic maps},
  year      = {2020},
  file      = {:FILES/2020 - Kovalsky2020 - Non-convex planar harmonic maps.pdf:PDF},
  groups    = {mathematical basis},
  journal   = {arXiv preprint arXiv:2001.01322},
  timestamp = {2020-08-06},
}

@InProceedings{Kramer2009,
  author    = {Kramer, Oliver and Koch, Patrick},
  booktitle = {{KI} 2009: Advances in Artificial Intelligence, 32nd Annual German Conference on AI, Paderborn, Germany, September 15-18, 2009. Proceedings},
  title     = {Rake selection: {A} novel evolutionary multi-objective optimization algorithm},
  year      = {2009},
  editor    = {Mertsching, B\"{a}rbel and Hund, Marcus and Aziz, Muhammad Zaheer},
  pages     = {177--184},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  volume    = {5803},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/ki/KramerK09.bib},
  doi       = {10.1007/978-3-642-04617-9\_23},
  file      = {:FILES/2009 - Kramer2009 - Rake Selection- A Novel Evolutionary Multi-Objective Optimization Algorithm.pdf:PDF},
  groups    = {genetic algorithms},
  timestamp = {2020-06-05},
  url       = {https://doi.org/10.1007/978-3-642-04617-9_23},
}

@Article{Kretowska2017,
  author    = {Kretowska, Malgorzata},
  journal   = {Artificial Intelligence in Medicine},
  title     = {Piecewise-linear criterion functions in oblique survival tree induction},
  year      = {2017},
  issn      = {0933-3657},
  pages     = {32 -- 39},
  volume    = {75},
  abstract  = {Objective Recursive partitioning is a common, assumption-free method of survival data analysis. It focuses mainly on univariate trees, which use splits based on a single variable in each internal node. In this paper, I provide an extension of an oblique survival tree induction technique, in which axis-parallel splits are replaced by hyperplanes, dividing the feature space into areas with a homogeneous survival experience. Method and materials The proposed tree induction algorithm consists of two steps. The first covers the induction of a large tree with internal nodes represented by hyperplanes, whose positions are calculated by the minimization of a piecewise-linear criterion function, the dipolar criterion. The other phase uses a split-complexity algorithm to prune unnecessary tree branches and a 10-fold cross-validation technique to choose the best tree. The terminal nodes of the final tree are characterised by Kaplan-Meier survival functions. A synthetic data set was used to test the performance, while seven real data sets were exploited to validate the proposed method. Results The evaluation of the method was focused on two features: predictive ability and tree size. These were compared with two univariate tree models: the conditional inference tree and recursive partitioning for survival trees, respectively. The comparison of the predictive ability, expressed as an integrated Brier score, showed no statistically significant differences (p=0.486) among the three methods. Similar results were obtained for the tree size (p=0.11), which was calculated as a median value over 20 runs of a 10-fold cross-validation. Conclusions The predictive ability of trees generated using piecewise-linear criterion functions is comparable to that of univariate tree-based models. Although a similar conclusion may be drawn from the analysis of the tree size, in the majority of the studied cases, the number of nodes of the dipolar tree is one of the smallest among all the methods.},
  doi       = {https://doi.org/10.1016/j.artmed.2016.12.004},
  file      = {:FILES/2017 - Kretowska2017 - Piecewise-linear criterion functions in oblique survival tree induction.pdf:PDF},
  groups    = {application},
  keywords  = {Piecewise-linear criterion function, Survival tree, Oblique splits, Right-censored data},
  timestamp = {2020-08-06},
  url       = {https://www.sciencedirect.com/science/article/pii/S0933365716302792},
}

@Misc{kuester1974optimization,
  author    = {Kuester, James L and Mize, Joe H and Griffin, DS},
  title     = {Optimization techniques with {Fortran}},
  year      = {1974},
  publisher = {American Society of Mechanical Engineers Digital Collection},
  timestamp = {2020-08-06},
}

@Article{kuh1971nonlinear,
  author    = {Kuh, Ernest S. and Hajj, Ibrahim H.},
  journal   = {Proceedings of the IEEE},
  title     = {Nonlinear circuit theory: {Resistive} networks},
  year      = {1971},
  number    = {3},
  pages     = {340--355},
  volume    = {59},
  file      = {:FILES/1971 - kuh1971nonlinear - Nonlinear circuit theory Resistive networks.pdf:PDF},
  groups    = {machine learning},
  publisher = {IEEE},
  timestamp = {2020-08-06},
}

@Article{Kumar2012,
  author     = {Kumar, Rakesh and Jyotishree},
  journal    = {International Journal of Machine Learning and Computing},
  title      = {Blending roulette wheel selection \& rank selection in genetic algorithms},
  year       = {2012},
  issn       = {2010-3700},
  number     = {4},
  pages      = {365--370},
  volume     = {2},
  abstract   = {Both exploration and exploitation are the techniques employed normally by all the optimization techniques. In genetic algorithms, the roulette wheel selection operator has essence of exploitation while rank selection is influenced by exploration. In this paper, a blend of these two selection operators is proposed that is a perfect mix of both i.e. exploration and exploitation. The blended selection operator is more exploratory in nature in initial iterations and with the passage of time, it gradually shifts towards exploitation. The proposed solution is implemented in MATLAB using travelling salesman problem and the results were compared with roulette wheel selection and rank selection with different problem sizes.},
  doi        = {10.7763/ijmlc.2012.v2.146},
  file       = {:FILES/2012 - Kumar2012 - Blending roulette wheel selection \& rank selection in genetic algorithms.pdf:PDF},
  groups     = {genetic algorithms},
  keywords   = {read},
  readstatus = {read},
  timestamp  = {2020-06-05},
}

@InProceedings{Kuramoto2019,
  author    = {Kuramoto, T. and Yamamura, K.},
  booktitle = {2019 IEEE Asia Pacific Conference on Postgraduate Research in Microelectronics and Electronics (PrimeAsia)},
  title     = {An efficient method for finding all characteristic curves of piecewise-linear resistive circuits using integer programming},
  year      = {2019},
  month     = {11},
  pages     = {41--44},
  doi       = {10.1109/PrimeAsia47521.2019.8950733},
  groups    = {application, MILP},
  issn      = {2159-2144},
  timestamp = {2020-08-06},
}

@Article{kurutach2018model,
  author    = {Kurutach, Thanard and Clavera, Ignasi and Duan, Yan and Tamar, Aviv and Abbeel, Pieter},
  journal   = {arXiv preprint arXiv:1802.10592},
  title     = {Model-ensemble trust-region policy optimization},
  year      = {2018},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@Article{kvanli1980financial,
  author    = {Kvanli, Alan H.},
  journal   = {Omega},
  title     = {Financial planning using goal programming},
  year      = {1980},
  number    = {2},
  pages     = {207--218},
  volume    = {8},
  file      = {:FILES/1980 - kvanli1980financial - Financial planning using goal programming.pdf:PDF},
  groups    = {Portfolio Selection},
  publisher = {Elsevier},
  timestamp = {2020-09-04},
}

@InProceedings{Kwan2016bee,
  author     = {Kwan, Hon Keung and Raju, R.},
  booktitle  = {2016 8th International Conference on Wireless Communications Signal Processing (WCSP)},
  title      = {Minimax design of linear phase {FIR} differentiators using artificial bee colony algorithm},
  year       = {2016},
  month      = {10},
  pages      = {1--4},
  abstract   = {Artificial bee colony (ABC) algorithm is a swarm based meta-heuristic algorithm inspired by the foraging behavior of honey bees. Due to its simplicity, the ABC algorithm is used for minimax design of linear phase FIR fullband digital differentiators in this paper. Results in term of peak error obtained from designed digital differentiator examples indicate that the approach can reach smaller peak errors when compared to those obtained by the least-squares error minimization method and the optimal Parks-McClellan algorithm.},
  doi        = {10.1109/WCSP.2016.7752727},
  file       = {:FILES/2016 - Kwan2016bee - Minimax Design of Linear Phase FIR Differentiators using Artificial Bee Colony Algorithm.pdf:PDF},
  groups     = {FIR filter design, ABC},
  issn       = {2472-7628},
  keywords   = {FIR filters;least squares approximations;linear phase filters;minimisation;artificial bee colony algorithm;ABC algorithm;swarm-based metaheuristic algorithm;honey bees foraging behavior;linear phase FIR fullband digital differentiator minimax design;least-squares error minimization method;optimal Parks-McClellan algorithm;Finite impulse response filters;Algorithm design and analysis;Optimization;Signal processing algorithms;Approximation algorithms;Frequency response;Digital differentiators;Fullband digital differentiator design;Type 4 linear phase FIR digital filters;Minimax design;Artificial Bee Colony Algorithm;Evolutionary optimization;Global optimization, read},
  readstatus = {read},
}

@InProceedings{Kwan2016fircuckoo,
  author     = {Kwan, Hon Keung and Liang, J.},
  booktitle  = {2016 8th International Conference on Wireless Communications Signal Processing (WCSP)},
  title      = {Minimax design of linear phase {FIR} filters using cuckoo search algorithm},
  year       = {2016},
  month      = {10},
  pages      = {1--4},
  abstract   = {A method for minimax design of linear phase finite impulse response (FIR) digital filters using cuckoo search algorithm (CSA) is presented. Lowpass and bandpass digital filters are used as filter examples. Equiripple linear phase FIR digital filter design results indicate that the peak errors in passband and stopband(s) obtained using the cuckoo search algorithm are similar to those obtained by the Parks-McClellan optimal method but smaller than those obtained by the particle swarm optimization method.},
  doi        = {10.1109/WCSP.2016.7752723},
  file       = {:FILES/2016 - Kwan2016fircuckoo - Minimax design of linear phase FIR filters using cuckoo search algorithm.pdf:PDF},
  groups     = {FIR filter design, Heuristics},
  issn       = {2472-7628},
  keywords   = {band-pass filters;FIR filters;linear phase filters;low-pass filters;minimax techniques;particle swarm optimisation;search problems;minimax design;cuckoo search algorithm;linear phase finite impulse response digital filters;lowpass digital filters;bandpass digital filters;equiripple linear phase FIR digital filter design;Parks-McClellan optimal method;particle swarm optimization method;Finite impulse response filters;Algorithm design and analysis;Band-pass filters;Passband;Signal processing algorithms;Optimization;Digital filter design;Type 1 linear phase FIR digital filters;Lowpass digital filters;Bandpass digital filters;Minimax design;Cuckoo search algorithm;Evolutionary optimization;Global optimization, read},
  readstatus = {read},
}

@InProceedings{Kwan2016teaching,
  author    = {Kwan, Hon Keung and Zhang, M.},
  booktitle = {2016 8th International Conference on Wireless Communications Signal Processing (WCSP)},
  title     = {Minimax design of linear phase {FIR} hilbert transformer using teaching-learning-based optimization},
  year      = {2016},
  month     = {10},
  pages     = {1--4},
  abstract  = {In this paper, teaching-learning-based optimization (TLBO) is used for minimax design of linear phase finite impulse response (FIR) digital Hilbert transformers. TLBO is a population-based and heuristic search algorithm which is parameter-free and exhibits a strong convergence ability. The results obtained from using TLBO to design Type 4 linear phase FIR highpass digital Hilbert transformers indicate that it is an effective method to reach smaller equiripple peak errors as compared to those obtained by the least-squares error minimization method and the optimal Parks-McClellan algorithm.},
  doi       = {10.1109/WCSP.2016.7752728},
  file      = {:FILES/2016 - Kwan2016teaching - Minimax design of linear phase FIR Hilbert transformer using teaching-learning-based optimization.pdf:PDF},
  groups    = {FIR filter design, Heuristics},
  issn      = {2472-7628},
  keywords  = {FIR filters;Hilbert transforms;least squares approximations;minimisation;signal processing;linear phase finite impulse response digital Hilbert transformers;linear phase FIR Hilbert transformer;teaching learning based optimization;TLBO;heuristic search algorithm;least squares error minimization method;Parks-McClellan algorithm;Finite impulse response filters;Optimization;Algorithm design and analysis;Signal processing algorithms;Transforms;Approximation algorithms;Digital Hilbert transformer;Highpass digital Hilbert transformer design;Type 4 linear phase FIR digital filters;Minimax design;Teaching-learning-based optimization;Evolutionary optimization;Global optimization},
}

@InProceedings{Kwan2018fir,
  author     = {Kwan, Hon Keung and Liang, J. and Jiang, Aimin},
  booktitle  = {2018 IEEE 23rd International Conference on Digital Signal Processing {(DSP)}},
  title      = {Sparse linear phase {FIR} filter design using iterative {CSA}},
  year       = {2018},
  month      = {11},
  pages      = {1--4},
  abstract   = {In this paper, sparse linear phase FIR Iowpass digital filter design using iterative cuckoo search algorithm with step-descendant coefficient thresholding is presented. During each iteration, the least-squares frequency response error is minimized using cuckoo search algorithm. A step-descendant coefficient threshold is used to iteratively update the zero-valued filter coefficients. With the same set of sparsity levels, the obtained design results indicate that smaller weighted least-squares errors and slightly smaller peak magnitude errors can be obtained when compared to those of a recent design method.},
  doi        = {10.1109/ICDSP.2018.8631659},
  file       = {:FILES/2018 - Kwan2018fir - Sparse Linear Phase FIR Filter Design using Iterative CSA.pdf:PDF},
  groups     = {sparse},
  issn       = {2165-3577},
  keywords   = {FIR filters;frequency response;iterative methods;least squares approximations;search problems;sparse linear phase FIR filter design;iterative CSA;sparse linear phase FIR Iowpass digital filter design;iterative cuckoo search algorithm;step-descendant coefficient thresholding;least-squares frequency response error;zero-valued filter coefficients;least-squares errors;peak magnitude errors;Finite impulse response filters;Signal processing algorithms;Optimization;Maximum likelihood detection;Nonlinear filters;Filtering algorithms;Sparse linear phase FIR filter design;Weighted least-squares error minimization;Iterative cuckoo search;Step-descendant coefficient thresholding, read},
  readstatus = {read},
}

@InProceedings{kwan2018mocsa,
  author     = {Kwan, Hon Keung and Liang, J. and Jiang, Aimin},
  booktitle  = {2018 IEEE 61st International Midwest Symposium on Circuits and Systems (MWSCAS)},
  title      = {Sparse {FIR} filter design using iterative {MOCSA}},
  year       = {2018},
  month      = {8},
  pages      = {952--955},
  abstract   = {In this paper, sparse FIR digital filter design using iterative multiobjective cuckoo search algorithm (MOCSA) is presented. The least-squares frequency response error and the l1 norm of selected non-zero filter coefficients of a sparse digital filter are jointly minimized by iterative multiobjective cuckoo search algorithm until convergence. After convergence, a final round of single-objective cuckoo search is performed to minimize the least-square frequency response error of the sparse digital filter to arrive at an optimal solution. With the same set of sparsity levels, the sparse digital filter design results obtained by the iterative MOCSA indicates that smaller weighted least-squares frequency response errors can be obtained as compared to those of another optimization method.},
  doi        = {10.1109/MWSCAS.2018.8623954},
  file       = {:FILES/2018 - kwan2018mocsa - Sparse FIR Filter Design using Iterative MOCSA.pdf:PDF},
  groups     = {sparse},
  issn       = {1558-3899},
  keywords   = {FIR filters;frequency response;iterative methods;least squares approximations;optimisation;iterative multiobjective cuckoo search algorithm;single-objective cuckoo search;iterative MOCSA;least-squares frequency response error;sparse FIR digital filter design;nonzero filter coefficients;Finite impulse response filters;Frequency response;Optimization;IIR filters;Convergence;Delays;Sparse FIR digital filter design;Least-squares error minimization;l1-norm minimization;Iterative multiobjective cuckoo search algorithm, read},
  readstatus = {read},
}

@Article{Lachhwani2019,
  author    = {Lachhwani, Kailash},
  journal   = {Archives of Computational Methods in Engineering},
  title     = {Application of neural network models for mathematical programming problems: {A} state of art review},
  year      = {2019},
  pages     = {1--12},
  file      = {:FILES/2019 - Lachhwani2019 - Application of Neural Network Models for Mathematical Programming Problems- A State of Art Review.pdf:PDF},
  groups    = {Application},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@InProceedings{ladicky2011locally,
  author    = {Ladicky, Lubor and Torr, Philip},
  booktitle = {Proceedings of the 28th International Conference on Machine Learning (ICML-11)},
  title     = {Locally linear support vector machines},
  year      = {2011},
  pages     = {985--992},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@Misc{Lakshminarayanan2016,
  author    = {Lakshminarayanan, Aravind S. and Sharma, Sahil and Ravindran, Balaraman},
  title     = {Dynamic frame skip deep {Q} network},
  year      = {2016},
  file      = {:FILES/2016 - Lakshminarayanan2016 - Dynamic frame skip deep {Q} network.pdf:PDF},
  groups    = {RL},
  timestamp = {2020-08-06},
  url       = {https://arxiv.org/abs/1605.05365},
}

@ARTICLE{lange2000optimization,
 AUTHOR = {Lange, Kenneth and Hunter, David R and Yang, Ilsoon},
 JOURNAL = {Journal of computational and graphical statistics},
 NUMBER = {1},
 PAGES = {1--20},
 PUBLISHER = {Taylor \& Francis},
 TITLE = {Optimization transfer using surrogate objective functions},
 VOLUME = {9},
 YEAR = {2000}
}

@InProceedings{lange2010deep,
  author       = {Lange, Sascha and Riedmiller, Martin},
  booktitle    = {The 2010 International Joint Conference on Neural Networks (IJCNN)},
  title        = {Deep auto-encoder neural networks in reinforcement learning},
  year         = {2010},
  organization = {IEEE},
  pages        = {1--8},
  groups       = {RL},
  timestamp    = {2020-08-06},
}

@InProceedings{lange2012autonomous,
  author       = {Lange, Sascha and Riedmiller, Martin and Voigtl\"{a}nder, Arne},
  booktitle    = {The 2012 international joint conference on neural networks (IJCNN)},
  title        = {Autonomous reinforcement learning on raw visual input data in a real world application},
  year         = {2012},
  organization = {IEEE},
  pages        = {1--8},
  groups       = {RL},
  timestamp    = {2020-08-06},
}

@Article{lange2014mm,
  author    = {Lange, Kenneth and Zhou, Hua},
  journal   = {Mathematical programming},
  title     = {{MM} algorithms for geometric and signomial programming},
  year      = {2014},
  number    = {1-2},
  pages     = {339--356},
  volume    = {143},
  file      = {:FILES/2014 - lange2014mm - MM algorithms for geometric and signomial programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-08-31},
}

@Article{Larranaga1999,
  author   = {Larra\~{n}aga, P. and Kuijpers, C. M. H. and Murga, R. H. and Inza, I. and Dizdarevic, S.},
  journal  = {Artificial Intelligence Review},
  title    = {Genetic algorithms for the travelling salesman problem: {A} review of representations and operators},
  year     = {1999},
  issn     = {1573-7462},
  number   = {2},
  pages    = {129--170},
  volume   = {13},
  abstract = {This paper is the result of a literature study carried out by the authors. It is a review of the different attempts made to solve the Travelling Salesman Problem with Genetic Algorithms. We present crossover and mutation operators, developed to tackle the Travelling Salesman Problem with Genetic Algorithms with different representations such as: binary representation, path representation, adjacency representation, ordinal representation and matrix representation. Likewise, we show the experimental results obtained with different standard examples using combination of crossover and mutation operators in relation with path representation.},
  doi      = {10.1023/A:1006529012972},
  file     = {:FILES/1999 - Larranaga1999 - Genetic Algorithms for the Travelling Salesman Problem A Review of Representations and Operators.pdf:PDF},
  groups   = {genetic algorithms},
  url      = {https://doi.org/10.1023/A:1006529012972},
}

@InBook{Larsen2002,
  author    = {Larsen, Nicklas and Mausser, Helmut and Uryasev, Stanislav},
  editor    = {Pardalos, Panos M. and Tsitsiringos, Vassilis K.},
  pages     = {19--46},
  publisher = {Springer US},
  title     = {Algorithms for optimization of value-at-risk},
  year      = {2002},
  address   = {Boston, MA},
  series    = {Applied Optimization},
  volume    = {70},
  booktitle = {Financial engineering, e-commerce and supply chain},
  file      = {:FILES/2002 - Larsen2002 - Algorithms for Optimization of Value-at-Risk.pdf:PDF},
  groups    = {VaR, TEC},
  timestamp = {2020-09-05},
}

@Article{lasserre1998integration,
  author    = {Lasserre, Jean},
  journal   = {Proceedings of the American Mathematical Society},
  title     = {Integration on a convex polytope},
  year      = {1998},
  number    = {8},
  pages     = {2433--2441},
  volume    = {126},
  groups    = {mathematical basis},
  timestamp = {2020-08-06},
}

@Article{Lawson1964,
  author    = {Lawson, Charles L.},
  journal   = {Numerische Mathematik},
  title     = {Characteristic properties of the segmented rational minmax approximation problem},
  year      = {1964},
  issn      = {0945-3245},
  month     = {12},
  number    = {1},
  pages     = {293--301},
  volume    = {6},
  day       = {01},
  doi       = {10.1007/BF01386077},
  file      = {:FILES/1964 - Lawson1964 - Characteristic properties of the segmented rational minmax approximation problem.pdf:PDF},
  groups    = {Approximation},
  timestamp = {2020-08-06},
  url       = {https://doi.org/10.1007/BF01386077},
}

@Article{Laxmi2020,
  author    = {Laxmi, Scindhiya and Gupta, Shiv Kumar},
  journal   = {Neural Processing Letters},
  title     = {Intuitionistic fuzzy proximal support vector machines for pattern classification},
  year      = {2020},
  issn      = {1573-773X},
  month     = {6},
  number    = {3},
  pages     = {2701--2735},
  volume    = {51},
  abstract  = {Support vector machine is a powerful technique for classification and regression problems. In the binary data problems, it classifies the points by assigning them to one of the two disjoint halfspaces. However, this method fails to handle the noises and outliers present in the dataset and the solution of a large-sized quadratic programming problem is required to obtain the decision surface in input or in feature space. We propose the intuitionistic fuzzy proximal support vector machine (IFPSVM) which classifies the patterns according to its proximity with the two parallel planes that are kept as distant as possible from each other. These two parallel `proximal' planes can be obtained by solving a system of linear equations only. There is an intuitionistic fuzzy number associated with each training point which is framed by its degree of membership and non-membership. The membership degree of a pattern considers its distance from the corresponding class center and the degree of non-membership of a pattern is given by the ratio of the number of heterogeneous points to the number of total points in its neighborhood. The proposed technique effectively reduces the impact of noises and distinguishes the edge support vectors and outliers. Computational simulations on an artificial and eleven UCI benchmark datasets using linear, polynomial and Gaussian kernel functions, show the effectiveness of the proposed IFPSVM method. The experiments prove that it can handle large datasets with less computational time and yields better accuracy.},
  day       = {01},
  doi       = {10.1007/s11063-020-10222-x},
  file      = {:FILES/2020 - Laxmi2020 - Intuitionistic Fuzzy Proximal Support Vector Machines for Pattern Classification.pdf:PDF},
  groups    = {interesting articles, SVM},
  timestamp = {2020-08-30},
  url       = {https://doi.org/10.1007/s11063-020-10222-x},
}

@Article{lee2013study,
  author    = {Lee, Ching-Pei and Lin, Chih-Jen},
  journal   = {Neural Computation},
  title     = {A study on {L2}-loss squared hinge-loss multiclass {SVM}},
  year      = {2013},
  number    = {5},
  pages     = {1302--1323},
  volume    = {25},
  groups    = {SVM},
  publisher = {MIT Press},
  timestamp = {2020-08-30},
}

@Article{Lee2018,
  author     = {Lee, C. K. H.},
  journal    = {Engineering Applications of Artificial Intelligence},
  title      = {A review of applications of genetic algorithms in operations management},
  year       = {2018},
  issn       = {0952-1976},
  pages      = {1 -- 12},
  volume     = {76},
  abstract   = {Many decisions in operations management (OM) belong to the class of Non-deterministic Polynomial hard problems and thus heuristic search methods have been applied to improve OM decisions. While genetic algorithms (GAs) are promising tools for searching fast and good solutions in diverse OM areas, future research will benefit from a review of the OM problems solved by GAs. The purpose of this paper is to review the literature on OM with GA-based solutions and to suggest possible gaps from the point of view of researchers and practitioners. A total of 119 peer reviewed journal papers published from 2007 to 2017 are reviewed and analysed methodologically. The applications of GAs in OM are categorized into process and product design, operations planning and control, and operations improvement. Observations from the existing literature are presented and future research directions are suggested. Although GAs have been one of the most popular heuristic approaches for optimization, there are OM problems that are yet to be investigated. The findings of this review pave the path for future research to apply GAs to solve OM problems.},
  doi        = {https://doi.org/10.1016/j.engappai.2018.08.011},
  file       = {:FILES/2018 - Lee2018 - A review of applications of genetic algorithms in operations management.pdf:PDF},
  groups     = {genetic algorithms},
  keywords   = {Operations management, Genetic algorithms, Review, skimmed},
  readstatus = {skimmed},
  url        = {http://www.sciencedirect.com/science/article/pii/S095219761830174X},
}

@Article{lemarechal1997variable,
  author    = {Lemar\'{e}chal, Claude and Sagastiz\'{a}bal, Claudia},
  journal   = {Mathematical Programming},
  title     = {Variable metric bundle methods: {From} conceptual to implementable forms},
  year      = {1997},
  number    = {3},
  pages     = {393--410},
  volume    = {76},
  abstract  = {To minimize a convex function, we combine Moreau-Yosida regularizations, quasi-Newton matrices and bundling mechanisms. First we develop conceptual forms using “reversal” quasi-Newton formulae and we state their global and local convergence. Then, to produce implementable versions, we incorporate a bundle strategy together with a “curve-search”. No convergence results are given for the implementable versions; however some numerical illustrations show their good behaviour even for large-scale problems.},
  file      = {:FILES/1997 - lemarechal1997variable - Variable metric bundle methods- from conceptual to implementable.pdf:PDF},
  groups    = {proximal bundle method},
  publisher = {Springer},
  timestamp = {2020-09-04},
}

@InProceedings{levine2014learning,
  author    = {Levine, Sergey and Abbeel, Pieter},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Learning neural network policies with guided policy search under unknown dynamics},
  year      = {2014},
  pages     = {1071--1079},
  groups    = {RL},
  timestamp = {2020-08-06},
}

@InProceedings{Levine2015,
  author    = {Levine, S. and Wagener, N. and Abbeel, P.},
  booktitle = {2015 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Learning contact-rich manipulation skills with guided policy search},
  year      = {2015},
  month     = {5},
  pages     = {156--163},
  abstract  = {Autonomous learning of object manipulation skills can enable robots to acquire rich behavioral repertoires that scale to the variety of objects found in the real world. However, current motion skill learning methods typically restrict the behavior to a compact, low-dimensional representation, limiting its expressiveness and generality. In this paper, we extend a recently developed policy search method [1] and use it to learn a range of dynamic manipulation behaviors with highly general policy representations, without using known models or example demonstrations. Our approach learns a set of trajectories for the desired motion skill by using iteratively refitted time-varying linear models, and then unifies these trajectories into a single control policy that can generalize to new situations. To enable this method to run on a real robot, we introduce several improvements that reduce the sample count and automate parameter selection. We show that our method can acquire fast, fluent behaviors after only minutes of interaction time, and can learn robust controllers for complex tasks, including putting together a toy airplane, stacking tight-fitting lego blocks, placing wooden rings onto tight-fitting pegs, inserting a shoe tree into a shoe, and screwing bottle caps onto bottles.},
  doi       = {10.1109/ICRA.2015.7138994},
  groups    = {RL},
  issn      = {1050-4729},
  keywords  = {learning systems;linear systems;robots;robust control;search problems;time-varying systems;contact-rich manipulation skill learning;guided policy search method;autonomous object manipulation skill learning;motion skill learning methods;compact low-dimensional representation;dynamic manipulation behaviors;iterativel refitted time-varying linear models;single control policy;parameter selection automation;sample count reduction;learn robust controllers;toy airplane;tight-fitting lego block stacking;Trajectory;Robots;Training;Heuristic algorithms;Cost function;Neural networks},
  timestamp = {2020-08-06},
}

@Article{levine2016end,
  author    = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal   = {The Journal of Machine Learning Research},
  title     = {End-to-end training of deep visuomotor policies},
  year      = {2016},
  number    = {1},
  pages     = {1334--1373},
  volume    = {17},
  groups    = {RL},
  publisher = {JMLR. org},
  timestamp = {2020-08-06},
}

@Article{li1998approximate,
  author    = {Li, Han-Lin and Chang, Ching-Ter},
  journal   = {European Journal of Operational Research},
  title     = {An approximate approach of global optimization for polynomial programming problems},
  year      = {1998},
  number    = {3},
  pages     = {625--632},
  volume    = {107},
  file      = {:FILES/1998 - li1998approximate - An Approximate Approach of Global Optimization for Polynomial Programming Problems.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@InProceedings{Li1998filter,
  author    = {Li, Wenzhe and Lin, Ji-Nan and Unbehauen, R.},
  booktitle = {Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (ISCAS '98)},
  title     = {On piecewise-quadratic filter for {Gaussian} noisy image filtering},
  year      = {1998},
  month     = {5},
  pages     = {178--181},
  volume    = {4},
  doi       = {10.1109/ISCAS.1998.698788},
  file      = {:FILES/1998 - Li1998filter - On piecewise-quadratic filter for Gaussian noisy image filtering.pdf:PDF},
  groups    = {application},
  keywords  = {image classification;filtering theory;feature extraction;learning (artificial intelligence);Gaussian noise;nonlinear network synthesis;digital simulation;piecewise-quadratic filter;Gaussian noisy image filtering;image classification;statistical property;image domain space;image filtering;nonlinear filter;filter function;noise smoothing;effective edge/detail-preserving;simulations;natural images;Gaussian noise;Filtering;Nonlinear filters;Smoothing methods;Arithmetic;Adaptive filters;Function approximation;Polynomials;Image classification;Maximum likelihood estimation},
  timestamp = {2020-08-06},
}

@Article{Li1998polynomial,
  author    = {Li, Wenzhe and Lin, Ji-Nan and Unbehauen, R.},
  journal   = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title     = {Canonical representation of piecewise-polynomial functions with nondegenerate linear-domain partitions},
  year      = {1998},
  issn      = {1558-1268},
  month     = {8},
  number    = {8},
  pages     = {838--848},
  volume    = {45},
  doi       = {10.1109/81.704823},
  file      = {:FILES/1998 - Li1998polynomial - Canonical representation of piecewise-polynomial functions with nondegenerate linear-domain partitions.pdf:PDF},
  groups    = {identification},
  keywords  = {piecewise polynomial techniques;canonical representation;piecewise-polynomial function;nondegenerate linear-domain partition;nonlinear approximate function;hypersurface;Function approximation;Polynomials;Surface fitting;Circuit analysis;Piecewise linear techniques;Mathematics;Sufficient conditions;Neural networks;Signal processing;Image processing},
  timestamp = {2020-08-06},
}

@Article{li2002approximately,
  author    = {Li, Han-Lin and Chang, Ching-Ter and Tsai, Jung-Fa},
  journal   = {European Journal of Operational Research},
  title     = {Approximately global optimization for assortment problems using piecewise linearization techniques},
  year      = {2002},
  number    = {3},
  pages     = {584--589},
  volume    = {140},
  groups    = {optimization},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@Article{LI2005lms,
  author    = {Li, Lei M.},
  journal   = {Computational Statistics & Data Analysis},
  title     = {An algorithm for computing exact least-trimmed squares estimate of simple linear regression with constraints},
  year      = {2005},
  issn      = {0167-9473},
  number    = {4},
  pages     = {717 -- 734},
  volume    = {48},
  abstract  = {The least-trimmed squares estimation (LTS) is a robust solution for regression problems. On the one hand, it can achieve any given breakdown value by setting a proper trimming fraction. On the other hand, it has n-consistency and asymptotic normality under some conditions. In addition, the LTS estimator is regression, scale, and affine equivariant. In practical regression problems, we often need to impose constraints on slopes. In this paper, we describe a stable algorithm to compute the exact LTS solution for simple linear regression with constraints on the slope parameter. Without constraints, the overall complexity of the algorithm is O(n2logn) in time and O(n2) in storage. According to our numerical tests, constraints can reduce computing load substantially. In order to achieve stability, we design the algorithm in such a way that we can take advantage of well-developed sorting algorithms and softwares. We illustrate the algorithm by some examples.},
  doi       = {https://doi.org/10.1016/j.csda.2004.04.003},
  file      = {:FILES/2005 - LI2005lms - An algorithm for computing exact least-trimmed squares estimate of simple linear regression with constraints.pdf:PDF},
  groups    = {LMS},
  keywords  = {Least-trimmed squares, Simple regression, Robust, Breakdown value, Constraint},
  timestamp = {2020-08-06},
  url       = {http://www.sciencedirect.com/science/article/pii/S0167947304001082},
}

@Article{li2005treating,
  author    = {Li, Han-Lin and Tsai, Jung-Fa},
  journal   = {Journal of Global Optimization},
  title     = {Treating free variables in generalized geometric global optimization programs},
  year      = {2005},
  number    = {1},
  pages     = {1--13},
  volume    = {33},
  file      = {:FILES/2005 - li2005treating - Treating free variables in generalized geometric global optimization programs.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-07-16},
}

@Article{li2008convex,
  author    = {Li, {Han-Lin} and Tsai, {Jung-Fa} and Floudas, Christodoulos A.},
  journal   = {Optimization letters},
  title     = {Convex underestimation for posynomial functions of positive variables},
  year      = {2008},
  number    = {3},
  pages     = {333--340},
  volume    = {2},
  file      = {:FILES/2008 - li2008convex - Convex Underestimation for Posynomial Functions of Positive Variables.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{Li2009CS,
  author    = {Li, Yingying and Osher, Stanley},
  journal   = {Inverse Problems and Imaging},
  title     = {Coordinate descent optimization for {$l^1$} minimization with application to compressed sensing; a greedy algorithm},
  year      = {2009},
  number    = {3},
  pages     = {487--503},
  volume    = {3},
  groups    = {application},
  timestamp = {2020-08-06},
  type      = {Journal Article},
}

@Article{li2009global,
  author    = {Li, Han-Lin and Lu, Hao-Chun},
  journal   = {Operations research},
  title     = {Global optimization for generalized geometric programs with mixed free-sign variables},
  year      = {2009},
  number    = {3},
  pages     = {701--713},
  volume    = {57},
  file      = {:FILES/2009 - li2009global - Global optimization for generalized geometric programs with mixed free-sign variables.pdf:PDF},
  groups    = {SGP},
  publisher = {INFORMS},
  timestamp = {2020-07-16},
}

@Article{li2009superior,
  author    = {Li, Han-Lin and Lu, Hao-Chun and Huang, Chia-Hui and Hu, Nian-Ze},
  journal   = {INFORMS Journal on Computing},
  title     = {A superior representation method for piecewise linear functions},
  year      = {2009},
  number    = {2},
  pages     = {314--321},
  volume    = {21},
  file      = {:FILES/2009 - li2009superior - A superior representation method for piecewise linear functions.pdf:PDF},
  groups    = {identification},
  publisher = {INFORMS},
  timestamp = {2020-08-06},
}

@Article{li2012logarithmic,
  author    = {Li, Han-Lin and Huang, Yao-Huei and Fang, Shu-Cherng},
  journal   = {INFORMS Journal on Computing},
  title     = {A logarithmic method for reducing binary variables and inequality constraints in solving task assignment problems},
  year      = {2012},
  number    = {4},
  pages     = {643--653},
  volume    = {25},
  groups    = {MILP},
  publisher = {INFORMS},
  timestamp = {2020-08-06},
}

@Article{li2016enhanced,
  author    = {Li, Han-Lin and Fang, Shu-Cherng and Huang, Yao-Huei and Nie, Tiantian},
  journal   = {European Journal of Operational Research},
  title     = {An enhanced logarithmic method for signomial programming with discrete variables},
  year      = {2016},
  number    = {3},
  pages     = {922--934},
  volume    = {255},
  file      = {:FILES/2016 - li2016enhanced - An enhanced logarithmic method for signomial programming with discrete variables.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@Article{li2016linear,
  author    = {Li, Han-Lin and Huang, Yao-Huei and Fang, Shu-Cherng},
  journal   = {INFORMS Journal on Computing},
  title     = {Linear reformulation of polynomial discrete programming for fast computation},
  year      = {2016},
  number    = {1},
  pages     = {108--122},
  volume    = {29},
  file      = {:FILES/2016 - li2016linear - Linear Reformulation of Polynomial Discrete Programming for Fast Computation.pdf:PDF},
  groups    = {SGP},
  publisher = {INFORMS},
  timestamp = {2020-08-06},
}

@Article{Li2018,
  author    = {Li, Junbin and Wang, Renhong and Xu, Min and Fang, Qin},
  journal   = {Journal of Computational and Applied Mathematics},
  title     = {Piecewise linear approximation methods with stochastic sampling sites},
  year      = {2018},
  issn      = {0377-0427},
  note      = {The International Conference on Information and Computational Science, 2--6 August 2016, Dalian, China},
  pages     = {173 -- 178},
  volume    = {329},
  abstract  = {We study a generalization of the classical piecewise linear approximation methods with equally spaced breaks by considering the sampling sites as random variables. The new methods are motivated by the facts that real-world data collected from what are perceived to be equally spaced sites suffer from random errors due to measurement inaccuracies and other known or unknown factors. We establish error estimates and convergence results under practical assumptions about the distribution of the sampling sites.},
  doi       = {https://doi.org/10.1016/j.cam.2017.02.041},
  file      = {:FILES/2018 - Li2018 - Piecewise linear approximation methods with stochastic sampling sites.pdf:PDF},
  groups    = {identification},
  keywords  = {Piecewise linear approximation, Sampling sites, Normal distribution, prio1},
  priority  = {prio1},
  timestamp = {2020-08-06},
  url       = {https://www.sciencedirect.com/science/article/abs/pii/S0377042717301061},
}

@Article{li2019autoencoder,
  author    = {Li, Weite and Liang, Peifeng and Hu, Jinglu},
  journal   = {IEEJ Transactions on Electrical and Electronic Engineering},
  title     = {An autoencoder-based piecewise linear model for nonlinear classification using quasilinear support vector machines},
  year      = {2019},
  groups    = {SVM},
  publisher = {Wiley Online Library},
  timestamp = {2020-08-30},
}

@Article{li2019large,
  author    = {Li, Xiaoxu and Chang, Dongliang and Tian, Tao and Cao, Jie},
  journal   = {IEEE Access},
  title     = {Large-margin regularized softmax cross-entropy loss},
  year      = {2019},
  pages     = {19572--19578},
  volume    = {7},
  file      = {:FILES/2019 - li2019large - Large-Margin Regularized Softmax Cross-Entropy Loss.pdf:PDF},
  groups    = {Neural Network},
  publisher = {IEEE},
  timestamp = {2020-08-31},
}

@Article{Li2020,
  author    = {Li, Zheng and Micchelli, Charles A. and Xu, Yuesheng},
  journal   = {Applied and Computational Harmonic Analysis},
  title     = {Fixed-point proximity algorithm for minimal norm interpolation},
  year      = {2020},
  issn      = {1063-5203},
  abstract  = {Our goal in the paper is to address the following problem: From an unknown matrix, we are given inner products of that matrix with a set of prescribed matrices, and wish to find the unknown matrix. We shall consider this problem by using the notion of minimal norm interpolation. A fixed-point proximity algorithm for solving this problem will be developed.},
  doi       = {https://doi.org/10.1016/j.acha.2019.12.002},
  file      = {:FILES/2020 - Li2020 - Fixed-point proximity algorithm for minimal norm interpolation.pdf:PDF},
  groups    = {global optimization},
  timestamp = {2020-08-06},
  url       = {http://www.sciencedirect.com/science/article/pii/S1063520320300026},
}

@Article{liang2019exponential,
  author    = {Liang, Shu and Wang, Le Yi and Yin, George},
  journal   = {Automatica},
  title     = {Exponential convergence of distributed primal--dual convex optimization algorithm without strong convexity},
  year      = {2019},
  month     = jul,
  pages     = {298--306},
  volume    = {105},
  doi       = {10.1016/j.automatica.2019.04.004},
  file      = {:FILES/2019 - liang2019exponential - Exponential convergence of distributed primal--dual convex optimization algorithm without strong convexity.pdf:PDF},
  groups    = {global optimization},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
  url       = {https://www.sciencedirect.com/science/article/pii/S0005109819301645},
}

@Article{liberti2003convex,
  author    = {Liberti, Leo and Pantelides, Constantinos C.},
  journal   = {Journal of Global Optimization},
  title     = {Convex envelopes of monomials of odd degree},
  year      = {2003},
  number    = {2},
  pages     = {157--168},
  volume    = {25},
  file      = {:FILES/2003 - liberti2003convex - Convex envelopes of monomials of odd degree.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Book{lihang2012,
  author    = {李航},
  publisher = {清华大学出版社},
  title     = {统计学习方法.},
  year      = {2012},
  groups    = {machine learning},
  timestamp = {2020-08-06},
}

@InProceedings{lillicrap015,
  author    = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  booktitle = {Proceedings of 4th International Conference on Learning Representations},
  title     = {Continuous control with deep reinforcement learning},
  year      = {2016},
  editor    = {Bengio, Yoshua and LeCun, Yann},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/journals/corr/LillicrapHPHETS15.bib},
  groups    = {RL},
  timestamp = {2020-08-06},
  url       = {http://arxiv.org/abs/1509.02971},
}

@Article{Lim1999spt,
  author    = {Lim, YongChing and Yang, Rui and Li, Dongning and Song, Jianjian},
  journal   = {IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing},
  title     = {Signed power-of-two term allocation scheme for the design of digital filters},
  year      = {1999},
  issn      = {1558-125X},
  month     = {5},
  number    = {5},
  pages     = {577--584},
  volume    = {46},
  abstract  = {It is well known that if each coefficient value of a digital filter is a sum of signed power-of-two (SPT) terms, the filter can be implemented without using multipliers. In the past decade, several methods have been developed for the design of filters whose coefficient values are sums of SPT terms. Most of these methods are for the design of filters where all the coefficient values have the same number of SPT terms. It has also been demonstrated recently that significant advantage can be achieved if the coefficient values are allocated with different number of SPT terms while keeping the total number of SPT terms for the filter fixed. In this paper, we present a new method for allocating the number of SPT terms to each coefficient value. In our method, the number of SPT terms allocated to a coefficient is determined by the statistical quantization step-size of that coefficient and the sensitivity of the frequency response of the filter to that coefficient. After the assignment of the SPT terms, an integer-programming algorithm is used to optimize the coefficient values. Our technique yields excellent results but does not guarantee optimum assignment of SPT terms. Nevertheless, for any particular assignment of SPT terms, the result obtained is optimum with respect to that assignment.},
  doi       = {10.1109/82.769806},
  groups    = {SPT},
  keywords  = {digital filters;frequency response;filtering theory;statistical analysis;sensitivity analysis;integer programming;signed power-of-two term allocation scheme;digital filter design;filters coefficient values;statistical quantization step-size;frequency response sensitivity;integer programming algorithm;Digital filters;Finite impulse response filter;Quantization;Frequency response;Switches;Filtering;Distributed computing;Digital modulation;Digital-analog conversion;Sampling methods},
  timestamp = {2020-08-06},
}

@Article{lim2010bilinear,
  author    = {Lim, Ch\urlzu},
  journal   = {Wiley Encyclopedia of Operations Research and Management Science},
  title     = {Bilinear optimization},
  year      = {2010},
  groups    = {bilinear},
  publisher = {Wiley Online Library},
  timestamp = {2020-08-06},
}

@Article{Lin1992canonical,
  author    = {Lin, Ji-Nan and Unbehauen, Rolf},
  journal   = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title     = {Canonical piecewise-linear approximations},
  year      = {1992},
  issn      = {1558-1268},
  month     = {8},
  number    = {8},
  pages     = {697--699},
  volume    = {39},
  doi       = {10.1109/81.168933},
  file      = {:FILES/1992 - Lin1992canonical - Canonical piecewise-linear approximations.pdf:PDF},
  groups    = {identification},
  keywords  = {adaptive filters;neural nets;nonlinear network analysis;piecewise-linear techniques;canonical representation;piecewise-linear functions;universal approximation scheme;multivariate functions;mapping networks;neural networks;adaptive nonlinear filters;Piecewise linear techniques;Ear;Neural networks;Adaptive systems;Adaptive filters;Intelligent networks;Circuit analysis;Nonlinear circuits;Spline;Lattices},
  timestamp = {2020-08-06},
}

@InProceedings{Lin1992quadratic,
  author    = {Lin, J.-. and Unbehauen, R.},
  booktitle = {[Proceedings] 1992 IEEE International Symposium on Circuits and Systems},
  title     = {On the quadratic extension of the canonical piecewise-linear network},
  year      = {1992},
  month     = {5},
  pages     = {316--319},
  volume    = {1},
  doi       = {10.1109/ISCAS.1992.229950},
  file      = {:FILES/1992 - Lin1992quadratic - On the quadratic extension of the canonical piecewise-linear network.pdf:PDF},
  groups    = {identification},
  issn      = {null},
  keywords  = {learning systems;neural nets;nonlinear network synthesis;piecewise-linear techniques;global learning;surface fitting;quadratic extension;canonical piecewise-linear network;linear partitions;spline approximation;nonlinear functions;Piecewise linear techniques;Neural networks;Spline;Cost function;Computational efficiency;Computer networks;Computational modeling;Radiofrequency interference;Vectors;Feedforward neural networks},
  timestamp = {2020-08-06},
}

@PhdThesis{lin1992thesis,
  author    = {Lin, Long-Ji},
  title     = {Reinforcement learning for robots using neural networks},
  year      = {1992},
  address   = {USA},
  groups    = {RL},
  publisher = {Carnegie Mellon University},
  timestamp = {2020-08-06},
}

@Article{Lin1993smooth,
  author    = {Lin, J.-. and Unbehauen, R.},
  journal   = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title     = {Canonical representation: {From} piecewise-linear function to piecewise-smooth functions},
  year      = {1993},
  issn      = {1558-1268},
  month     = {7},
  number    = {7},
  pages     = {461--468},
  volume    = {40},
  doi       = {10.1109/81.257301},
  file      = {:FILES/1993 - Lin1993smooth - Canonical representation- from piecewise-linear function to piecewise-smooth functions.pdf:PDF},
  groups    = {identification},
  keywords  = {functions;nonlinear network analysis;nonlinear systems;piecewise-linear techniques;piecewise-linear function;piecewise-smooth functions;canonical representation;nonlinear systems;PWL functions;Piecewise linear techniques;Nonlinear systems;Function approximation;Neural networks;Signal mapping;Signal processing;Spline;Equations;Nonlinear circuits},
  timestamp = {2020-08-06},
}

@InProceedings{Lin1993unify,
  author    = {Lin, J.-. and Unbehauen, R.},
  booktitle = {1993 IEEE International Symposium on Circuits and Systems},
  title     = {Canonical {PWL} network and multilayer perceptron-like networks: {A} unified view},
  year      = {1993},
  month     = {5},
  pages     = {2588--2591},
  abstract  = {The authors consider the behavior of the most popular type of mapping networks, the multilayer perceptron-like (MLPL) networks in implementing or approximating functions, in terms of the canonical piecewise-linear (PWL) functions. They show that a MLPL network may be understood as performing a canonical PWL function or a PWL function which is a composition of the canonical PWL functions. The discussion further suggests a generalized class of the canonical-PWL (CPWL) networks, i.e., networks which perform a canonical PWL function or a composition of the canonical PWL functions, which includes all layered feedforward networks where the nonlinearity of the units is represented or approximately represented by a PWL function.},
  doi       = {10.1109/ISCAS.1993.394295},
  file      = {:FILES/1993 - Lin1993unify - Canonical PWL network and multilayer perceptron-like networks- A unified view.pdf:PDF},
  groups    = {identification, Neural Network},
  keywords  = {piecewise-linear techniques;multilayer perceptrons;function approximation;feedforward neural nets;canonical piecewise-linear functions;function approximation;multilayer perceptron-like networks;mapping networks;layered feedforward networks;nonlinearity;Nonhomogeneous media;Piecewise linear techniques;Signal processing algorithms;Signal mapping;Pattern recognition;Adaptive signal processing;Multidimensional signal processing;Biomedical signal processing;Biological system modeling;Approximation methods},
  timestamp = {2020-09-04},
}

@Article{Lin1994CS,
  author    = {Lin, J. N. and Xu, Hong-Qing and Unbehauen, R.},
  journal   = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title     = {A generalization of canonical piecewise-linear functions},
  year      = {1994},
  issn      = {1558-1268},
  month     = {4},
  number    = {4},
  pages     = {345--347},
  volume    = {41},
  doi       = {10.1109/81.285696},
  file      = {:FILES/1994 - Lin1994CS - A generalization of canonical piecewise-linear functions.pdf:PDF},
  groups    = {identification},
  keywords  = {piecewise-linear techniques;neural nets;splines (mathematics);functional analysis;canonical piecewise-linear functions;high-level canonical representation;continuous piecewise-linear functions;PWL functions;neural networks;splines;Piecewise linear techniques;Vectors;Neural networks;Proposals;Region 4;Jacobian matrices;Circuits},
  timestamp = {2020-08-06},
}

@Article{Lin1994generalization,
  author    = {Lin, Ji-Nan and Unbehauen, R.},
  journal   = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title     = {Explicit piecewise-linear models},
  year      = {1994},
  issn      = {1558-1268},
  month     = {12},
  number    = {12},
  pages     = {931--933},
  volume    = {41},
  doi       = {10.1109/81.340865},
  file      = {:FILES/1994 - Lin1994generalization - Explicit piecewise-linear models.pdf:PDF},
  groups    = {identification},
  keywords  = {piecewise-linear techniques;nonlinear systems;nonlinear network analysis;neural nets;signal processing;explicit model;piecewise-linear models;nonlinear systems;fundamental scheme;continuous PWL functions;network implementation;neural networks;nonlinear signal processing;Piecewise linear techniques;Signal processing;Logic arrays;Nonlinear systems;Neural networks;Nonlinear circuits;Circuit analysis;Analytical models;Circuit simulation;Signal mapping},
  timestamp = {2020-08-06},
}

@Article{Lin1995NN,
  author    = {Lin, J.-N. and Unbehauen, R.},
  journal   = {IEEE Transactions on Neural Networks},
  title     = {Canonical piecewise-linear networks},
  year      = {1995},
  issn      = {1941-0093},
  month     = {1},
  number    = {1},
  pages     = {43--50},
  volume    = {6},
  doi       = {10.1109/72.363451},
  file      = {:FILES/1995 - Lin1995NN - Canonical piecewise-linear networks.pdf:PDF},
  groups    = {identification, Neural Network},
  keywords  = {piecewise-linear techniques;neural nets;canonical piecewise-linear networks;mapping networks;piecewise-linear approximation;canonical representation;high-level generalization;multilayer perceptron-like networks;neural nets;Piecewise linear techniques;Neurons;Nonhomogeneous media;Signal processing algorithms;Computer networks;Kernel;Mathematics;Circuit simulation;Neural networks;Mathematical model},
  timestamp = {2020-08-06},
}

@Article{Lin2006,
  author   = {Lin, Wei and Chen, Tianping},
  journal  = {Neurocomputing},
  title    = {Analysis of two restart algorithms},
  year     = {2006},
  issn     = {0925-2312},
  note     = {Brain Inspired Cognitive Systems},
  number   = {16},
  pages    = {2301 -- 2308},
  volume   = {69},
  abstract = {Since the backpropagation algorithm used for neural network training suffers from a slow convergence and often sticking in local minima, the restart mechanism has been introduced, whose strategy is to cut off the training process and restart it with a fresh initialization when it seems unlikely to converge in a relatively short time. In this paper, we give detailed mathematical analysis on two versions of the restart algorithms. By deriving analytic expressions of the expected convergence time and the success rate, we illustrate why the restart algorithms work well and gain insights into the proper use of restarting. Numerical simulations are performed on the XOR problem, symmetry detection, parity problem and Arabic numeral recognition. We show the effectiveness of the restart algorithms, and compare them with simulated annealing. The analysis can also be applied to many other fields.},
  doi      = {https://doi.org/10.1016/j.neucom.2005.04.015},
  file     = {:FILES/2006 - Lin2006 - Analysis of two restart algorithms.pdf:PDF},
  groups   = {training algorithm},
  keywords = {Restart mechanism, Neural network training, Backpropagation algorithm, Gradient descent method},
  url      = {http://www.sciencedirect.com/science/article/pii/S0925231205003243},
}

@Article{lin2011finding,
  author    = {Lin, Ming-Hua and Tsai, Jung-Fa},
  journal   = {Optimization and Engineering},
  title     = {Finding multiple optimal solutions of signomial discrete programming problems with free variables},
  year      = {2011},
  number    = {3},
  pages     = {425--443},
  volume    = {12},
  file      = {:FILES/2011 - lin2011finding - Finding multiple solutions of signomial discrete programming problems with free variables.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{lin2012range,
  author    = {Lin, Ming-Hua and Tsai, Jung-Fa},
  journal   = {European Journal of Operational Research},
  title     = {Range reduction techniques for improving computational efficiency in global optimization of signomial geometric programming problems},
  year      = {2012},
  number    = {1},
  pages     = {17--25},
  volume    = {216},
  file      = {:FILES/2012 - lin2012range - Range reduction techniques for improving computational efficiency in global optimization of signomial geometric programming problems.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@Article{lin2012review,
  author    = {Lin, Ming-Hua and Tsai, Jung-Fa and Yu, Chian-Son},
  journal   = {Mathematical Problems in Engineering},
  title     = {A review of deterministic optimization methods in engineering and management},
  year      = {2012},
  volume    = {2012},
  groups    = {global optimization},
  publisher = {Hindawi},
  timestamp = {2020-08-06},
}

@Article{lin2013review,
  author    = {Lin, Ming-Hua and Carlsson, John Gunnar and Ge, Dongdong and Shi, Jianming and Tsai, Jung-Fa},
  journal   = {Mathematical problems in Engineering},
  title     = {A review of piecewise linearization methods},
  year      = {2013},
  volume    = {2013},
  file      = {:FILES/2013 - lin2013review - A Review of Piecewise Linearization Methods.pdf:PDF},
  groups    = {identification},
  keywords  = {prio1},
  priority  = {prio1},
  publisher = {Hindawi},
  timestamp = {2020-08-06},
}

@InProceedings{Lin2015rucci,
  author    = {Lin, A. S. and Luo, B. Z. and Zhang, C. J. and Saucan, D. E.},
  booktitle = {2015 23rd European Signal Processing Conference (EUSIPCO)},
  title     = {Generalized {Ricci} curvature based sampling and reconstruction of images},
  year      = {2015},
  month     = {8},
  pages     = {604--608},
  abstract  = {We introduce a novel method of image sampling based on viewing grayscale images as manifolds with density, and sampling them according to the generalized Ricci curvature introduced by Bakry, Emery and Ledoux. A variation of this approach, due to Morgan and his students is also considered. This new paradigm generalizes ideas and results that are by now common in Imaging and Graphics. We apply the new algorithm to natural and range images, as well as cartoons and show that the proposed method produces results similar to those obtained by employing more standard approaches. Furthermore, we show that our approach extends naturally to other types of images, in particular to MRI and CT, where its potential applications are maximal, as well as to meshes.},
  doi       = {10.1109/EUSIPCO.2015.7362454},
  file      = {:FILES/2015 - Lin2015rucci - Generalized {Ricci} curvature based sampling and reconstruction of images.pdf:PDF},
  groups    = {machine learning},
  issn      = {2076-1465},
  keywords  = {differential geometry;image reconstruction;image sampling;Ricci curvature;image reconstruction;image sampling;grayscale images;Manifolds;Image reconstruction;Gray-scale;Laplace equations;Imaging;Surface reconstruction;Image coding;Weighted manifolds;generalized Ricci curvature;image sampling and reconstruction},
  timestamp = {2020-09-04},
}

@Article{lin2017superior,
  author    = {Lin, Ming-Hua and Tsai, Jung-Fa and Chang, Shu-Chuan},
  journal   = {Engineering Optimization},
  title     = {A superior linearization method for signomial discrete functions in solving three-dimensional open-dimension rectangular packing problems},
  year      = {2017},
  number    = {5},
  pages     = {746--761},
  volume    = {49},
  file      = {:FILES/2017 - lin2017superior - A superior linearization method for signomial discrete functions in solving three dimensional open-dimension rectangular packing problems.pdf:PDF},
  groups    = {SGP},
  publisher = {Taylor \& Francis},
  timestamp = {2020-08-06},
}

@Article{linderoth2005simplicial,
  author    = {Linderoth, Jeff},
  journal   = {Mathematical programming},
  title     = {A simplicial branch-and-bound algorithm for solving quadratically constrained quadratic programs},
  year      = {2005},
  number    = {2},
  pages     = {251--282},
  volume    = {103},
  file      = {:FILES/2005 - linderoth2005simplicial - A simplicial branch-and-bound algorithm for solving quadratically constrained quadratic programs.pdf:PDF},
  groups    = {global optimization},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@InProceedings{Lis1997,
  author    = {Lis, J. and Eiben, A. E.},
  booktitle = {Proceedings of 1997 IEEE International Conference on Evolutionary Computation (ICEC '97)},
  title     = {A multi-sexual genetic algorithm for multiobjective optimization},
  year      = {1997},
  month     = {4},
  pages     = {59--64},
  abstract  = {In this paper a new method for solving multicriteria optimization problems by Genetic Algorithms is proposed. Standard Genetic Algorithms use a population, where each individual has the same sex (or has no sex) and any two individuals can be crossed over. In the proposed Multisexual Genetic Algorithm (MSGA), individuals have an additional feature, their sex or gender and one individual from each sex is used in the recombination process. In our multicriteria optimization application there are as many sexes as optimization criteria and each individual is evaluated according to the optimization criterion related to its sex. Furthermore, a multi-parent crossover is applied to generate offspring of parents belonging to all different sexes, so the offspring represents intermediate solutions not totally optimal with respect to any single criterion. During the execution of the algorithm the set of nondominated solutions is updated and this set is presented as the output of MSGA at the end.},
  doi       = {10.1109/ICEC.1997.592269},
  file      = {:FILES/1997 - Lis1997 - A multi-sexual genetic algorithm for multiobjective optimization.pdf:PDF},
  groups    = {genetic algorithms},
  keywords  = {genetic algorithms;multi-sexual genetic algorithm;multiobjective optimization;recombination process;multi-parent crossover;intermediate solutions;nondominated solutions;Genetic algorithms;Optimization methods;Biomedical engineering;Computer science;Decision making;Sorting;Constraint optimization;Design optimization;Decision feedback equalizers},
}

@Article{liu1993remark,
  author    = {Liu, WB and Floudas, Christodoulos A},
  journal   = {Journal of Global Optimization},
  title     = {A remark on the {GOP} algorithm for global optimization},
  year      = {1993},
  number    = {4},
  pages     = {519--521},
  volume    = {3},
  groups    = {global optimization},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{liu2005multicategory,
  author    = {Liu, Yufeng and Shen, Xiaotong and Doss, Hani},
  journal   = {Journal of Computational and Graphical Statistics},
  title     = {Multicategory $\psi$-learning and support vector machine: {Computational} tools},
  year      = {2005},
  number    = {1},
  pages     = {219--236},
  volume    = {14},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@Article{liu2006optimizing,
  author    = {Liu, Yufeng and Wu, Yichao},
  journal   = {Statistica Sinica},
  title     = {Optimizing $\psi$-learning via mixed integer programming},
  year      = {2006},
  number    = {2},
  pages     = {441},
  volume    = {16},
  groups    = {MILP},
  publisher = {C/O DR HC HO, INST STATISTICAL SCIENCE, ACADEMIA SINICA, TAIPEI 115, TAIWAN},
  timestamp = {2020-08-06},
}

@Article{liu2007support,
  author    = {Liu, Yufeng and Helen Zhang, Hao and Park, Cheolwoo and Ahn, Jeongyoun},
  journal   = {Computational Statistics \& Data Analysis},
  title     = {Support vector machines with adaptive ${l}_q$ penalty},
  year      = {2007},
  number    = {12},
  pages     = {6380--6394},
  volume    = {51},
  groups    = {SVM},
  publisher = {Elsevier},
  timestamp = {2020-08-30},
}

@InProceedings{liu2009blockwise,
  author    = {Liu, Han and Palatucci, Mark and Zhang, Jian},
  booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
  title     = {Blockwise coordinate descent procedures for the multi-task {LASSO}, with applications to neural semantic basis discovery},
  year      = {2009},
  pages     = {649--656},
  groups    = {machine learning},
  timestamp = {2020-08-06},
}

@Article{liu2011finite,
  author    = {Liu, Qingshan and Wang, Jun},
  journal   = {IEEE Transactions on Neural Networks},
  title     = {Finite-time convergent recurrent neural network with a hard-limiting activation function for constrained optimization with piecewise-linear objective functions},
  year      = {2011},
  number    = {4},
  pages     = {601--613},
  volume    = {22},
  file      = {:FILES/2011 - liu2011finite - Finite-time convergent recurrent neural network with a hard-limiting activation function for constrained optimization with piecewise-linear objective functions.pdf:PDF},
  groups    = {Neural Network, optimization},
  publisher = {IEEE},
  timestamp = {2020-08-06},
}

@Article{liu2012hybrid,
  author    = {Gu, Wei and Wu, Yonggang and Xiao, Xiaohong and Hu, Binqi},
  journal   = {Journal of Computational Information Systems},
  title     = {A hybrid chaotic estimation of distribution algorithm for global numerical optimization},
  year      = {2012},
  number    = {14},
  pages     = {6087--6094},
  volume    = {8},
  file      = {:FILES/2012 - liu2012hybrid - a hybrid chaotic estimation of distribution algorithm for global numerical optimization.pdf:PDF},
  groups    = {global optimization},
  timestamp = {2020-08-06},
}

@Article{Liu2016,
  author     = {Liu, Kuangyu and Xu, Zhiming and Xi, Xiangming and Wang, Shuning},
  journal    = {Digital Signal Processing},
  title      = {Sparse signal reconstruction via concave continuous piecewise linear programming},
  year       = {2016},
  issn       = {1051-2004},
  month      = apr,
  pages      = {12--26},
  volume     = {54},
  author+an  = {3=highlight},
  comment    = {2.337},
  file       = {:FILES/2016 - Liu2016 - Sparse signal reconstruction via concave continuous piecewise linear programming.pdf:PDF},
  groups     = {my paper, Wang's Work, Compressive sensing},
  keywords   = {read},
  readstatus = {read},
  timestamp  = {2020-09-04},
}

@Article{Liu2016a,
  author     = {Liu, Jianjun and Teo, K. L. and Wang, Xiangyu and Wu, Changzhi},
  journal    = {Soft Computing},
  title      = {An exact penalty function-based differential search algorithm for constrained global optimization},
  year       = {2016},
  issn       = {1432-7643},
  pages      = {1305--1313},
  volume     = {20},
  abstract   = {Differential search (DS) is a recently developed derivative-free global heuristic optimization algorithm for solving unconstrained optimization problems. In this paper, by applying the idea of exact penalty function approach, a DS algorithm, where an S-type dynamical penalty factor is introduced so as to achieve a better balance between exploration and exploitation, is developed for constrained global optimization problems. To illustrate the applicability and effectiveness of the proposed approach, a comparison study is carried out by applying the proposed algorithm and other widely used evolutionary methods on 24 benchmark problems. The results obtained clearly indicate that the proposed method is more effective and efficient over the other widely used evolutionary methods for most these benchmark problems.},
  doi        = {10.1007/s00500-015-1588-6},
  file       = {:FILES/2016 - Liu2016a - An exact penalty function-based differential search algorithm for constrained global optimization.pdf:PDF},
  groups     = {genetic algorithms, global optimization},
  keywords   = {read},
  readstatus = {read},
  timestamp  = {2020-06-08},
  url        = {https://link.springer.com/article/10.1007/s00500-015-1588-6},
}

@InProceedings{Liu2016b,
  author    = {Liu, Kuangyu and Xu, Zhiming and Xi, Xiangming and Wang, Shuning},
  booktitle = {2016 12th World Congress on Intelligent Control and Automation (WCICA)},
  title     = {A modified hill detouring algorithm for hinging hyperplanes minimization},
  year      = {2016},
  address   = {Guilin, China},
  month     = {6},
  pages     = {2749--2754},
  abstract  = {This paper considers the global optimization of hinging hyperplanes (HH), which is a widely applied nonlinear model. HH minimization can be equivalently transformed into difference of convex functions (D.C.) programming, and further, concave optimization over a polyhedron. Motivated by a novel algorithm called Hill Detouring (HD), we present a modified hill detouring (MHD) algorithm. The proposed algorithm escapes local optima efficiently with a new search strategy, and establishes an exact stopping criterion for global optimality based on the theory of γ valid cut. In the numerical experiments, MHD is compared with mixed integer programming (MIP) and HD, which shows its superior performance on the numerical efficiency and the global search capability.},
  author+an = {3=highlight},
  doi       = {10.1109/WCICA.2016.7578702},
  file      = {:FILES/2016 - Liu2016b - A modified hill detouring algorithm for hinging hyperplanes minimization.pdf:PDF},
  groups    = {my paper, Wang's Work},
  keywords  = {High definition video;Linear programming;Optimization;Magnetohydrodynamics;Search problems;Automation;Minimization},
}

@Article{Liu2017,
  author    = {Liu, Kuangyu and Xi, Xiangming and Xu, Zhiming and Wang, Shuning},
  journal   = {Tsinghua Science and Technology},
  title     = {A piecewise linear programming algorithm for sparse signal reconstruction},
  year      = {2017},
  issn      = {1007-0214},
  month     = {2},
  number    = {01},
  pages     = {29--41},
  volume    = {22},
  abstract  = {In order to recover a signal from its compressive measurements, the compressed sensing theory seeks the sparsest signal that agrees with the measurements, which is actually an l norm minimization problem. In this paper, we equivalently transform the l norm minimization into a concave continuous piecewise linear programming, and propose an optimization algorithm based on a modified interior point method. Numerical experiments demonstrate that our algorithm improves the sufficient number of measurements, relaxes the restrictions of the sensing matrix to some extent, and performs robustly in the noisy scenarios.},
  author+an = {2=highlight},
  comment   = {SCI，JCR Q3，1.365,26 January 2017},
  doi       = {10.1109/TST.2017.7830893},
  file      = {:FILES/2017 - Liu2017 - A piecewise linear programming algorithm for Sparse Signal Reconstruction.pdf:PDF},
  groups    = {my paper, Wang's Work},
  keywords  = {linear programming;signal reconstruction;sparse matrices;sensing matrix;modified interior point method;concave continuous piecewise linear programming algorithm;sparse signal reconstruction;Linear programming;Matching pursuit algorithms;Minimization;Algorithm design and analysis;Approximation algorithms;Signal reconstruction;Sparse matrices;compressed sensing;continuous piecewise linear programming;interior point method},
}

@Article{Ljungqvist2005,
  author    = {Ljungqvist, Alexander and Wilhelm Jr, William J.},
  journal   = {Journal of Finance},
  title     = {Does prospect theory explain {IPO} market behavior?},
  year      = {2005},
  number    = {4},
  pages     = {1759--1790},
  volume    = {60},
  groups    = {prospect theory},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@InProceedings{Lofberg2004,
  author    = {L\"{o}fberg, J.},
  booktitle = {In Proceedings of the CACSD Conference},
  title     = {Yalmip: {A} toolbox for modeling and optimization in matlab},
  year      = {2004},
  address   = {Taipei, Taiwan},
  groups    = {MILP},
  timestamp = {2020-08-06},
}

@InProceedings{Louis1991,
  author     = {Louis, Sushil J. and Rawlins, Gregory J. E.},
  booktitle  = {Proceedings of the 4th International Conference on Genetic Algorithms, San Diego, CA, USA, July 1991},
  title      = {Designer genetic algorithms: {Genetic} algorithms in structure design},
  year       = {1991},
  editor     = {Belew, Richard K. and Booker, Lashon B.},
  pages      = {53--60},
  publisher  = {Morgan Kaufmann},
  abstract   = {This paper considers the problem of using genetic algorithms to design structures. We relax one constraint on classical genetic algorithms and describe a genetic algorithm that uses dierential information about search direction to design structures. This dierential information is captured by a masked crossover operator which also removes the bias toward short schemas. We analyze performance and present some preliminary results. Further, consideration of this problem suggests a partial solution to the identication of the deception problem.},
  bibsource  = {dblp computer science bibliography, https://dblp.org},
  biburl     = {https://dblp.org/rec/conf/icga/LouisR91.bib},
  file       = {:FILES/1991 - Louis1991 - Designer Genetic Algorithms- Genetic Algorithms in Structure Design.pdf:PDF},
  groups     = {genetic algorithms, TEC},
  keywords   = {read},
  readstatus = {read},
  timestamp  = {2020-09-05},
}

@TechReport{Louis1991a,
  author      = {Louis, Sushil J. and Rawlins, Gregory J. E.},
  institution = {Computer science department, Indiana University},
  title       = {Using genetic algorithms to design structures},
  year        = {1991},
  address     = {Bloomington, Indiana 47405-4101},
  month       = {2},
  number      = {326},
  type        = {techreport},
  comment     = {This is an extension of the conference paper "Louis1991"},
  file        = {:FILES/1991 - Louis1991a - Using genetic algorithms to design structures.pdf:PDF},
  groups      = {genetic algorithms},
  keywords    = {skimmed},
  readstatus  = {skimmed},
}

@Article{lu2010convex,
  author    = {Lu, {Hao-Chun} and Li, {Han-Lin} and Gounaris, Chrysanthos E. and Floudas, Christodoulos A.},
  journal   = {Journal of Global Optimization},
  title     = {Convex relaxation for solving posynomial programs},
  year      = {2010},
  number    = {1},
  pages     = {147},
  volume    = {46},
  file      = {:FILES/2010 - lu2010convex - Convex relaxation for solving posynomial programs.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@InProceedings{lu2010digital,
  author     = {Lu, W. and Hinamoto, T.},
  booktitle  = {Proceedings of 2010 IEEE International Symposium on Circuits and Systems},
  title      = {Digital filters with sparse coefficients},
  year       = {2010},
  month      = {5},
  pages      = {169--172},
  abstract   = {Is sparsity an issue in filter design problems? and why is it important? How a digital filter can be designed to have a sparse impulse response for efficient implementation while achieving improved performance relative to its non-sparse counterpart? In an attempt to address these questions, this paper comes up with a design technique for optimal linear-phase FIR filters with sparse impulse responses.},
  doi        = {10.1109/ISCAS.2010.5538018},
  file       = {:FILES/2010 - lu2010digital - Digital filters with sparse coefficients.pdf:PDF},
  groups     = {sparse},
  issn       = {2158-1525},
  keywords   = {FIR filters;transient response;digital filters;sparse coefficient;impulse response;linear-phase FIR filters;Digital filters;Finite impulse response filter;Signal design;Design methodology;Frequency response;Algorithm design and analysis;Filtering theory;Design engineering;Signal analysis;Digital signal processing, read},
  readstatus = {read},
}

@Article{Lu2011,
  author        = {Lu, Wu-Sheng and Hinamoto, Takao},
  journal       = {Multidimensional Systems and Signal Processing},
  title         = {Two-dimensional digital filters with sparse coefficients},
  year          = {2011},
  number        = {1},
  pages         = {173--189},
  volume        = {22},
  abstract      = {Is sparsity an issue in 2-D digital filter design problems to explore and why is it important? How a 2-D filter can be designed to retain a desired coefficient sparsity for efficient implementation while achieving best possible performance subject to that sparsity constraint? These are the focus of this paper in which we present a two-phase design method for 2-D FIR digital filters in two most common design settings, namely, the least squares and minimax designs. Simulation studies are presented to illustrate each phase of the proposed design method and to evaluate the performance of the filters designed.},
  bdsk-url-1    = {https://doi.org/10.1007/s11045-010-0129-9},
  da            = {2011/03/01},
  date-added    = {2020-03-26 13:51:12 +0000},
  date-modified = {2020-03-26 13:51:12 +0000},
  doi           = {10.1007/s11045-010-0129-9},
  file          = {:FILES/2011 - Lu2011 - Two-dimensional digital filters with sparse coefficients.pdf:PDF},
  groups        = {two-dimensional FIR, sparse},
  isbn          = {1573-0824},
  ty            = {JOUR},
  url           = {https://doi.org/10.1007/s11045-010-0129-9},
}

@Article{lu2012efficient,
  author    = {Lu, Hao-Chun},
  journal   = {Journal of Industrial \& Management Optimization},
  title     = {An efficient convexification method for solving generalized geometric problems},
  year      = {2012},
  number    = {2},
  pages     = {429--455},
  volume    = {8},
  file      = {:FILES/2012 - lu2012efficient - An efficient convexification method for solving generalized geometric problems.pdf:PDF},
  groups    = {SGP},
  timestamp = {2020-07-16},
}

@InProceedings{lu2012firSparse,
  author    = {Lu, W. and Hinamoto, T.},
  booktitle = {2012 IEEE International Symposium on Circuits and Systems (ISCAS)},
  title     = {Variable fractional delay {FIR} filters with sparse coefficients},
  year      = {2012},
  month     = {5},
  pages     = {782--785},
  abstract  = {Implementing a variable fractional delay (VFD) filter in Farrow model is costly as each coefficient of a VFD filter is a polynomial rather than a numerical scalar as in a conventional digital filter. This paper presents a method for the design of VFD filters with sparse coefficients which admits efficient implementation. The design is accomplished in two phases with the first phase identifying locations in polynomial impulse response that are suitable to be set to zero and the second phase optimizing the remaining nonzero coefficients so as for the VFD filter to best approximate a desired frequency response. Performance evaluation and comparison of the proposed algorithm relative to an equivalent nonsparse counterpart are also presented.},
  doi       = {10.1109/ISCAS.2012.6272156},
  file      = {:FILES/2012 - lu2012firSparse - Variable fractional delay FIR filters with sparse coefficients.pdf:PDF},
  groups    = {sparse},
  issn      = {2158-1525},
  keywords  = {delay filters;FIR filters;polynomials;variable fractional delay;FIR filter;sparse coefficient;VFD filter;Farrow model;numerical scalar;digital filter;polynomial impulse response;frequency response;Delay;Finite impulse response filter;Algorithm design and analysis;Indexes;Frequency response;Design methodology;Vectors},
}

@Article{lu2013logarithmic,
  author    = {Lu, Hao-Chun},
  journal   = {Discrete Optimization},
  title     = {A logarithmic method for eliminating binary variables and constraints for the product of free-sign discrete functions},
  year      = {2013},
  number    = {1},
  pages     = {11--24},
  volume    = {10},
  groups    = {global optimization},
  publisher = {Elsevier},
  timestamp = {2020-08-06},
}

@Article{Lu2015cda,
  author    = {Lu, Zhaosong and Xiao, Lin},
  journal   = {Mathematical Programming},
  title     = {On the complexity analysis of randomized block-coordinate descent methods},
  year      = {2015},
  issn      = {0025-5610},
  number    = {1-2},
  pages     = {615--642},
  volume    = {152},
  groups    = {convergence},
  timestamp = {2020-08-06},
}

@Article{lu2019GGP,
  author    = {Lu, Hao-Chun and Yao, Liming},
  journal   = {INFORMS Journal on Computing},
  title     = {Efficient convexification strategy for generalized geometric programming problems},
  year      = {2019},
  number    = {2},
  pages     = {226--234},
  volume    = {31},
  doi       = {10.1287/ijoc.2018.0850},
  file      = {:FILES/2019 - lu2019GGP - Efficient Convexification Strategy for Generalized Geometric Programming Problems.pdf:PDF},
  groups    = {SGP},
  timestamp = {2020-07-16},
}

@Article{Lucas1978,
  author    = {Lucas, Jr.},
  journal   = {Econometrica},
  title     = {Asset prices in an exchange economy},
  year      = {1978},
  number    = {6},
  pages     = {1429--1445},
  volume    = {46},
  groups    = {asset allocation},
  timestamp = {2020-09-04},
}

@Article{lundell2007optimization,
  author    = {Lundell, Andreas and Westerlund, Tapio},
  journal   = {Chemical Engineering Transactions},
  title     = {Optimization of power transformations in global optimization},
  year      = {2007},
  pages     = {95--100},
  volume    = {11},
  file      = {:FILES/2007 - lundell2007optimization - Optimization of power transformations in global optimization.pdf:PDF},
  groups    = {SGP},
  timestamp = {2020-08-06},
}

@InProceedings{lundell2008exponential,
  author       = {Lundell, Andreas and Westerlund, Tapio},
  booktitle    = {Proceedings of the 27th IASTED International Conference on Modelling, Identification and Control},
  title        = {Exponential and power transformations for convexifying signomial terms in minlp problems},
  year         = {2008},
  organization = {ACTA Press},
  pages        = {154--159},
  groups       = {SGP},
  timestamp    = {2020-08-06},
}

@Article{lundell2009convex,
  author    = {Lundell, Andreas and Westerlund, Tapio},
  journal   = {Optimization Methods \& Software},
  title     = {Convex underestimation strategies for signomial functions},
  year      = {2009},
  number    = {4-5},
  pages     = {505--522},
  volume    = {24},
  file      = {:FILES/2009 - lundell2009convex - Convex underestimation strategies for signomial functions.pdf:PDF},
  groups    = {SGP},
  publisher = {Taylor \& Francis},
  timestamp = {2020-08-06},
}

@InCollection{lundell2009implementation,
  author    = {Lundell, Andreas and Westerlund, Tapio},
  booktitle = {Computer Aided Chemical Engineering},
  publisher = {Elsevier},
  title     = {Implementation of a convexification technique for signomial functions},
  year      = {2009},
  pages     = {579--583},
  volume    = {26},
  groups    = {SGP},
  timestamp = {2020-08-06},
}

@InCollection{lundell2009optimization,
  author    = {Lundell, Andreas and Westerlund, Tapio},
  booktitle = {Computer Aided Chemical Engineering},
  publisher = {Elsevier},
  title     = {Optimization of transformations for convex relaxations of {MINLP} problems containing signomial functions},
  year      = {2009},
  pages     = {231--236},
  volume    = {27},
  groups    = {SGP},
  timestamp = {2020-08-06},
}

@Article{lundell2009relationship,
  author    = {Lundell, Andreas and Westerlund, Tapio},
  journal   = {Chemical Engineering Transactions},
  title     = {On the relationship between power and exponential transformations for positive signomial functions},
  year      = {2009},
  pages     = {1287--1292},
  volume    = {17},
  file      = {:FILES/2009 - lundell2009relationship - On the relationship between power and exponential transformations for positive signomial functions,.pdf:PDF},
  groups    = {SGP},
  timestamp = {2020-08-06},
}

@Article{lundell2009some,
  author    = {Lundell, Andreas and Westerlund, Joakim and Westerlund, Tapio},
  journal   = {Journal of Global Optimization},
  title     = {Some transformation techniques with applications in global optimization},
  year      = {2009},
  number    = {2-3},
  pages     = {391--405},
  volume    = {43},
  file      = {:FILES/2009 - lundell2009some - Some transformation techniques with applications in global optimization.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@PhdThesis{lundell2009transformation,
  author    = {Lundell, Andreas},
  title     = {Transformation techniques for signomial functions in global optimization},
  year      = {2009},
  file      = {:FILES/2009 - lundell2009transformation - Transformation techniques for signomial functions in global optimization.pdf:PDF},
  groups    = {SGP},
  publisher = {{\AA}bo Akademi University},
  timestamp = {2020-08-06},
}

@InCollection{lundell2012global,
  author    = {Lundell, Andreas and Westerlund, Tapio},
  booktitle = {Mixed Integer Nonlinear Programming},
  publisher = {Springer},
  title     = {Global optimization of mixed-integer signomial programming problems},
  year      = {2012},
  pages     = {349--369},
  file      = {:FILES/2012 - lundell2012global - Global optimization of mixed-integer signomial programming problems.pdf:PDF},
  groups    = {MILP, SGP},
  timestamp = {2020-08-06},
}

@Article{luo1992convergence,
  author    = {Luo, Zhiquan and Tseng, Paul},
  journal   = {Journal of Optimization Theory and Applications},
  title     = {On the convergence of the coordinate descent method for convex differentiable minimization},
  year      = {1992},
  number    = {1},
  pages     = {7--35},
  volume    = {72},
  groups    = {global optimization},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{luo1993error,
  author    = {Luo, Zhi-Quan and Tseng, Paul},
  journal   = {Annals of Operations Research},
  title     = {Error bounds and convergence analysis of feasible descent methods: {A} general approach},
  year      = {1993},
  number    = {1},
  pages     = {157--178},
  volume    = {46},
  groups    = {convergence},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{luo2018algorithmic,
  author  = {Luo, Yuping and Xu, Huazhe and Li, Yuanzhi and Tian, Yuandong and Darrell, Trevor and Ma, Tengyu},
  journal = {arXiv preprint arXiv:1807.03858},
  title   = {Algorithmic framework for model-based deep reinforcement learning with theoretical guarantees},
  year    = {2018},
  groups  = {RL},
}

@Article{Lustig1991InteriorFeasibility,
  author    = {Lustig, Irvin J.},
  journal   = {Mathematical Programming},
  title     = {Feasibility issues in a primal-dual interior-point method for linear programming},
  year      = {1991},
  number    = {1},
  pages     = {145--162},
  volume    = {49},
  groups    = {convergence},
  timestamp = {2020-08-05},
}

@Article{magnani2009convex,
  author    = {Magnani, Alessandro and Boyd, Stephen P.},
  journal   = {Optimization and Engineering},
  title     = {Convex piecewise-linear fitting},
  year      = {2009},
  number    = {1},
  pages     = {1--17},
  volume    = {10},
  file      = {:FILES/2009 - magnani2009convex - Convex piecewise-linear fitting.pdf:PDF},
  groups    = {identification},
  publisher = {Springer},
}

@InProceedings{mahadevan1997self,
  author       = {Mahadevan, Sridhar and Marchalleck, Nicholas and Das, Tapas K and Gosavi, Abhijit},
  booktitle    = {MACHINE LEARNING-INTERNATIONAL WORKSHOP THEN CONFERENCE-},
  title        = {Self-improving factory simulation using continuous-time average-reward reinforcement learning},
  year         = {1997},
  organization = {MORGAN KAUFMANN PUBLISHERS, INC.},
  pages        = {202--210},
  groups       = {RL},
}

@PhdThesis{Mahfoud1995,
  author  = {Mahfoud, Samir W.},
  school  = {University of Illinois at UrbanaChampaign},
  title   = {Niching methods for genetic algorithms},
  year    = {1995},
  address = {Transportation Building, South Mathews Avenue,Urbana, IL},
  month   = {5},
  type    = {phdthesis},
  file    = {:FILES/1995 - Mahfoud1995 - Niching Methods for Genetic Algorithms.pdf:PDF},
  groups  = {genetic algorithms},
  url     = {http://www.leg.ufpr.br/~leonardo/artigos/tese_mahfoud.pdf},
}

@Article{Malash2010,
  author     = {Malash, Gihan F. and El-Khaiary, Mohammad I.},
  journal    = {Chemical Engineering Journal},
  title      = {Piecewise linear regression: {A} statistical method for the analysis of experimental adsorption data by the intraparticle-diffusion models},
  year       = {2010},
  number     = {3},
  pages      = {256 -- 263},
  volume     = {163},
  bdsk-url-1 = {http://www.sciencedirect.com/science/article/pii/S1385894710006789},
  file       = {:FILES/2010 - Malash2010 - Piecewise linear regression- A statistical method for the analysis of experimental adsorption data by the intraparticle-diffusion models.pdf:PDF},
  groups     = {identification},
  timestamp  = {2020-09-04},
  url        = {http://www.sciencedirect.com/science/article/pii/S1385894710006789},
}

@Article{mandal2019dynamics,
  author  = {Mandal, Dhrubajyoti},
  journal = {Advances in Dynamical Systems and Applications (ADSA)},
  title   = {Dynamics of two dimensional piecewise smooth maps with stochastically varying border},
  year    = {2019},
  number  = {2},
  pages   = {245--255},
  volume  = {14},
  groups  = {application},
}

@Article{mandelbrot1963variation,
  author    = {Mandelbrot, Benoit},
  journal   = {The Journal of Business},
  title     = {The variation of certain speculative prices},
  year      = {1963},
  number    = {4},
  pages     = {394--419},
  volume    = {36},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
}

@Article{mangasarian1999generalized,
  author    = {Mangasarian, Olvi L.},
  journal   = {Advances in Neural Information Processing Systems},
  title     = {Generalized support vector machines},
  year      = {1999},
  pages     = {135--146},
  groups    = {SVM},
  publisher = {Citeseer},
  timestamp = {2020-08-30},
}

@Article{mangasarian1999successive,
  author    = {Mangasarian, Olvi L. and Musicant, David R.},
  journal   = {IEEE Transactions on Neural Networks},
  title     = {Successive overrelaxation for support vector machines},
  year      = {1999},
  number    = {5},
  pages     = {1032--1037},
  volume    = {10},
  groups    = {Neural Network, SVM},
  publisher = {IEEE},
  timestamp = {2020-08-30},
}

@Article{mangasarian2002finite,
  author  = {Mangasarian, Olvi L.},
  journal = {Optimization Methods and Software},
  title   = {A finite {Newton} method for classification},
  year    = {2002},
  number  = {5},
  pages   = {913--929},
  volume  = {17},
  groups  = {Neural Network},
}

@Article{Mangasarian2006exact,
  author    = {Mangasarian, Olvi L.},
  journal   = {Journal of Machine Learning Research},
  title     = {Exact 1-norm support vector machines via unconstrained convex differentiable minimization},
  year      = {2006},
  pages     = {1517--1530},
  volume    = {7},
  groups    = {SVM},
  numpages  = {14},
  timestamp = {2020-08-30},
}

@Article{Mangasarian2007,
  author    = {Mangasarian, Olvi L.},
  journal   = {Optimization Letters},
  title     = {Absolute value equation solution via concave minimization},
  year      = {2007},
  number    = {1},
  pages     = {3--8},
  volume    = {1},
  groups    = {global optimization},
  keywords  = {Absolute value equation; Concave minimization; Successive linear programming},
  language  = {English},
  publisher = {Springer-Verlag},
}

@Article{Mansini2007cvar,
  author    = {Mansini, Renata and Ogryczak, W{\l}odzimierz and Speranza, M. Grazia},
  journal   = {Annals of Operations Research},
  title     = {Conditional value at risk and related linear programming models for portfolio optimization},
  year      = {2007},
  number    = {1},
  pages     = {227--256},
  volume    = {152},
  file      = {:FILES/2007 - Mansini2007cvar - Conditional value at risk and related linear programming models for portfolio optimization.pdf:PDF},
  groups    = {cvar},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{maranas1992global,
  author    = {Maranas, Costas D and Floudas, Christodoulos A},
  journal   = {The Journal of chemical physics},
  title     = {A global optimization approach for lennard-jones microclusters},
  year      = {1992},
  number    = {10},
  pages     = {7667--7678},
  volume    = {97},
  groups    = {global optimization},
  publisher = {AIP},
}

@Article{maranas1993global,
  author    = {Maranas, Costas D and Floudas, Christodoulos A},
  journal   = {Annals of Operations Research},
  title     = {Global optimization for molecular conformation problems},
  year      = {1993},
  number    = {1},
  pages     = {85--117},
  volume    = {42},
  groups    = {global optimization},
  publisher = {Springer},
}

@Article{maranas1994deterministic,
  author    = {Maranas, Costas D and Floudas, Christodoulos A},
  journal   = {The Journal of chemical physics},
  title     = {A deterministic global optimization approach for molecular structure determination},
  year      = {1994},
  number    = {2},
  pages     = {1247--1261},
  volume    = {100},
  groups    = {global optimization},
  publisher = {AIP},
}

@ARTICLE{maranas1994global,
 AUTHOR = {Maranas, Costas D and Floudas, Christodoulos A},
 JOURNAL = {Journal of Global Optimization},
 NUMBER = {2},
 PAGES = {135--170},
 PUBLISHER = {Springer},
 TITLE = {Global minimum potential energy conformations of small molecules},
 VOLUME = {4},
 YEAR = {1994}
}

@Article{maranas1995finding,
  author    = {Maranas, Costas D and Floudas, Christodoulos A},
  journal   = {Journal of Global Optimization},
  title     = {Finding all solutions of nonlinearly constrained systems of equations},
  year      = {1995},
  number    = {2},
  pages     = {143--182},
  volume    = {7},
  groups    = {mathematical basis},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{maranas1997global,
  author    = {Maranas, Costas D. and Floudas, Christodoulos A.},
  journal   = {Computers \& Chemical Engineering},
  title     = {Global optimization in generalized geometric programming},
  year      = {1997},
  number    = {4},
  pages     = {351--369},
  volume    = {21},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@TechReport{marechal2014three,
  author      = {Mar\'{e}chal, Alexandre and P\'{e}rin, Micha\"{e}l},
  institution = {Citeseer},
  title       = {Three linearization techniques for multivariate polynomials in static analysis using convex polyhedra},
  year        = {2014},
  groups      = {SGP},
}

@InBook{maringer2008risk,
  author        = {Maringer, Dietmar},
  chapter       = {Natural Computing in Computational Finance},
  editor        = {Brabazon, Anthony and O\'Neill, Michael},
  pages         = {7--24},
  publisher     = {Springer Berlin Heidelberg},
  title         = {Constrained index tracking under loss aversion using differential evolution},
  year          = {2008},
  address       = {Berlin, Heidelberg},
  date-added    = {2016-03-03 06:01:11 +0000},
  date-modified = {2016-03-03 06:03:16 +0000},
  groups        = {differential evolution, Portfolio Selection},
  timestamp     = {2020-09-04},
}

@Article{markowitz1952portfolio,
  author    = {Markowitz, Harry},
  journal   = {Journal of Finance},
  title     = {Portfolio selection},
  year      = {1952},
  number    = {1},
  pages     = {77--91},
  volume    = {7},
  groups    = {Portfolio Selection},
  publisher = {Wiley Online Library},
  timestamp = {2020-09-04},
}

@Article{Markowitz1952Utility,
  author    = {Markowitz, Harry},
  journal   = {Journal of Political Economy},
  title     = {The utility of wealth},
  year      = {1952},
  number    = {2},
  pages     = {151--151},
  volume    = {60},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
}

@Article{markowitz1957solution,
  author    = {Markowitz, Harry M. and Manne, Alan S.},
  journal   = {Econometrica: Journal of the Econometric Society},
  title     = {On the solution of discrete programming problems},
  year      = {1957},
  pages     = {84--110},
  file      = {:FILES/1957 - markowitz1957solution - On the Solution of Discrete Programming Problems.pdf:PDF},
  groups    = {MILP},
  publisher = {JSTOR},
}

@Book{Markowitz1959book,
  author        = {Markowitz, Harry M.},
  publisher     = {Yale University Press},
  title         = {Portfolio selection: {Efficient} diversification of investments},
  year          = {1959},
  address       = {New Haven, Connecticut},
  series        = {Cowles Foundation Monograph: No. 16},
  bdsk-url-1    = {http://gen.lib.rus.ec/book/index.php?md5=BA9F07D3A6B88034394BD196045D2B8F},
  date-modified = {2016-03-03 05:30:38 +0000},
  groups        = {Portfolio Selection},
  timestamp     = {2020-09-04},
  url           = {http://gen.lib.rus.ec/book/index.php?md5=BA9F07D3A6B88034394BD196045D2B8F},
}

@Article{Echaust2020,
  author         = {Echaust, Krzysztof and Just, Ma{\l}gorzata},
  journal        = {Mathematics},
  title          = {Value at risk estimation using the {GARCH-EVT} approach with optimal tail selection},
  year           = {2020},
  issn           = {2227-7390},
  number         = {1},
  volume         = {8},
  abstract       = {A conditional Extreme Value Theory (GARCH-EVT) approach is a two-stage hybrid method that combines a Generalized Autoregressive Conditional Heteroskedasticity (GARCH) filter with the Extreme Value Theory (EVT). The approach requires pre-specification of a threshold separating distribution tails from its middle part. The appropriate choice of a threshold level is a demanding task. In this paper we use four different optimal tail selection algorithms, i.e., the path stability method, the automated Eye-Ball method, the minimization of asymptotic mean squared error method and the distance metric method with a mean absolute penalty function, to estimate out-of-sample Value at Risk (VaR) forecasts and compare them to the fixed threshold approach. Unlike other studies, we update the optimal fraction of the tail for each rolling window of the returns. The research objective is to verify to what extent optimization procedures can improve VaR estimates compared to the fixed threshold approach. Results are presented for a long and a short position applying 10 world stock indices in the period from 2000 to June 2019. Although each approach generates different threshold levels, the GARCH-EVT model produces similar Value at Risk estimates. Therefore, no improvement of VaR accuracy may be observed relative to the conservative approach taking the 95th quantile of returns as a threshold.},
  article-number = {114},
  comment        = {This paper may investigate the estimation of VaR using a hybrid method of the pametric method (GARCH) and the semiparametric method (EVT) and considers the influence of extreme events.},
  doi            = {10.3390/math8010114},
  file           = {:FILES/2020 - Echaust2020 - Value at Risk Estimation Using the GARCH-EVT Approach with Optimal Tail Selection.pdf:PDF},
  groups         = {TEC, parametric approach},
  keywords       = {skimmed},
  readstatus     = {skimmed},
  timestamp      = {2020-09-06},
  url            = {https://www.mdpi.com/2227-7390/8/1/114},
}

@InProceedings{Matsuoka2014fir,
  author    = {Matsuoka, R. and Baba, T. and Okuda, M.},
  booktitle = {Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific},
  title     = {Constrained design of {FIR} filters with sparse coefficients},
  year      = {2014},
  pages     = {1--4},
  file      = {:FILES/2014 - Matsuoka2014fir - Constrained Design of FIR Filters with Sparse Coefficients.pdf:PDF},
  groups    = {sparse},
}

@Article{Matsuoka2018fir,
  author     = {Matsuoka, R. and Kyochi, S. and Ono, S. and Okuda, M.},
  journal    = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title      = {Joint sparsity and order optimization based on admm with non-uniform group hard thresholding},
  year       = {2018},
  issn       = {1558-0806},
  month      = {5},
  number     = {5},
  pages      = {1602--1613},
  volume     = {65},
  abstract   = {This paper proposes a new optimization framework for the joint optimization of sparsity and filter order (JOSFO) for FIR filter design. Since the cost function for JOSFO involves ℓ0 and non-uniform overlapped group ℓ0 norms, which are not convex, a global optimal solution is difficult to obtain. To find an approximate solution of the non-convex problem, existing approaches repeat the following steps: 1) approximate the cost function; 2) find candidates of zero coefficients by minimizing the cost function; and 3) set them to zero. On the other hand, this paper directly solves the optimization problem, without any approximation to the cost function, by using the alternating direction method of multipliers with the pseudo-proximity operators of ℓ0 and non-uniform non-overlapped group ℓ0 norms. Experimental results show that resulting filters designed by the proposed method have sparser coefficients and lower orders, while satisfying filter specifications, such as an error from a desired frequency response.},
  doi        = {10.1109/TCSI.2017.2763969},
  file       = {:FILES/2018 - Matsuoka2018fir - Joint Sparsity and Order Optimization Based on ADMM With Non-Uniform Group Hard Thresholding.pdf:PDF},
  groups     = {sparse},
  keywords   = {concave programming;FIR filters;frequency response;filter specifications;joint sparsity;order optimization;nonuniform group hard;joint optimization;filter order;JOSFO;FIR filter design;cost function;nonuniform overlapped group;global optimal solution;approximate solution;nonconvex problem;nonoverlapped group;Finite impulse response filters;Frequency response;Cost function;Convex functions;Approximation algorithms;Algorithm design and analysis;FIR filter design;sparsity;l₀ pseudo-norm;ADMM algorithm, read},
  readstatus = {read},
}

@InProceedings{Mattera2002FIR,
  author    = {Mattera, D. and Palmierl, F. and Haykin, S.},
  booktitle = {2002 IEEE International Conference on Acoustics, Speech, and Signal Processing},
  title     = {Efficient sparse {FIR} filter design},
  year      = {2002},
  month     = {5},
  pages     = {II-1537-II-1540},
  volume    = {2},
  abstract  = {We consider the problem of designing a sparse FIR filter and show that it can be cast into a problem of determining a sparse solution of a linear system of equations. Previously proposed design algorithms for FIR filter utilize an intelligent search over all possible structures for sparse filter. We propose a new filter design method based on a simpler algorithm for finding a sparse solution of the linear system. Simulation experiments show significant improvements over classical nonsparse methods.},
  doi       = {10.1109/ICASSP.2002.5744907},
  file      = {:FILES/2002 - Mattera2002FIR - Efficient sparse FIR filter design.pdf:PDF},
  groups    = {sparse},
  issn      = {1520-6149},
  keywords  = {Complexity theory},
}

@INPROCEEDINGS{Mauldin1984,
 AUTHOR = {Mauldin, Michael L.},
 BOOKTITLE = {AAAI},
 GROUPS = {genetic algorithms},
 TIMESTAMP = {2020-06-13},
 TITLE = {Maintaining diversity in genetic search},
 YEAR = {1984}
}

@InProceedings{Mausser1999,
  author    = {Mausser, Helmut and Rosen, Dan},
  booktitle = {(CIFEr) Proceedings of the IEEE/IAFE 1999 Conference on Computational Intelligence for Financial Engineering},
  title     = {Beyond {VaR}: {From} measuring risk to managing risk},
  year      = {1999},
  pages     = {163--178},
  publisher = {IEEE},
  file      = {:FILES/1999 - Mausser1999 - Beyond VaR-rom measuring risk to managing risk.pdf:PDF},
  groups    = {VaR},
  timestamp = {2020-09-04},
  type      = {Conference Proceedings},
}

@Article{mazumder2011sparsenet,
  author  = {Mazumder, Rahul and Friedman, Jerome H. and Hastie, Trevor},
  journal = {Journal of the American Statistical Association},
  title   = {Sparsenet: {Coordinate} descent with nonconvex penalties},
  year    = {2011},
  number  = {495},
  pages   = {1125--1138},
  volume  = {106},
  groups  = {Neural Network},
}

@InProceedings{mcallester2011generalization,
  author    = {McAllester, David and Keshet, Joseph},
  booktitle = {Advances in Neural Information Processing Systems 24},
  title     = {Generalization bounds and consistency for latent structural probit and ramp loss},
  year      = {2011},
  pages     = {2205--2212},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@ARTICLE{mcclellan1973fortran,
 ABSTRACT = {This paper presents a general-purpose computer program which is capable of designing a large Class of optimum (in the minimax sense) FIR linear phase digital filters. The program has options for designing such standard filters as low-pass, high-pass, bandpass, and bandstop filters, as well as multipassband-stopband filters, differentiators, and Hilbert transformers. The program can also be used to design filters which approximate arbitrary frequency specifications which are provided by the user. The program is written in Fortran, and is carefully documented both by comments and by detailed flowcharts. The filter design algorithm is shown to be exceedingly efficient, e.g., it is capable of designing a filter with a 100-point impulse response in about 20 s.},
 AUTHOR = {McClellan, J. and Parks, T. and Rabiner, L.},
 DOI = {10.1109/TAU.1973.1162525},
 GROUPS = {FIR filter design},
 ISSN = {1558-2582},
 JOURNAL = {IEEE Transactions on Audio and Electroacoustics},
 KEYWORDS = {Finite impulse response filter;Digital filters;Band pass filters;Chebyshev approximation;Algorithm design and analysis;Frequency response;Nonlinear filters;Minimax techniques;Transformers;Flowcharts},
 MONTH = {12},
 NUMBER = {6},
 PAGES = {506--526},
 TITLE = {A computer program for designing optimum {FIR} linear phase digital filters},
 VOLUME = {21},
 YEAR = {1973}
}

@Article{McClellan2005fir,
  author   = {McClellan, J. H. and Parks, T. W.},
  journal  = {IEEE Signal Processing Magazine},
  title    = {A personal history of the {Parks-McClellan} algorithm},
  year     = {2005},
  issn     = {1558-0792},
  month    = {3},
  number   = {2},
  pages    = {82--86},
  volume   = {22},
  abstract = {This article describes the work that led to what is now known as the Parks-McClellan algorithm. Within the bigger picture of filter design methods, this paper recount events that had an impact on the inspiration to develop the Parks-McClellan algorithm, i.e., the Remez exchange algorithm with optimal Chebyshev approximation for FIR filter design.},
  doi      = {10.1109/MSP.2005.1406492},
  groups   = {FIR filter design},
  keywords = {FIR filters;network synthesis;Parks-McClellan algorithm;finite impulse response;optimal filter;Remez exchange algorithm;optimal Chebyshev approximation;FIR filter design;History;Digital signal processing;Finite impulse response filter;Signal processing algorithms;Chebyshev approximation;Springs;Approximation algorithms;Algorithm design and analysis;Approximation methods;Signal design},
}

@Article{mccormick1976computability,
  author    = {McCormick, Garth P},
  journal   = {Mathematical programming},
  title     = {Computability of global solutions to factorable nonconvex programs: {Part} i. - convex underestimating problems},
  year      = {1976},
  number    = {1},
  pages     = {147--175},
  volume    = {10},
  groups    = {global optimization},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{mcculloch1943logical,
  author    = {{McCulloch}, Warren S. and Pitts, Walter},
  journal   = {The bulletin of mathematical biophysics},
  title     = {A logical calculus of the ideas immanent in nervous activity},
  year      = {1943},
  number    = {4},
  pages     = {115--133},
  volume    = {5},
  file      = {:FILES/1943 - mcculloch1943logical - A logical calculus of the ideas immanent in nervous activity.pdf:PDF},
  groups    = {genetic algorithms},
  publisher = {Springer},
  timestamp = {2020-08-06},
}

@Article{mehra1985equity,
  author    = {Mehra, Rajnish and Prescott, Edward C},
  journal   = {Journal of monetary Economics},
  title     = {The equity premium: {A} puzzle},
  year      = {1985},
  number    = {2},
  pages     = {145--161},
  volume    = {15},
  groups    = {Portfolio Selection},
  publisher = {Elsevier},
  timestamp = {2020-09-04},
}

@Article{Mehrotra1992,
  author  = {Mehrotra, Sanjay},
  journal = {SIAM Journal on Optimization},
  title   = {On the implementation of a primal-dual interior point method},
  year    = {1992},
  number  = {4},
  pages   = {575--601},
  volume  = {2},
  groups  = {global optimization},
}

@Article{Mehrotra1993convergence,
  author    = {Mehrotra, Sanjay},
  journal   = {Mathematics of Operations Research},
  title     = {Quadratic convergence in a primal-dual method},
  year      = {1993},
  number    = {3},
  pages     = {741--751},
  volume    = {18},
  groups    = {global optimization},
  publisher = {INFORMS},
}

@Article{meng2000optimization,
  author    = {Meng, Xiao-Li},
  journal   = {Journal of Computational and Graphical Statistics},
  title     = {[optimization transfer using surrogate objective functions]: {Discussion}},
  year      = {2000},
  number    = {1},
  pages     = {35--43},
  volume    = {9},
  groups    = {interesting articles},
  publisher = {JSTOR},
}

@Article{Merton1969,
  author    = {Merton, Robert C.},
  journal   = {The review of Economics and Statistics},
  title     = {Lifetime portfolio selection under uncertainty: {The} continuous-time case},
  year      = {1969},
  month     = aug,
  number    = {3},
  pages     = {247--257},
  volume    = {51},
  file      = {:FILES/1969 - Merton1969 - Lifetime portfolio selection under uncertainty- {The} continuous-time case.pdf:PDF},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
  url       = {https://www.jstor.org/stable/1926560},
}

@Article{meyer2000simple,
  author    = {Meyer, Christophe},
  journal   = {Journal of Global Optimization},
  title     = {A simple finite cone covering algorithm for concave minimization},
  year      = {2000},
  number    = {4},
  pages     = {357--365},
  volume    = {18},
  groups    = {global optimization},
  publisher = {Springer},
}

@Article{meyer2004trilinear,
  author    = {Meyer, Clifford A and Floudas, Christodoulos A},
  journal   = {Journal of Global Optimization},
  title     = {Trilinear monomials with mixed sign domains: {Facets} of the convex and concave envelopes},
  year      = {2004},
  number    = {2},
  pages     = {125--155},
  volume    = {29},
  groups    = {MILP},
  publisher = {Springer},
}

@Article{meyer2005convex,
  author    = {Meyer, Clifford A and Floudas, Christodoulos A},
  journal   = {Mathematical programming},
  title     = {Convex envelopes for edge-concave functions},
  year      = {2005},
  number    = {2},
  pages     = {207--224},
  volume    = {103},
  groups    = {global optimization},
  publisher = {Springer},
}

@InProceedings{meyer2005robust,
  author       = {Meyer, Miriah D and Georgel, Pierre and Whitaker, Ross T},
  booktitle    = {International Conference on Shape Modeling and Applications 2005 (SMI'05)},
  title        = {Robust particle systems for curvature dependent sampling of implicit surfaces},
  year         = {2005},
  organization = {IEEE},
  pages        = {124--133},
  groups       = {interesting articles},
}

@Article{MezuraMontes2011,
  author     = {Mezura-Montes, Efr\'{o}n and Coello Coello, Carlos A.},
  journal    = {Swarm and Evolutionary Computation},
  title      = {Constraint-handling in nature-inspired numerical optimization: {Past,} present and future},
  year       = {2011},
  issn       = {2210-6502},
  number     = {4},
  pages      = {173 -- 194},
  volume     = {1},
  abstract   = {In their original versions, nature-inspired search algorithms such as evolutionary algorithms and those based on swarm intelligence, lack a mechanism to deal with the constraints of a numerical optimization problem. Nowadays, however, there exists a considerable amount of research devoted to design techniques for handling constraints within a nature-inspired algorithm. This paper presents an analysis of the most relevant types of constraint-handling techniques that have been adopted with nature-inspired algorithms. From them, the most popular approaches are analyzed in more detail. For each of them, some representative instantiations are further discussed. In the last part of the paper, some of the future trends in the area, which have been only scarcely explored, are briefly discussed and then the conclusions of this paper are presented.},
  doi        = {https://doi.org/10.1016/j.swevo.2011.10.001},
  file       = {:FILES/2011 - MezuraMontes2011 - Constraint-handling in nature-inspired numerical optimization- Past, present and future .pdf:PDF},
  groups     = {genetic algorithms, Evolutionary Algorithms},
  keywords   = {Constraint-handling, Differential evolution, Evolution strategies, Particle swarm optimization, Genetic algorithms, Evolutionary programming, read, prio1},
  priority   = {prio1},
  readstatus = {read},
  timestamp  = {2020-06-08},
  url        = {http://www.sciencedirect.com/science/article/pii/S2210650211000538},
}

@Book{michalewicz2013genetic,
  author    = {Michalewicz, Zbigniew},
  publisher = {Springer Science \& Business Media},
  title     = {Genetic algorithms $+$ data structures {=} evolution programs},
  year      = {2013},
  address   = {New York},
  groups    = {genetic algorithms, TEC},
  timestamp = {2020-09-05},
}

@MISC{Michie_9boxes,
 AUTHOR = {Michie, Donald and Chambers, R. A.},
 TITLE = {Boxes: {An} experiment in adaptive control},
 YEAR = {1968}
}

@Article{Milgrom2002envelop,
  author   = {Milgrom, Paul and Segal, Ilya},
  journal  = {Econometrica},
  title    = {Envelope theorems for arbitrary choice sets},
  year     = {2002},
  number   = {2},
  pages    = {583--601},
  volume   = {70},
  abstract = {The standard envelope theorems apply to choice sets with convex and topological structure, providing sufficient conditions for the value function to be differentiable in a parameter and characterizing its derivative. This paper studies optimization with arbitrary choice sets and shows that the traditional envelope formula holds at any differentiability point of the value function. We also provide conditions for the value function to be, variously, absolutely continuous, left- and right-differentiable, or fully differentiable. These results are applied to mechanism design, convex programming, continuous optimization problems, saddle-point problems, problems with parameterized constraints, and optimal stopping problems.},
  doi      = {10.1111/1468-0262.00296},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1468-0262.00296},
  file     = {:FILES/2002 - Milgrom2002envelop - Envelope Theorems for Arbitrary Choice Sets.pdf:PDF},
  groups   = {interesting articles},
  keywords = {envelope theorem, differentiable value function, sensitivity analysis, math programming, mechanism design},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-0262.00296},
}

@MISC{minimaxIntro,
 TITLE = {Best approximation: {Minimax} theory},
 URL = {http://home.iitk.ac.in/~sghorai/TEACHING/MTH308/minimax.pdf}
}

@Book{minsky1954theory,
  author    = {Minsky, M.L.},
  publisher = {Princeton University.},
  title     = {Theory of neural-analog reinforcement systems and its application to the brain model problem},
  year      = {1954},
  groups    = {interesting articles},
  url       = {https://books.google.com/books?id=qSwZAQAAIAAJ},
}

@InBook{Mirjalili2020,
  author     = {Mirjalili, Seyedali and Song Dong, Jin and Sadiq, Ali Safa and Faris, Hossam},
  editor     = {Mirjalili, Seyedali and Song Dong, Jin and Lewis, Andrew},
  pages      = {69--85},
  publisher  = {Springer International Publishing},
  title      = {Genetic algorithm: {Theory,} literature review, and application in image reconstruction},
  year       = {2020},
  address    = {Cham},
  isbn       = {978-3-030-12127-3},
  abstract   = {Genetic Algorithm (GA) is one of the most well-regarded evolutionary algorithms in the history. This algorithm mimics Darwinian theory of survival of the fittest in nature. This chapter presents the most fundamental concepts, operators, and mathematical models of this algorithm. The most popular improvements in the main component of this algorithm (selection, crossover, and mutation) are given too. The chapter also investigates the application of this technique in the field of image processing. In fact, the GA algorithm is employed to reconstruct a binary image from a completely random image.},
  booktitle  = {Nature-Inspired Optimizers: Theories, Literature Reviews and Applications},
  doi        = {10.1007/978-3-030-12127-3_5},
  file       = {:FILES/2020 - Mirjalili2020 - Genetic Algorithm- Theory, Literature Review, and Application in Image Reconstruction.pdf:PDF},
  groups     = {genetic algorithms, TEC},
  keywords   = {read},
  readstatus = {read},
  timestamp  = {2020-09-05},
  url        = {https://doi.org/10.1007/978-3-030-12127-3_5},
}

@Article{Misener2010,
  author    = {Misener, R. and Floudas, C. A.},
  journal   = {Journal of optimization theory and applications},
  title     = {Piecewise-linear approximations of multidimensional functions},
  year      = {2010},
  number    = {1},
  pages     = {120--147},
  volume    = {145},
  file      = {:FILES/2010 - Misener2010 - Piecewise-Linear Approximations of Multidimensional Functions.pdf:PDF},
  groups    = {Approximation},
  publisher = {Springer},
}

@Article{misener2011apogee,
  author    = {Misener, Ruth and Thompson, Jeffrey P. and Floudas, Christodoulos A.},
  journal   = {Computers \& Chemical Engineering},
  title     = {{APOGEE}: {Global} optimization of standard, generalized, and extended pooling problems via linear and logarithmic partitioning schemes},
  year      = {2011},
  number    = {5},
  pages     = {876--892},
  volume    = {35},
  file      = {:FILES/2011 - misener2011apogee - APOGEE- Global optimization of standard, generalized, and extended pooling problems via linear and logarithmic partitioning schemes.pdf:PDF},
  groups    = {global optimization},
  publisher = {Elsevier},
}

@InBook{mitchell1999interior,
  author        = {Mitchell, John E. and Pardalos, Panos M. and Resende, Mauricio G. C.},
  chapter       = {Interior point methods for combinatorial optimization},
  editor        = {Du, Ding-Zhu and Pardalos, Panos M.},
  pages         = {189--297},
  publisher     = {Springer US},
  year          = {1998},
  address       = {Boston, MA},
  isbn          = {978-1-4613-7987-4},
  booktitle     = {Handbook of combinatorial optimization},
  date-modified = {2016-03-03 05:38:22 +0000},
  doi           = {https://doi.org/10.1007/978-1-4613-0303-9_4},
  groups        = {MILP},
  url           = {https://link.springer.com/chapter/10.1007/978-1-4613-0303-9_4},
}

@Article{Mitra1993firsubfilter,
  author   = {Mitra, S. K. and Mahalonobis, A. and Saramaki, T.},
  journal  = {IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing},
  title    = {A generalized structural subband decomposition of {FIR} filters and its application in efficient {FIR} filter design and implementation},
  year     = {1993},
  issn     = {1558-125X},
  month    = {6},
  number   = {6},
  pages    = {363--374},
  volume   = {40},
  abstract = {It is shown that any FIR (finite-impulse-response) transfer function can be realized as a parallel connection of interpolated FIR (IFIR) sections consisting of a cascade of a subfilter with a sparse impulse response and an FIR interpolator which fills in the missing samples of the corresponding subfilter. The set of interpolators can be realized as a subband filter bank, and as a result, each IFIR section contributes to the overall frequency response essentially within a given band of frequencies. The proposed decomposition can be considered as a generalization of the polyphase decomposition. It results in a computationally efficient structure in sampling rate alteration applications and also leads to faster FIR filter design algorithms. Examples are included to demonstrate the improvements in the speed of least-squares and minimax design algorithms based on the suggested structure.<>},
  doi      = {10.1109/82.277881},
  file     = {:FILES/1993 - Mitra1993firsubfilter - A generalized structural subband decomposition of FIR filters and its application in efficient FIR filter design and implementation.pdf:PDF},
  groups   = {FIR filter design},
  keywords = {digital filters;frequency response;interpolation;transfer functions;least-squares design;generalized structural subband decomposition;FIR filters;filter design;transfer function;parallel connection;interpolated FIR;subfilter;sparse impulse response;subband filter bank;IFIR section;frequency response;polyphase decomposition;computationally efficient structure;sampling rate;minimax design;Finite impulse response filter;Algorithm design and analysis;Frequency response;Nonlinear filters;Transfer functions;Sampling methods;Minimax techniques;Arithmetic;Filtering theory;Band pass filters},
}

@Book{mitra2006DSP,
  author    = {Mitra, Sanjit K.},
  publisher = {Singapur: McGraw Hill},
  title     = {Digital signal processing: {A} computer-based approach},
  year      = {2006},
  edition   = {third},
  groups    = {DSP},
}

@Article{mnih2013playing,
  author  = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal = {arXiv preprint arXiv:1312.5602},
  title   = {Playing {Atari} with deep reinforcement learning},
  year    = {2013},
  groups  = {RL},
}

@Article{Mnih2015,
  author        = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  journal       = {Nature},
  title         = {Human-level control through deep reinforcement learning},
  year          = {2015},
  number        = {7540},
  pages         = {529--533},
  volume        = {518},
  abstract      = {An artificial agent is developed that learns to play a diverse range of classic Atari 2600 computer games directly from sensory experience, achieving a performance comparable to that of an expert human player; this work paves the way to building general-purpose learning algorithms that bridge the divide between perception and action.},
  bdsk-url-1    = {https://doi.org/10.1038/nature14236},
  da            = {2015/02/01},
  date-added    = {2020-02-21 08:45:43 +0000},
  date-modified = {2020-02-21 08:45:43 +0000},
  doi           = {10.1038/nature14236},
  groups        = {RL},
  isbn          = {1476-4687},
  publisher     = {Nature Publishing Group},
  ty            = {JOUR},
  url           = {https://doi.org/10.1038/nature14236},
}

@InProceedings{mnih2016rl,
  author    = {Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle = {Proceedings of The 33rd International Conference on Machine Learning},
  title     = {Asynchronous methods for deep reinforcement learning},
  year      = {2016},
  address   = {New York, New York, USA},
  editor    = {Balcan, Maria Florina and Weinberger, Kilian Q.},
  month     = {6},
  pages     = {1928--1937},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {48},
  abstract  = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
  groups    = {RL},
  pdf       = {http://proceedings.mlr.press/v48/mniha16.pdf},
  url       = {http://proceedings.mlr.press/v48/mniha16.html},
}

@Article{Monteiro1989interiorPart1,
  author     = {Monteiro, Renato D. C. and Adler, Ilan},
  journal    = {Mathematical Programming},
  title      = {Interior path following primal-dual algorithms. {Part} {II}: {Convex} quadratic programming},
  year       = {1989},
  number     = {1},
  pages      = {43--66},
  volume     = {44},
  address    = {Secaucus, NJ, USA},
  groups     = {global optimization},
  issue_date = {1989},
  publisher  = {Springer-Verlag New York, Inc.},
  timestamp  = {2020-08-05},
}

@InProceedings{montgomery2016guided,
  author    = {Montgomery, William H and Levine, Sergey},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Guided policy search via approximate mirror descent},
  year      = {2016},
  pages     = {4008--4016},
  groups    = {RL},
}

@InProceedings{Morgan2015,
  author    = {Morgan, Thomas J. H. and Griffiths, Thomas L.},
  booktitle = {Proceedings of the 37th Annual Meeting of the Cognitive Science Society, CogSci 2015, Pasadena, California, USA, July 22-25, 2015},
  title     = {What the baldwin effect affects},
  year      = {2015},
  editor    = {Noelle, David C. and Dale, Rick and Warlaumont, Anne S. and Yoshimi, Jeff and Matlock, Teenie and Jennings, Carolyn D. and Maglio, Paul P.},
  publisher = {cognitivesciencesociety.org},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl    = {https://dblp.org/rec/conf/cogsci/MorganG15.bib},
  file      = {:FILES/2015 - Morgan2015 - What the Baldwin Effect affects.pdf:PDF},
  groups    = {genetic algorithms},
  timestamp = {2020-06-05},
  url       = {https://mindmodeling.org/cogsci2015/papers/0286/index.html},
}

@Article{muller1996bayesian,
  author    = {M\"{u}ller, Peter and Erkanli, Alaattin and West, Mike},
  journal   = {Biometrika},
  title     = {Bayesian curve fitting using multivariate normal mixtures},
  year      = {1996},
  number    = {1},
  pages     = {67--79},
  volume    = {83},
  groups    = {machine learning},
  publisher = {Oxford University Press},
}

@Article{murray1971analytical,
  author    = {Murray, Walter},
  journal   = {Journal of Optimization Theory and Applications},
  title     = {Analytical expressions for the eigenvalues and eigenvectors of the {Hessian} matrices of barrier and penalty functions},
  year      = {1971},
  number    = {3},
  pages     = {189--196},
  volume    = {7},
  groups    = {interesting articles},
  publisher = {Springer},
}

@Article{muu1993combined,
  author    = {Muu, L\^{E} D and Oettli, Werner},
  journal   = {Journal of Global Optimization},
  title     = {Combined branch-and-bound and cutting plane methods for solving a class of nonlinear programming problems},
  year      = {1993},
  number    = {3},
  pages     = {377--391},
  volume    = {3},
  groups    = {MILP},
  publisher = {Springer},
}

@Article{muu1994efficient,
  author  = {Muu, LD and Tam, BT},
  journal = {Acta Mathematica Vietnamica},
  title   = {Efficient methods for solving certain bilinear programming problem},
  year    = {1994},
  groups  = {bilinear},
}

@Article{Myerson1981OptimalAD,
  author    = {Myerson, Roger B.},
  journal   = {Mathematics of Operations Research},
  title     = {Optimal auction design},
  year      = {1981},
  month     = feb,
  number    = {1},
  pages     = {58--73},
  volume    = {6},
  file      = {:FILES/1981 - Myerson1981OptimalAD - Optimal auction design.pdf:PDF},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
}

@InProceedings{Nagabandi2018,
  author    = {Nagabandi, A. and Kahn, G. and Fearing, R. S. and Levine, S.},
  booktitle = {2018 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  year      = {2018},
  month     = {5},
  pages     = {7559--7566},
  abstract  = {Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that neural network dynamics models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits that accomplish various complex locomotion tasks. We further propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free methods. We empirically demonstrate on MuJoCo locomotion tasks that our pure model-based approach trained on just random action data can follow arbitrary trajectories with excellent sample efficiency, and that our hybrid algorithm can accelerate model-free learning on high-speed benchmark tasks, achieving sample efficiency gains of 3-5× on swimmer, cheetah, hopper, and ant agents. Videos can be found at https://sites.google.com/view/mbmf.},
  doi       = {10.1109/ICRA.2018.8463189},
  groups    = {RL},
  issn      = {2577-087X},
  keywords  = {computational complexity;learning (artificial intelligence);neural nets;predictive control;model-free learning;model-free fine-tuning;model-free deep reinforcement learning algorithms;model-based algorithms;model predictive control;model-based reinforcement learning algorithm;complex locomotion tasks;deep neural network dynamics models;model-free learner;model-based approaches;model-free methods;sample complexity;model-based deep reinforcement learning;robotic skills;MPC;plausible gaits;stable gaits;Task analysis;Predictive models;Neural networks;Data models;Heuristic algorithms;Machine learning;Complexity theory},
}

@Article{Nagahara2014fir_hinf,
  author    = {Nagahara, Masaaki and Yamamoto, Yutaka},
  journal   = {IFAC Proceedings Volumes},
  title     = {{FIR} digital filter design by sampled-data {$H^\infty$} discretization},
  year      = {2014},
  issn      = {1474-6670},
  note      = {19th IFAC World Congress},
  number    = {3},
  pages     = {3110--3115},
  volume    = {47},
  abstract  = {FIR (finite impulse response) digital filter design is a fundamental problem in signal processing. In particular, FIR approximation of analog filters (or systems) is ubiquitous not only in signal processing but also in digital implementation of controllers. In this article, we propose a new design method of an FIR digital filter that optimally approximates a given analog filter in the sense of minimizing the H∞ norm of the sampled-data error system. By using the lifting technique and the KYP (KalmanYakubovichPopov) lemma, we reduce the H∞ optimization to a convex optimization described by an LMI (linear matrix inequality). We also extend the method to multi-rate and multi-delay systems. A design example is shown to illustrate the effectiveness of the proposed method.},
  doi       = {https://doi.org/10.3182/20140824-6-ZA-1003.00831},
  file      = {:FILES/2014 - Nagahara2014fir_hinf - FIR Digital Filter Design by Sampled-Data H-infinity Discretization.pdf:PDF},
  groups    = {FIR filter design},
  timestamp = {2020-08-07},
  url       = {http://www.sciencedirect.com/science/article/pii/S1474667016420859},
}

@Article{nemirovski2009robust,
  author    = {Nemirovski, Arkadi and Juditsky, Anatoli and Lan, Guanghui and Shapiro, Alexander},
  journal   = {SIAM Journal on optimization},
  title     = {Robust stochastic approximation approach to stochastic programming},
  year      = {2009},
  number    = {4},
  pages     = {1574--1609},
  volume    = {19},
  file      = {:FILES/2009 - nemirovski2009robust - Robust stochastic approximation approach to stochastic programming.pdf:PDF},
  groups    = {stochastic programming},
  publisher = {SIAM},
}

@Book{nesterov1994interior,
  author        = {Nesterov, Yurii and Nemirovskii, Arkadii},
  publisher     = {Society for Industrial and Applied Mathematics},
  title         = {Interior-point polynomial algorithms in convex programming},
  year          = {1994},
  address       = {Philadelphia, PA},
  volume        = {13},
  date-modified = {2016-03-03 05:57:26 +0000},
  doi           = {10.1137/1.9781611970791},
  eprint        = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611970791},
  groups        = {convergence},
  url           = {https://epubs.siam.org/doi/abs/10.1137/1.9781611970791},
}

@Article{Nesterov2012cda,
  author  = {Nesterov, Yu},
  journal = {SIAM Journal on Optimization},
  title   = {Efficiency of coordinate descent methods on huge-scale optimization problems},
  year    = {2012},
  issn    = {1052-6234},
  number  = {2},
  pages   = {341--362},
  volume  = {22},
  groups  = {global optimization},
}

@InProceedings{Neubauer1997,
  author    = {Neubauer, A.},
  booktitle = {Proceedings of 1997 IEEE International Conference on Evolutionary Computation (ICEC '97)},
  title     = {A theoretical analysis of the non-uniform mutation operator for the modified genetic algorithm},
  year      = {1997},
  month     = {4},
  pages     = {93--96},
  abstract  = {This paper presents a theoretical investigation of Michalewicz's non-uniform mutation operator proposed for his modified variant of genetic algorithms modGA to tackle numerical parameter optimization problems. As is shown by mathematical analysis, the non-uniform mutation operator prefers parameter values in the center of the corresponding feasible region. This leads to problems if the optimum is situated near the boundaries of the feasible region. In order to avoid this undesirable tendency, an adaptive non-uniform mutation operator is proposed, the development of which rests on the mathematical analysis. Experimental results for a standard numerical parameter optimization problem are given that illustrate the superiority of this novel mutation operator.},
  doi       = {10.1109/ICEC.1997.592275},
  file      = {:FILES/1997 - Neubauer1997 - A theoretical analysis of the non-uniform mutation operator for the modified genetic algorithm.pdf:PDF},
  groups    = {genetic algorithms},
  keywords  = {genetic algorithms;mathematical analysis;parameter estimation;nonuniform mutation operator;modified genetic algorithm;numerical parameter optimization problems;mathematical analysis;numerical parameter optimization problem;Algorithm design and analysis;Genetic mutations;Genetic algorithms;Mathematical analysis;Evolutionary computation},
  timestamp = {2020-06-13},
}

@Article{Newmann1953EUT,
  author    = {Von Neumann, John and Morgenstern, Oskar},
  journal   = {Princeton Paperbacks},
  title     = {Theory of games and economic behavior},
  year      = {1953},
  number    = {1},
  pages     = {2--14},
  volume    = {21},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@InCollection{nguyen2003dc,
  author    = {Nguyen, TQ and Bouhtou, M and Lutton, J-L},
  booktitle = {Optimization and Optimal Control},
  publisher = {World Scientific},
  title     = {{DC} approach to bilevel bilinear programming problem: {Application} in telecommunication pricing},
  year      = {2003},
  pages     = {211--231},
  groups    = {bilinear},
}

@InCollection{Nie2010,
  author    = {Nie, Feiping and Huang, Heng and Cai, Xiao and Ding, Chris H.},
  booktitle = {Advances in Neural Information Processing Systems 23},
  publisher = {Curran Associates, Inc.},
  title     = {Efficient and robust feature selection via joint \mathscr{l}2,1-norms minimization},
  year      = {2010},
  editor    = {Lafferty, J. D. and Williams, C. K. I. and Shawe-Taylor, J. and Zemel, R. S. and Culotta, A.},
  pages     = {1813--1821},
  file      = {:FILES/2010 - Nie2010 - Efficient and robust feature selection via joint ℓ2, 1-norms minimization.pdf:PDF},
  groups    = {Feature Selection},
  timestamp = {2020-06-08},
  url       = {http://papers.nips.cc/paper/3988-efficient-and-robust-feature-selection-via-joint-l21-norms-minimization.pdf},
}

@Article{Nielsen2016,
  author    = {Nielsen, Frank and Sun, Ke},
  journal   = {Entropy},
  title     = {Guaranteed bounds on information-theoretic measures of univariate mixtures using piecewise log-sum-exp inequalities},
  year      = {2016},
  number    = {12},
  pages     = {442},
  volume    = {18},
  file      = {:FILES/2016 - Nielsen2016 - guaranteed bounds on information-theoretic measures of univariate mixtures using piecewise log-sum-exp inequalities.pdf:PDF},
  groups    = {LSEO},
  publisher = {Multidisciplinary Digital Publishing Institute},
  timestamp = {2020-08-31},
}

@TECHREPORT{North1996,
 AUTHOR = {North, Christopher Houck and Joines, Jeffery A. and Kay, Michael G. and Houck, Christopher R. and Houck, Christopher R.},
 GROUPS = {genetic algorithms},
 TITLE = {A genetic algorithm for function optimization: {A} matlab implementation},
 YEAR = {1996}
}

@Article{ohtsuki1977existence,
  author  = {Ohtsuki, T. and Fujisawa, T. and Kumagai, S.},
  journal = {SIAM Journal on Mathematical Analysis},
  title   = {Existence theorems and a solution algorithm for piecewise-linear resistor networks},
  year    = {1977},
  pages   = {69},
  volume  = {8},
  groups  = {application},
}

@Article{OLEARY1990497,
  author  = {O\'Leary, D.P and Stewart, G.W},
  journal = {Journal of Computational Physics},
  title   = {Computing the eigenvalues and eigenvectors of symmetric arrowhead matrices},
  year    = {1990},
  issn    = {0021-9991},
  number  = {2},
  pages   = {497 -- 505},
  volume  = {90},
  doi     = {https://doi.org/10.1016/0021-9991(90)90177-3},
  groups  = {interesting articles},
  url     = {http://www.sciencedirect.com/science/article/pii/0021999190901773},
}

@INPROCEEDINGS{Oliver1987,
 ADDRESS = {USA},
 AUTHOR = {Oliver, I. M. and Smith, D. J. and Holland, J. R. C.},
 BOOKTITLE = {Proceedings of the Second International Conference on Genetic Algorithms on Genetic Algorithms and Their Application},
 GROUPS = {genetic algorithms},
 ISBN = {0805801588},
 LOCATION = {Cambridge, Massachusetts, USA},
 NUMPAGES = {7},
 PAGES = {224--230},
 PUBLISHER = {L. Erlbaum Associates Inc.},
 TITLE = {A study of permutation crossover operators on the traveling salesman problem},
 YEAR = {1987}
}

@InBook{Ono2003,
  author    = {Ono, Isao and Kita, Hajime and Kobayashi, Shigenobu},
  editor    = {Ghosh, Ashish and Tsutsui, Shigeyoshi},
  pages     = {213--237},
  publisher = {Springer Berlin Heidelberg},
  title     = {A real-coded genetic algorithm using the unimodal normal distribution crossover},
  year      = {2003},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-18965-4},
  abstract  = {This chapter presents a real-coded genetic algorithm using the Unimodal Normal Distribution Crossover (UNDX) that can efficiently optimize functions with epistasis among parameters. Most conventional crossover operators for function optimization have been reported to have a serious problem in that their performance deteriorates considerably when they are applied to functions with epistasis among parameters. We believe that the reason for the poor performance of the conventional crossover operators is that they cannot keep the distribution of individuals unchanged in the process of repetitive crossover operations on functions with epistasis among parameters. In considering the above problem, we introduce three guidelines, `Preservation of Statistics', `Diversity of Offspring', and `Enhancement of Robustness', for designing crossover operators that show good performance even on epistatic functions. We show that the UNDX meets the guidelines very well by a theoretical analysis and that the UNDX shows better performance than some conventional crossover operators by applying them to some benchmark functions including multimodal and epistatic ones. We also discuss some improvements of the UNDX under the guidelines and the relation between real-coded genetic algorithms using the UNDX and evolution strategies (ESs) using the correlated mutation.},
  booktitle = {Advances in Evolutionary Computing: {Theory} and Applications},
  doi       = {10.1007/978-3-642-18965-4_8},
  file      = {:FILES/2003 -  Advances in Evolutionary Computing_ Theory and Applications-Springer.pdf:PDF},
  groups    = {genetic algorithms},
  url       = {https://doi.org/10.1007/978-3-642-18965-4_8},
}

@InProceedings{Oosthuizen1987,
  author    = {Oosthuizen, Deon G.},
  booktitle = {Proceedings of the Second International Conference on Genetic Algorithms on Genetic Algorithms and Their Application},
  title     = {{SUPERGRAN}: {A} connectionist approach to learning, integrating genetic algorithms and graph induction},
  year      = {1987},
  address   = {USA},
  pages     = {132--139},
  publisher = {L. Erlbaum Associates Inc.},
  groups    = {genetic algorithms},
  isbn      = {0805801588},
  location  = {Cambridge, Massachusetts, USA},
  numpages  = {8},
  timestamp = {2020-06-13},
}

@Article{orlov2008numerical,
  author    = {Orlov, Andrei Vasil\'evich},
  journal   = {Computational Mathematics and Mathematical Physics},
  title     = {Numerical solution of bilinear programming problems},
  year      = {2008},
  number    = {2},
  pages     = {225--241},
  volume    = {48},
  groups    = {bilinear},
  publisher = {Springer},
}

@Article{Ortobelli2005risk,
  author    = {Ortobelli, Sergio and Rachev, Svetlozar T. and Stoyanov, Stoyan and Fabozzi, Frank J. and Biglova, Almira},
  journal   = {International Journal of Theoretical \& Applied Finance},
  title     = {The proper use of risk measures in portfolio theory},
  year      = {2005},
  number    = {8},
  pages     = {1107--1133},
  volume    = {8},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{osnaga2005rank,
  author    = {Osnaga, Silvia Monica},
  journal   = {Balkan Journal of Geometry and Its Applications},
  title     = {On rank one matrices and invariant subspaces},
  year      = {2005},
  number    = {1},
  pages     = {145},
  volume    = {10},
  groups    = {interesting articles},
  publisher = {GEOMETRY BALKON PRESS},
}

@Article{Ozkan2003control,
  author   = {\"Ozkan, Leyla and Kothare, Mayuresh V. and Georgakis, Christos},
  journal  = {Chemical Engineering Science},
  title    = {Control of a solution copolymerization reactor using multi-model predictive control},
  year     = {2003},
  number   = {7},
  pages    = {1207 -- 1221},
  volume   = {58},
  groups   = {interesting articles},
  keywords = {Linear matrix inequalities},
}

@Article{Pachon2009,
  author   = {Pach\'{o}n, Ricardo and Trefethen, Lloyd N.},
  journal  = {BIT Numerical Mathematics},
  title    = {{Barycentric-Remez} algorithms for best polynomial approximation in the chebfun system},
  year     = {2009},
  issn     = {1572-9125},
  month    = {10},
  number   = {4},
  pages    = {721},
  volume   = {49},
  abstract = {The Remez algorithm, 75 years old, is a famous method for computing minimax polynomial approximations. Most implementations of this algorithm date to an era when tractable degrees were in the dozens, whereas today, degrees of hundreds or thousands are not a problem. We present a 21st-century update of the Remez ideas in the context of the chebfun software system, which carries out numerical computing with functions rather than numbers. A crucial feature of the new method is its use of chebfun global rootfinding to locate extrema at each iterative step, based on a recursive algorithm combining ideas of Specht, Good, Boyd, and Battles. Another important feature is the use of the barycentric interpolation formula to represent the trial polynomials, which points the way to generalizations for rational approximations. We comment on available software for minimax approximation and its scientific context, arguing that its greatest importance these days is probably for fundamental studies rather than applications.},
  day      = {10},
  doi      = {10.1007/s10543-009-0240-1},
  groups   = {FIR filter design, interesting articles},
  url      = {https://doi.org/10.1007/s10543-009-0240-1},
}

@Article{padberg2000approximating,
  author  = {Padberg, Manfred},
  journal = {Operations Research Letters},
  title   = {Approximating separable nonlinear functions via mixed zero-one programs},
  year    = {2000},
  number  = {1},
  pages   = {1--5},
  volume  = {27},
  file    = {:FILES/2000 - padberg2000approximating - Approximating separable nonlinear functions via mixed zero-one programs.pdf:PDF},
  groups  = {DSP, global optimization},
}

@Article{Palacios-Gomez1982NLPproof,
  author    = {Palacios-Gomez, F. and Lasdon, L. and Engquist, M.},
  journal   = {Management Science},
  title     = {Nonlinear optimization by successive linear programming},
  year      = {1982},
  issn      = {00251909, 15265501},
  number    = {10},
  pages     = {1106--1120},
  volume    = {28},
  abstract  = {Successive Linear Programming (SLP), which is also known as the Method of Approximation Programming, solves nonlinear optimization problems via a sequence of linear programs. This paper reports on promising computational results with SLP that contrast with the poor performance indicated by previously published comparative tests. The paper provides a detailed description of an efficient, reliable SLP algorithm along with a convergence theorem for linearly constrained problems and extensive computational results. It also discusses several alternative strategies for implementing SLP. The computational results show that SLP compares favorably with the Generalized Reduced Gradient Code GRG2 and with MINOS/GRG. It appears that SLP will be most successful when applied to large problems with low degrees of freedom.},
  groups    = {global optimization},
  publisher = {INFORMS},
  url       = {http://www.jstor.org/stable/2630940},
}

@Article{PAN1987285,
  author   = {Pan, V.},
  journal  = {Computers \& Mathematics with Applications},
  title    = {Algebraic complexity of computing polynomial zeros},
  year     = {1987},
  issn     = {0898-1221},
  number   = {4},
  pages    = {285 -- 304},
  volume   = {14},
  abstract = {Using the power sum techniques of Turan, we evaluate all the complex zeros of an nth degree univariate polynomial with relative errors ⩽ ϵ using O(n2 log n (n log n + log(1/ϵ))) arithmetic operations. O(n log n log(1/ϵ)) operations suffice to approximate (with relative error ⩽ ϵ) a single complex zero using Turan's method and all the zeros if they are real using Graeffe's method. In all cases n processors suffice for cn times parallel acceleration where c is a positive constant. Incorporating Turan's techniques into another, more recent algorithm gives a single complex zero with absolute error ⩽ ϵ using O(log2n log log(|λ1/ϵ|)) arithmetic parallel steps, n2 processors (which places the problem in NC) and also gives all the complex zeros in O(n2 log n + log log(|λ1/ϵ|))) arithmetic operations, where λ1 is the absolutely largest zero. Computations with O(log(n|λ1/ϵ|))) binary bits support the latter estimates for the arithmetic complexity, which leads to a simple proof of the current best estimate for the Boolean circuit complexity (bit-operation complexity) of computing all the complex zeros of a polynomial, announced by A. Schönhage in 1982 but not proven yet.},
  doi      = {https://doi.org/10.1016/0898-1221(87)90137-4},
  groups   = {interesting articles},
  url      = {http://www.sciencedirect.com/science/article/pii/0898122187901374},
}

@Article{Pang2004,
  author    = {Pang, Jong-shi and Leyffer, Sven},
  journal   = {Optimization Methods and Software},
  title     = {On the global minimization of the value-at-risk},
  year      = {2004},
  number    = {5},
  pages     = {611--631},
  volume    = {19},
  abstract  = {n this article, we consider the nonconvex minimization problem of the value-at-risk (VaR) that arise from financial risk analysis. By considering this problem as a special linear program (LP) with linear complementarity constraints (a bilevel LP to be more precise), we develop upper and lower bounds for the minimum VaR and show how the combined bounding procedures can be used to compute the latter value to global optimality. A numerical example is provided to illustrate the methodology.},
  file      = {:FILES/2004 - Pang2004 - On the global minimization of the value-at-risk.pdf:PDF},
  groups    = {VaR, TEC},
  timestamp = {2020-09-05},
  type      = {Journal Article},
}

@Book{pardalos1987constrained,
  author    = {Pardalos, Panos M and Rosen, Judah Ben},
  publisher = {Springer},
  title     = {Constrained global optimization: {Algorithms} and applications},
  year      = {1987},
  volume    = {268},
  groups    = {global optimization},
}

@Article{Pardalos2000recent,
  author    = {Pardalos, P.M. and Romeijn, H.E. and Tuy, H.},
  journal   = {Journal of Computational and Applied Mathematics},
  title     = {Recent developments and trends in global optimization},
  year      = {2000},
  number    = {1--2},
  pages     = {209--228},
  volume    = {124},
  groups    = {global optimization},
  publisher = {Elsevier},
}

@Article{Parks1972filter,
  author   = {Parks, T. and McClellan, J.},
  journal  = {IEEE Transactions on Circuit Theory},
  title    = {Chebyshev approximation for nonrecursive digital filters with linear phase},
  year     = {1972},
  issn     = {2374-9555},
  month    = {3},
  number   = {2},
  pages    = {189--194},
  volume   = {19},
  abstract = {An efficient procedure for the design of finite-length impulse response filters with linear phase is presented. The algorithm obtains the optimum Chebyshev approximation on separate intervals corresponding to passbands and/or stopbands, and is capable of designing very long filters. This approach allows the exact specification of arbitrary band-edge frequencies as opposed to previous algorithms which could not directly control pass- and stopband locations and could only obtain(N - 1)/2different band-edge locations for a lengthNlow-pass filter, for fixed\delta_{1}and\delta_{2}. As an aid in practical application of the algorithm, several graphs are included to show relations among the parameters of filter length, transition width, band-edge frequencies, passband ripple, and stopband attenuation.},
  doi      = {10.1109/TCT.1972.1083419},
  file     = {:FILES/1972 - Parks1972filter - Chebyshev Approximation for Nonrecursive Digital Filters with Linear Phase.pdf:PDF},
  groups   = {DSP},
  keywords = {Chebyshev filters;Filters;Linear-phase filters;Nonrecursive digital filters;Chebyshev approximation;Digital filters;Band pass filters;Low pass filters;Passband;Frequency;Nonlinear filters;Approximation algorithms;Algorithm design and analysis;Attenuation},
}

@PhdThesis{parr1998thesis,
  author    = {Parr, Ronald Edward and Russell, Stuart},
  title     = {Hierarchical control and learning for markov decision processes},
  year      = {1998},
  note      = {AAI9902197},
  groups    = {interesting articles},
  isbn      = {059199304X},
  publisher = {University of California, Berkeley},
}

@ARTICLE{pascual1970constrained,
 AUTHOR = {Pascual, Luis D and Ben-Israel, Adi},
 GROUPS = {SGP},
 JOURNAL = {Journal of Optimization Theory and Applications},
 NUMBER = {2},
 PAGES = {73--80},
 PUBLISHER = {Springer},
 TIMESTAMP = {2020-07-16},
 TITLE = {Constrained maximization of posynomials by geometric programming},
 VOLUME = {5},
 YEAR = {1970}
}

@Article{passy1967generalized,
  author    = {Passy, Ury and Wilde, DJ},
  journal   = {SIAM Journal on Applied Mathematics},
  title     = {Generalized polynomial optimization},
  year      = {1967},
  number    = {5},
  pages     = {1344--1356},
  volume    = {15},
  groups    = {SGP},
  publisher = {SIAM},
}

@Article{passy1971generalized,
  author    = {Passy, Ury},
  journal   = {SIAM Journal on Applied Mathematics},
  title     = {Generalized weighted mean programming},
  year      = {1971},
  number    = {4},
  pages     = {763--778},
  volume    = {20},
  groups    = {SGP},
  publisher = {SIAM},
}

@Article{pee2011solving,
  author    = {Pee, E. Y. and Royset, Johannes O.},
  journal   = {Journal of optimization theory and applications},
  title     = {On solving large-scale finite minimax problems using exponential smoothing},
  year      = {2011},
  number    = {2},
  pages     = {390--421},
  volume    = {148},
  file      = {:FILES/2011 - pee2011solving - On solving large-scale finite minimax problems using exponential smoothing.pdf:PDF},
  groups    = {optimization},
  publisher = {Springer},
  timestamp = {2020-08-31},
}

@Article{peng2016drl,
  author     = {Peng, Xue Bin and Berseth, Glen and Panne, Michiel},
  journal    = {ACM Trans. Graph.},
  title      = {Terrain-adaptive locomotion skills using deep reinforcement learning},
  year       = {2016},
  issn       = {0730-0301},
  month      = {7},
  number     = {4},
  volume     = {35},
  address    = {New York, NY, USA},
  articleno  = {Article 81},
  doi        = {10.1145/2897824.2925881},
  groups     = {RL},
  issue_date = {July 2016},
  keywords   = {physics-based characters, reinforcement learning},
  numpages   = {12},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/2897824.2925881},
}

@InProceedings{peng2018deepdyna,
  author    = {Peng, Baolin and Li, Xiujun and Gao, Jianfeng and Liu, Jingjing and Wong, Kam-Fai},
  booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  title     = {{d}eep {d}yna-{q}: {Integrating} planning for task-completion dialogue policy learning},
  year      = {2018},
  address   = {Melbourne, Australia},
  month     = {7},
  pages     = {2182--2192},
  publisher = {Association for Computational Linguistics},
  abstract  = {Training a task-completion dialogue agent via reinforcement learning (RL) is costly because it requires many interactions with real users. One common alternative is to use a user simulator. However, a user simulator usually lacks the language complexity of human interlocutors and the biases in its design may tend to degrade the agent. To address these issues, we present Deep Dyna-Q, which to our knowledge is the first deep RL framework that integrates planning for task-completion dialogue policy learning. We incorporate into the dialogue agent a model of the environment, referred to as the world model, to mimic real user response and generate simulated experience. During dialogue policy learning, the world model is constantly updated with real user experience to approach real user behavior, and in turn, the dialogue agent is optimized using both real experience and simulated experience. The effectiveness of our approach is demonstrated on a movie-ticket booking task in both simulated and human-in-the-loop settings.},
  doi       = {10.18653/v1/P18-1203},
  groups    = {RL},
  url       = {https://www.aclweb.org/anthology/P18-1203},
}

@Article{pessoa2013solving,
  author  = {Pessoa, Artur Alves and Poss, Michael and Roboredo, Marcos Costa and Aizemberg, Luiz},
  journal = {Anais do XLV Simp{\'o}sio Brasileiro de Pesquisa Operacional},
  title   = {Solving bilevel combinatorial optimization as bilinear min-max optimization via a branch-and-cut algorithm},
  year    = {2013},
  file    = {:FILES/2013 - pessoa2013solving - Solving bilevel combinatorial optimization as bilinear min-max optimization via a branch-and-cut algorithm.pdf:PDF},
  groups  = {bilevel, optimization},
}

@Article{peters1969eigenvalues,
  author    = {Peters, Gwendoline and Wilkinson, James Hardy},
  journal   = {The Computer Journal},
  title     = {Eigenvalues of {$Ax = \lambda B x$} with band symmetric {A} and {B}},
  year      = {1969},
  number    = {4},
  pages     = {398--404},
  volume    = {12},
  file      = {:FILES/1969 - peters1969eigenvalues - Eigenvalues of Ax = λBx with band symmetric A and B.pdf:PDF},
  groups    = {interesting articles},
  publisher = {Oxford University Press},
}

@InBook{Peterson1980,
  author    = {Peterson, E. L.},
  editor    = {Avriel, Mordecai},
  pages     = {95--105},
  publisher = {Springer US},
  title     = {Optimality conditions in generalized geometric programming},
  year      = {1980},
  address   = {Boston, MA},
  isbn      = {978-1-4615-8285-4},
  abstract  = {Generalizations of the Kuhn-Tucker optimality conditions are given, as are the fundamental theorems having to do with their necessity and sufficiency.},
  booktitle = {Advances in Geometric Programming},
  doi       = {10.1007/978-1-4615-8285-4_4},
  groups    = {SGP},
  timestamp = {2020-07-16},
  url       = {https://doi.org/10.1007/978-1-4615-8285-4_4},
}

@InProceedings{Petrowski1996,
  author    = {Petrowski, A.},
  booktitle = {Proceedings of IEEE International Conference on Evolutionary Computation},
  title     = {A clearing procedure as a niching method for genetic algorithms},
  year      = {1996},
  month     = {5},
  pages     = {798--803},
  abstract  = {The clearing procedure is a niching method inspired by the principle stated by J.H. Holland (1975) - that of sharing limited resources within subpopulations of individuals characterized by some similarities - but instead of evenly sharing the available resources among the individuals of a subpopulation, the clearing procedure supplies these resources only to the best individuals of each subpopulation. The clearing is naturally adapted to elitist strategies. This can significantly improve the performance of genetic algorithms (GAs) applied to multimodal optimization. Moreover, the clearing procedure allows a GA to efficiently reduce the genetic drift when used with an appropriate selection operator. Some experimental results are presented for a massively multimodal deceptive function optimization.},
  doi       = {10.1109/ICEC.1996.542703},
  file      = {:FILES/1996 - Petrowski1996 - A clearing procedure as a niching method for genetic algorithms.pdf:PDF},
  groups    = {genetic algorithms},
  keywords  = {genetic algorithms;resource allocation;functional analysis;clearing procedure;niching method;genetic algorithms;limited resource sharing;subpopulations;similar individuals;best individuals;elitist strategies;performance;genetic drift reduction;selection operator;massively multimodal deceptive function optimization;Genetic algorithms;Steady-state;Hamming distance},
}

@Article{Petsagkourakis2020,
  author   = {Petsagkourakis, Panagiotis and Heath, William Paul and Theodoropoulos, Constantinos},
  journal  = {Automatica},
  title    = {Stability analysis of piecewise affine systems with multi-model predictive control},
  year     = {2020},
  issn     = {0005-1098},
  pages    = {108539},
  volume   = {111},
  abstract = {We propose an input-output stability analysis for closed-loop systems of piece-wise affine models under unstructured uncertainty and controlled by multi-model linear MPC with input constraints. Integral quadratic constraints (IQCs) are employed to assess the robustness of MPC under uncertainty. We efficiently create a model pool, by performing linearization on selected transient points. All the possible uncertainties and nonlinearities (including the controller) can be introduced in the framework, assuming that they admit the appropriate IQCs, whilst the dissipation inequality can provide sufficient conditions for stability through the incorporation of IQCs. We demonstrate the existence of static multipliers, which can reduce the conservatism of the stability analysis significantly. The proposed methodology is demonstrated through two illustrative case studies.},
  doi      = {10.1016/j.automatica.2019.108539},
  file     = {:FILES/2020 - Petsagkourakis2020 - Stability analysis of piecewise affine systems with multi-model predictive control.pdf:PDF},
  groups   = {application},
  keywords = {Unstructured uncertainty, Piecewise affine, Model predictive control, Robust stability},
  url      = {http://www.sciencedirect.com/science/article/pii/S0005109819304005},
}

@Article{PEYGHAMI201474,
  author   = {Peyghami, M. Reza and Hafshejani, S. Fathi and Shirvani, L.},
  journal  = {Journal of Computational and Applied Mathematics},
  title    = {Complexity of interior-point methods for linear optimization based on a new trigonometric kernel function},
  year     = {2014},
  issn     = {0377-0427},
  pages    = {74 -- 85},
  volume   = {255},
  abstract = {In this paper, we propose a new kernel function with trigonometric barrier term for primal-dual interior point methods in linear optimization. Using an elegant and simple analysis and under some easy to check conditions, we explore the worst case complexity result for the large update primal-dual interior point methods. We obtain the worst case iteration bound for the large update primal-dual interior point methods as O(n23lognϵ) which improves the so far obtained complexity results for the trigonometric kernel function in [M. El Ghami, Z.A. Guennoun, S. Boula, T. Steihaug, Interior-point methods for linear optimization based on a kernel function with a trigonometric barrier term, Journal of Computational and Applied Mathematics 236 (2012) 3613-3623] significantly.},
  doi      = {https://doi.org/10.1016/j.cam.2013.04.039},
  file     = {:FILES/2014 - PEYGHAMI201474 - Complexity of interior-point methods for linear optimization based on a new trigonometric kernel function.pdf:PDF},
  groups   = {convergence},
  keywords = {Kernel function, Linear optimization, Primal-dual interior-point methods, Large-update methods},
  url      = {http://www.sciencedirect.com/science/article/pii/S0377042713002355},
}

@Article{phillips1968algorithms,
  author    = {Phillips, George M.},
  journal   = {The Computer Journal},
  title     = {Algorithms for piecewise straight line approximations},
  year      = {1968},
  number    = {2},
  pages     = {211--212},
  volume    = {11},
  file      = {:FILES/1968 - phillips1968algorithms - Algorithms for piecewise straight line approximations.pdf:PDF},
  groups    = {Approximation},
  publisher = {The British Computer Society},
}

@InCollection{pinter2002global,
  author    = {Pint\'{e}r, J\'{a}nos D},
  booktitle = {Handbook of global optimization},
  publisher = {Springer},
  title     = {Global optimization: {Software,} test problems, and applications},
  year      = {2002},
  pages     = {515--569},
  groups    = {global optimization},
}

@InCollection{platt1999smo,
  author    = {Platt, John},
  booktitle = {Advances in Kernel Methods: Support Vector Learning},
  publisher = {MIT press},
  title     = {Fast training of support vector machines using sequential minimal optimization},
  year      = {1999},
  editor    = {Sch\"{o}lkopf, Bernhard and Burges, Christopher J.C. and Smola, Alexander J.},
  pages     = {185--208},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@Article{plaziac1997pwl,
  author        = {Plaziac, Nathalie and Ledinh, {Chon Tam} and Adoul, {J.-P.}},
  journal       = {IEEE transactions on signal processing},
  title         = {{PWL} nonlinear adaptive filter via {RLS} and {NLMS} algorithms},
  year          = {1997},
  number        = {5},
  pages         = {1364--1367},
  volume        = {45},
  abstract      = {The recursive least square (RLS) and the normalized least mean square (NLMS) algorithms are proposed for canonical piecewise linear (PWL) adaptive filters. The parameters are updated recursively in a manner similar to back-propagation. The simulation results indicate PWL adaptive filters can suitably model nonlinear systems.},
  date-modified = {2016-04-05 02:48:40 +0000},
  file          = {:FILES/1997 - plaziac1997pwl - PWL nonlinear adaptive filter via RLS and NLMS algorithms.pdf:PDF},
  groups        = {DSP, application},
  publisher     = {Institute of Electrical and Electronics Engineers},
}

@Article{pohlheim1998genetic,
  author  = {Pohlheim, Hartmut},
  journal = {{IEE} Colloqium on Applied Control Techniques Using {MATLAB}},
  title   = {Genetic and evolutionary algorithm toolbox for use with {MATLAB}},
  year    = {1998},
  volume  = {14},
  groups  = {genetic algorithms},
  issue   = {1},
}

@Article{Polak2003,
  author    = {Polak, E. and Royset, J. O. and Womersley, R. S.},
  journal   = {Journal of Optimization Theory and Applications},
  title     = {Algorithms with adaptive smoothing for finite minimax problems},
  year      = {2003},
  number    = {3},
  pages     = {459--484},
  volume    = {119},
  file      = {:FILES/2003 - Polak2003 - Algorithms with adaptive smoothing for finite minimax problems.pdf:PDF},
  groups    = {application},
  publisher = {Springer},
  timestamp = {2020-08-31},
}

@Article{porn1999convexification,
  author    = {P\"{o}rn, Ray and Harjunkoski, Iiro and Westerlund, Tapio},
  journal   = {Computers \& chemical engineering},
  title     = {Convexification of different classes of non-convex {MINLP} problems},
  year      = {1999},
  number    = {3},
  pages     = {439--448},
  volume    = {23},
  groups    = {global optimization, MILP},
  publisher = {Elsevier},
}

@Article{porn2008global,
  author    = {P\"{o}Rn, Ray and Bj\"{o}Rk, Kaj-Mikael and Westerlund, Tapio},
  journal   = {Discrete optimization},
  title     = {Global solution of optimization problems with signomial parts},
  year      = {2008},
  number    = {1},
  pages     = {108--120},
  volume    = {5},
  file      = {:FILES/2008 - porn2008global - Global solution of optimization problems with signomial parts.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
}

@Book{powell2011adp,
  author    = {Powell, Warren B.},
  publisher = {John Wiley \& Sons},
  title     = {Approximate dynamic programming: {Solving} the curses of dimensionality},
  year      = {2011},
  edition   = {second},
  groups    = {RL},
}

@Article{premoli1986piecewise,
  author        = {Premoli, Amedeo},
  journal       = {Mathematical Programming},
  title         = {Piecewise-linear programming: {The} compact {CPLP} algorithm},
  year          = {1986},
  number        = {2},
  pages         = {210--227},
  volume        = {36},
  date-modified = {2016-04-05 02:47:48 +0000},
  groups        = {optimization},
  publisher     = {Springer},
}

@Book{Proakis1996DSP,
  author    = {Proakis, John G. and Manolakis, Dimitris G.},
  publisher = {Prentice-Hall International, Inc.},
  title     = {Digital signal processing: {Principles,} algorithms, and applications},
  year      = {1996},
  edition   = {3rd},
  file      = {:FILES/1996 - Proakis1996DSP - Digital signal processing. Principles, algorithms and applications.pdf:PDF},
  groups    = {DSP},
}

@Article{Pucar1998,
  author    = {Pucar, P. and Sj\"{o}berg, J.},
  journal   = {IEEE Transactions on Information Theory},
  title     = {On the hinge-finding algorithm for hinging hyperplanes},
  year      = {1998},
  number    = {3},
  pages     = {3310--3319},
  volume    = {44},
  abstract  = {This correspondence concerns the estimation algorithm for hinging hyperplane (HH) models, a piecewise-linear model for approximating functions of several variables, suggested in Breiman (1993). The estimation algorithm is analyzed and it is shown that it is a special case of a Newton algorithm applied to a sum of squared error criterion. This insight is then used to suggest possible improvements of the algorithm so that convergence to a local minimum can be guaranteed. In addition, the way of updating the parameters in the HH model is discussed. In Breiman, a stepwise updating procedure is proposed where only a subset of the parameters are changed in each step. This connects closely to some previously suggested greedy algorithms and these greedy algorithms are discussed and compared to a simultaneous updating of all parameters.},
  file      = {:FILES/1998 - Pucar1998 - On the hinge-finding algorithm for hinging hyperplanes.pdf:PDF},
  groups    = {identification},
  timestamp = {2020-09-04},
}

@Article{qu2007new,
  author    = {Qu, Shao-Jian and Zhang, Ke-Cun and Ji, Ying},
  journal   = {Applied Mathematics and Computation},
  title     = {A new global optimization algorithm for signomial geometric programming via lagrangian relaxation},
  year      = {2007},
  number    = {2},
  pages     = {886--894},
  volume    = {184},
  file      = {:FILES/2007 - qu2007new - A new global optimization algorithm for signomial geometric programming via Lagrangian relaxation.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@Article{qu2008global,
  author    = {Qu, Shaojian and Zhang, Kecun and Wang, Fusheng},
  journal   = {European Journal of Operational Research},
  title     = {A global optimization using linear relaxation for generalized geometric programming},
  year      = {2008},
  number    = {2},
  pages     = {345--356},
  volume    = {190},
  file      = {:FILES/2008 - qu2008global - A global optimization using linear relaxation for generalized geometric programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@Article{quesada1995global,
  author    = {Quesada, Ignacio and Grossmann, Ignacio E},
  journal   = {Journal of Global Optimization},
  title     = {A global optimization algorithm for linear fractional and bilinear programs},
  year      = {1995},
  number    = {1},
  pages     = {39--76},
  volume    = {6},
  groups    = {bilinear},
  publisher = {Springer},
}

@Article{Quiggin1991EUT,
  author    = {Quiggin, John},
  journal   = {Journal of Risk and Uncertainty},
  title     = {Comparative statics for rank-dependent expected utility theory},
  year      = {1991},
  number    = {4},
  pages     = {339--350},
  volume    = {4},
  groups    = {utility theory},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@InProceedings{QuXi2010,
  author    = {Qu, Zhenshen and Xi, Xiangming and Girard, Anouck},
  booktitle = {AIAA Guidance, Navigation, and Control Conference},
  title     = {Cooperative {UAV} trajectory planning with multiple dynamic targets},
  year      = {2010},
  address   = {Toronto, Ontario Canada},
  month     = {8},
  pages     = {1--9},
  abstract  = {The paper addresses the problem of multiple UAV trajectory planning with dynamic targets. The problem is studied under the MILP framework, where how to express the nonlinear time-dependent cost function between two targets in a linear form makes the key difficulties. To solve the problem, the cost function between two nodes is determined using propotional guidance law to achieve shortest chasing time, then it is linearized with nonuniform segmented time intervals to keep the problem solvable with MILP. To process the problem with obstacle avoidance, additional time intervals corresponding to blocked obstacle regions are introduced into the cost function. Target leaving time decision variable values fallen in the intervals are treated as infeasible by introducing new logic decision variables. Various simulation examples verify the proposed method.},
  author+an = {2=highlight},
  comment   = {26 Jun 2012},
  doi       = {10.2514/6.2010-8437},
  eprint    = {https://arc.aiaa.org/doi/pdf/10.2514/6.2010-8437},
  file      = {:FILES/2010 - QuXi2010 - Cooperative UAV Trajectory Planning with Multiple dynamic targets.pdf:PDF},
  groups    = {my paper},
  timestamp = {2020-06-20},
  url       = {https://arc.aiaa.org/doi/abs/10.2514/6.2010-8437},
}

@Article{Rabin2000eut,
  author    = {Rabin, Matthew},
  journal   = {Econometrica},
  title     = {Risk aversion and expected-utility theory: {A} calibration theorem},
  year      = {2000},
  number    = {5},
  pages     = {1281--1292},
  volume    = {68},
  groups    = {utility theory},
  publisher = {Wiley Online Library},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{Rabiner1972,
  author   = {Rabiner, L.},
  journal  = {IEEE Transactions on Audio and Electroacoustics},
  title    = {Linear program design of finite impulse response ({FIR}) digital filters},
  year     = {1972},
  issn     = {1558-2582},
  month    = {10},
  number   = {4},
  pages    = {280--288},
  volume   = {20},
  abstract = {The use of optimization techniques for designing digital filters has become widespread in recent years. Among the techniques that have been used include steepest descent methods, conjugate gradient techniques, penalty function techniques, and polynomial interpolation procedures. The theory of linear programming offers many advantages for designing digital filters. The programs are easy to implement and yield solutions that are guaranteed to converge. There are many areas of finite impulse response (FIR) filter design where linear programming can be used conveniently. These include design of the following: filters of the frequency sampling type; optimal filters where the passband and stopband edge frequencies of the filter may be specified exactly; and filters with simultaneous constraints on the time and frequency response. The design method is illustrated by examples from each of these areas.},
  doi      = {10.1109/TAU.1972.1162395},
  file     = {:FILES/1972 - Rabiner1972 - Linear program design of finite impulse response (FIR) Digital filters.pdf:PDF},
  groups   = {FIR filter design},
  keywords = {Finite impulse response filter;Digital filters;Linear programming;Frequency;Design optimization;Polynomials;Interpolation;Nonlinear filters;Sampling methods;Passband},
}

@ARTICLE{rabiner1974FIR,
 ABSTRACT = {Although much has been learned about the relationships between design parameters for finite impulse-response (FIR) low-pass digital filters, very little is known about the relationships between the parameters of multiband filters. Thus given a set of design specifications for a multiband FIR filter (e.g., filter band edge frequencies and desired ripples in each of the bands) it is difficult to choose a set of modified parameters which will yield an acceptable filter using a standard FIR design algorithm. By an acceptable filter we mean one with monotonic behavior of the frequency response in the DON'T-CARE or transition regions between bands and one providing at least the desired attenuation (or ripple) in each of the bands. In this paper, we examine the theoretical and practical issues of designing multiband filters and present several strategies for choosing the input parameters for the McClellan et al. filter-design algorithm to yield reasonable filters which meet arbitrary specifications.},
 AUTHOR = {Rabiner, L. and Kaiser, J. and Schafer, R.},
 DOI = {10.1109/TASSP.1974.1162607},
 GROUPS = {FIR filter design},
 ISSN = {0096-3518},
 JOURNAL = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
 KEYWORDS = {Digital filters;Finite impulse response filter;Semiconductor device noise;Filtering;Circuit theory;Algorithm design and analysis;Error analysis;Semiconductor memory;Logic;Power generation economics},
 MONTH = {12},
 NUMBER = {6},
 PAGES = {462--472},
 TITLE = {Some considerations in the design of multiband finite-impulse-response digital filters},
 VOLUME = {22},
 YEAR = {1974}
}

@Article{Rabinerfir1975,
  author   = {Rabiner, L. R. and McClellan, J. H. and Parks, T. W.},
  journal  = {Proceedings of the IEEE},
  title    = {{FIR} digital filter design techniques using weighted {Chebyshev} approximation},
  year     = {1975},
  issn     = {1558-2256},
  month    = {4},
  number   = {4},
  pages    = {595--610},
  volume   = {63},
  abstract = {This paper discusses the various approaches to designing FIR digital filters using the theory of weighted Chebyshev approximation. The different design techniques are explained and compared on the basis of their capabilities and limitations. The relationships between filter parameters are briefly discussed for the case of low-pass filters. Extensions of the theory to the problems of magnitude and complex approximation are also included, as are some recent results on the design of two-dimensional FIR filters by transformation.},
  doi      = {10.1109/PROC.1975.9794},
  file     = {:FILES/1975 - Rabinerfir1975 - FIR digital filter design techniques using weighted Chebyshev approximation.pdf:PDF},
  groups   = {FIR filter design},
  keywords = {Chebyshev approximation;Finite impulse response filter;Digital filters;Circuit theory;Filtering theory;Image processing;Circuits and systems;Quantization;Electrons;Gold},
}

@Article{Rajagpoal1987maximalflat,
  author   = {Rajagpoal, L. and Roy, S. D.},
  journal  = {IEEE Transactions on Circuits and Systems},
  title    = {Design of maximally-flat {FIR} filters using the bernstein polynomial},
  year     = {1987},
  issn     = {1558-1276},
  month    = {12},
  number   = {12},
  pages    = {1587--1590},
  volume   = {34},
  abstract = {The paper provides, through the use of Bernstein polynomials, a new insight into the design of maximally-flat (MAXFLAT) FIR filters. In particular, it demonstrates a link between the various existing methods, and provides an analytical support to the empirical relation given by Herrmann. It is also shown to provide a new computationally efficient algorithm for the design of such filters.},
  doi      = {10.1109/TCS.1987.1086077},
  file     = {:FILES/1987 - Rajagpoal1987maximalflat - Design of maximally flat FIR filters using the Bernstein polynomial.pdf:PDF},
  groups   = {FIR filter design},
  keywords = {FIR (finite-duration impulse-response) digital filters;Maximally-flat-delay filters;Maximally-flat-magnitude filters;Polynomials;Finite impulse response filter;Polynomials;Digital filters;Transfer functions;Interpolation;Conformal mapping;Circuit synthesis;Speech processing;Signal processing;Inverse problems},
}

@InProceedings{Raju2017bee,
  author     = {Raju, R. and Kwan, Hon Keung},
  booktitle  = {2017 IEEE 30th Canadian Conference on Electrical and Computer Engineering (CCECE)},
  title      = {{FIR} filter design using multiobjective artificial bee colony algorithm},
  year       = {2017},
  month      = {4},
  pages      = {1--4},
  abstract   = {In this paper, general FIR filters are designed using multiobjective Artificial Bee Colony algorithm. Spherical pruning (SP) and physical programming (PP) techniques are combined together in the implementation of multiobjective Artificial Bee Colony algorithm. Physical programming converts the design objectives into an intuitive language and spherical pruning maintains diversity in the Pareto front. The design of general FIR filters require simultaneous optimization of magnitude and group delay errors and therefore can be formulated as a Multiobjective Optimization (MOO) problem. All the non-dominated solutions of the general FIR design problem can be approximated into a Pareto front. Numerical results show that, multiobjective Artificial Bee Colony algorithm can achieve lower passband, stopband, group delay errors when compared to those of spherical pruning Multiobjective Differential Evolution (spMODE-II).},
  doi        = {10.1109/CCECE.2017.7946703},
  file       = {:FILES/2017 - Raju2017bee - FIR filter design using multiobjective artificial bee Colony Algorithm.pdf:PDF},
  groups     = {FIR filter design, ABC},
  keywords   = {evolutionary computation;FIR filters;Pareto optimisation;FIR filter design;multiobjective artificial bee colony algorithm;general filters;PP techniques;physical programming;design objectives;intuitive language;Pareto front;group delay errors;magnitude delay errors;MOO problem;stopband errors;passband errors;spherical pruning multiobjective differential evolution;spMODE-II;Finite impulse response filters;Algorithm design and analysis;Optimization;Programming;Delays;Linear programming;Evolutionary computation;Multiobjective optimization;physical programming;spherical pruning;digital filter design;general FIR filters;artificial bee colony algorithm;optimization;minimax formulation;digital filters;evolutionary algorithms, read},
  readstatus = {read},
}

@InProceedings{Raju2018fir,
  author     = {Raju, R. and Kwan, Hon Keung and Jiang, Aimin},
  booktitle  = {2018 IEEE 61st International Midwest Symposium on Circuits and Systems (MWSCAS)},
  title      = {Sparse {FIR} filter design using artificial bee colony algorithm},
  year       = {2018},
  month      = {8},
  pages      = {956--959},
  abstract   = {In this paper, sparse linear-phase FIR digital filters are designed using artificial bee colony (ABC) algorithm. Sparse digital filters can be used in applications where computational cost and complexities are of concern as zero-valued coefficients eliminate multiplications required for implementation. In this method, sparse digital filters are designed using minimax optimization by ABC algorithm and successive elimination. In contrast to methods which minimize insignificant coefficient values, this method eliminates insignificant coefficients by setting them to zero. The sparse linear-phase FIR filters designed using ABC algorithm are compared to the partial l1-norm optimization design, the minimum increase design, and the smallest coefficient design to illustrate the effectiveness of each design method.},
  doi        = {10.1109/MWSCAS.2018.8624036},
  file       = {:FILES/2018 - Raju2018fir - Sparse FIR Filter Design Using Artificial Bee Colony Algorithm.pdf:PDF},
  groups     = {sparse},
  issn       = {1558-3899},
  keywords   = {artificial bee colony algorithm;FIR filters;linear phase filters;sparse FIR filter design;artificial bee colony algorithm;linear-phase FIR digital filters;sparse digital filters;zero-valued coefficients;ABC algorithm;successive elimination;sparse linear-phase FIR filters;Finite impulse response filters;Artificial bee colony algorithm;Optimization;Filtering algorithms;IIR filters;Passband;Sparse linear phase FIR digital filter design;artificial bee colony algorithm;constrained optimization;minimax design;successive elimination, read},
  readstatus = {read},
}

@Article{Ramirez2004implimentation,
  author  = {Ram\'{i}rez, D. R. and Camacho, E. F. and Arahal, M. R.},
  journal = {Control Engineering Practice},
  title   = {Implementation of min-max {MPC} using hinging hyperplanes. application to a heat exchanger},
  year    = {2004},
  pages   = {1197--1205},
  volume  = {12},
  groups  = {application},
}

@Article{rao2009survey,
  author    = {Rao, Anil V},
  journal   = {Advances in the Astronautical Sciences},
  title     = {A survey of numerical methods for optimal control},
  year      = {2009},
  number    = {1},
  pages     = {497--528},
  volume    = {135},
  groups    = {interesting articles},
  publisher = {Univelt, Inc.},
}

@Article{RASHID20131440,
  author   = {Rashid, Abdulmuttalib Turky and Ali, Abduladhem Abdulkareem and Frasca, Mattia and Fortuna, Luigi},
  journal  = {Robotics and Autonomous Systems},
  title    = {Path planning with obstacle avoidance based on visibility binary tree algorithm},
  year     = {2013},
  issn     = {0921-8890},
  number   = {12},
  pages    = {1440 -- 1449},
  volume   = {61},
  abstract = {In this paper, a novel method for robot navigation in dynamic environments, referred to as visibility binary tree algorithm, is introduced. To plan the path of the robot, the algorithm relies on the construction of the set of all complete paths between robot and target taking into account inner and outer visible tangents between robot and circular obstacles. The paths are then used to create a visibility binary tree on top of which an algorithm for shortest path is run. The proposed algorithm is implemented on two simulation scenarios, one of them involving global knowledge of the environment, and the other based on local knowledge of the environment. The performance are compared with three different algorithms for path planning.},
  doi      = {https://doi.org/10.1016/j.robot.2013.07.010},
  groups   = {interesting articles},
  keywords = {Path planning, Obstacle avoidance, Visibility graph, Bresenham algorithm},
  url      = {http://www.sciencedirect.com/science/article/pii/S092188901300136X},
}

@ARTICLE{ratner1978solving,
 AUTHOR = {Ratner, M and Lasdon, Leon S and Jain, A},
 GROUPS = {SGP},
 JOURNAL = {Journal of optimization theory and applications},
 NUMBER = {2},
 PAGES = {253--264},
 PUBLISHER = {Springer},
 TIMESTAMP = {2020-07-16},
 TITLE = {Solving geometric programs using grg: {Results} and comparisons},
 VOLUME = {26},
 YEAR = {1978}
}

@TechReport{Rebennack2012a,
  author      = {Rebennack, Steffen and Kallrath, Josef},
  institution = {Colorado School of Mines, Division of Economics and Business},
  title       = {Continuous piecewise linear $\delta$-approximations for minlp problems. {I}. minimal breakpoint systems for univariate functions},
  year        = {2012},
  file        = {:FILES/2012 - Rebennack2012a - Continuous Piecewise Linear δ-Approximations for MINLP Problems. I. Minimal Breakpoint Systems for Univariate Functions.pdf:PDF},
  groups      = {identification},
}

@TechReport{Rebennack2012,
  author      = {Rebennack, Steffen and Kallrath, Josef},
  institution = {Colorado School of Mines, Division of Economics and Business},
  title       = {Continuous piecewise linear $\delta$-approximations for minlp problems. ii. bivariate and multivariate functions},
  year        = {2012},
  file        = {:FILES/2012 - Rebennack2012 - Continuous Piecewise Linear δ-Approximations for MINLP Problems. II. Bivariate and Multivariate Functions.pdf:PDF},
  groups      = {identification},
}

@Article{rebennack2015bivariate,
  author    = {Rebennack, Steffen and Kallrath, Josef},
  journal   = {Journal of Optimization Theory and Applications},
  title     = {Continuous piecewise linear delta-approximations for bivariate and multivariate functions},
  year      = {2015},
  number    = {1},
  pages     = {102--117},
  volume    = {167},
  doi       = {https://doi.org/10.1007/s10957-014-0688-2},
  file      = {:FILES/2015 - rebennack2015bivariate - Continuous Piecewise Linear Delta-Approximations for Bivariate and Multivariate Functions.pdf:PDF},
  groups    = {identification},
  publisher = {Springer},
  url       = {https://link.springer.com/article/10.1007/s10957-014-0688-2},
}

@Article{rebennack2015univariate,
  author    = {Rebennack, Steffen and Kallrath, Josef},
  journal   = {Journal of Optimization Theory and Applications},
  title     = {Continuous piecewise linear {Delta}-approximations for univariate functions: {Computing} minimal breakpoint systems},
  year      = {2015},
  number    = {2},
  pages     = {617--643},
  volume    = {167},
  file      = {:FILES/2015 - rebennack2015univariate - Continuous Piecewise Linear Delta-Approximations for Univariate Functions-Computing Minimal Breakpoint Systems.pdf:PDF},
  groups    = {Approximation},
  publisher = {Springer},
}

@Article{Rebennack2016,
  author   = {Rebennack, Steffen},
  journal  = {Mathematical Methods of Operations Research},
  title    = {Computing tight bounds via piecewise linear functions through the example of circle cutting problems},
  year     = {2016},
  issn     = {1432-5217},
  month    = {8},
  number   = {1},
  pages    = {3--57},
  volume   = {84},
  abstract = {This paper discusses approximations of continuous and mixed-integer non-linear optimization problems via piecewise linear functions. Various variants of circle cutting problems are considered, where the non-overlap of circles impose a non-convex feasible region. While the paper is written in an ``easy-to-understand'' and ``hands-on'' style which should be accessible to graduate students, also new ideas are presented. Specifically, piecewise linear functions are employed to yield mixed-integer linear programming problems which provide lower and upper bounds on the original problem, the circle cutting problem. The piecewise linear functions are modeled by five different formulations, containing the incremental and logarithmic formulations. Another variant of the cutting problem involves the assignment of circles to pre-defined rectangles. We introduce a new global optimization algorithm, based on piecewise linear function approximations, which converges in finitely many iterations to a globally optimal solution. The discussed formulations are implemented in GAMS. All GAMS-files are available for download in the Electronic supplementary material. Extensive computational results are presented with various illustrations.},
  day      = {01},
  doi      = {10.1007/s00186-016-0546-0},
  file     = {:FILES/2016 - Rebennack2016 - Computing tight bounds via piecewise linear functions through the example of circle cutting problems.pdf:PDF},
  groups   = {identification},
  url      = {https://doi.org/10.1007/s00186-016-0546-0},
}

@Article{Rebennack2020,
  author    = {Rebennack, Steffen and Krasko, Vitaliy},
  journal   = {INFORMS Journal on Computing},
  title     = {Piecewise linear function fitting via mixed-integer linear programming},
  year      = {2020},
  number    = {2},
  pages     = {507--530},
  volume    = {32},
  abstract  = {Piecewise linear (PWL) functions are used in a variety of applications. Computing such continuous PWL functions, however, is a challenging task. Software packages and the literature on PWL function fitting are dominated by heuristic methods. This is true for both fitting discrete data points and continuous univariate functions. The only exact methods rely on nonconvex model formulations. Exact methods compute continuous PWL function for a fixed number of breakpoints minimizing some distance function between the original function and the PWL function. An optimal PWL function can only be computed if the breakpoints are allowed to be placed freely and are not fixed to a set of candidate breakpoints. In this paper, we propose the first convex model for optimal continuous univariate PWL function fitting. Dependent on the metrics chosen, the resulting formulations are either mixed-integer linear programming or mixed-integer quadratic programming problems. These models yield optimal continuous PWL functions for a set of discrete data. On the basis of these convex formulations, we further develop an exact algorithm to fit continuous univariate functions. Computational results for benchmark instances from the literature demonstrate the superiority of the proposed convex models compared with state-of-the-art nonconvex models.},
  doi       = {10.1287/ijoc.2019.0890},
  file      = {:FILES/2020 - Rebennack2020 - Piecewise Linear Function Fitting via Mixed-Integer Linear Programming.pdf:PDF},
  groups    = {identification, MILP},
  timestamp = {2020-08-05},
  url       = {https://doi.org/10.1287/ijoc.2019.0890},
}

@InProceedings{Rehbach2020,
  author    = {Rehbach, Frederik and Zaefferer, Martin and Naujoks, Boris and Bartz-Beielstein, Thomas},
  booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference (GECCO2020)},
  title     = {Expected improvement versus predicted value in surrogate-based optimization},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {868--876},
  publisher = {Association for Computing Machinery},
  abstract  = {Surrogate-based optimization relies on so-called infill criteria (acquisition functions) to decide which point to evaluate next. When Kriging is used as the surrogate model of choice (also called Bayesian optimization), one of the most frequently chosen criteria is expected improvement. We argue that the popularity of expected improvement largely relies on its theoretical properties rather than empirically validated performance. Few results from the literature show evidence, that under certain conditions, expected improvement may perform worse than something as simple as the predicted value of the surrogate model. We benchmark both infill criteria in an extensive empirical study on the `BBOB' function set. This investigation includes a detailed study of the impact of problem dimensionality on algorithm performance. The results support the hypothesis that exploration loses importance with increasing problem dimensionality. A statistical analysis reveals that the purely exploitative search with the predicted value criterion performs better on most problems of five or higher dimensions. Possible reasons for these results are discussed. In addition, we give an in-depth guide for choosing the infill criteria based on prior knowledge about the problem at hand, its dimensionality, and the available budget.},
  doi       = {10.1145/3377930.3389816},
  file      = {:FILES/2020 - Rehbach2020 - Expected improvement versus predicted value in surrogate-based optimization.pdf:PDF},
  groups    = {interesting articles},
  keywords  = {surrogate-based optimization, acquisition function, infill criterion, bayesian optimization},
  url       = {https://dl.acm.org/doi/10.1145/3377930.3389816},
}

@Article{REID199687,
  author     = {Reid, D. J.},
  journal    = {Mathematical and Computer Modelling},
  title      = {Genetic algorithms in constrained optimization},
  year       = {1996},
  issn       = {0895-7177},
  number     = {5},
  pages      = {87 -- 111},
  volume     = {23},
  abstract   = {The behavior of the two-point crossover operator, on candidate solutions to an optimization problem that is restricted to integer values and by some set of constraints, is investigated theoretically. This leads to the development of new genetic operators for the case in which the constraint system is linear. The computational difficulty asserted by many optimization problems has lead to exploration of a class of randomized algorithms based on biological adaption. The considerable interest that surrounds these evolutionary algorithms is largely centered on problems that have defied satisfactory illation by traditional means because of badly behaved or noisy objective functions, high dimensionality, or intractable algorithmic complexity. Under such conditions, these alternative methods have often proved invaluable. Despite their attraction, the applicability of evolutionary algorithms has been limited by a deficiency of general techniques to manage constraints, and the difficulty is compounded when the decision variables are discrete. Several new genetic operators are presented here that are guaranteed to preserve the feasibility of discrete aspirant solutions with respect to a system of linear constraints. To avoid performance degradation as the probability of finding a feasible and meaningful information exchange between two candidate solutions decreases, relaxations of the modified genetic crossover operator are also proposed. The effective utilization of these also suggests a manipulation of the genetic algorithm itself, in which the population is evanescently permitted to grow beyond its normal size.},
  comment    = {The journal has been shut down.},
  doi        = {https://doi.org/10.1016/0895-7177(96)00014-3},
  file       = {:FILES/1996 - REID199687 - Genetic algorithms in constrained optimization .pdf:PDF},
  groups     = {genetic algorithms, TEC},
  keywords   = {Discrete optimization, Genetic algorithm, Linear constraints, read},
  readstatus = {read},
  timestamp  = {2020-09-05},
  url        = {http://www.sciencedirect.com/science/article/pii/0895717796000143},
}

@InProceedings{Resende2000fir,
  author    = {Resende, L. S. and Rocha, C. A. F. and Bellanger, M. G.},
  booktitle = {2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100)},
  title     = {A linearly-constrained approach to the interpolated {FIR} filtering problem},
  year      = {2000},
  month     = {6},
  pages     = {392--395 vol.1},
  volume    = {1},
  abstract  = {We introduce the optimum interpolated Wiener filter, which resulted from an original and elegant linearly-constrained approach to the interpolated transversal filtering problem. An accurate analytical model for the mean coefficient behavior of LMS-AIFIR filters is also presented. Simulation results illustrate the effectiveness of the proposed model.},
  doi       = {10.1109/ICASSP.2000.861987},
  file      = {:FILES/2000 - Resende2000fir -A linearly-constrained approach to the interpolated FIR filtering problem.pdf:PDF},
  groups    = {FIR filter design},
  issn      = {1520-6149},
  keywords  = {FIR filters;digital filters;adaptive filters;adaptive signal processing;filtering theory;interpolation;Wiener filters;circuit optimisation;linearly-constrained approach;interpolated FIR filtering;optimum interpolated Wiener filter;interpolated transversal filtering;accurate analytical model;mean coefficient behavior;LMS-AIFIR filters;simulation results;adaptive IFIR filters;narrowband digital FIR filters;constrained least mean squares algorithm;Finite impulse response filter;Filtering;Transversal filters;Wiener filter;Adaptive filters;Electronic mail;Analytical models;Sparse matrices;Art;Computational modeling},
}

@InProceedings{rezende2014stochastic,
  author    = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning},
  title     = {Stochastic backpropagation and approximate inference in deep generative models},
  year      = {2014},
  pages     = {1278--1286},
  groups    = {Neural Network},
}

@PhdThesis{richards2005robust,
  author = {Richards, Arthur George},
  school = {Massachusetts Institute of Technology},
  title  = {Robust constrained model predictive control},
  year   = {2005},
  groups = {interesting articles},
}

@Article{Richtarik2014cda,
  author  = {Richt\'{a}rik, Peter and Tak\'{a}\v{c}, Martin},
  journal = {Mathematical Programming},
  title   = {Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function},
  year    = {2014},
  issn    = {0025-5610},
  number  = {1-2},
  pages   = {1--38},
  volume  = {144},
  groups  = {global optimization},
}

@InProceedings{riedmiller2005neural,
  author       = {Riedmiller, Martin},
  booktitle    = {European Conference on Machine Learning},
  title        = {Neural fitted q iteration--first experiences with a data efficient neural reinforcement learning method},
  year         = {2005},
  organization = {Springer},
  pages        = {317--328},
  groups       = {RL},
}

@INCOLLECTION{rijckaert1980bibliographical,
 AUTHOR = {Rijckaert, MJ and Martens, XM},
 BOOKTITLE = {Advances in Geometric Programming},
 GROUPS = {SGP},
 PAGES = {441--453},
 PUBLISHER = {Springer},
 TIMESTAMP = {2020-07-16},
 TITLE = {Bibliographical note on geometric programming},
 YEAR = {1980}
}

@INCOLLECTION{rijckaert1980comparison,
 AUTHOR = {Rijckaert, MJ and Martens, XM},
 BOOKTITLE = {Advances in geometric programming},
 GROUPS = {SGP},
 PAGES = {283--320},
 PUBLISHER = {Springer},
 TIMESTAMP = {2020-07-16},
 TITLE = {Comparison of generalized geometric programming algorithms},
 YEAR = {1980}
}

@Article{Rippa1992pwl,
  author  = {Rippa, Shmuel},
  journal = {SIAM Journal on Scientific and Statistical Computing},
  title   = {Adaptive approximation by piecewise linear polynomials on triangulations of subsets of scattered data},
  year    = {1992},
  number  = {5},
  pages   = {1123--1141},
  volume  = {13},
  doi     = {10.1137/0913065},
  eprint  = {https://doi.org/10.1137/0913065},
  file    = {:FILES/1992 - Rippa1992pwl - Adaptive Approximation by Piecewise Linear Polynomials on Triangulations of Subsets of Scattered Data.pdf:PDF},
  groups  = {application, Approximation},
  url     = {https://doi.org/10.1137/0913065},
}

@TechReport{riskmetrics1995,
  institution   = {J.P. Morgan},
  title         = {Introduction to {RiskMetrics}},
  year          = {1995},
  month         = {11},
  type          = {Report},
  date-modified = {2016-04-05 02:51:57 +0000},
  day           = {21},
  file          = {:FILES/1995 - riskmetrics1995 - Introduction to risk metrics.pdf:PDF},
  groups        = {VaR, TEC},
  timestamp     = {2020-09-05},
}

@Article{ritter1966method,
  author    = {Ritter, Klaus},
  journal   = {Probability Theory and Related Fields},
  title     = {A method for solving maximum-problems with a nonconcave quadratic objective function},
  year      = {1966},
  number    = {4},
  pages     = {340--351},
  volume    = {4},
  groups    = {global optimization},
  publisher = {Springer},
}

@Article{Rockafellar2000,
  author    = {Rockafellar, R. Tyrrell and Uryasev, Stanislav},
  journal   = {Journal of Risk},
  title     = {Optimization of conditional value-at-risk},
  year      = {2000},
  number    = {3},
  pages     = {21--41},
  volume    = {2},
  file      = {:FILES/2000 - Rockafellar2000 - Optimization of conditional value-at-risk.pdf:PDF},
  groups    = {cvar},
  timestamp = {2020-09-04},
}

@Book{rockafellar2015convex,
  author        = {Rockafellar, Ralph Tyrell},
  publisher     = {Princeton university press},
  title         = {Convex analysis},
  year          = {2015},
  address       = {Princeton, New Jersey},
  date-modified = {2016-03-03 05:59:47 +0000},
  groups        = {global optimization},
}

@Article{rodriguez2013comparative,
  author    = {Rodriguez, Maria Analia and Vecchietti, Aldo},
  journal   = {Computers \& Chemical Engineering},
  title     = {A comparative assessment of linearization methods for bilinear models},
  year      = {2013},
  pages     = {218--233},
  volume    = {48},
  groups    = {bilinear},
  publisher = {Elsevier},
}

@InProceedings{rosch1997interactive,
  author       = {R\"{o}sch, Angela and Ruhl, Matthias and Saupe, Dietmar},
  booktitle    = {Computer Graphics Forum},
  title        = {Interactive visualization of implicit surfaces with singularities},
  year         = {1997},
  number       = {5},
  organization = {Wiley Online Library},
  pages        = {295--306},
  volume       = {16},
  groups       = {interesting articles},
}

@Article{rosen1986global,
  author    = {Rosen, {J. Ben} and Pardalos, Panos M.},
  journal   = {Mathematical Programming},
  title     = {Global minimization of large-scale constrained concave quadratic problems by separable programming},
  year      = {1986},
  number    = {2},
  pages     = {163--174},
  volume    = {34},
  file      = {:FILES/1986 - rosen1986global - Global minimization of large-scale constrained concave quadratic problems by separable programming.pdf:PDF},
  groups    = {global optimization},
  publisher = {Springer},
}

@Article{rosenblatt1958perceptron,
  author        = {Rosenblatt, Frank},
  journal       = {Psychological Review},
  title         = {The perceptron: {A} probabilistic model for information storage and organization in the brain.},
  year          = {1958},
  number        = {6},
  pages         = {386--408},
  volume        = {65},
  date-modified = {2016-04-05 02:48:16 +0000},
  file          = {:FILES/1958 - rosenblatt1958perceptron - The perceptron A probabilistic model for information storage and organization in the brain..pdf:PDF},
  groups        = {Neural Network},
  publisher     = {American Psychological Association},
}

@Book{Rosenblatt1961,
  author    = {Rosenblatt, Frank},
  publisher = {Cornell Aeronautical Laboratory, Inc.},
  title     = {Principles of neurodynamics: {「perceptrons」} and the theory of brain mechanisms},
  year      = {1961},
  groups    = {interesting articles, Neural Network},
}

@Article{rossi2014piecewise,
  author    = {Rossi, Roberto and Tarim, S. Armagan and Prestwich, Steven and Hnich, Brahim},
  journal   = {Applied Mathematics and Computation},
  title     = {Piecewise linear lower and upper bounds for the standard normal first order loss function},
  year      = {2014},
  pages     = {489--502},
  volume    = {231},
  doi       = {10.1016/j.amc.2014.01.019},
  file      = {:FILES/2014 - rossi2014piecewise - Piecewise linear lower and upper bounds for the standard normal first order loss function.pdf:PDF},
  groups    = {application},
  publisher = {Elsevier},
}

@ARTICLE{rountree1982penalty,
 AUTHOR = {Rountree, DH and Rigler, AK},
 GROUPS = {SGP},
 JOURNAL = {Journal of Optimization Theory and Applications},
 NUMBER = {2},
 PAGES = {169--178},
 PUBLISHER = {Springer},
 TIMESTAMP = {2020-07-16},
 TITLE = {A penalty treatment of equality constraints in generalized geometric programming},
 VOLUME = {38},
 YEAR = {1982}
}

@Book{Rourke2012,
  author    = {Rourke, Colin and Sanderson, Brian},
  publisher = {Springer Science \& Business Media},
  title     = {Introduction to piecewise-linear topology},
  year      = {2012},
  file      = {:FILES/2012 - Rourke2012 - Introduction to piecewise-linear topology.pdf:PDF},
  groups    = {identification},
  timestamp = {2020-09-04},
}

@Article{Rousseeuw1984LMS,
  author    = {Rousseeuw, Peter J.},
  journal   = {Journal of the American Statistical Association},
  title     = {Least median of squares regression},
  year      = {1984},
  number    = {388},
  pages     = {871--880},
  volume    = {79},
  abstract  = {Abstract Classical least squares regression consists of minimizing the sum of the squared residuals. Many authors have produced more robust versions of this estimator by replacing the square by something else, such as the absolute value. In this article a different approach is introduced in which the sum is replaced by the median of the squared residuals. The resulting estimator can resist the effect of nearly 50\% of contamination in the data. In the special case of simple regression, it corresponds to finding the narrowest strip covering half of the observations. Generalizations are possible to multivariate location, orthogonal regression, and hypothesis testing in linear models.},
  doi       = {10.1080/01621459.1984.10477105},
  eprint    = {https://www.tandfonline.com/doi/pdf/10.1080/01621459.1984.10477105},
  file      = {:FILES/1984 - Rousseeuw1984LMS - Least Median of Squares Regression.pdf:PDF},
  groups    = {LMS},
  publisher = {Taylor \& Francis},
  url       = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1984.10477105},
}

@Article{roy1952safety,
  author    = {Roy, Andrew Donald},
  journal   = {Econometrica},
  title     = {Safety first and the holding of assets},
  year      = {1952},
  number    = {3},
  pages     = {431--449},
  volume    = {20},
  groups    = {Portfolio Selection},
  publisher = {JSTOR},
  timestamp = {2020-09-04},
}

@Article{Royset2003,
  author    = {Royset, Johannes O. and Polak, Elijah and Kiureghian, A.},
  journal   = {SIAM Journal on Optimization},
  title     = {Adaptive approximations and exact penalization for the solution of generalized semi-infinite min-max problems},
  year      = {2003},
  number    = {1},
  pages     = {1--34},
  volume    = {14},
  file      = {:FILES/2003 - Royset2003 - Adaptive approximations and exact penalization for the solution of generalized semi-infinite min-max problems.pdf:PDF},
  groups    = {optimization},
  publisher = {SIAM},
  timestamp = {2020-08-31},
}

@Article{Rucco2017,
  author   = {Rucco, Matteo and Gonzalez-Diaz, Rocio and Jimenez, Maria-Jose and Atienza, Nieves and Cristalli, Cristina and Concettoni, Enrico and Ferrante, Andrea and Merelli, Emanuela},
  journal  = {Signal Processing},
  title    = {A new topological entropy-based approach for measuring similarities among piecewise linear functions},
  year     = {2017},
  issn     = {0165-1684},
  pages    = {130 -- 138},
  volume   = {134},
  abstract = {In this paper we present a novel methodology based on a topological entropy, the so-called persistent entropy, for addressing the comparison between discrete piecewise linear functions. The comparison is certified by the stability theorem for persistent entropy that is presented here. The theorem is used in the implementation of a new algorithm. The algorithm transforms a discrete piecewise linear function into a filtered simplicial complex that is analyzed via persistent homology and persistent entropy. Persistent entropy is used as a discriminant feature for solving the supervised classification problem of real long-length noisy signals of DC electrical motors. The quality of classification is stated in terms of the area under receiver operating characteristic curve (AUC=93.87\%).},
  doi      = {10.1016/j.sigpro.2016.12.006},
  file     = {:FILES/2017 - Rucco2017 - A new topological entropy-based approach for measuring similarities among piecewise linear functions.pdf:PDF},
  groups   = {identification},
  keywords = {Piecewise linear functions, Noisy signals, Persistent homology, Persistent entropy, Supervised classification},
}

@Article{ruder2016overview,
  author  = {Ruder, Sebastian},
  journal = {arXiv preprint arXiv:1609.04747},
  title   = {An overview of gradient descent optimization algorithms},
  year    = {2016},
  file    = {:FILES/2016 - ruder2016overview - An overview of gradient descent optimization algorithms.pdf:PDF},
  groups  = {global optimization},
}

@ARTICLE{Rudolph1994,
 AUTHOR = {Rudolph, G.},
 GROUPS = {genetic algorithms},
 JOURNAL = {IEEE Transactions on Neural Networks},
 NUMBER = {1},
 PAGES = {96--101},
 TITLE = {Convergence analysis of canonical genetic algorithms},
 VOLUME = {5},
 YEAR = {1994}
}

@Article{ruiz2011exploiting,
  author    = {Ruiz, Juan P. and Grossmann, Ignacio E.},
  journal   = {Optimization Letters},
  title     = {Exploiting vector space properties to strengthen the relaxation of bilinear programs arising in the global optimization of process networks},
  year      = {2011},
  number    = {1},
  pages     = {1--11},
  volume    = {5},
  file      = {:FILES/2011 - ruiz2011exploiting - Exploiting vector space properties to strengthen the relaxation of bilinear programs arising in the global optimization of process networks.pdf:PDF},
  groups    = {bilinear},
  publisher = {Springer},
}

@Article{rumelhart1988learning,
  author  = {Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal = {Cognitive modeling},
  title   = {Learning representations by back-propagating errors},
  year    = {1988},
  pages   = {533--536},
  volume  = {5},
  groups  = {Neural Network},
}

@Book{rummery1994line,
  author    = {Rummery, Gavin A and Niranjan, Mahesan},
  publisher = {University of Cambridge, Department of Engineering Cambridge, UK},
  title     = {On-line {Q-learning} using connectionist systems},
  year      = {1994},
  volume    = {37},
  groups    = {RL},
}

@Article{RUSU2012905,
  author   = {Rusu, Cristian and Dumitrescu, Bogdan},
  journal  = {Signal Processing},
  title    = {Iterative reweighted $l_1$ design of sparse {FIR} filters},
  year     = {2012},
  issn     = {0165-1684},
  number   = {4},
  pages    = {905 -- 911},
  volume   = {92},
  abstract = {Sparse FIR filters have lower implementation complexity than full filters, while keeping a good performance level. This paper describes a new method for designing 1D and 2D sparse filters in the minimax sense using a mixture of reweighted l1 minimization and greedy iterations. The combination proves to be quite efficient; after the reweighted l1 minimization stage introduces zero coefficients in bulk, a small number of greedy iterations serve to eliminate a few extra coefficients. Experimental results and a comparison with the latest methods show that the proposed method performs very well both in the running speed and in the quality of the solutions obtained.},
  doi      = {https://doi.org/10.1016/j.sigpro.2011.09.031},
  file     = {:FILES/2012 - RUSU2012905 - Iterative reweighted L1 design of sparse.pdf:PDF},
  groups   = {sparse, two-dimensional FIR},
  keywords = {Sparse filters, Reweighted minimization, Greedy algorithms},
  url      = {http://www.sciencedirect.com/science/article/pii/S0165168411003483},
}

@Article{rusu2016pnn,
  author        = {Rusu, Andrei A. and Rabinowitz, Neil C. and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
  journal       = {CoRR},
  title         = {Progressive neural networks},
  year          = {2016},
  volume        = {abs/1606.04671},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/RusuRDSKKPH16.bib},
  eprint        = {1606.04671},
  groups        = {Neural Network},
  timestamp     = {Mon, 13 Aug 2018 16:46:11 +0200},
  url           = {http://arxiv.org/abs/1606.04671},
}

@Article{ryoo1995global,
  author    = {Ryoo, Hong S and Sahinidis, Nikolaos V},
  journal   = {Computers \& Chemical Engineering},
  title     = {Global optimization of nonconvex {NLPs} and {MINLPs} with applications in process design},
  year      = {1995},
  number    = {5},
  pages     = {551--566},
  volume    = {19},
  groups    = {global optimization},
  publisher = {Elsevier},
}

@Article{ryoo2001analysis,
  author    = {Ryoo, Hong Seo and Sahinidis, Nikolaos V},
  journal   = {Journal of Global Optimization},
  title     = {Analysis of bounds for multilinear functions},
  year      = {2001},
  number    = {4},
  pages     = {403--424},
  volume    = {19},
  groups    = {bilinear},
  publisher = {Springer},
}

@Article{Sadegheih2006,
  author   = {Sadegheih, A.},
  journal  = {Applied Mathematical Modelling},
  title    = {Scheduling problem using genetic algorithm, simulated annealing and the effects of parameter values on {GA} performance},
  year     = {2006},
  issn     = {0307-904X},
  number   = {2},
  pages    = {147 -- 154},
  volume   = {30},
  abstract = {Genetics algorithms have been designed as general purpose optimisation methods. Simulated annealing simulates the cooling process of solid materials-known as annealing. However this analogy is limited to the physical movement of the molecules without involving complex thermodynamic systems. Physical annealing refers to the process of cooling a solid material so that it reaches a low energy state. Initially the solid is heated up to the melting point. Then it is cooled very slowly, allowing it is to come to thermal equilibrium at each temperature. This process of slow cooling is called annealing. The goal is to find the best arrangement of molecules that minimises the energy of the system, which is referred to as the ground state of the solid material. If the cooling process is fast, the solid will not attain the ground state, but a locally optimal structure. In this paper presents a general purpose schedule optimiser for manufacturing shop scheduling using genetic algorithms and simulated annealing. Then, the ‘uniform order-based’ crossover and mutation operators and novel general effects of parameter values on minimised objective value are presented.},
  doi      = {https://doi.org/10.1016/j.apm.2005.03.017},
  file     = {:FILES/2006 - Sadegheih2006 - Scheduling problem using genetic algorithm, simulated annealing and the effects of parameter values on GA performance.pdf:PDF},
  groups   = {genetic algorithms, Simulated Annealing},
  keywords = {Job shop scheduling, Genetic algorithms, Flow shop scheduling, Heuristic algorithms, Branch and bound programming, Dynamic programming, Simulated annealing},
  url      = {http://www.sciencedirect.com/science/article/pii/S0307904X05000521},
}

@Article{SAGRALOFF201646,
  author   = {Sagraloff, Michael and Mehlhorn, Kurt},
  journal  = {Journal of Symbolic Computation},
  title    = {Computing real roots of real polynomials},
  year     = {2016},
  issn     = {0747-7171},
  pages    = {46 -- 86},
  volume   = {73},
  abstract = {Computing the roots of a univariate polynomial is a fundamental and long-studied problem of computational algebra with applications in mathematics, engineering, computer science, and the natural sciences. For isolating as well as for approximating all complex roots, the best algorithm known is based on an almost optimal method for approximate polynomial factorization, introduced by Pan in 2002. Pan's factorization algorithm goes back to the splitting circle method from Schönhage in 1982. The main drawbacks of Pan's method are that it is quite involved22In Victor Pan's own words: “Our algorithms are quite involved, and their implementation would require a non-trivial work, incorporating numerous known implementation techniques and tricks”. In fact, we are not aware of any implementation of Pan's method. and that all roots have to be computed at the same time. For the important special case, where only the real roots have to be computed, much simpler methods are used in practice; however, they considerably lag behind Pan's method with respect to complexity. In this paper, we resolve this discrepancy by introducing a hybrid of the Descartes method and Newton iteration, denoted ANewDsc, which is simpler than Pan's method, but achieves a run-time comparable to it. Our algorithm computes isolating intervals for the real roots of any real square-free polynomial, given by an oracle that provides arbitrary good approximations of the polynomial's coefficients. ANewDsc can also be used to only isolate the roots in a given interval and to refine the isolating intervals to an arbitrary small size; it achieves near optimal complexity for the latter task.},
  doi      = {https://doi.org/10.1016/j.jsc.2015.03.004},
  groups   = {interesting articles},
  keywords = {Root finding, Root isolation, Root refinement, Approximate arithmetic, Certified computation, Complexity analysis},
  url      = {http://www.sciencedirect.com/science/article/pii/S0747717115000292},
}

@InProceedings{Saha2010,
  author          = {Saha, Amit and Datta, Rituparna and Deb, Kalyanmoy},
  booktitle       = {IEEE Congress on Evolutionary Computation},
  title           = {Hybrid gradient projection based genetic algorithms for constrained optimization},
  year            = {2010},
  pages           = {1--8},
  publisher       = {IEEE},
  abstract        = {Genetic Algorithms (GAs) are a highly successful population based approach to solve global optimization problems. They have carved out a niche for themselves in solving optimization problems of varying difficulty levels involving single and multiple objectives. Most real-world optimization problems involve equality and / or inequality constraints and hence posed as constrained optimization problems. The most common approach to solve such problems using GAs is the method of penalty functions, which however suffers from the drawback of appropriate selection of penalty parameters for their optimal functioning. Given the nature of the problems at hand, we have used an adaptive mutation based Real-Coded GA (RGA), which uses a popular penalty parameter-less approach to handle constraints and search the feasible region effectively for the global best solution, and at the same time use an adaptive mutation strategy to maintain diversity in the population to enable creation of new solutions. We have coupled our RGA with ideas from the gradient projection method to specifically handle equality constraints. We have found our simple procedure working quite well in most of the test problems provided as part of the competition on Single-objective Constrained Real Parameter Optimization in CEC 2010 and hence simplicity remains the hallmark of our study here.},
  date            = {18-23 July 2010},
  doi             = {10.1109/CEC.2010.5586303},
  eventdate       = {18-23 July 2010},
  eventtitleaddon = {Barcelona},
  file            = {:FILES/2010 - Saha2010 - Hybrid gradient projection based Genetic Algorithms for constrained optimization.pdf:PDF},
  groups          = {genetic algorithms},
  isbn            = {978-1-4244-6910-9},
  issn            = {1941-0026},
  keywords        = {Optimization, Search problems, Maintenance engineering, Convergence, Radiation detectors, Evolutionary computation, Polynomials},
  location        = {Barcelona},
}

@Article{Saini2017,
  author       = {Saini, Nisha},
  journal      = {International Journal of Engineering and Computer Science},
  title        = {Review of selection methods in genetic algorithms},
  year         = {2017},
  month        = {12},
  number       = {12},
  pages        = {22261--22263},
  volume       = {6},
  abstractnote = {Genetic Algorithm solves a problem using an evolutionary approach by generating mutations to the current solution method, selecting the better methods from this new generation, and then using these improved methods to repeat the process. Selection is the process of finding out the best individuals for mating process so that the offsprings are produced are fit than the previous population. This paper reviews the commonly used selection methods.},
  file         = {:FILES/2017 - Saini2017 - Review of Selection Methods in Genetic Algorithms.pdf:PDF},
  groups       = {genetic algorithms},
  keywords     = {read},
  place        = {india},
  readstatus   = {read},
  url          = {http://www.ijecs.in/index.php/ijecs/article/view/2562},
}

@InProceedings{sakinah2009,
  author    = {Goudos, S.K. and Zaharis, Z.D. and Baltzis, K.B. and Hilas, C.S. and Sahalos, J.N.},
  booktitle = {Electromagnetic Compatibility - EMC Europe, 2009 International Symposium on},
  title     = {A comparative study of particle swarm optimization and differential evolution on radar absorbing materials design for emc applications},
  year      = {2009},
  pages     = {1--4},
  groups    = {PSO, differential evolution},
}

@Article{salahi2008predictor,
  author  = {Salahi, Maziar and Peng, Jiming and Terlaky, Tam\`{a}s},
  journal = {SIAM Journal on Optimization},
  title   = {On mehrotra-type predictor-corrector algorithms},
  year    = {2008},
  number  = {4},
  pages   = {1377--1397},
  volume  = {18},
  groups  = {RL},
}

@Article{Salhi1994,
  author    = {Salhi, A.},
  journal   = {The Journal of the Operational Research Society},
  title     = {Global optimization: {Deterministic} approaches},
  year      = {1994},
  number    = {5},
  pages     = {595--597},
  volume    = {45},
  doi       = {10.1057/jors.1994.88},
  groups    = {global optimization},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1057/jors.1994.88},
}

@Article{sallans2004reinforcement,
  author  = {Sallans, Brian and Hinton, Geoffrey E},
  journal = {Journal of Machine Learning Research},
  title   = {Reinforcement learning with factored states and actions},
  year    = {2004},
  number  = {Aug},
  pages   = {1063--1088},
  volume  = {5},
  groups  = {RL},
}

@Article{samiel2059,
  author   = {Samuel, A. L.},
  journal  = {IBM Journal of Research and Development},
  title    = {Some studies in machine learning using the game of checkers},
  year     = {1959},
  issn     = {0018-8646},
  month    = {7},
  number   = {3},
  pages    = {210--229},
  volume   = {3},
  abstract = {Two machine-learning procedures have been investigated in some detail using the game of checkers. Enough work has been done to verify the fact that a computer can be programmed so that it will learn to play a better game of checkers than can be played by the person who wrote the program. Furthermore, it can learn to do this in a remarkably short period of time (8 or 10 hours of machine-playing time) when given only the rules of the game, a sense of direction, and a redundant and incomplete list of parameters which are thought to have something to do with the game, but whose correct signs and relative weights are unknown and unspecified. The principles of machine learning verified by these experiments are, of course, applicable to many other situations.},
  doi      = {10.1147/rd.33.0210},
  groups   = {interesting articles},
}

@Article{Sastry2014A,
  author  = {Sastry, Shankar P. and Shontz, Suzanne M. and Vavasis, Stephen A.},
  journal = {Engineering with Computers},
  title   = {A log-barrier method for mesh quality improvement and untangling},
  year    = {2014},
  number  = {3},
  pages   = {315--329},
  volume  = {30},
  groups  = {RL, interesting articles},
}

@InProceedings{Satoh1996,
  author    = {Satoh, Hiroaki and Yamamura, Masayuki and Kobayashi, Shigenobu},
  booktitle = {Proceedings of the IIZUKA'96: Methodologies for the Conception, Design, and Application of Intelligent Systems},
  title     = {Minimal generation gap model for {GA}s considering both exploration and exploitation},
  year      = {1996},
  address   = {Singapore},
  editor    = {Yamakawa, T. and Matsumoto, G.},
  pages     = {494--497},
  publisher = {World Scientific},
  groups    = {genetic algorithms, interesting articles},
}

@InCollection{schaal1997,
  author    = {Schaal, Stefan},
  booktitle = {Advances in Neural Information Processing Systems 9},
  publisher = {MIT Press},
  title     = {Learning from demonstration},
  year      = {1997},
  editor    = {Mozer, M. C. and Jordan, M. I. and Petsche, T.},
  pages     = {1040--1046},
  groups    = {RL},
  url       = {http://papers.nips.cc/paper/1224-learning-from-demonstration.pdf},
}

@Article{schaul2015prioritized,
  author  = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal = {arXiv preprint arXiv:1511.05952},
  title   = {Prioritized experience replay},
  year    = {2015},
  groups  = {RL},
}

@InProceedings{schaul2015universal,
  author    = {Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle = {International conference on machine learning},
  title     = {Universal value function approximators},
  year      = {2015},
  pages     = {1312--1320},
  abstract  = {Value functions are a core component of reinforcement learning systems. The main idea is
to to construct a single function approximator
V (s; θ) that estimates the long-term reward from
any state s, using parameters θ. In this paper
we introduce universal value function approximators (UVFAs) V (s, g; θ) that generalise not
just over states s but also over goals g. We develop an efficient technique for supervised learning of UVFAs, by factoring observed values into
separate embedding vectors for state and goal,
and then learning a mapping from s and g to
these factored embedding vectors. We show how
this technique may be incorporated into a reinforcement learning algorithm that updates the
UVFA solely from observed rewards. Finally, we
demonstrate that a UVFA can successfully generalise to previously unseen goals},
  file      = {:FILES/2015 - schaul2015universal - Universal value function approximators.pdf:PDF},
  groups    = {RL},
  timestamp = {2020-09-04},
}

@Article{Schmidt20053rdExpl,
  author    = {Schmidt, Ulrich and Starmer, Chris and Sugden, Robert},
  journal   = {Discussion Papers},
  title     = {Explaining preference reversal with third-generation prospect theory},
  year      = {2005},
  number    = {3},
  pages     = {203--223},
  volume    = {36},
  groups    = {prospect theory},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@InProceedings{schmidt2007fast,
  author    = {Schmidt, Mark and Fung, Glenn and Rosales, R\'{o}mer},
  booktitle = {Machine Learning: ECML 2007},
  title     = {Fast optimization methods for {L1} regularization: {A} comparative study and two new approaches},
  year      = {2007},
  address   = {Berlin, Heidelberg},
  editor    = {Kok, Joost N. and Koronacki, Jacek and Mantaras, Raomon Lopez de and Matwin, Stan and Mladeni\v{c}, Dunja and Skowron, Andrzej},
  pages     = {286--297},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {L1 regularization is effective for feature selection, but the resulting optimization is challenging due to the non-differentiability of the 1-norm. In this paper we compare state-of-the-art optimization techniques to solve this problem across several loss functions. Furthermore, we propose two new techniques. The first is based on a smooth (differentiable) convex approximation for the L1 regularizer that does not depend on any assumptions about the loss function used. The other technique is a new strategy that addresses the non-differentiability of the L1-regularizer by casting the problem as a constrained optimization problem that is then solved using a specialized gradient projection method. Extensive comparisons show that our newly proposed approaches consistently rank among the best in terms of convergence speed and efficiency by measuring the number of function evaluations required.},
  groups    = {global optimization, SVM},
  isbn      = {978-3-540-74958-5},
  timestamp = {2020-08-30},
}

@Article{Schmidt2008,
  author    = {Schmidt, Ulrich and Starmer, Chris and Sugden, Robert},
  journal   = {Journal of Risk and Uncertainty},
  title     = {Third-generation prospect theory},
  year      = {2008},
  number    = {3},
  pages     = {203--223},
  volume    = {36},
  groups    = {prospect theory},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{schmidt2008risk,
  author    = {Schmidt, Ulrich and Zank, Horst},
  journal   = {Management Science},
  title     = {Risk aversion in cumulative prospect theory},
  year      = {2008},
  number    = {1},
  pages     = {208--216},
  volume    = {54},
  groups    = {prospect theory},
  publisher = {INFORMS},
  timestamp = {2020-09-04},
}

@Book{scholkopf2002learning,
  author    = {Sch\"{o}lkopf, Bernhard and Smola, Alexander J},
  publisher = {MIT press},
  title     = {Learning with kernels: {Support} vector machines, regularization, optimization, and beyond},
  year      = {2002},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@Article{Schubert2002,
  author    = {Schubert, Leo},
  journal   = {Economic Analysis Working Papers},
  title     = {Portfolio optimization with target-shortfall-probability vector},
  year      = {2002},
  number    = {3},
  pages     = {1--19},
  volume    = {1},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{schulman2015high,
  author  = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal = {arXiv preprint arXiv:1506.02438},
  title   = {High-dimensional continuous control using generalized advantage estimation},
  year    = {2015},
  groups  = {RL},
}

@InProceedings{schulman2015trust,
  author    = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle = {International conference on machine learning},
  title     = {Trust region policy optimization},
  year      = {2015},
  pages     = {1889--1897},
  groups    = {RL},
}

@PhdThesis{schulman2016thesis,
  author    = {Schulman, John},
  title     = {Optimizing expectations: {From} deep reinforcement learning to stochastic computation graphs},
  year      = {2016},
  groups    = {RL},
  publisher = {University of California, Berkeley},
}

@Article{Schulman2017ppo,
  author        = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal       = {CoRR},
  title         = {Proximal policy optimization algorithms},
  year          = {2017},
  volume        = {abs/1707.06347},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  eprint        = {1707.06347},
  groups        = {RL},
  timestamp     = {Mon, 13 Aug 2018 16:47:34 +0200},
  url           = {http://arxiv.org/abs/1707.06347},
}

@InProceedings{Semenkin2012,
  author    = {Semenkin, Eugene and Semenkina, Maria},
  booktitle = {Advances in Swarm Intelligence. ICSI 2012. Lecture Notes in Computer Science},
  title     = {Self-configuring genetic algorithm with modified uniform crossover operator},
  year      = {2012},
  address   = {Berlin, Heidelberg},
  editor    = {Tan, Ying and Shi, Yuhui and Ji, Zhen},
  pages     = {414--421},
  publisher = {Springer Berlin Heidelberg},
  volume    = {7331},
  abstract  = {For genetic algorithms, new variants of the uniform crossover operator that introduce selective pressure on the recombination stage are proposed. Operator probabilistic rates based approach to genetic algorithms self-configuration is suggested. The usefulness of the proposed modifications is demonstrated on benchmark tests and real world problems.},
  doi       = {https://doi.org/10.1007/978-3-642-30976-2_50},
  file      = {:FILES/2012 - Semenkin2012 - Self-configuring Genetic Algorithm with Modified Uniform Crossover Operator.pdf:PDF},
  groups    = {genetic algorithms},
  isbn      = {978-3-642-30976-2},
}

@InProceedings{semenov2019loss,
  author    = {Semenov, Alexander and Boginski, Vladimir and Pasiliao, Eduardo L.},
  booktitle = {Computational Data and Social Networks},
  title     = {Neural networks with multidimensional cross-entropy loss functions},
  year      = {2019},
  address   = {Cham},
  editor    = {Tagarelli, Andrea and Tong, Hanghang},
  pages     = {57--62},
  publisher = {Springer International Publishing},
  abstract  = {Deep neural networks have emerged as an effective machine learning tool successfully applied for many tasks, such as misinformation detection, natural language processing, image recognition, machine translation, etc. Neural networks are often applied to binary or multi-class classification problems. In these settings, cross-entropy is used as a loss function for neural network training. In this short note, we propose an extension of the concept of cross-entropy, referred to as multidimensional cross-entropy, and its application as a loss function for classification using neural networks. The presented computational experiments on a benchmark dataset suggest that the proposed approaches may have a potential for increasing the classification accuracy of neural network based algorithms.},
  file      = {:FILES/2019 - semenov2019loss - Neural Networks with Multidimensional Cross-Entropy Loss Functions.pdf:PDF},
  groups    = {Neural Network},
  isbn      = {978-3-030-34980-6},
  timestamp = {2020-08-31},
}

@Article{shalev2011stochastic,
  author    = {Shalev-Shwartz, Shai and Tewari, Ambuj},
  journal   = {Journal of Machine Learning Research},
  title     = {Stochastic methods for $l_1$-regularized loss minimization},
  year      = {2011},
  pages     = {1865--1892},
  volume    = {12},
  groups    = {SVM},
  publisher = {JMLR. org},
  timestamp = {2020-08-30},
}

@Article{shao2012coordinate,
  author    = {Shao, Yuan-Hai and Deng, Nai-Yang},
  journal   = {Neural Networks},
  title     = {A coordinate descent margin based-twin support vector machine for classification},
  year      = {2012},
  number    = {0},
  pages     = {114--121},
  volume    = {25},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@ARTICLE{sharapov2006convergence,
 AUTHOR = {Sharapov, R.R. and Lapshin, A.V.},
 GROUPS = {genetic algorithms},
 JOURNAL = {Pattern Recognition and Image Analysis},
 LANGUAGE = {English},
 NUMBER = {3},
 PAGES = {392--397},
 PUBLISHER = {Nauka/Interperiodica},
 TITLE = {Convergence of genetic algorithms},
 VOLUME = {16},
 YEAR = {2006}
}

@Article{sharpe2007expected,
  author    = {Sharpe, William F.},
  journal   = {Financial Analysts Journal},
  title     = {Expected utility asset allocation},
  year      = {2007},
  number    = {5},
  pages     = {18--30},
  volume    = {63},
  groups    = {utility theory, asset allocation},
  timestamp = {2020-09-04},
}

@Article{shen2004global,
  author    = {Shen, Peiping and Zhang, Kecun},
  journal   = {Applied Mathematics and Computation},
  title     = {Global optimization of signomial geometric programming using linear relaxation},
  year      = {2004},
  number    = {1},
  pages     = {99--114},
  volume    = {150},
  file      = {:FILES/2004 - shen2004global - Global optimization of signomial geometric programming using linear relaxation.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@Article{shen2005linearization,
  author    = {Shen, Peiping},
  journal   = {Applied Mathematics and Computation},
  title     = {Linearization method of global optimization for generalized geometric programming},
  year      = {2005},
  number    = {1},
  pages     = {353--370},
  volume    = {162},
  file      = {:FILES/2005 - shen2005linearization - Linearization method of global optimization for generalized geometric programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@Article{shen2006new,
  author    = {Shen, Peiping and Jiao, Hongwei},
  journal   = {Applied Mathematics and Computation},
  title     = {A new rectangle branch-and-pruning approach for generalized geometric programming},
  year      = {2006},
  number    = {2},
  pages     = {1027--1038},
  volume    = {183},
  file      = {:FILES/2006 - shen2006new - A new rectangle branch-and-pruning approach for generalized geometric programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@InProceedings{shen2007binary,
  author       = {Shen, Yijiang and Lam, Edmund Y. and Wong, Ngai},
  booktitle    = {Signal Recovery and Synthesis},
  title        = {Binary image restoration by signomial programming},
  year         = {2007},
  organization = {Optical Society of America},
  pages        = {SMA3},
  file         = {:FILES/2007 - shen2007binary - Binary image restoration by signomial programming.pdf:PDF},
  groups       = {SGP},
}

@Article{shen2008accelerating,
  author    = {Shen, Pei-Ping and Li, Xiao-ai and Jiao, Hong-Wei},
  journal   = {Journal of Computational and Applied Mathematics},
  title     = {Accelerating method of global optimization for signomial geometric programming},
  year      = {2008},
  number    = {1},
  pages     = {66--77},
  volume    = {214},
  file      = {:FILES/2008 - shen2008accelerating - Accelerating method of global optimization for signomial geometric programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@Article{shen2008robust,
  author    = {Shen, Peiping and Ma, Yuan and Chen, Yongqiang},
  journal   = {Journal of Global Optimization},
  title     = {A robust algorithm for generalized geometric programming},
  year      = {2008},
  number    = {4},
  pages     = {593--612},
  volume    = {41},
  file      = {:FILES/2008 - shen2008robust - A robust algorithm for generalized geometric programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-07-16},
}

@Article{shen2013branch,
  author    = {Shen, Peiping and Li, Xiaoai},
  journal   = {Journal of Global Optimization},
  title     = {Branch-reduction-bound algorithm for generalized geometric programming},
  year      = {2013},
  number    = {3},
  pages     = {1123--1142},
  volume    = {56},
  file      = {:FILES/2013 - shen2013branch - Branch-reduction-bound algorithm for generalized geometric programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-07-16},
}

@Article{sherali1980finitely,
  author    = {Sherali, Hanif D and Shetty, CM},
  journal   = {Mathematical Programming},
  title     = {A finitely convergent algorithm for bilinear programming problems using polar cuts and disjunctive face cuts},
  year      = {1980},
  number    = {1},
  pages     = {14--31},
  volume    = {19},
  groups    = {bilinear},
  publisher = {Springer},
}

@Article{sherali1992global,
  author    = {Sherali, Hanif D and Tuncbilek, Cihan H},
  journal   = {Journal of Global Optimization},
  title     = {A global optimization algorithm for polynomial programming problems using a reformulation-linearization technique},
  year      = {1992},
  number    = {1},
  pages     = {101--112},
  volume    = {2},
  groups    = {SGP},
  publisher = {Springer},
}

@Article{sherali1992new,
  author    = {Sherali, Hanif D and Alameddine, Amine},
  journal   = {Journal of Global optimization},
  title     = {A new reformulation-linearization technique for bilinear programming problems},
  year      = {1992},
  number    = {4},
  pages     = {379--410},
  volume    = {2},
  groups    = {bilinear},
  publisher = {Springer},
}

@Article{sherali1995reformulation,
  author    = {Sherali, Hanif D and Tuncbilek, Cihan H},
  journal   = {Journal of Global Optimization},
  title     = {A reformulation-convexification approach for solving nonconvex quadratic programming problems},
  year      = {1995},
  number    = {1},
  pages     = {1--31},
  volume    = {7},
  abstract  = {In this paper, we consider the class of linearly constrained nonconvex quadratic programming problems, and present a new approach based on a novel Reformulation-Linearization/Convexification Technique. In this approach, a tight linear (or convex) programming relaxation, or outer-approximation to the convex envelope of the objective function over the constrained region, is constructed for the problem by generating new constraints through the process of employing suitable products of constraints and using variable redefinitions. Various such relaxations are considered and analyzed, including ones that retain some useful nonlinear relationships. Efficient solution techniques are then explored for solving these relaxations in order to derive lower and upper bounds on the problem, and appropriate branching/partitioning strategies are used in concert with these bounding techniques to derive a convergent algorithm. Computational results are presented on a set of test problems from the literature to demonstrate the efficiency of the approach. (One of these test problems had not previously been solved to optimality). It is shown that for many problems, the initial relaxation itself produces an optimal solution.},
  groups    = {application},
  publisher = {Springer},
}

@Article{sherali1998global,
  author    = {Sherali, Hanif D.},
  journal   = {Journal of Global Optimization},
  title     = {Global optimization of nonconvex polynomial programming problems having rational exponents},
  year      = {1998},
  number    = {3},
  pages     = {267--283},
  volume    = {12},
  file      = {:FILES/1998 - sherali1998global - Global optimization of nonconvex polynomial programming problems having rational exponents.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
}

@Article{Sherali2001mixed,
  author    = {Sherali, H.D.},
  journal   = {Operations Research Letters},
  title     = {On mixed-integer zero-one representations for separable lower-semicontinuous piecewise-linear functions},
  year      = {2001},
  number    = {4},
  pages     = {155--160},
  volume    = {28},
  groups    = {optimization},
  publisher = {Elsevier},
}

@Article{sherali2007improved,
  author    = {Sherali, Hanif D and Smith, J Cole},
  journal   = {Optimization Letters},
  title     = {An improved linearization strategy for zero-one quadratic programming problems},
  year      = {2007},
  number    = {1},
  pages     = {33--47},
  volume    = {1},
  groups    = {global optimization},
  publisher = {Springer},
}

@Article{shpak1990remez,
  author   = {Shpak, D. J. and Antoniou, A.},
  journal  = {IEEE Transactions on Circuits and Systems},
  title    = {A generalized {Remez} method for the design of {FIR} digital filters},
  year     = {1990},
  issn     = {1558-1276},
  month    = {2},
  number   = {2},
  pages    = {161--174},
  volume   = {37},
  abstract = {A generalized Remez method for the design of finite impulse response (FIR) filters is proposed. The method is based on a new problem formulation which largely eliminates certain difficulties brought about by an undetermined approximating polynomial. The new method can be used to design maximal-ripple (MR), extra-ripple (ER), and weighted-Chebyshev filters satisfying prescribed specifications, and, with the addition of some simple techniques, filters can be designed that are free from transition region anomalies. The method incorporates a new initialization strategy and a selective search technique to reduce the amount of computation needed to carry out a design. Extensive experimental results show that the new method is robust and at least as efficient as existing methods for the design of weighted-Chebyshev filters. For MR as well as ER filters, the new method is both robust and very efficient.<>},
  doi      = {10.1109/31.45709},
  groups   = {FIR filter design},
  keywords = {Chebyshev approximation;digital filters;generalized Remez method;FIR digital filters;finite impulse response;problem formulation;undetermined approximating polynomial;maximal-ripple;extra-ripple;weighted-Chebyshev filters;transition region anomalies;initialization strategy;selective search technique;robust;Design methodology;Finite impulse response filter;Digital filters;Chebyshev approximation;Erbium;Polynomials;Robustness;Frequency;Computer errors},
}

@InProceedings{silver2008dyna2,
  author    = {Silver, David and Sutton, Richard S. and M\"{u}ller, Martin},
  booktitle = {Proceedings of the 25th International Conference on Machine Learning},
  title     = {Sample-based learning and search with permanent and transient memories},
  year      = {2008},
  address   = {New York, NY, USA},
  pages     = {968--975},
  publisher = {Association for Computing Machinery},
  series    = {ICML ’08},
  doi       = {10.1145/1390156.1390278},
  groups    = {RL},
  isbn      = {9781605582054},
  location  = {Helsinki, Finland},
  numpages  = {8},
  url       = {https://doi.org/10.1145/1390156.1390278},
}

@InProceedings{silver2014deterministic,
  author    = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning-Volume 32},
  title     = {Deterministic policy gradient algorithms},
  year      = {2014},
  pages     = {I--387},
  groups    = {RL},
}

@Article{silver2016mastering,
  author    = {Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal   = {nature},
  title     = {Mastering the game of go with deep neural networks and tree search},
  year      = {2016},
  number    = {7587},
  pages     = {484},
  volume    = {529},
  groups    = {RL},
  publisher = {Nature Publishing Group},
}

@Article{silver2017mastering,
  author    = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal   = {Nature},
  title     = {Mastering the game of go without human knowledge},
  year      = {2017},
  number    = {7676},
  pages     = {354--359},
  volume    = {550},
  groups    = {RL},
  publisher = {Nature Publishing Group},
}

@Book{Simon2013,
  author    = {Simon, Dan},
  publisher = {John Wiley \& Sons, Inc.},
  title     = {Evolutionary optimization algorithms: {Biologically} inspired and population-basedapproaches to computer intelligence},
  year      = {2013},
  groups    = {genetic algorithms, TEC},
  timestamp = {2020-09-05},
}

@Article{sinha1987geometric,
  author    = {Sinha, S. B. and Biswas, A. and Biswal, M. P.},
  journal   = {European Journal of Operational Research},
  title     = {Geometric programming problems with negative degrees of difficulty},
  year      = {1987},
  number    = {1},
  pages     = {101--103},
  volume    = {28},
  abstract  = {This paper proposes two methods to solve posynomial geometric programs with negative degrees of difficulty of lower integral values. Such a case arises when a primal program has a number of variables equal or slightly greater than the number of terms. In this specific case the normality and the orthogonality conditions of the dual geometric program give a system of linear equations, where the number of linear equations is greater than the number of dual variables. No general solution vector exists for this system of linear equations. Either the least square or linear programming method can be applied to get an approximate solution vector for this system. Then the optimum value of the dual objective function can be obtained from the approximate solution vector.},
  doi       = {10.1016/0377-2217(87)90175-5},
  file      = {:FILES/1987 - sinha1987geometric - Geometric programming problems with negative degrees of difficulty.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
  url       = {https://www.sciencedirect.com/science/article/abs/pii/0377221787901755},
}

@InProceedings{Sjoeberg1994,
  author    = {Sj\"{o}berg, Jonas and Hjalmarsson, H\a{a}kan and Ljung, Lennart},
  booktitle = {10th IFAC Symposium on System Identification, Copenhagen, Denmark, July, 1994},
  title     = {Neural networks in system identification},
  year      = {1994},
  pages     = {49--72},
  volume    = {2},
  groups    = {Neural Network},
}

@InBook{Sloss2019,
  author     = {Sloss, Andrew N. and Gustafson, Steven},
  editor     = {Banzhaf, W. and Goodman, E. and Sheneman, L. and Trujillo, L. and Worzel, B.},
  pages      = {307--344},
  publisher  = {Springer, Cham},
  title      = {2019 evolutionary algorithms review},
  year       = {2020},
  series     = {Genetic and Evolutionary Computation},
  abstract   = {Evolutionary algorithm research and applications began over 50 years ago. Like other artificial intelligence techniques, evolutionary algorithms will likely see increased use and development due to the increased availability of computation, more robust and available open source software libraries, and the increasing demand for artificial intelligence techniques. As these techniques become more adopted and capable, it is the right time to take a perspective of their ability to integrate into society and the human processes they intend to augment. In this review, we explore a new taxonomy of evolutionary algorithms and resulting classifications that look at five main areas: the ability to manage the control of the environment with limiters, the ability to explain and repeat the search process, the ability to understand input and output causality within a solution, the ability to manage algorithm bias due to data or user design, and lastly, the ability to add corrective measures. These areas are motivated by today's pressures on industry to conform to both societies concerns and new government regulatory rules. As many reviews of evolutionary algorithms exist, after motivating this new taxonomy, we briefly classify a broad range of algorithms and identify areas of future research.},
  booktitle  = {Genetic Programming Theory and Practice XVII},
  doi        = {https://doi.org/10.1007/978-3-030-39958-0_16},
  file       = {:FILES/2019 - Sloss2019 - 2019 Evolutionary Algorithms Review .pdf:PDF},
  groups     = {genetic algorithms},
  readstatus = {read},
  timestamp  = {2020-06-05},
}

@InProceedings{Smit2010,
  author    = {Smit, S. K. and Eiben, A. E.},
  booktitle = {Applications of Evolutionary Computation},
  title     = {Parameter tuning of evolutionary algorithms: {Generalist} vs. specialist},
  year      = {2010},
  address   = {Berlin, Heidelberg},
  editor    = {Di Chio, Cecilia and Cagnoni, Stefano and Cotta, Carlos and Ebner, Marc and Ek\'{a}rt, Anik\'{o} and Esparcia-Alcazar, Anna I. and Goh, Chi-Keong and Merelo, Juan J. and Neri, Ferrante and Preu\ss, Mike and Togelius, Julian and Yannakakis, Georgios N.},
  pages     = {542--551},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Finding appropriate parameter values for Evolutionary Algorithms (EAs) is one of the persistent challenges of Evolutionary Computing. In recent publications we showed how the REVAC (Relevance Estimation and VAlue Calibration) method is capable to find good EA parameter values for single problems. Here we demonstrate that REVAC can also tune an EA to a set of problems (a whole test suite). Hereby we obtain robust, rather than problem-tailored, parameter values and an EA that is a `generalist, rather than a `specialist. The optimized parameter values prove to be different from problem to problem and also different from the values of the generalist. Furthermore, we compare the robust parameter values optimized by REVAC with the supposedly robust conventional values and see great differences. This suggests that traditional settings might be far from optimal, even if they are meant to be robust.},
  file      = {:FILES/2010 - Smit2010 - Parameter Tuning of Evolutionary Algorithms- Generalist vs. Specialist.pdf:PDF},
  groups    = {genetic algorithms},
  isbn      = {978-3-642-12239-2},
}

@Article{smith1999symbolic,
  author    = {Smith, Edward MB and Pantelides, Constantinos C},
  journal   = {Computers \& Chemical Engineering},
  title     = {A symbolic reformulation/spatial branch-and-bound algorithm for the global optimisation of nonconvex MINLPs},
  year      = {1999},
  number    = {4-5},
  pages     = {457--478},
  volume    = {23},
  groups    = {MILP},
  publisher = {Elsevier},
}

@Article{snyder1984linear,
  author    = {Snyder, R. D.},
  journal   = {Journal of the Operational Research Society},
  title     = {Linear programming with special ordered sets},
  year      = {1984},
  number    = {1},
  pages     = {69--74},
  volume    = {35},
  file      = {:FILES/1984 - snyder1984linear - Linear Programming with Special Ordered Sets.pdf:PDF},
  groups    = {MILP},
  publisher = {JSTOR},
}

@Article{sodhani2019consistent,
  author        = {Sodhani, Shagun and Goyal, Anirudh and Deleu, Tristan and Bengio, Yoshua and Levine, Sergey and Tang, Jian},
  journal       = {CoRR},
  title         = {Learning powerful policies by using consistent dynamics model},
  year          = {2019},
  volume        = {abs/1906.04355},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1906-04355.bib},
  eprint        = {1906.04355},
  groups        = {RL},
  timestamp     = {Fri, 14 Jun 2019 09:38:24 +0200},
  url           = {http://arxiv.org/abs/1906.04355},
}

@InProceedings{song1997fir,
  author     = {Song, Young-Seog and Lee, YongHoon},
  booktitle  = {Proceedings of 40th Midwest Symposium on Circuits and Systems. Dedicated to the Memory of Professor Mac Van Valkenburg},
  title      = {Design of sparse {FIR} filters based on branch-and-bound algorithm},
  year       = {1997},
  month      = {8},
  pages      = {1445--1448 vol.2},
  volume     = {2},
  abstract   = {Branch-and-bound algorithm is applied to the design of sparse FIR filters having intentionally zeroed tap positions. It is shown that this algorithm coupled with a suitable optimization technique for filter design can lead to an optimal sparse FIR filter satisfying given specifications. Design examples demonstrate that the proposed method requires less computation than the conventional optimization such as the subset selection method.},
  doi        = {10.1109/MWSCAS.1997.662356},
  file       = {:FILES/1997 - song1997fir - Design of sparse FIR filters based on branch-and-bound algorithm.pdf:PDF},
  groups     = {sparse, MILP},
  keywords   = {digital filters;FIR filters;zero assignment;computational complexity;sparse FIR filters;branch-and-bound algorithm;intentionally zeroed tap positions;computational complexity;Finite impulse response filter;Algorithm design and analysis;Signal processing algorithms;Design optimization;Integer linear programming;Design methodology;Signal design;Delay;Narrowband;Wideband, read},
  readstatus = {read},
}

@Article{Srinivas1994,
  author    = {Srinivas, M. and Patnaik, L. M.},
  journal   = {IEEE Transactions on Systems, Man, and Cybernetics},
  title     = {Adaptive probabilities of crossover and mutation in genetic algorithms},
  year      = {1994},
  issn      = {2168-2909},
  month     = {4},
  number    = {4},
  pages     = {656--667},
  volume    = {24},
  abstract  = {In this paper we describe an efficient approach for multimodal function optimization using genetic algorithms (GAs). We recommend the use of adaptive probabilities of crossover and mutation to realize the twin goals of maintaining diversity in the population and sustaining the, convergence capacity of the GA. In the adaptive genetic algorithm (AGA), the probabilities of crossover and mutation, p/sub c/ and p/sub m/, are varied depending on the fitness values of the solutions. High-fitness solutions are 'protected', while solutions with subaverage fitnesses are totally disrupted. By using adaptively varying p/sub c/ and p/sub ,/ we also provide a solution to the problem of deciding the optimal values of p/sub c/ and p/sub m/, i.e., p/sub c/ and p/sub m/ need not be specified at all. The AGA is compared with previous approaches for adapting operator probabilities in genetic algorithms. The Schema theorem is derived for the AGA, and the working of the AGA is analyzed. We compare the performance of the AGA with that of the standard GA (SGA) in optimizing several nontrivial multimodal functions with varying degrees of complexity.<>},
  doi       = {10.1109/21.286385},
  file      = {:FILES/1994 - Srinivas1994 - Adaptive probabilities of crossover and mutation in genetic algorithms.pdf:PDF},
  groups    = {genetic algorithms},
  keywords  = {genetic algorithms;probability;convergence of numerical methods;optimisation;adaptive probabilities;crossover;mutation;fitness values;multimodal function optimization;convergence capacity;adaptive genetic algorithm;Schema theorem;Genetic mutations;Genetic algorithms;Robustness;Design optimization;Neural networks;Optimal control;Capacity planning;Sampling methods;Organizing;Encoding},
  timestamp = {2020-06-13},
}

@Article{STEEGER2017669,
  author   = {Steeger, Gregory and Rebennack, Steffen},
  journal  = {European Journal of Operational Research},
  title    = {Dynamic convexification within nested benders decomposition using {Lagrangian} relaxation: {An} application to the strategic bidding problem},
  year     = {2017},
  issn     = {0377-2217},
  month    = mar,
  number   = {2},
  pages    = {669--686},
  volume   = {257},
  abstract = {Many decomposition algorithms like Benders decomposition and stochastic dual dynamic programming are limited to convex optimization problems. In this paper, we utilize a dynamic convexification method that makes use of Lagrangian relaxation to overcome this limitation and enables the modeling of non-convex multi-stage problems using decomposition algorithms. Though the algorithm is confined by the duality gap of the problem being studied, the computed upper bounds (for maximization problems) are at least as good as those found via a linear programming relaxation approach. We apply the method to the strategic bidding problem for a hydroelectric producer, in which we ask: What is the revenue-maximizing production schedule for a single price-maker hydroelectric producer in a deregulated, bid-based market? Because the price-maker’s future revenue function has a sawtooth shape, we model it using mixed-integer linear programming. To remedy the non-concavity issues associated with modeling the future revenue function as a mixed-integer linear program, we model the price-maker’s bidding decision utilizing both Benders decomposition and Lagrangian relaxation. We demonstrate the utility of our algorithm through an illustrative example and through three case studies in which we model electricity markets in El Salvador, Honduras, and Nicaragua.},
  doi      = {10.1016/j.ejor.2016.08.006},
  file     = {:FILES/2017 - STEEGER2017669 - Dynamic convexification within nested benders decomposition using Lagrangian relaxation- An application to the strategic bidding problem.pdf:PDF},
  groups   = {interesting articles},
  keywords = {Lagrangian relaxation, Mixed-integer linear programming, Benders decomposition, Hydroelectric scheduling, Strategic bidding problem, Stochastic dual dynamic programming},
  url      = {https://www.sciencedirect.com/science/article/pii/S037722171630621X},
}

@Article{STEELE198693,
  author   = {Steele, J.M. and Steiger, W.L.},
  journal  = {Discrete Applied Mathematics},
  title    = {Algorithms and complexity for least median of squares regression},
  year     = {1986},
  issn     = {0166-218X},
  number   = {1},
  pages    = {93 -- 100},
  volume   = {14},
  abstract = {Given n points {(xi, yi)} in the plane we study the problem of calculating the least median of squares regression line. This involves the study of the function ƒ(α, β) = median(|yi−(α+βxi)|); it is piecewise linear and can have a quadratic number of local minima. Several algorithms that locate a minimizer of ƒ are presented. The best of these has time complexity O(n3) in the worst case. Our most practical algorithm appears to be one which has worst case behavior of O(n3 log(n)), but we provide a probabilistic speed-up of this algorithm which appears to have expected time complexity of O((n log(n))2).},
  doi      = {https://doi.org/10.1016/0166-218X(86)90009-0},
  file     = {:FILES/1986 - STEELE198693 - Algorithms and complexity for least median of squares regression.pdf:PDF},
  groups   = {LMS},
  url      = {http://www.sciencedirect.com/science/article/pii/0166218X86900090},
}

@Article{Stone1961,
  author    = {Stone, Henry},
  journal   = {Mathematics of Computation},
  title     = {Approximation of curves by line segments},
  year      = {1961},
  pages     = {40--47},
  file      = {:FILES/1961 - Stone1961 - Approximation of curves by line segments.pdf:PDF},
  groups    = {Approximation},
  publisher = {JSTOR},
}

@InCollection{Strang1979,
  author    = {Strang, Gilbert},
  booktitle = {Functional analysis methods in numerical analysis},
  publisher = {Springer},
  title     = {A minimax problem in plasticity theory},
  year      = {1979},
  pages     = {319--333},
  file      = {:FILES/1979 - Strang1979 - A minimax problem in plasticity theory.pdf:PDF},
  groups    = {interesting articles},
  timestamp = {2020-08-31},
}

@Article{styblinski1990experiments,
  author    = {Styblinski, MA and Tang, T-S},
  journal   = {Neural Networks},
  title     = {Experiments in nonconvex optimization: {Stochastic} approximation with function smoothing and simulated annealing},
  year      = {1990},
  number    = {4},
  pages     = {467--483},
  volume    = {3},
  groups    = {global optimization, Simulated Annealing},
  publisher = {Elsevier},
}

@InCollection{sutton1990integrated,
  author    = {Sutton, Richard S},
  booktitle = {Machine learning proceedings 1990},
  publisher = {Elsevier},
  title     = {Integrated architectures for learning, planning, and reacting based on approximating dynamic programming},
  year      = {1990},
  pages     = {216--224},
  groups    = {RL},
}

@Article{sutton1991dyna,
  author    = {Sutton, Richard S},
  journal   = {ACM Sigart Bulletin},
  title     = {Dyna, an integrated architecture for learning, planning, and reacting},
  year      = {1991},
  number    = {4},
  pages     = {160--163},
  volume    = {2},
  groups    = {RL},
  publisher = {ACM New York, NY, USA},
}

@InCollection{sutton1991planning,
  author    = {Sutton, Richard S},
  booktitle = {Machine Learning Proceedings 1991},
  publisher = {Elsevier},
  title     = {Planning by incremental dynamic programming},
  year      = {1991},
  pages     = {353--357},
  groups    = {RL},
}

@InProceedings{sutton2000policy,
  author    = {Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle = {Advances in neural information processing systems},
  title     = {Policy gradient methods for reinforcement learning with function approximation},
  year      = {2000},
  pages     = {1057--1063},
  groups    = {RL},
}

@Book{sutton2018book,
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  publisher = {The MIT Press},
  title     = {Reinforcement learning: {An} introduction},
  year      = {2018},
  edition   = {second},
  series    = {Adaptive Computation and Machine Learning},
  groups    = {RL},
}

@Article{suykens1999least,
  author    = {Suykens, Johan A.K. and Vandewalle, Joos},
  journal   = {Neural Processing Letters},
  title     = {Least squares support vector machine classifiers},
  year      = {1999},
  number    = {3},
  pages     = {293--300},
  volume    = {9},
  groups    = {SVM},
  publisher = {Springer},
  timestamp = {2020-08-30},
}

@INPROCEEDINGS{Syswerda1989,
 ADDRESS = {San Francisco, CA, USA},
 AUTHOR = {Syswerda, Gilbert},
 BOOKTITLE = {Proceedings of the 3rd International Conference on Genetic Algorithms},
 COMMENT = {have not found the paper. it is mentioned in \cite{Semenkin2012}.},
 GROUPS = {genetic algorithms},
 ISBN = {1558600663},
 NUMPAGES = {8},
 PAGES = {2--9},
 PUBLISHER = {Morgan Kaufmann Publishers Inc.},
 TITLE = {Uniform crossover in genetic algorithms},
 YEAR = {1989}
}

@INBOOK{Syswerda1991,
 ADDRESS = {New York},
 AUTHOR = {Syswerda, G.},
 BOOKTITLE = {Handbook of Genetic Algorithms},
 EDITOR = {Davis, L.},
 GROUPS = {genetic algorithms},
 PAGES = {332--349},
 PUBLISHER = {Van Nostrand Reinhold},
 TITLE = {Schedule optimization using genetic algorithms},
 YEAR = {1991}
}

@INCOLLECTION{Syswerda1991a,
 ABSTRACT = {Two techniques of population control are currently used in the field of serial genetic algorithms: generational and steady state. Although they have been used somewhat interchangeably in the past, it has become apparent that the two techniques are actually quite different. In this paper, I study the behavior of each with regard to reproduction, and show that while each can be made similar with respect to the schema theorem, in practice their behavior is quite different.},
 AUTHOR = {Syswerda, Gilbert},
 BOOKTITLE = {Foundations of Genetic Algorithms},
 DOI = {https://doi.org/10.1016/B978-0-08-050684-5.50009-4},
 EDITOR = {RAWLINS, GREGORY J.E.},
 GROUPS = {genetic algorithms},
 ISSN = {1081-6593},
 KEYWORDS = {reproduction, steady-state reproduction, generational reproduction, population},
 PAGES = {94 -- 101},
 PUBLISHER = {Elsevier},
 TIMESTAMP = {2020-06-13},
 TITLE = {A study of reproduction in generational and steady-state genetic algorithms},
 URL = {http://www.sciencedirect.com/science/article/pii/B9780080506845500094},
 VOLUME = {1},
 YEAR = {1991}
}

@InProceedings{tahbaz2006one,
  author       = {Tahbaz-Salehi, Alireza and Jadbabaie, Ali},
  booktitle    = {Proceedings of the 45th IEEE Conference on Decision and Control},
  title        = {A one-parameter family of distributed consensus algorithms with boundary: {From} shortest paths to mean hitting times},
  year         = {2006},
  organization = {IEEE},
  pages        = {4664--4669},
  abstract     = {We present a one-parameter family of consensus algorithms over a time-varying network of agents. The proposed family of algorithms contains the average and minimum consensus algorithms as two special cases. Furthermore, we investigate a closely related family of distributed algorithms which can be considered as a consensus scheme with fixed boundary conditions and constant inputs. The proposed algorithms recover both the Bellman-Ford iteration for finding shortest paths as well as the algorithm for calculating the mean hitting time of a random walk on a graph. Finally, we demonstrate the potential utility of these algorithms for routing in adhoc networks},
  file         = {:FILES/2006 - tahbaz2006one - A one-parameter family of distributed consensus algorithms with boundary- From shortest paths to mean hitting times.pdf:PDF},
  groups       = {interesting articles, LSEO},
}

@InProceedings{Takahama2006,
  author    = {Takahama, T. and Sakai, S.},
  booktitle = {2006 IEEE International Conference on Evolutionary Computation},
  title     = {Constrained optimization by the $\epsilon$ constrained differential evolution with gradient-based mutation and feasible elites},
  year      = {2006},
  month     = {7},
  pages     = {1--8},
  abstract  = {While research on constrained optimization using evolutionary algorithms has been actively pursued, it has had to face the problem that the ability to solve multi-modal problems, which have many local solutions within a feasible region, is insufficient, that the ability to solve problems with equality constraints is inadequate, and that the stability and efficiency of searches is low. We proposed the epsivDE, defined by applying the epsiv constrained method to a differential evolution (DE). DE is a simple, fast and stable population based search algorithm that is robust to multi-modal problems. The epsivDE is improved to solve problems with many equality constraints by introducing a gradient-based mutation that finds feasible point using the gradient of constraints at an infeasible point. Also the epsivDE is improved to find feasible solutions faster by introducing elitism where more feasible points are preserved as feasible elites. The improved epsivDE realizes stable and efficient searches that can solve multi-modal problems and those with equality constraints. The advantage of the epsivDE is shown by applying it to twenty four constrained problems of various types.},
  doi       = {10.1109/CEC.2006.1688283},
  file      = {:FILES/2006 - Takahama2006 - Constrained optimization by the ϵ constrained differential evolution with gradient-based mutation and feasible elites.pdf:PDF},
  groups    = {differential evolution, TEC},
  issn      = {1941-0026},
  keywords  = {evolutionary computation;optimisation;search problems;constrained optimization;constrained differential evolution;gradient-based mutation;evolutionary algorithms;multimodal problems;population based search algorithm;equality constraints;Constraint optimization;Genetic mutations;Stability;Evolutionary computation;Robustness;Stochastic processes;Computational efficiency;Intelligent systems;Computational intelligence;Postal services},
  timestamp = {2020-09-05},
}

@InProceedings{tamar2016value,
  author    = {Tamar, Aviv and Wu, Yi and Thomas, Garrett and Levine, Sergey and Abbeel, Pieter},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Value iteration networks},
  year      = {2016},
  pages     = {2154--2162},
  groups    = {Neural Network},
}

@Article{tan2018sim,
  author        = {Tan, Jie and Zhang, Tingnan and Coumans, Erwin and Iscen, Atil and Bai, Yunfei and Hafner, Danijar and Bohez, Steven and Vanhoucke, Vincent},
  journal       = {CoRR},
  title         = {Sim-to-real: {Learning} agile locomotion for quadruped robots},
  year          = {2018},
  volume        = {abs/1804.10332},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1804-10332.bib},
  eprint        = {1804.10332},
  groups        = {interesting articles},
  timestamp     = {Mon, 13 Aug 2018 16:46:27 +0200},
  url           = {http://arxiv.org/abs/1804.10332},
}

@Article{TandK1991,
  author            = {Tversky, Amos and Kahneman, Daniel},
  journal           = {The Quarterly Journal of Economics},
  title             = {Loss aversion in riskless choice: {A} reference-dependent model},
  year              = {1991},
  number            = {4},
  pages             = {1039--1061},
  volume            = {106},
  groups            = {Portfolio Selection},
  jstor_articletype = {research-article},
  timestamp         = {2020-09-04},
}

@Article{tao1997convex,
  author    = {Tao, P. D. and An, L. T. H.},
  journal   = {Acta Mathematica Vietnamica},
  title     = {Convex analysis approach to {DC} programming: {Theory,} algorithms and applications},
  year      = {1997},
  number    = {1},
  pages     = {289--355},
  volume    = {22},
  abstract  = {Dedicated to Hoang Tuy on the occasion of his seventieth birthday Abstract. This paper is devoted to a thorough study on convex analysis approach to d.c. (difierence of convex functions) programming and gives the State of the Art. Main results about d.c. duality, local and global opti- malities in d.c. programming are presented. These materials constitute the basis of the DCA (d.c. algorithms). Its convergence properties have been tackled in detail, especially in d.c. polyhedral programming where it has flnite convergence. Exact penalty, Lagrangian duality without gap, and regularization techniques have beeen studied to flnd appropriate d.c. de- compositions and to improve consequently the DCA. Finally we present the application of the DCA to solving a lot of important real-life d.c. pro- grams.},
  file      = {:FILES/1997 - tao1997convex - CONVEX ANALYSIS APPROACH TO D. C. PROGRAMMING- THEORY, ALGORITHMS AND APPLICATIONS .pdf:PDF},
  groups    = {global optimization, proximal bundle method},
  timestamp = {2020-09-04},
}

@Article{tao2005dc,
  author    = {An, Le Thi Hoai and Tao, Pham Dinh},
  journal   = {Annals of Operations Research},
  title     = {The {DC} (difference of convex functions) programming and {DCA} revisited with {DC} models of real world nonconvex optimization problems},
  year      = {2005},
  number    = {1},
  pages     = {23--46},
  volume    = {133},
  groups    = {global optimization},
  publisher = {Springer},
}

@Article{Tao2009dc,
  author  = {Tao, Pham Dinh and Canh, Nam Nguyen and Van Thoai, Nguyen},
  journal = {Journal of Global Optimization},
  title   = {{DC} programming techniques for solving a class of nonlinear bilevel programs},
  year    = {2009},
  number  = {3},
  pages   = {313--337},
  volume  = {44},
  groups  = {bilevel},
  type    = {Journal Article},
}

@Article{Tao2016,
  author    = {Tao, Qinghua and Huang, Xiaolin and Wang, Shuning and Xi, Xiangming and Li, Li},
  journal   = {Signal Processing},
  title     = {Multiple {G}aussian graphical estimation with jointly sparse penalty},
  year      = {2016},
  issn      = {0165-1684},
  month     = mar,
  pages     = {88 -- 97},
  volume    = {128},
  abstract  = {In this paper, we consider estimating multiple Gaussian graphs with a similar sparsity structure. Most related solving methods, such as GGL (Group graphical lasso) and FMGL (Fused multiple graphical lasso), focus on the information of the edge values, and pay few attention to the estimation based on structure information. We construct a jointly sparse penalty to encourage graphs to share a similar sparsity structure by utilizing information of the common structure across the graphs. The new objective function is neither convex nor differentiable. Combining block coordinate descent and majorization-minimization strategies, we derive a new re-weighed algorithm to solve the problem by transforming the subproblems in every iteration into convex ones. Experimental results show that the proposed algorithm outperforms FMGL and GGL when the sparsity structure is similar but the edge values are not.},
  author+an = {4=highlight},
  comment   = {3.11},
  doi       = {https://doi.org/10.1016/j.sigpro.2016.03.009},
  file      = {:FILES/2016 - Tao2016 - multiple gaussian graphical estimation with jointly sparse penalty.pdf:PDF},
  groups    = {my paper, Wang's Work},
  keywords  = {Gaussian graphical models, Non-convex penalty, Block coordinate descent, Majorization and minimization, Re-weighted algorithm},
  url       = {http://www.sciencedirect.com/science/article/pii/S0165168416300032},
}

@Article{Tao2018,
  author    = {Tao, Songqiao and Tan, Juan},
  journal   = {Journal of Robotics},
  title     = {Path planning with obstacle avoidance based on normalized $R$-functions},
  year      = {2018},
  issn      = {1687-9600},
  month     = {10},
  pages     = {5868915},
  volume    = {2018},
  abstract  = {Existing methods for path planning with obstacle avoidance need to check having the interference between a moving part and an obstacle at iteration and even to calculate their shortest distance in the case of given motion parameters. Besides, the tasks like collision-checking and minimum-distance calculating themselves are complicated and time-consuming. Rigorous mathematical analysis might be a practical way for dealing with the above-mentioned problems. An<italic> R</italic>-function is a real-valued function whose properties are fully determined by corresponding attributes of their parameters, which is usually applied to express a geometrical object. Thus, a signed distance function based on<italic> R</italic>-functions is created to represent whether two objects intervene and their level of intervention or separation. As the signed function is continuous and differentiable, the gradient information of the objective function guides a moving part to avoid its obstacles and to approach its target position rapidly. Therefore, a path planning approach with obstacle avoidance based on normalized<italic> R</italic>-functions is proposed in this paper. A discrete convex hull approach is adopted to solve the problem that<italic> R</italic>-function is inappropriate to represent a geometric object with some curves or surfaces, and pendent points and edges are generated in Boolean operations. Besides, a normalized approach ensures accuracy calculation of signed distance function. Experimental results have shown that the presented approach is a feasible way for path planning with obstacle avoidance.},
  day       = {04},
  doi       = {10.1155/2018/5868915},
  groups    = {RL, interesting articles},
  publisher = {Hindawi},
  url       = {https://doi.org/10.1155/2018/5868915},
}

@InCollection{tardella2004existence,
  author    = {Tardella, Fabio},
  booktitle = {Frontiers in global optimization},
  publisher = {Springer},
  title     = {On the existence of polyhedral convex envelopes},
  year      = {2004},
  pages     = {563--573},
  groups    = {mathematical basis},
}

@InProceedings{tassa2012synthesis,
  author       = {Tassa, Yuval and Erez, Tom and Todorov, Emanuel},
  booktitle    = {2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  title        = {Synthesis and stabilization of complex behaviors through online trajectory optimization},
  year         = {2012},
  organization = {IEEE},
  pages        = {4906--4913},
  abstract     = {We present an online trajectory optimization method and software platform applicable to complex humanoid robots performing challenging tasks such as getting up from an arbitrary pose on the ground and recovering from large disturbances using dexterous acrobatic maneuvers. The resulting behaviors, illustrated in the attached video, are computed only 7 × slower than real time, on a standard PC. The video also shows results on the acrobot problem, planar swimming and one-legged hopping. These simpler problems can already be solved in real time, without pre-computing anything.},
  groups       = {interesting articles},
}

@Article{tawarmalani2005polyhedral,
  author    = {Tawarmalani, Mohit and Sahinidis, Nikolaos V},
  journal   = {Mathematical Programming},
  title     = {A polyhedral branch-and-cut approach to global optimization},
  year      = {2005},
  number    = {2},
  pages     = {225--249},
  volume    = {103},
  groups    = {global optimization},
  publisher = {Springer},
}

@Article{tawarmalani2009allocating,
  author    = {Tawarmalani, Mohit and Kannan, Karthik and De, Prabuddha},
  journal   = {Management Science},
  title     = {Allocating objects in a network of caches: {Centralized} and decentralized analyses},
  year      = {2009},
  number    = {1},
  pages     = {132--147},
  volume    = {55},
  groups    = {Neural Network},
  publisher = {INFORMS},
}

@Article{tax2004,
  author     = {Tax, David M.J. and Duin, Robert P.W.},
  journal    = {Machine Learning},
  title      = {Support vector data description},
  year       = {2004},
  number     = {1},
  pages      = {45--66},
  volume     = {54},
  bdsk-url-1 = {http://dx.doi.org/10.1023/B%3AMACH.0000008084.60811.49},
  groups     = {SVM},
  publisher  = {Kluwer Academic Publishers-Plenum Publishers},
  timestamp  = {2020-08-30},
  url        = {http://dx.doi.org/10.1023/B%3AMACH.0000008084.60811.49},
}

@Article{teles2013multi,
  author    = {Teles, Jo\~{a}o P and Castro, Pedro M and Matos, Henrique A},
  journal   = {Journal of Global Optimization},
  title     = {Multi-parametric disaggregation technique for global optimization of polynomial programming problems},
  year      = {2013},
  number    = {2},
  pages     = {227--251},
  volume    = {55},
  file      = {:FILES/2013 - teles2013multi - Multi-parametric disaggregation technique for global optimization of polynomial programming problems.pdf:PDF},
  groups    = {SGP, MILP},
  publisher = {Springer},
}

@Article{teles2013univariate,
  author    = {Teles, {Jo\~{a}o P.} and Castro, {Pedro M.} and Matos, {Henrique A.}},
  journal   = {European Journal of Operational Research},
  title     = {Univariate parameterization for global optimization of mixed-integer polynomial problems},
  year      = {2013},
  number    = {3},
  pages     = {613--625},
  volume    = {229},
  file      = {:FILES/2013 - teles2013univariate - Univariate parameterization for global optimization of mixed-integer polynomial problems.pdf:PDF},
  groups    = {SGP, MILP},
  publisher = {Elsevier},
}

@Article{Terela1999Lattice,
  author   = {Tarela, J. and Mart\'{i}nez, M.},
  journal  = {Mathematical and Computer Modelling},
  title    = {Region configurations for realizability of lattice piecewise-linear models},
  year     = {1999},
  number   = {11-12},
  pages    = {17--27},
  volume   = {30},
  file     = {:FILES/1999 - Terela1999Lattice - Region configurations for realizability of lattice piecewise-linear models.pdf:PDF},
  groups   = {identification},
  keywords = {prio1},
  priority = {prio1},
}

@InCollection{tesauro1995td,
  author    = {Tesauro, Gerald},
  booktitle = {Applications of neural networks},
  publisher = {Springer},
  title     = {{TD-Gammon}: {A} self-teaching backgammon program, Achieves Master-Level Play},
  year      = {1995},
  pages     = {267--285},
  abstract  = {TD-Gammon is a neural network that is able to teach itself to play backgammon solely by playing against itself and learning from the results, based on the TD(λ) reinforcement learning algorithm (Sutton 1988). Despite starting from random initial weights (and hence random initial strategy), TD-Gammon achieves a surprisingly strong level of play. With zero knowledge built in at the start of learning (i.e., given only a “raw” description of the board state), the network learns to play at a strong intermediate level. Furthermore, when a set of hand-crafted features is added to the network's input representation, the result is a truly staggering level of performance: the latest version of TD-Gammon is now estimated to play at a strong master level that is extremely close to the world's best human players.},
  groups    = {RL},
}

@Article{thakur1978pwl,
  author  = {Thakur, Lakshman S.},
  journal = {SIAM Journal on Applied Mathematics},
  title   = {Error analysis for convex separable programs: {The} piecewise linear approximation and the bounds on the optimal objective value},
  year    = {1978},
  number  = {4},
  pages   = {704--714},
  volume  = {34},
  doi     = {10.1137/0134059},
  eprint  = {https://doi.org/10.1137/0134059},
  groups  = {optimization},
  url     = {https://doi.org/10.1137/0134059},
}

@Article{thakur1980error,
  author    = {Thakur, Lakshman S},
  journal   = {Journal of Mathematical Analysis and Applications},
  title     = {Error analysis for convex separable programs: {Bounds} on optimal and dual optimal solutions},
  year      = {1980},
  number    = {2},
  pages     = {486--494},
  volume    = {75},
  groups    = {global optimization},
  publisher = {Elsevier},
}

@Article{thakur1984solving,
  author    = {Thakur, Lakshman S},
  journal   = {Computers \& operations research},
  title     = {Solving highly nonlinear convex separable programs using successive approximation},
  year      = {1984},
  number    = {2},
  pages     = {113--128},
  volume    = {11},
  groups    = {global optimization},
  publisher = {Elsevier},
}

@Article{thakur1986successive,
  author    = {Thakur, Lakshman S},
  journal   = {Naval research logistics quarterly},
  title     = {Successive approximation in separable programming: {An} improved procedure for convex separable programs},
  year      = {1986},
  number    = {2},
  pages     = {325--358},
  volume    = {33},
  groups    = {global optimization},
  publisher = {Wiley Online Library},
}

@Article{thieu1980relationship,
  author  = {Thieu, Tran Vu},
  journal = {Acta Math. Vietnam},
  title   = {Relationship between bilinear programming and concave minimization under linear constraints},
  year    = {1980},
  number  = {2},
  pages   = {106--113},
  volume  = {5},
  groups  = {bilinear},
}

@Article{thieu1988note,
  author    = {Thieu, Tran Vu},
  journal   = {Mathematical Programming},
  title     = {A note on the solution of bilinear programming problems by reduction to concave minimization},
  year      = {1988},
  number    = {1-3},
  pages     = {249--260},
  volume    = {41},
  groups    = {bilinear},
  publisher = {Springer},
}

@Book{thorndike1911,
  author    = {Thorndike, Edward L.},
  publisher = {The MacMillan Company},
  title     = {Animal intelligence},
  year      = {1911},
  groups    = {Heuristics},
}

@Article{Ting2010,
  author     = {Ting, Chuan-Kang and Su, Chien-Hao and Lee, Chung-Nan},
  journal    = {Expert Systems with Applications},
  title      = {Multi-parent extension of partially mapped crossover for combinatorial optimization problems},
  year       = {2010},
  issn       = {0957-4174},
  number     = {3},
  pages      = {1879 -- 1886},
  volume     = {37},
  abstract   = {This paper proposes the multi-parent partially mapped crossover (MPPMX), which generalizes the partially mapped crossover (PMX) to a multi-parent crossover. The mapping list and legalization of PMX are modified to deal with the issues that arise from the increase of parents in PMX. Experimental results on five traveling salesman problems show that MPPMX significantly improves PMX by up to 13.95\% in mean tour length. These preferable results not only demonstrate the advantage of the proposed MPPMX over PMX, but also confirm the merit of using more than two parents in crossover.},
  doi        = {https://doi.org/10.1016/j.eswa.2009.07.082},
  file       = {:FILES/2010 - Ting2010 - Multi-parent extension of partially mapped crossover for combinatorial optimization problems.pdf:PDF},
  groups     = {genetic algorithms},
  keywords   = {Genetic algorithms, Multi-parent crossover, Partially mapped crossover (PMX), Combinatorial optimization, Traveling salesman problem (TSP), read},
  readstatus = {read},
  url        = {http://www.sciencedirect.com/science/article/pii/S0957417409006800},
}

@Article{toriello2012fitting,
  author  = {Toriello, Alejandro and Vielma, Juan Pablo},
  journal = {European Journal of Operational Research},
  title   = {Fitting piecewise linear continuous functions},
  year    = {2012},
  number  = {1},
  pages   = {86--95},
  volume  = {219},
  file    = {:FILES/2012 - toriello2012fitting - Fitting piecewise linear continuous functions.pdf:PDF},
  groups  = {identification},
}

@Article{toscano2012some,
  author    = {Toscano, R. and Amouri, S. B.},
  journal   = {Engineering Optimization},
  title     = {Some heuristic approaches for solving extended geometric programming problems},
  year      = {2012},
  number    = {12},
  pages     = {1425--1446},
  volume    = {44},
  file      = {:FILES/2012 - toscano2012some - Some heuristic approaches for solving extended geometric programming problems.pdf:PDF},
  groups    = {SGP},
  publisher = {Taylor \& Francis},
  timestamp = {2020-07-16},
}

@InCollection{Traffic2009Wang,
  author    = {Lu, Yang and Hu, Jianming and Xu, Jun and Wang, Shuning},
  booktitle = {Artificial Intelligence and Computational Intelligence},
  publisher = {Springer Berlin Heidelberg},
  title     = {Urban traffic flow forecasting based on adaptive hinging hyperplanes},
  year      = {2009},
  editor    = {Deng, Hepu and Wang, Lanzhou and Wang, FuLee and Lei, Jingsheng},
  pages     = {658--667},
  series    = {Lecture Notes in Computer Science},
  volume    = {5855},
  file      = {:FILES/2009 - Traffic2009Wang - Urban Traffic Flow Forecasting Based on Adaptive Hinging Hyperplanes.pdf:PDF},
  groups    = {application, Wang's Work},
  language  = {English},
}

@Article{tsai2002global,
  author    = {Tsai, Jung-Fa and Li, Han-Lin and Hu, Nian-Ze},
  journal   = {Engineering Optimization},
  title     = {Global optimization for signomial discrete programming problems in engineering design},
  year      = {2002},
  number    = {6},
  pages     = {613--622},
  volume    = {34},
  file      = {:FILES/2002 - tsai2002global - Global optimization for signomial discrete programming problems in engineering design.pdf:PDF},
  groups    = {SGP},
  publisher = {Taylor \& Francis},
}

@Article{tsai2006optimization,
  author    = {Tsai, Jung-Fa and Lin, Ming-Hua},
  journal   = {Computers \& chemical engineering},
  title     = {An optimization approach for solving signomial discrete programming problems with free variables},
  year      = {2006},
  number    = {8},
  pages     = {1256--1263},
  volume    = {30},
  file      = {:FILES/2006 - tsai2006optimization - An optimization approach for solving signomial discrete programming problems with free variables.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
}

@Article{tsai2007generalized,
  author    = {Tsai, Jung-Fa and Lin, Ming-Hua and Hu, Yi-Chung},
  journal   = {European Journal of Operational Research},
  title     = {On generalized geometric programming problems with non-positive variables},
  year      = {2007},
  number    = {1},
  pages     = {10--19},
  volume    = {178},
  file      = {:FILES/2007 - tsai2007generalized - On generalized geometric programming problems with non-positive variables.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@Article{tsai2008global,
  author    = {Tsai, Jung-Fa and Lin, Ming-Hua},
  journal   = {Journal of Global Optimization},
  title     = {Global optimization of signomial mixed-integer nonlinear programming problems with free variables},
  year      = {2008},
  number    = {1},
  pages     = {39--49},
  volume    = {42},
  file      = {:FILES/2008 - tsai2008global - Global optimization of signomial mixed-integer nonlinear programming problems with free variables.pdf:PDF},
  groups    = {SGP, MILP},
  publisher = {Springer},
}

@Article{tsai2009treating,
  author    = {Tsai, Jung-Fa},
  journal   = {Computers \& Chemical Engineering},
  title     = {Treating free variables in generalized geometric programming problems},
  year      = {2009},
  number    = {1},
  pages     = {239--243},
  volume    = {33},
  file      = {:FILES/2009 - tsai2009treating - Treating free variables in generalized geometric programming problems.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@Article{tsai2011efficient,
  author    = {Tsai, Jung-Fa and Lin, Ming-Hua},
  journal   = {INFORMS Journal on Computing},
  title     = {An efficient global approach for posynomial geometric programming problems},
  year      = {2011},
  number    = {3},
  pages     = {483--492},
  volume    = {23},
  file      = {:FILES/2011 - tsai2011efficient - An efficient global approach for posynomial geometric programming problems.pdf:PDF},
  groups    = {SGP},
  publisher = {INFORMS},
  timestamp = {2020-07-16},
}

@Article{tsai2013improved,
  author    = {Tsai, Jung-Fa and Lin, Ming-Hua},
  journal   = {Computers \& Chemical Engineering},
  title     = {An improved framework for solving {NLIPs} with signomial terms in the objective or constraints to global optimality},
  year      = {2013},
  pages     = {44--54},
  volume    = {53},
  abstract  = {Real application problems are often formulated as nonlinear integer programming problems or as discrete global optimization problems with signomial terms in the objective or constraints. Although various approaches have been proposed to solve the problems, they either utilize numerous extra binary variables and constraints to reconstruct the problems for finding a global solution or are unable to obtain globally optimized solutions. This study proposes a novel linearization method that employs a logarithmic number of extra binary variables and constraints to reformulate a signomial term with discrete variables. The original nonlinear integer program is therefore converted into a mixed-integer linear program solvable to obtain a global optimum. Several numerical experiments are presented to demonstrate the computational efficiency of the proposed methods in solving nonlinear integer problems, especially for treating signomial functions with large-interval variables or multiple variables.},
  file      = {:FILES/2013 - tsai2013improved - An Improved Framework for Solving NLIPs with Signomial Terms in the Objective or Constraints to Global Optimality.pdf:PDF},
  groups    = {SGP, global optimization},
  publisher = {Elsevier},
}

@Article{tseng2001Convergence,
  author    = {Tseng, Paul},
  journal   = {Journal of Optimization Theory and Applications},
  title     = {Convergence of a block coordinate descent method for nondifferentiable minimization},
  year      = {2001},
  number    = {3},
  pages     = {475--494},
  volume    = {109},
  groups    = {global optimization},
  keywords  = {block coordinate descent; nondifferentiable minimization; stationary point; Gauss每Seidel method; convergence; quasiconvex functions; pseudoconvex functions},
  publisher = {Kluwer Academic Publishers-Plenum Publishers},
}

@Article{tseng2009coordinate,
  author  = {Tseng, Paul and Yun, Sangwoon},
  journal = {Mathematical Programming},
  title   = {A coordinate gradient descent method for nonsmooth separable minimization},
  year    = {2009},
  number  = {1-2},
  pages   = {387--423},
  volume  = {117},
  groups  = {global optimization},
}

@Article{tseng2015milp,
  author     = {Tseng, {Chung-Li} and Zhan, Yiduo and Zheng, Qipeng P. and Kumar, Manish},
  journal    = {European Journal of Operational Research},
  title      = {A {MILP} formulation for generalized geometric programming using piecewise-linear approximations},
  year       = {2015},
  number     = {2},
  pages      = {360--370},
  volume     = {245},
  file       = {:FILES/2015 - tseng2015milp - A MILP formulation for generalized geometric programming using piecewise-linear approximations.pdf:PDF},
  groups     = {SGP},
  keywords   = {read},
  publisher  = {Elsevier},
  readstatus = {read},
  timestamp  = {2020-08-31},
}

@InProceedings{tsitsiklis1997analysis,
  author    = {Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle = {Advances in neural information processing systems},
  title     = {Analysis of temporal-diffference learning with function approximation},
  year      = {1997},
  pages     = {1075--1081},
  groups    = {interesting articles},
}

@Article{Tsui2005fir,
  author   = {Tsui, K. M. and Chan, S. C. and Yeung, K. S.},
  journal  = {IEEE Transactions on Circuits and Systems II: Express Briefs},
  title    = {Design of {FIR} digital filters with prescribed flatness and peak error constraints using second-order cone programming},
  year     = {2005},
  issn     = {1558-3791},
  month    = {9},
  number   = {9},
  pages    = {601--605},
  volume   = {52},
  abstract = {This paper studies the design of digital finite impulse response (FIR) filters with prescribed flatness and peak design error constraints using second-order cone programming (SOCP). SOCP is a powerful convex optimization method, where linear and convex quadratic inequality constraints can readily be incorporated. It is utilized in this study for the optimal minimax and least squares design of linear-phase and low-delay (LD) FIR filters with prescribed magnitude flatness and peak design error. The proposed approach offers more flexibility than traditional maximally-flat approach for the tradeoff between the approximation error and the degree of design freedom. Using these results, new LD specialized filters such as digital differentiators, Hilbert Transformers, Mth band filters and variable digital filters with prescribed magnitude flatness constraints can also be derived.},
  doi      = {10.1109/TCSII.2005.850515},
  file     = {:FILES/2005 - Tsui2005fir - Design of FIR digital filters with prescribed flatness and peak error constraints using second-order cone programming.pdf:PDF},
  groups   = {FIR filter design},
  keywords = {FIR filters;minimax techniques;least squares approximations;convex programming;linear phase filters;FIR digital filter design;prescribed flatness;peak error constraints;second-order cone programming;digital finite impulse response filters;convex optimization;linear quadratic inequality constraints;convex quadratic inequality constraints;optimal minimax;least squares design;linear-phase FIR filters;low-delay FIR filters;Finite impulse response filter;Digital filters;Minimax techniques;IIR filters;Delay;Optimization methods;Transformers;Linear programming;Design methodology;Least squares methods;Constrained finite impulse response (FIR) filter design;digital differentiators;low-delay (LD);magnitude and group delay flatness;peak error constraints;second-order cone programming (SOCP)},
}

@InProceedings{Tsutsui1993,
  author    = {Tsutsui, Shigeyoshi and Fujimoto, Yoshiji},
  booktitle = {ICGA},
  title     = {Forking genetic algorithm with blocking and shrinking modes (fga)},
  year      = {1993},
  file      = {:FILES/1993 - Tsutsui1993 - Forking genetic algorithm with blocking and shrinking modes.pdf:PDF},
  groups    = {genetic algorithms},
  timestamp = {2020-06-13},
}

@InProceedings{Tsutsui1998,
  author          = {Tsutsui, S. and Ghosh, A.},
  booktitle       = {1998 IEEE International Conference on Evolutionary Computation Proceedings. IEEE World Congress on Computational Intelligence},
  title           = {A study on the effect of multi-parent recombination in real coded genetic algorithms},
  year            = {1998},
  pages           = {828--833},
  publisher       = {IEEE},
  abstract        = {We investigate real coded genetic algorithms in which more than two parents are involved in recombination operation. We propose three types of multi-parent recombination operators; the center of mass crossover (CMX), multi-parent feature-wise crossover (MFX), and seed crossover (SX). Each of these operators is a natural generalization of 2-parent recombination operator. These operators are evaluated on several test functions. The results showed clearly that multi-parent recombinations lead to better performance, although the performance improvement for different techniques were found to be dependent on problems.},
  comment         = {This article introduces some literatures on using multiple parents, which has not been included in my report.},
  date            = {4-9 May 1998},
  doi             = {10.1109/ICEC.1998.700159},
  eventdate       = {4-9 May 1998},
  eventtitleaddon = {Anchorage, AK, USA},
  file            = {:FILES/1998 - Tsutsui1998 - A study on the effect of multi-parent recombination in real coded genetic algorithms.pdf:PDF},
  groups          = {genetic algorithms},
  isbn            = {0-7803-4869-9},
  keywords        = {Genetic algorithms, Testing, Biological cells, Production systems, Evolutionary computation, Electronic switching systems, Machine intelligence, Control systems, Springs, read},
  location        = {Anchorage, AK, USA},
  readstatus      = {read},
}

@InProceedings{Tsutsui1998a,
  author    = {Tsutsui, Shigeyoshi},
  booktitle = {Parallel Problem Solving from Nature -- PPSN V},
  title     = {Multi-parent recombination in genetic algorithms with search space boundary extension by mirroring},
  year      = {1998},
  address   = {Berlin, Heidelberg},
  editor    = {Eiben, Agoston E. and B\"{a}ck, Thomas and Schoenauer, Marc and Schwefel, Hans-Paul},
  pages     = {428--437},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {In previous work, we have investigated real coded genetic algorithms with several types of multi-parent recombination operators and found evidence that multi-parent recombination with center of mass crossover (CMX) seems a good choice for real coded GAs. But CMX does not work well on functions which have their optimum on the corner of the search space. In this paper, we propose a method named boundary extension by mirroring (BEM) to cope with this problem. Applying BEM to CMX, the performance of CMX on the test functions which have their optimum on the corner of the search space was much improved. Further, by applying BEM, we observed clear improvement in performance of two-parent recombination on the functions which have their optimum on the corner of the search space. Thus, we suggest that BEM is a good general technique to improve the efficiency of crossover operators in real-coded GAs for a wide range of functions.},
  file      = {:FILES/1998 - Tsutsui1998a - Multi-parent recombination in genetic algorithms with search space boundary extension by mirroring.pdf:PDF},
  groups    = {genetic algorithms},
  isbn      = {978-3-540-49672-4},
}

@InProceedings{Tsutsui1999,
  author     = {Tsutsui, Shigeyoshi and Yamamura, Masayuki and Higuchi, Takahide},
  booktitle  = {Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation - Volume 1},
  title      = {Multi-parent recombination with simplex crossover in real coded genetic algorithms},
  year       = {1999},
  address    = {San Francisco, CA, USA},
  pages      = {657--664},
  publisher  = {Morgan Kaufmann Publishers Inc.},
  series     = {GECCO’99},
  file       = {:FILES/1999 - Tsutsui1999 - Multi-parent Recombination with Simplex Crossover in Real Coded Genetic Algorithms.pdf:PDF},
  groups     = {genetic algorithms},
  isbn       = {1558606114},
  keywords   = {read},
  location   = {Orlando, Florida},
  numpages   = {8},
  readstatus = {read},
  timestamp  = {2020-06-10},
}

@Article{tuy1964concave,
  author  = {Tuy, Hoang},
  journal = {Soviet Math.},
  title   = {Concave programming under linear constraints},
  year    = {1964},
  pages   = {1437--1440},
  volume  = {5},
  groups  = {global optimization},
}

@Article{Tuy1985concave,
  author    = {Tuy, Hoang},
  journal   = {Optimization},
  title     = {Concave minimization under linear constraints with special structure},
  year      = {1985},
  number    = {3},
  pages     = {335--352},
  volume    = {16},
  abstract  = {A class of concave minimization problems having a special structure is investigated. In each of these problems, the total number of variables may be fairly large, but only relatively few variables are actually responsible for the nonlinearity of the objective function. This suggest using decomposition techniques to reduce the problem to a sequence of smaller ones tractable by the currently available algorithms. Preliminary computational experiments with this method have given encouraging results.},
  doi       = {10.1080/02331938508843024},
  eprint    = {https://doi.org/10.1080/02331938508843024},
  groups    = {global optimization},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/02331938508843024},
}

@InCollection{tuy1995dc,
  author    = {Tuy, Hoang},
  booktitle = {Handbook of global optimization},
  publisher = {Springer},
  title     = {{DC} optimization: {Theory,} methods and algorithms},
  year      = {1995},
  pages     = {149--216},
  groups    = {global optimization},
}

@Book{tuy1998convex,
  author    = {Tuy, Hoang and Hoang, Tuy and Hoang, Tuy and Math\'{e}maticien, Vi\^{e}t-nam and Hoang, Tuy and Mathematician, Vietnam},
  publisher = {Springer},
  title     = {Convex analysis and global optimization},
  year      = {1998},
  groups    = {global optimization},
}

@Article{tuy2000monotonic,
  author    = {Tuy, Hoang},
  journal   = {SIAM Journal on Optimization},
  title     = {Monotonic optimization: {Problems} and solution approaches},
  year      = {2000},
  number    = {2},
  pages     = {464--494},
  volume    = {11},
  groups    = {global optimization},
  publisher = {SIAM},
}

@InBook{Tuy2001,
  author    = {Tuy, Hoang},
  editor    = {Floudas, Christodoulos A. and Pardalos, Panos M.},
  pages     = {366--371},
  publisher = {Springer US},
  title     = {Cutting plane methods for global optimization},
  year      = {2001},
  address   = {Boston, MA},
  isbn      = {978-0-306-48332-5},
  booktitle = {Encyclopedia of Optimization},
  doi       = {10.1007/0-306-48332-7_79},
  groups    = {global optimization},
  url       = {https://doi.org/10.1007/0-306-48332-7_79},
}

@Article{Tversky1967,
  author    = {Tversky, Amos},
  journal   = {Journal of Mathematical Psychology},
  title     = {Additivity, utility, and subjective probability},
  year      = {1967},
  number    = {2},
  pages     = {175--201},
  volume    = {4},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{Tversky1992,
  author    = {Tversky, Amos and Kahneman, Daniel},
  journal   = {Journal of Risk and Uncertainty},
  title     = {Advances in prospect theory: {Cumulative} representation of uncertainty},
  year      = {1992},
  issn      = {0895-5646},
  number    = {4},
  pages     = {297--323},
  volume    = {5},
  groups    = {prospect theory},
  timestamp = {2020-09-04},
}

@TECHREPORT{userbook1994genetic,
 AUTHOR = {Chipperfield, Andrew and Fleming, Peter and Pohlheim, Hartmut and Fonseca, Carlos},
 GROUPS = {genetic algorithms},
 INSTITUTION = {Department of Automatic Control and System Engineering, University of Sheffield},
 TITLE = {Genetic algorithm toolbox for use with matlab},
 YEAR = {1994}
}

@Article{Vaidyanathan1987fir,
  author   = {Vaidyanathan, P. and Nguyen, Truong},
  journal  = {IEEE Transactions on Circuits and Systems},
  title    = {Eigenfilters: {A} new approach to least-squares {FIR} filter design and applications including {Nyquist} filters},
  year     = {1987},
  issn     = {1558-1276},
  month    = {1},
  number   = {1},
  pages    = {11--23},
  volume   = {34},
  abstract = {A new method of designing linear-phase FIR filters is proposed by minimizing a quadratic measure of the error in the passband and stopband. The method is based on the computation of an eigenvector of an appropriate real, symmetric, and positive-definite matrix. The proposed design procedure is general enough to incorporate both time- and frequency-domain constraints. For example, Nyquist filters can be easily designed using this approach. The design time for the new method is comparable to that of Remez exchange techniques. The passband and stopband errors in the frequency domain can be made equiripple by an iterative process, which involves feeding back the approximation error at each iteration. Several numerical design examples and comparisons to existing methods are presented, which demonstrate the usefulness of the present approach.},
  doi      = {10.1109/TCS.1987.1086033},
  file     = {:FILES/1987 - Vaidyanathan1987fir - Eigenfilters- A new approach to least-squares FIR filter design and applications including Nyquist filters.pdf:PDF},
  groups   = {FIR filter design},
  keywords = {Band-limited signals;Digital filters;Eigenvalues/eigenvectors;FIR (finite-duration impulse-response) digital filters;Least-squares approximation;Linear-phase filters;Pulse generators;Finite impulse response filter;Passband;Symmetric matrices;Equations;Closed-form solution;Design methodology;Q measurement;Frequency domain analysis;Approximation error;Algorithm design and analysis},
}

@Article{vaish1976bilinear,
  author    = {Vaish, Harish and Shetty, CM},
  journal   = {Naval Research Logistics Quarterly},
  title     = {The bilinear programming problem},
  year      = {1976},
  number    = {2},
  pages     = {303--309},
  volume    = {23},
  groups    = {bilinear},
  publisher = {Wiley Online Library},
}

@Article{vaish1977cutting,
  author    = {Vaish, Harish and Shetty, CM},
  journal   = {Naval Research Logistics Quarterly},
  title     = {A cutting plane algorithm for the bilinear programming problem},
  year      = {1977},
  number    = {1},
  pages     = {83--94},
  volume    = {24},
  groups    = {bilinear, global optimization},
  publisher = {Wiley Online Library},
}

@Book{vajda2009mathematical,
  author    = {Vajda, Steven},
  publisher = {Dover Publication, {INC}},
  title     = {Mathematical programming},
  year      = {2009},
  address   = {Mineola, New York},
  groups    = {global optimization},
}

@InProceedings{van1975another,
  author    = {Van Dam, C.},
  booktitle = {Seminar on Recent Research in Finance and Monetary Economics, Cergy-Pontoise},
  title     = {Another look at inconsistency in financial decision-making},
  year      = {1975},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
}

@Book{van1981piecewise,
  author    = {Van Bokhoven, W.M.G.},
  publisher = {Kluwer},
  title     = {Piecewise-linear modelling and analysis},
  year      = {1981},
  groups    = {identification},
}

@Article{van1986piecewise,
  author  = {Van Bokhoven, W.M.G.},
  journal = {Circuit Analysis, Simulation and Design},
  title   = {Piecewise linear analysis and simulation},
  year    = {1986},
  volume  = {2},
  groups  = {application},
}

@InProceedings{van2008kernel,
  author       = {Van Gemert, Jan C and Geusebroek, Jan-Mark and Veenman, Cor J and Smeulders, Arnold WM},
  booktitle    = {European conference on computer vision},
  title        = {Kernel codebooks for scene categorization},
  year         = {2008},
  organization = {Springer},
  pages        = {696--709},
  groups       = {SVM},
  timestamp    = {2020-08-30},
}

@InProceedings{van2016deep,
  author    = {Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle = {Thirtieth AAAI conference on artificial intelligence},
  title     = {Deep reinforcement learning with double {Q-learning}},
  year      = {2016},
  groups    = {RL},
}

@InProceedings{van2016learning,
  author    = {Hasselt, Hado P and Guez, Arthur and Hessel, Matteo and Mnih, Volodymyr and Silver, David},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Learning values across many orders of magnitude},
  year      = {2016},
  pages     = {4287--4295},
  abstract  = {Most learning algorithms are not invariant to the scale of the function that is being approximated. We propose to adaptively normalize the targets used in learning. This is useful in value-based reinforcement learning, where the magnitude of appropriate value approximations can change over time when we update the policy of behavior. Our main motivation is prior work on learning to play Atari games, where the rewards were all clipped to a predetermined range. This clipping facilitates learning across many different games with a single learning algorithm, but a clipped reward function can result in qualitatively different behavior. Using the adaptive normalization we can remove this domain-specific heuristic without diminishing overall performance.},
  groups    = {Neural Network},
}

@Article{vandewalle1975pwl,
  author   = {Vandewalle, Joos},
  journal  = {IEEE Transactions on Computers},
  title    = {On the calculation of the piecewise linear approximation to a discrete function},
  year     = {1975},
  issn     = {2326-3814},
  month    = {8},
  number   = {8},
  pages    = {843--846},
  volume   = {C-24},
  doi      = {10.1109/T-C.1975.224320},
  file     = {:FILES/1975 - vandewalle1975pwl - On the Calculation of the Piecewise Linear Approximation to a Discrete Function.pdf:PDF},
  groups   = {identification},
  keywords = {Discrete data, feature generation, minimax approximation, piecewise linear function, waveform seghnentation.;Discrete data, feature generation, minimax approximation, piecewise linear function, waveform seghnentation.},
}

@Article{veelaert1993flatness,
  author    = {Veelaert, Peter},
  journal   = {Journal of Mathematical Imaging and Vision},
  title     = {On the flatness of digital hyperplanes},
  year      = {1993},
  number    = {2},
  pages     = {205--221},
  volume    = {3},
  abstract  = {This paper investigates the properties of digital hyperplanes of arbitrary dimension. We extend previous results that have been obtained for digital straight lines and digital planes, namely, Hung's evenness, Rosenfeld's chord, and Kim's chordal triangle property. To characterize digital hyperplanes we introduce the notion of digital flatness. We make a distinction between flatness and local flatness. The main tool we use is Helly's First Theorem, a classical result on convex sets, by means of which precise and verifiable conditions are given for the flatness of digital point sets. The main result is the proof of the equivalence of local flatness, evenness, and the chord property for certain infinite digital point sets in spaces of arbitrary dimension.},
  groups    = {interesting articles},
  publisher = {Springer},
}

@Article{viana2013new,
  author    = {Viana, Ana and Pedroso, Jo\~{a}o Pedro},
  journal   = {International Journal of Electrical Power \& Energy Systems},
  title     = {A new {MILP-based} approach for unit commitment in power production planning},
  year      = {2013},
  number    = {1},
  pages     = {997--1005},
  volume    = {44},
  groups    = {MILP},
  publisher = {Elsevier},
}

@Article{vielma2008nonconvex,
  author    = {Vielma, Juan Pablo and Keha, Ahmet B. and Nemhauser, George L.},
  journal   = {Discrete Optimization},
  title     = {Nonconvex, lower semicontinuous piecewise linear optimization},
  year      = {2008},
  number    = {2},
  pages     = {467--488},
  volume    = {5},
  file      = {:FILES/2008 - vielma2008nonconvex - Nonconvex, lower semicontinuous piecewise linear optimization.pdf:PDF},
  groups    = {optimization},
  publisher = {Elsevier},
}

@Article{Vielma2010mixed,
  author    = {Vielma, J. P. and Ahmed, S. and Nemhauser, G.},
  journal   = {Operations Research},
  title     = {Mixed-integer models for nonseparable piecewise-linear optimization: {Unifying} framework and extensions},
  year      = {2010},
  number    = {2},
  pages     = {303--315},
  volume    = {58},
  file      = {:FILES/2010 - Vielma2010mixed - Mixed-integer models for nonseparable piecewise-linear optimization- Unifying framework and extensions.pdf:PDF},
  groups    = {optimization, MILP},
  publisher = {INFORMS},
}

@Article{vielma2010note,
  author    = {Vielma, Juan Pablo and Ahmed, Shabbir and Nemhauser, George},
  journal   = {INFORMS Journal on Computing},
  title     = {A note on “a superior representation method for piecewise linear functions”},
  year      = {2010},
  number    = {3},
  pages     = {493--497},
  volume    = {22},
  file      = {:FILES/2010 - vielma2010note - A note on “A superior representation method for piecewise linear functions”.pdf:PDF},
  groups    = {identification},
  publisher = {INFORMS},
}

@Article{vielma2011modeling,
  author    = {Vielma, Juan Pablo and Nemhauser, George L.},
  journal   = {Mathematical Programming},
  title     = {Modeling disjunctive constraints with a logarithmic number of binary variables and constraints},
  year      = {2011},
  number    = {1-2},
  pages     = {49--72},
  volume    = {128},
  abstract  = {Many combinatorial constraints over continuous variables such as SOS1 and SOS2 constraints can be interpreted as disjunctive constraints that restrict the variables to lie in the union of a finite number of specially structured polyhedra. Known mixed integer binary formulations for these constraints have a number of binary variables and extra constraints linear in the number of polyhedra. We give sufficient conditions for constructing formulations for these constraints with a number of binary variables and extra constraints logarithmic in the number of polyhedra. Using these conditions we introduce mixed integer binary formulations for SOS1 and SOS2 constraints that have a number of binary variables and extra constraints logarithmic in the number of continuous variables. We also introduce the first mixed integer binary formulations for piecewise linear functions of one and two variables that use a number of binary variables and extra constraints logarithmic in the number of linear pieces of the functions. We prove that the new formulations for piecewise linear functions have favorable tightness properties and present computational results showing that they can significantly outperform other mixed integer binary formulations.},
  file      = {:FILES/2011 - vielma2011modeling - Modeling disjunctive constraints with a logarithmic number of binary variables and constraints.pdf:PDF},
  groups    = {optimization, MILP},
  publisher = {Springer},
}

@Article{VIEN20111671,
  author   = {Vien, Ngo Anh and Yu, Hwanjo and Chung, TaeChoong},
  journal  = {Information Sciences},
  title    = {Hessian matrix distribution for bayesian policy gradient reinforcement learning},
  year     = {2011},
  issn     = {0020-0255},
  number   = {9},
  pages    = {1671 -- 1685},
  volume   = {181},
  abstract = {Bayesian policy gradient algorithms have been recently proposed for modeling the policy gradient of the performance measure in reinforcement learning as a Gaussian process. These methods were known to reduce the variance and the number of samples needed to obtain accurate gradient estimates in comparison to the conventional Monte-Carlo policy gradient algorithms. In this paper, we propose an improvement over previous Bayesian frameworks for the policy gradient. We use the Hessian matrix distribution as a learning rate schedule to improve the performance of the Bayesian policy gradient algorithm in terms of the variance and the number of samples. As in computing the policy gradient distributions, the Bayesian quadrature method is used to estimate the Hessian matrix distributions. We prove that the posterior mean of the Hessian distribution estimate is symmetric, one of the important properties of the Hessian matrix. Moreover, we prove that with an appropriate choice of kernel, the computational complexity of Hessian distribution estimate is equal to that of the policy gradient distribution estimates. Using simulations, we show encouraging experimental results comparing the proposed algorithm to the Bayesian policy gradient and the Bayesian policy natural gradient algorithms described in Ghavamzadeh and Engel [10].},
  doi      = {http://eproxy2.lib.tsinghua.edu.cn:80/rwt/33/https/MSYXTLUQPJUB/10.1016/j.ins.2011.01.001},
  groups   = {RL},
  keywords = {Markov decision process, Reinforcement learning, Bayesian policy gradient, Monte-Carlo policy gradient, Policy gradient, Hessian matrix distribution},
  url      = {http://eproxy2.lib.tsinghua.edu.cn:80/rwt/33/http/P75YPLUUMNVXK5UDMWTGT6UFMN4C6Z5QNF/science/article/pii/S0020025511000028},
}

@Article{visweswaran1993new,
  author    = {Visweswaran, V and Floudas, Christodoulos A},
  journal   = {Journal of Global Optimization},
  title     = {New properties and computational improvement of the {GOP} algorithm for problems with quadratic objective functions and constraints},
  year      = {1993},
  number    = {4},
  pages     = {439--462},
  volume    = {3},
  abstract  = {In Floudas and Visweswaran (1990, 1993), a deterministic global optimization approach was proposed for solving certain classes of nonconvex optimization problems. An algorithm, GOP, was presented for the solution of the problem through a series ofprimal andrelaxed dual problems that provide valid upper and lower bounds respectively on the global solution. The algorithm was proved to have finite convergence to an ∈-global optimum. In this paper, new theoretical properties are presented that help to enhance the computational performance of the GOP algorithm applied to problems of special structure. The effect of the new properties is illustrated through application of the GOP algorithm to a difficult indefinite quadratic problem, a multiperiod tankage quality problem that occurs frequently in the modeling of refinery processes, and a set of pooling/blending problems from the literature. In addition, extensive computational experience is reported for randomly generated concave and indefinite quadratic programming problems of different sizes. The results show that the properties help to make the algorithm computationally efficient for fairly large problems.},
  groups    = {global optimization},
  publisher = {Springer},
}

@InProceedings{Voigt1995,
  author    = {Voigt, Hans-Michael and M\"{u}hlenbein, Heinz and Cvetkovic, Dragan},
  booktitle = {Proceedings of the 6th International Conference on Genetic Algorithms},
  title     = {Fuzzy recombination for the breeder genetic algorithm},
  year      = {1995},
  address   = {San Francisco, CA, USA},
  pages     = {104--113},
  publisher = {Morgan Kaufmann Publishers Inc.},
  file      = {:FILES/1995 - Voigt1995 - Fuzzy recombination for the Breeder Genetic Algorithm.pdf:PDF},
  groups    = {genetic algorithms},
  isbn      = {1558603700},
  numpages  = {10},
}

@Article{wagner1959linear,
  author    = {Wagner, Harvey M.},
  journal   = {Journal of the American Statistical Association},
  title     = {Linear programming techniques for regression analysis},
  year      = {1959},
  number    = {285},
  pages     = {206--212},
  volume    = {54},
  file      = {:FILES/1959 - wagner1959linear - Linear Programming Techniques for Regression Analysis.pdf:PDF},
  groups    = {SVM},
  publisher = {Taylor \& Francis},
  timestamp = {2020-08-30},
}

@Article{Waller1993cpt,
  author    = {Wakker, Peter and Tversky, Amos},
  journal   = {Journal of Risk and Uncertainty},
  title     = {An axiomatization of cumulative prospect theory},
  year      = {1993},
  number    = {2},
  pages     = {147--175},
  volume    = {7},
  groups    = {prospect theory},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{waltz1965,
  author   = {Waltz, M. and Fu, K.},
  journal  = {IEEE Transactions on Automatic Control},
  title    = {A heuristic approach to reinforcement learning control systems},
  year     = {1965},
  issn     = {2334-3303},
  month    = {10},
  number   = {4},
  pages    = {390--398},
  volume   = {10},
  abstract = {This paper describes a learning control system using a reinforcement technique. The controller is capable of controlling a plant that may be nonlinear and nonstationary. The only a priori information required by the controller is the order of the plant. The approach is to design a controller which partitions the control measurement space into sets called control situations and then learns the best control choice for each control situation. The control measurements are those indicating the state of the plant and environment. The learning is accomplished by reinforcement of the probability of choosing a particular control choice for a given control situation. The system was stimulated on an IBM 1710-GEDA hybrid computer facility. Experimental results obtained from the simulation are presented.},
  doi      = {10.1109/TAC.1965.1098193},
  groups   = {RL},
  keywords = {Learning control systems;Learning;Control systems;Automatic control;State-space methods;Extraterrestrial measurements;Computational modeling;Application software;Programmable control;Adaptive control;Differential equations},
}

@Article{wang2002new,
  author    = {Wang, Yanjun and Zhang, Kecun and Shen, Peiping},
  journal   = {Mathematical and computer modelling},
  title     = {A new type of condensation curvilinear path algorithm for unconstrained generalized geometric programming},
  year      = {2002},
  number    = {11-12},
  pages     = {1209--1219},
  volume    = {35},
  file      = {:FILES/2002 - wang2002new -A new type of condensation curvilinear path algorithm for unconstrained generalized geometric programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@Article{wang2004global,
  author    = {Wang, Yanjun and Zhang, Kecun and Gao, Yuelin},
  journal   = {Computers \& Mathematics with Applications},
  title     = {Global optimization of generalized geometric programming},
  year      = {2004},
  number    = {10-11},
  pages     = {1505--1516},
  volume    = {48},
  file      = {:FILES/2004 - wang2004global - Global optimization of generalized geometric programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@Article{wang2005deterministic,
  author    = {Wang, Yanjun and Liang, Zhian},
  journal   = {Applied Mathematics and Computation},
  title     = {A deterministic global optimization algorithm for generalized geometric programming},
  year      = {2005},
  number    = {1},
  pages     = {722--737},
  volume    = {168},
  file      = {:FILES/2005 - wang2005deterministic - A deterministic global optimization algorithm for generalized geometric programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@Article{wang2005ghh,
  author   = {Wang, Shuning and Sun, Xusheng},
  journal  = {IEEE Transactions on Information Theory},
  title    = {Generalization of hinging hyperplanes},
  year     = {2005},
  issn     = {1557-9654},
  month    = {12},
  number   = {12},
  pages    = {4425--4431},
  volume   = {51},
  abstract = {The model of hinging hyperplanes (HH) can approximate a large class of nonlinear functions to arbitrary precision, but represent only a small part of continuous piecewise-linear (CPWL) functions in two or more dimensions. In this correspondence, the influence of this drawback for black-box modeling is first illustrated by a simple example. Then it is shown that the above shortcoming can be amended by adding a sufficient number of linear functions to current hinges. It is proven that any CPWL function of n variables can be represented by a sum of hinges containing at most n+1 linear functions. Hence the model of a sum of such expanded hinges is a general representation for all CPWL functions. The structure of the novel general representation is much simpler than the existing generalized canonical representation that consists of nested absolute-value functions. This characteristic is very useful for black-box modeling. Based on the new general representation, an upper bound on the number of nestings of nested absolute-value functions of a generalized canonical representation is established, which is much smaller than the known result.},
  doi      = {10.1109/TIT.2005.859246},
  file     = {:FILES/2005 - wang2005ghh - Generalization of hinging hyperplanes.pdf:PDF},
  groups   = {identification, Wang's Work},
  keywords = {nonlinear functions;computational geometry;identification;piecewise linear techniques;approximation theory;hinging hyperplane;HH model approximation;nonlinear function;arbitrary precision;continuous piece wise-linear function;CPWL;black-box modeling;generalized canonical representation;nested absolute-value function;Rate-distortion;Channel capacity;Information theory;Fasteners;Rate distortion theory;Function approximation;Piecewise linear techniques;Source coding;Decoding;Digital modulation;Black-box modeling;canonical representation;continuous piecewise-linear function (CPWL);function approximation;hinging hyperplanes (HHs)},
}

@Article{Wang2007,
  author    = {Wang, Yong and Liu, Hui and Cai, Zixing and Zhou, Yuren},
  journal   = {Engineering Optimization},
  title     = {An orthogonal design based constrained evolutionary optimization algorithm},
  year      = {2007},
  number    = {6},
  pages     = {715--736},
  volume    = {39},
  abstract  = {Solving constrained optimization problems (COPs) via evolutionary algorithms (EAs) has attracted much attention. In this article, an orthogonal design based constrained optimization evolutionary algorithm (ODCOEA) to tackle COPs is proposed. In principle, ODCOEA belongs to a class of steady state evolutionary algorithms. In the evolutionary process, several individuals are chosen from the population as parents and orthogonal design is applied to pairs of parents to produce a set of representative offspring. Then, after combining the offspring generated by different pairs of parents, non-dominated individuals are chosen. Subsequently, from the parent’s perspective, it is decided whether a non-dominated individual replaces a selected parent. Finally, ODCOEA incorporates an improved BGA mutation operator to facilitate the diversity of the population. The proposed ODCOEA is effectively applied to 12 benchmark test functions. The computational experiments show that ODCOEA not only quickly converges to optimal or near-optimal solutions, but also displays a very high performance compared with another two state-of-the-art techniques.},
  doi       = {10.1080/03052150701280541},
  eprint    = {https://doi.org/10.1080/03052150701280541},
  file      = {:FILES/2006 - Wang2007 - An orthogonal design based constrained evolutionary optimization algorithm.pdf:PDF},
  groups    = {Evolutionary Algorithms},
  publisher = {Taylor \& Francis},
  timestamp = {2020-06-14},
  url       = {https://doi.org/10.1080/03052150701280541},
}

@Article{WANG2007RL,
  author   = {Wang, Xue-Song and Cheng, Yu-Hu and Yi, Jian-Qiang},
  journal  = {Information Sciences},
  title    = {A fuzzy actor-critic reinforcement learning network},
  year     = {2007},
  issn     = {0020-0255},
  number   = {18},
  pages    = {3764 -- 3781},
  volume   = {177},
  abstract = {One of the difficulties encountered in the application of reinforcement learning methods to real-world problems is their limited ability to cope with large-scale or continuous spaces. In order to solve the curse of the dimensionality problem, resulting from making continuous state or action spaces discrete, a new fuzzy Actor-Critic reinforcement learning network (FACRLN) based on a fuzzy radial basis function (FRBF) neural network is proposed. The architecture of FACRLN is realized by a four-layer FRBF neural network that is used to approximate both the action value function of the Actor and the state value function of the Critic simultaneously. The Actor and the Critic networks share the input, rule and normalized layers of the FRBF network, which can reduce the demands for storage space from the learning system and avoid repeated computations for the outputs of the rule units. Moreover, the FRBF network is able to adjust its structure and parameters in an adaptive way with a novel self-organizing approach according to the complexity of the task and the progress in learning, which ensures an economic size of the network. Experimental studies concerning a cart-pole balancing control illustrate the performance and applicability of the proposed FACRLN.},
  doi      = {https://doi.org/10.1016/j.ins.2007.03.012},
  groups   = {RL},
  keywords = {Reinforcement learning, Actor-Critic learning, Fuzzy inference system, Radial basis function neural network},
  url      = {http://www.sciencedirect.com/science/article/pii/S0020025507001569},
}

@Article{Wang2008,
  author  = {Wang, Shuning and Huang, Xiaolin and Junaid, K. M.},
  journal = {IEEE Transactions on Neural Networks},
  title   = {Configuration of continuous piecewise-linear neural networks},
  year    = {2008},
  number  = {8},
  pages   = {1431--1445},
  volume  = {19},
  file    = {:FILES/2008 - Wang2008 - Configuration of Continuous Piecewise-Linear Neural Networks.pdf:PDF},
  groups  = {Neural Network, application, Wang's Work},
}

@Article{wang2008training,
  author    = {Wang, Lei and Jia, Huading and Li, Jie},
  journal   = {Neurocomputing},
  title     = {Training robust support vector machine with smooth ramp loss in the primal space},
  year      = {2008},
  number    = {13},
  pages     = {3020--3025},
  volume    = {71},
  groups    = {SVM},
  publisher = {Elsevier},
  timestamp = {2020-08-30},
}

@MISC{wang2011nfsc,
 ADDRESS = {National Natural Science Foundation of China (NSFC). China. Participatant},
 GROUPS = {projects},
 KEYWORDS = {project},
 TIMESTAMP = {2020-06-20},
 TITLE = {Further study on piecewise linear problems},
 YEAR = {{2011/01$\sim$2013/12}},
 note = {deprecated}
}

@MISC{wang2011nfsc_cn,
 ADDRESS = {国家自然科学基金（面上项目），参与},
 GROUPS = {projects},
 KEYWORDS = {project},
 NOTE = {35w},
 TIMESTAMP = {2020-06-20},
 TITLE = {若干分片线性问题的深入研究},
 YEAR = {{2011/01$\sim$2013/12}},
 note = {deprecated}
}

@MISC{wang2015nfsc,
 ADDRESS = {National Natural Science Foundation of China (NSFC)61473465. China. Participatant},
 GROUPS = {projects},
 KEYWORDS = {project},
 TIMESTAMP = {2020-06-20},
 TITLE = {Global piecewise linear optimization methods and applications},
 YEAR = {{2015/01$\sim$2018/12}},
 note = {830k RMB}
}

@MISC{wang2015nfsc_cn,
 ADDRESS = {国家自然科学基金（面上项目）61473465，参与},
 GROUPS = {projects},
 KEYWORDS = {project},
 NOTE = {83w},
 TIMESTAMP = {2020-06-20},
 TITLE = {全局分片线性优化方法与应用},
 YEAR = {{2015/01$\sim$2018/12}},
 note = {83万元}
}

@InProceedings{wang2016dueling,
  author    = {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  booktitle = {International Conference on Machine Learning},
  title     = {Dueling network architectures for deep reinforcement learning},
  year      = {2016},
  pages     = {1995--2003},
  groups    = {RL},
}

@Article{wang2019benchmarking,
  author  = {Wang, Tingwu and Bao, Xuchan and Clavera, Ignasi and Hoang, Jerrick and Wen, Yeming and Langlois, Eric and Zhang, Shunshi and Zhang, Guodong and Abbeel, Pieter and Ba, Jimmy},
  journal = {arXiv preprint arXiv:1907.02057},
  title   = {Benchmarking model-based reinforcement learning},
  year    = {2019},
  groups  = {RL},
}

@Article{Wang2020,
  author     = {Wang, Yong and Li, J. and Xue, X. and Wang, B.},
  journal    = {IEEE Transactions on Evolutionary Computation},
  title      = {Utilizing the correlation between constraints and objective function for constrained evolutionary optimization},
  year       = {2020},
  issn       = {1941-0026},
  month      = {2},
  number     = {1},
  pages      = {29--43},
  volume     = {24},
  abstract   = {When solving constrained optimization problems by evolutionary algorithms, the core issue is to balance constraints and objective function. This paper is the first attempt to utilize the correlation between constraints and objective function to keep this balance. First of all, the correlation between constraints and objective function is mined and represented by a correlation index. Afterward, a weighted sum updating approach and an archiving and replacement mechanism are proposed to make use of this correlation index to guide the evolution. By the above process, a novel constrained optimization evolutionary algorithm is presented. Experiments on a broad range of benchmark test functions indicate that the proposed method shows better or at least competitive performance against other state-of-the-art methods. Moreover, the proposed method is applied to the gait optimization of humanoid robots.},
  doi        = {10.1109/TEVC.2019.2904900},
  file       = {:FILES/2020 - Wang2020 - Utilizing the Correlation Between Constraints and Objective Function for Constrained Evolutionary Optimization .pdf:PDF;:FILES/2020 - Wang2020 - Utilizing the Correlation Between Constraints and Objective Function for Constrained Evolutionary Optimization (sup).pdf:PDF},
  groups     = {genetic algorithms},
  keywords   = {evolutionary computation;optimisation;objective function;correlation index;novel constrained optimization evolutionary algorithm;benchmark test functions;constrained optimization problems;evolutionary algorithms;balance constraints;gait optimization;humanoid robots;Linear programming;Optimization;Correlation;Sociology;Humanoid robots;Indexes;Constrained optimization;constraints;correlation;evolutionary algorithms (EAs);humanoid robots;objective function, read},
  readstatus = {read},
  timestamp  = {2020-06-08},
}

@Article{wang2020fir,
  author  = {Wang, H. and Jin, Y. and Cheng, X. and Zeng, R.},
  journal = {IEEE Access},
  title   = {A theoretical question in the optimal design of matrix decomposition based {FIR} filter},
  year    = {2020},
  pages   = {6616--6626},
  volume  = {8},
  file    = {:FILES/2020 - wang2020fir - A Theoretical Question in the Optimal Design of Matrix Decomposition Based FIR Filter.pdf:PDF},
  groups  = {matrix decomposition},
}

@Article{wang2020fir_matrix,
  author  = {Wang, H. and Zhao, Z. and Zhao, L.},
  journal = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title   = {Matrix decomposition based low-complexity {FIR} filter: {Further} results},
  year    = {2020},
  number  = {2},
  pages   = {672--685},
  volume  = {67},
  file    = {:FILES/2020 - wang2020fir_matrix - Matrix Decomposition Based Low-Complexity FIR Filter- Further Results.pdf:PDF},
  groups  = {matrix decomposition},
}

@Article{wangwanbin2001,
  author  = {王万宾 and 王书宁 and 李星野},
  journal = {计算机工程与应用},
  title   = {分片线性函数逼近与{DCT}相结合的图像压缩方法},
  year    = {2001},
  pages   = {57--59},
  volume  = {11},
  file    = {:FILES/2001 - wangwanbin2001 - 分片线性函数逼近与DCT相结合的图像压缩方法_王万宾.pdf:PDF},
  groups  = {application, Wang's Work},
  lang    = {zh},
}

@Article{wangY2004transformation,
  author    = {wang and zhang},
  journal   = {Numerical Mathematics A Journal of Chinese Universities (English Series)},
  title     = {A transformation path algorithm for unconstrained signomial geometric programming},
  year      = {2004},
  number    = {1},
  pages     = {4},
  file      = {:FILES/2004 - wangY2004transformation - A transformation path algorithm for unconstrained signomial geometric programming.pdf:PDF},
  groups    = {SGP},
  timestamp = {2020-07-16},
}

@Article{Watkins1992,
  author        = {Watkins, Christopher J. C. H. and Dayan, Peter},
  journal       = {Machine Learning},
  title         = {Q-learning},
  year          = {1992},
  number        = {3},
  pages         = {279--292},
  volume        = {8},
  abstract      = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states.},
  bdsk-url-1    = {https://doi.org/10.1007/BF00992698},
  da            = {1992/05/01},
  date-added    = {2020-02-21 08:29:21 +0000},
  date-modified = {2020-02-21 08:29:21 +0000},
  doi           = {10.1007/BF00992698},
  groups        = {RL},
  isbn          = {1573-0565},
  ty            = {JOUR},
  url           = {https://doi.org/10.1007/BF00992698},
}

@InProceedings{Webb1993fir,
  author    = {Webb, J. H. and Munson, D. C.},
  booktitle = {1993 IEEE International Symposium on Circuits and Systems (ISCAS)},
  title     = {Design of sparse {FIR} filters using linear programming},
  year      = {1993},
  month     = {5},
  pages     = {339--342 vol.1},
  abstract  = {More efficient use of multipliers in finite impulse response (FIR) filters can be achieved at the expense of a slight increase in delay by designing sparse FIR filters. Two new methods of designing sparse linear phase FIR filters are reported. One results in sparse direct-form filters for a particular class of filters, and is based on Fourier analysis. The second method is heuristic in nature, and gives a relatively simple approach to designing sparse cascaded filters. Both methods use linear programming for the design.<>},
  doi       = {10.1109/ISCAS.1993.393727},
  file      = {:FILES/1993 - Webb1993fir - Design of sparse FIR filters using linear programming.pdf:PDF},
  groups    = {sparse},
  keywords  = {FIR filters;digital filters;filtering theory;linear programming;delay circuits;cascade networks;sparse FIR filters;linear programming;multipliers;finite impulse response;linear phase;sparse direct-form filters;Fourier analysis;sparse cascaded filters;Finite impulse response filter;Nonlinear filters;Linear programming;Frequency response;Filtering theory;Chebyshev approximation;Band pass filters;Delay;Design methodology;Inspection},
}

@Article{Webb1996,
  author     = {Webb, J. L. H. and Munson, D. C.},
  journal    = {IEEE Transactions on Signal Processing},
  title      = {Chebyshev optimization of sparse {FIR} filters using linear programming with an application to beamforming},
  year       = {1996},
  issn       = {1941-0476},
  month      = {8},
  number     = {8},
  pages      = {1912--1922},
  volume     = {44},
  abstract   = {Sparse FIR filter design, where some tap weights are zero, is of interest as a means of reducing the expense or enhancing the performance of a filter, as a result of fewer or more efficiently placed multipliers. We show that for certain classes of filters with moderately wide passbands, it is possible to increase the stopband suppression by up to 20 dB without increasing the number of multipliers, simply by increasing the number of delay elements, zeroing the appropriate taps, and optimizing the other taps using linear programming. Another use for sparse FIR filters is for the case where multipliers have failed. Graceful degradation can be achieved in some types of FIR filters by optimally adjusting the functional elements to compensate for the failed multipliers. This approach can also be used to minimize the peak sidelobe level for beamformers that may have failed elements. For the beamforming cases considered, the peak sidelobe level was decreased by as much as 5 dB.},
  doi        = {10.1109/78.533712},
  file       = {:FILES/1996 - Webb1996 - Chebyshev optimization of sparse FIR filters using linear programming with an application to beamforming.pdf:PDF},
  groups     = {sparse},
  keywords   = {Chebyshev filters;FIR filters;digital filters;circuit optimisation;linear programming;filtering theory;array signal processing;delay circuits;sparse FIR filters;Chebyshev optimization;linear programming;beamforming;multipliers;wide passbands;stopband suppression;delay elements;taps;graceful degradation;functional elements;failed multipliers;peak sidelobe level minimisation;beamformers;linear phase filters;Finite impulse response filter;Chebyshev approximation;Nonlinear filters;Linear programming;Frequency;Passband;Information filtering;Information filters;Band pass filters;Filtering theory, read},
  readstatus = {read},
}

@InProceedings{wei2009fir,
  author     = {Wei, D.},
  booktitle  = {2009 IEEE/SP 15th Workshop on Statistical Signal Processing},
  title      = {Non-convex optimization for the design of sparse {FIR} filters},
  year       = {2009},
  month      = {8},
  pages      = {117--120},
  abstract   = {This paper presents a method for designing sparse FIR filters by means of a sequence of p-norm minimization problems with p gradually decreasing from 1 toward 0. The lack of convexity for p < 1 is partially overcome by appropriately initializing each subproblem. A necessary condition of optimality is derived for the subproblem of p-norm minimization, forming the basis for an efficient local search algorithm. Examples demonstrate that the method is capable of producing filters approaching the optimal level of sparsity for a given set of specifications.},
  doi        = {10.1109/SSP.2009.5278626},
  file       = {:FILES/2009 - wei2009fir- Non-convex optimization for the design of sparse fir filters.pdf:PDF},
  groups     = {sparse},
  issn       = {2373-0803},
  keywords   = {concave programming;FIR filters;minimisation;search problems;nonconvex optimization;sparse FIR filter;p-norm minimization;local search algorithm;Design optimization;Finite impulse response filter;Minimization methods;Sensor arrays;Design methodology;Digital filters;Algorithm design and analysis;Equations;Frequency response;Delay;Sparse filters;non-convex optimization;FIR digital filters, read},
  readstatus = {read},
}

@Article{wei2013fir,
  author    = {Wei, D. and Sestok, C. K. and Oppenheim, A. V.},
  journal   = {IEEE Transactions on Signal Processing},
  title     = {Sparse filter design under a quadratic constraint: {Low-complexity} algorithms},
  year      = {2013},
  issn      = {1941-0476},
  month     = {2},
  number    = {4},
  pages     = {857--870},
  volume    = {61},
  abstract  = {This paper considers three problems in sparse filter design, the first involving a weighted least-squares constraint on the frequency response, the second a constraint on mean squared error in estimation, and the third a constraint on signal-to-noise ratio in detection. The three problems are unified under a single framework based on sparsity maximization under a quadratic performance constraint. Efficient and exact solutions are developed for specific cases in which the matrix in the quadratic constraint is diagonal, block-diagonal, banded, or has low condition number. For the more difficult general case, a low-complexity algorithm based on backward greedy selection is described with emphasis on its efficient implementation. Examples in wireless channel equalization and minimum-variance distortionless-response beamforming show that the backward selection algorithm yields optimally sparse designs in many instances while also highlighting the benefits of sparse design.},
  doi       = {10.1109/TSP.2012.2229996},
  file      = {:FILES/2013 - wei2013fir - Sparse Filter Design Under a Quadratic Constraint- Low-Complexity Algorithms.pdf:PDF},
  groups    = {sparse},
  keywords  = {array signal processing;filtering theory;least mean squares methods;optimisation;sparse filter design;quadratic constraint;low-complexity algorithm;weighted least-squares constraint;frequency response;mean squared error;signal-to-noise ratio;sparsity maximization;quadratic performance constraint;backward greedy selection;wireless channel equalization;minimum-variance distortionless-response beamforming;Algorithm design and analysis;Equalizers;Signal to noise ratio;Frequency response;Estimation;Chebyshev approximation;Measurement;FIR digital filters;MVDR beamforming;sparse equalizers;sparse filters, prio1},
  priority  = {prio1},
  timestamp = {2020-08-07},
}

@Article{Wei2013firBB,
  author   = {Wei, D. and Oppenheim, A. V.},
  journal  = {IEEE Transactions on Signal Processing},
  title    = {A branch-and-bound algorithm for quadratically-constrained sparse filter design},
  year     = {2013},
  issn     = {1941-0476},
  month    = {2},
  number   = {4},
  pages    = {1006--1018},
  volume   = {61},
  abstract = {This paper presents an exact algorithm for sparse filter design under a quadratic constraint on filter performance. The algorithm is based on branch-and-bound, a combinatorial optimization procedure that can either guarantee an optimal solution or produce a sparse solution with a bound on its deviation from optimality. To reduce the complexity of branch-and-bound, several methods are developed for bounding the optimal filter cost. Bounds based on infeasibility yield incrementally accumulating improvements with minimal computation, while two convex relaxations, referred to as linear and diagonal relaxations, are derived to provide stronger bounds. The approximation properties of the two relaxations are characterized analytically as well as numerically. Design examples involving wireless channel equalization and minimum-variance distortionless-response beamforming show that the complexity of obtaining certifiably optimal solutions can often be significantly reduced by incorporating diagonal relaxations, especially in more difficult instances. In the case of early termination due to computational constraints, diagonal relaxations strengthen the bound on the proximity of the final solution to the optimum.},
  doi      = {10.1109/TSP.2012.2226450},
  file     = {:FILES/2013 - Wei2013firBB - A Branch-and-Bound Algorithm for Quadratically-Constrained Sparse Filter Design.pdf:PDF},
  groups   = {MILP, sparse},
  keywords = {array signal processing;computational complexity;optimisation;tree searching;wireless channels;branch-and-bound algorithm;quadratically-constrained sparse filter design;combinatorial optimization;linear relaxation;diagonal relaxation;wireless channel equalization;minimum-variance distortionless-response beamforming;Algorithm design and analysis;Optimization;Complexity theory;Approximation methods;Approximation algorithms;Context;Array signal processing;Branch-and-bound;convex relaxation;FIR digital filters;MVDR beamforming;sparse equalizers;sparse filters},
}

@Article{Wen2005A,
  author  = {Wen, Chengtao and Wang, Shuning and Li, Feng and Khan, M. J.},
  journal = {IEEE Transactions on Circuits \& Systems I},
  title   = {A compact f-f model of high-dimensional piecewise-linear function over a degenerate intersection},
  year    = {2005},
  number  = {4},
  pages   = {815--821},
  volume  = {52},
  file    = {:FILES/2005 - Wen2005A - A compact f-f model of high-dimensional piecewise-linear function over a degenerate intersection.pdf:PDF},
  groups  = {identification, Wang's Work},
}

@Article{Wen2014,
  author   = {Wen, Bo and Li, Hongguang},
  journal  = {Chinese Journal of Chemical Engineering},
  title    = {An approach to formulation of {FNLP} with complex piecewise linear membership functions},
  year     = {2014},
  issn     = {1004-9541},
  number   = {4},
  pages    = {411 -- 417},
  volume   = {22},
  abstract = {Traditionally, extra binary variables are demanded to formulate a fuzzy nonlinear programming (FNLP) problem with piecewise linear membership functions (PLMFs). However, this kind of methodology usually suffers increasing computational burden associated with formulation and solution, particularly in the face of complex PLMFs. Motivated by these challenges, this contribution introduces a novel approach free of additional binary variables to formulate FNLP with complex PLMFs, leading to superior performance in reducing computational complexity as well as simplifying formulation. A depth discussion about the approach is conducted in this paper, along with a numerical case study to demonstrate its potential benefits.},
  doi      = {http://eproxy2.lib.tsinghua.edu.cn:80/rwt/33/https/MSYXTLUQPJUB/10.1016/S1004-9541(14)60039-2},
  file     = {:FILES/2014 - Wen2014 - An Approach to Formulation of FNLP with Complex Piecewise Linear Membership Functions.pdf:PDF},
  groups   = {application},
  keywords = {fuzzy nonlinear programming, piecewise linear membership functions, modeling},
}

@Article{Wen2019,
  author    = {Wen, Bo and Gu, Wen and Yang, Bo and Li, Hongguang and Chen, Xiaochun},
  journal   = {Chemometrics and Intelligent Laboratory Systems},
  title     = {A novel approach for {FNLP} with piecewise linear membership functions},
  year      = {2019},
  issn      = {0169-7439},
  pages     = {88 -- 95},
  volume    = {191},
  abstract  = {In the fuzzy nonlinear programming (FNLP) domain, piecewise linear membership functions (PLMFs) are often employed to linearize the nonlinear membership functions. However, the linearization error will reduce the accuracy of the solution, which has become an obstacle to the application of PLMFs. In this paper, we present an iterative algorithm based on geometrical means to solve the problems mentioned above. Firstly, the linearization error can be reduced by gradually modifying the programming model. Subsequently, compared with traditional methods, the linearization model is determined only by weighing the linearization degree of membership function and the accuracy of programming results, the proposed method is more directly and effectively. Furthermore, in-depth discussions are also given along with the algorithm for demonstrating the rationality. Finally, the proposed method is validated and compared with other methods. A real example is examined to demonstrate applicability of the proposed method in this paper.},
  doi       = {https://doi.org/10.1016/j.chemolab.2019.06.007},
  file      = {:FILES/2019 - Wen2019 - A novel approach for FNLP with piecewise linear membership functions.pdf:PDF},
  groups    = {application},
  keywords  = {Fuzzy nonlinear programming, Piecewise linear membership functions, Error analysis, Iterative algorithm},
  timestamp = {2020-07-16},
  url       = {http://www.sciencedirect.com/science/article/pii/S016974391830666X},
}

@Article{westerlund1995extended,
  author    = {Westerlund, Tapio and Pettersson, Frank},
  journal   = {Computers \& Chemical Engineering},
  title     = {An extended cutting plane method for solving convex {MINLP} problems},
  year      = {1995},
  pages     = {131--136},
  volume    = {19},
  file      = {:FILES/1995 - westerlund1995extended - An extended cutting plane method for solving convex MINLP problems.pdf:PDF},
  groups    = {global optimization, MINLP},
  publisher = {Elsevier},
}

@InCollection{westerlund2006some,
  author    = {Westerlund, Tapio},
  booktitle = {Global Optimization},
  publisher = {Springer},
  title     = {Some transformation techniques in global optimization},
  year      = {2006},
  pages     = {45--74},
  file      = {:FILES/2006 - westerlund2006some - Some transformation techniques in global optimization.pdf:PDF},
  groups    = {global optimization},
}

@Article{white1992linear,
  author    = {White, Douglas J},
  journal   = {Mathematical Programming},
  title     = {A linear programming approach to solving bilinear programmes},
  year      = {1992},
  number    = {1-3},
  pages     = {45--50},
  volume    = {56},
  groups    = {bilinear},
  publisher = {Springer},
}

@Article{Wiedemann1986sparse,
  author    = {Wiedemann, D.},
  journal   = {IEEE Transactions on Information Theory},
  title     = {Solving sparse linear equations over finite fields},
  year      = {1986},
  issn      = {1557-9654},
  month     = {1},
  number    = {1},
  pages     = {54--62},
  volume    = {32},
  abstract  = {A "coordinate recurrence" method for solving sparse systems of linear equations over finite fields is described. The algorithms discussed all requireO(n_{1}(\omega + n_{1})\log^{k}n_{1})field operations, wheren_{1}is the maximum dimension of the coefficient matrix,\omegais approximately the number of field operations required to apply the matrix to a test vector, and the value ofkdepends on the algorithm. A probabilistic algorithm is shown to exist for finding the determinant of a square matrix. Also, probabilistic algorithms are shown to exist for finding the minimum polynomial and rank with some arbitrarily small possibility of error.},
  doi       = {10.1109/TIT.1986.1057137},
  file      = {:FILES/1986 - Wiedemann1986sparse - Solving sparse linear equations over finite fields.pdf:PDF},
  groups    = {mathematical basis},
  keywords  = {Sparse matrices},
  timestamp = {2020-08-31},
}

@Article{williams1992simple,
  author    = {Williams, Ronald J},
  journal   = {Machine learning},
  title     = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  year      = {1992},
  number    = {3-4},
  pages     = {229--256},
  volume    = {8},
  groups    = {RL},
  publisher = {Springer},
}

@Article{Williams1999mechanism,
  author    = {Williams, Steven R.},
  journal   = {Economic Theory},
  title     = {A characterization of efficient, {Bayesian} incentive compatible mechanisms},
  year      = {1999},
  issn      = {09382259, 14320479},
  number    = {1},
  pages     = {155--180},
  volume    = {14},
  abstract  = {A mechanism that is both efficient and incentive compatible in the Bayesian-Nash sense is shown to be payoff-equivalent to a Groves mechanism at the point in time when each agent has just acquired his private information. This equivalence result simplifies the question of whether or not an efficient, Bayesian incentive compatible mechanism can satisfy other desired objectives, for the search for an appropriate mechanism can be restricted to the family of Groves mechanisms. The method is used to extend the result of Myerson and Satterthwaite on the inefficiency of bilateral bargaining to a multilateral setting.},
  file      = {:FILES/1999 - Williams1999mechanism - A characterization of efficient, bayesian incentive compatible mechanisms.pdf:PDF},
  groups    = {VaR},
  publisher = {Springer},
  timestamp = {2020-09-04},
  url       = {http://www.jstor.org/stable/25055206},
}

@InProceedings{williams2017information,
  author       = {Williams, Grady and Wagener, Nolan and Goldfain, Brian and Drews, Paul and Rehg, James M and Boots, Byron and Theodorou, Evangelos A},
  booktitle    = {2017 IEEE International Conference on Robotics and Automation (ICRA)},
  title        = {Information theoretic {MPC} for model-based reinforcement learning},
  year         = {2017},
  organization = {IEEE},
  pages        = {1714--1721},
  groups       = {RL},
}

@Article{WITTEN1977286,
  author   = {Witten, Ian H.},
  journal  = {Information and Control},
  title    = {An adaptive optimal controller for discrete-time markov environments},
  year     = {1977},
  issn     = {0019-9958},
  number   = {4},
  pages    = {286 -- 295},
  volume   = {34},
  abstract = {This paper describes an adaptive controller for discrete-time stochastic environments. The controller receives the environment's current state and a reward signal which indicates the desirability of that state. In response, it selects an appropriate control action and notes its effect. The cycle repeats indefinitely. The control environments to be tackled include the well-known n-armed bandit problem, and the adaptive controller comprises an ensemble of n-armed bandit controllers, suitably interconnected. The design of these constituent elements is not discussed. It is shown that, under certain conditions, the controller's actions eventually become optimal for the particular control task with which it is faced, in the sense that they maximize the expected reward obtained in the future.},
  doi      = {https://doi.org/10.1016/S0019-9958(77)90354-0},
  groups   = {RL},
  url      = {http://www.sciencedirect.com/science/article/pii/S0019995877903540},
}

@Article{wolfe1965composite,
  author    = {Wolfe, Philip},
  journal   = {Siam Review},
  title     = {The composite simplex algorithm},
  year      = {1965},
  number    = {1},
  pages     = {42--54},
  volume    = {7},
  groups    = {global optimization},
  publisher = {SIAM},
}

@Article{wozabal2010var,
  author    = {Wozabal, David and Hochreiter, Ronald and Pflug, Georg Ch.},
  journal   = {Optimization},
  title     = {A difference of convex formulation of value-at-risk constrained optimization},
  year      = {2010},
  number    = {3},
  pages     = {377--400},
  volume    = {59},
  doi       = {10.1080/02331931003700731},
  eprint    = {https://doi.org/10.1080/02331931003700731},
  file      = {:FILES/2010 - wozabal2010var - A difference of convex formulation of value at risk constrained optimization.pdf:PDF},
  groups    = {VaR},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/02331931003700731},
}

@InProceedings{wray2016log,
  author    = {Wray, K. H. and Ruiken, D. and Grupen, R. A. and Zilberstein, S.},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Log-space harmonic function path planning},
  year      = {2016},
  month     = {10},
  pages     = {1511--1516},
  doi       = {10.1109/IROS.2016.7759245},
  file      = {:FILES/2016 - wray2016log - Log-space harmonic function path planning.pdf:PDF},
  groups    = {application, SGP},
  issn      = {2153-0866},
  keywords  = {collision avoidance;control engineering computing;graphics processing units;harmonic analysis;humanoid robots;mobile robots;public domain software;robot vision;SLAM (robots);trajectory control;log-space mapping;harmonic function;robotic path planning;graphics processing unit;GPU;open source library;uBot-6 humanoid robot;obstacle-avoiding trajectory;Harmonic analysis;Path planning;Convergence;Laplace equations;Graphics processing units;Mobile robots},
  timestamp = {2020-08-31},
}

@Article{Wright1998IllCondition,
  author    = {Wright, Margaret H.},
  journal   = {SIAM Journal on Optimization},
  title     = {Ill-conditioning and computational error in interior methods for nonlinear programming},
  year      = {1998},
  number    = {1},
  pages     = {84--111},
  volume    = {9},
  address   = {Philadelphia, PA, USA},
  groups    = {convergence},
  keywords  = {barrier method, constrained optimization, interior method, primal-dual method},
  publisher = {Society for Industrial and Applied Mathematics},
}

@Article{Wright2001interiorPrecision,
  author     = {Wright, Stephen J.},
  journal    = {SIAM Journal on Optimization},
  title      = {Effects of finite-precision arithmetic on interior-point methods for nonlinear programming},
  year       = {2001},
  number     = {1},
  pages      = {36--78},
  volume     = {12},
  address    = {Philadelphia, PA, USA},
  groups     = {convergence},
  issue_date = {2001},
  keywords   = {constraint qualification, finite-precision arithmetic, nonlinear programming, primal-dual interior-point algorithms},
  publisher  = {Society for Industrial and Applied Mathematics},
}

@Article{Wright2001On,
  author  = {Wright, Stephen J.},
  journal = {Mathematical Programming},
  title   = {On the convergence of the newton/log-barrier method},
  year    = {2001},
  number  = {1},
  pages   = {71--100},
  volume  = {90},
  groups  = {convergence},
}

@Article{wu2007robust,
  author    = {Wu, Yichao and Liu, Yufeng},
  journal   = {Journal of the American Statistical Association},
  title     = {Robust truncated hinge loss support vector machines},
  year      = {2007},
  number    = {479},
  pages     = {974--983},
  volume    = {102},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@Article{wu2008customized,
  author    = {Wu, Shin-yi and Hitt, Lorin M and Chen, Pei-yu and Anandalingam, G},
  journal   = {Management Science},
  title     = {Customized bundle pricing for information goods: {A} nonlinear mixed-integer programming approach},
  year      = {2008},
  number    = {3},
  pages     = {608--622},
  volume    = {54},
  groups    = {MILP, Portfolio Selection, asset allocation},
  publisher = {INFORMS},
  timestamp = {2020-09-04},
}

@Article{Wu2009CAPM,
  author    = {Wu, Yahao and Wang, Xiao-Tian and Wu, Min},
  journal   = {Chaos, Solitons \& Fractals},
  title     = {Fractional-moment {CAPM} with loss aversion},
  year      = {2009},
  number    = {3},
  pages     = {1406--1414},
  volume    = {42},
  abstract  = {In this paper, we present a new fractional-order value function which generalizes the value function of Kahneman and Tversky [Kahneman D, Tversky A. Prospect theory: an analysis of decision under risk. Econometrica 1979;47:263–91; Tversky A, Kahneman D. Advances in prospect theory: cumulative representation of uncertainty. J. Risk Uncertainty 1992;4:297–323], and give the corresponding fractional-moment versions of CAPM in the cases of both the prospect theory [Kahneman D, Tversky A. Prospect theory: an analysis of decision under risk. Econometrica 1979;47:263–91; Tversky A, Kahneman D. Advances in prospect theory: cumulative representation of uncertainty. J. Risk Uncertainty 1992;4:297–323] and the expected utility model. The models that we obtain can be used to price assets when asset return distributions are likely to be asymmetric stable Levy distribution during panics and stampedes in worldwide security markets in 2008. In particular, from the prospect theory we get the following fractional-moment CAPM with loss aversion:},
  groups    = {prospect theory},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{wu2011tighter,
  author    = {Wu, Lei},
  journal   = {IEEE Transactions on Power Systems},
  title     = {A tighter piecewise linear approximation of quadratic cost curves for unit commitment problems},
  year      = {2011},
  number    = {4},
  pages     = {2581--2583},
  volume    = {26},
  file      = {:FILES/2011 - wu2011tighter - A Tighter Piecewise Linear Approximation of Quadratic Cost Curves for Unit Commitment Problems.pdf:PDF},
  groups    = {Approximation},
  publisher = {IEEE},
}

@Article{wu2019gnn,
  author        = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
  journal       = {CoRR},
  title         = {A comprehensive survey on graph neural networks},
  year          = {2019},
  volume        = {abs/1901.00596},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1901-00596.bib},
  eprint        = {1901.00596},
  groups        = {Neural Network},
  timestamp     = {Thu, 31 Jan 2019 13:52:49 +0100},
  url           = {http://arxiv.org/abs/1901.00596},
}

@InProceedings{xi2012continuous,
  author    = {Xi, Xiangming and Xu, Jun and Mu, Xiaomu and Wang, Shuning},
  booktitle = {2012 IEEE 51st Conference on Decision and Control},
  title     = {Continuous piecewise linear programming via concave optimization and genetic algorithm},
  year      = {2012},
  address   = {Maui, HI, USA},
  month     = dec,
  pages     = {2509--2514},
  abstract  = {This paper describes continuous piecewise linear (CPWL) programming where the objective and constraints are in the form of hinging hyperplane (HH). And HH has received wide attention due to its simplicity and good performance in system identification. When solving a CPWL programming problem, some excellent features inspire us to come up with more efficient algorithms: the two distinguished states of a hinge function reminds us of application of genetic algorithm, while the piecewise linearity and concavity of the problem of minimization of HH naturally lead to the usage of well developed methods for concave programming, such as the cutting plane method. In order to find the global minima, we propose an improved genetic algorithm (GA) incorporating the cutting plane method. The main improvement lies in three aspects. First, it utilizes binary strings that derive local minima as chromosomes, with the proposed local minima locating method. Second, a stopping criterion has been established to ensure the global optimality of GA, with the structure information provided by γ extension of local minima. And third, genetic operations have also been revised to enhance the performance of the algorithm, which is assessed by the computational experiments.},
  author+an = {1=highlight},
  comment   = {04 February 2013},
  doi       = {10.1109/CDC.2012.6426584},
  file      = {:FILES/2012 - xi2012continuous - Continuous piecewise linear programming via concave optimization and genetic algorithm.pdf:PDF},
  groups    = {genetic algorithms, my paper, optimization, Wang's Work},
  url       = {https://ieeexplore.ieee.org/document/6426584},
}

@InProceedings{xi2015Dalian,
  author    = {Xi, Xiangming and Gong, Chao and Xu, Chunhui and Wang, Shuning},
  booktitle = {Proceedings of 2015 Asian Conference of Management Science \& Applications ({ACMSA2015})},
  title     = {An efficient global optimization algorithm for portfolio optimization under prospect theory},
  year      = {2015},
  month     = sep,
  pages     = {1--13},
  abstract  = {The prospect theory (PT) is one of the most useful tools for portfolio optimization. The main concept of PT is to use a S-shaped value function to depict how human beings’s mental behaviour affect their investment decisions under different risk levels. As a result of the complex formulation, the portfolio model under the prospect theory is much more difficult to be optimized globally. In order to improve the efficiency in optimization, we approximate the S-shaped value function in PT with a piecewise linear (PWL) surrogate model, and transform it into a continuous concave piecewise linear minimization problem. We also propose a global search algorithm based on the famous interior point method (IPM) and the γ valid cut method in concave optimization for global convergence. To address the non-smoothness of the PWL function, we utilize its linear realization in each sub-region during the iteration of the proposed method. Due to the concavity of the the piecewise linear surrogate model, the proposed method is descent and can be proved to be convergent. The numerical experiments on the historical data of different securities obtained from Yahoo concern the comparisons of the proposed global search algorithm and the existing methods in literature. The results confirm the great performances of the proposed algorithm.},
  author+an = {1=highlight},
  file      = {:FILES/2015 - xi2015Dalian - An efficient global optimization algorithm for portfolio optimization under prospect theory.pdf:PDF},
  groups    = {my paper, application, Wang's Work, prospect theory},
  location  = {Dalian, China},
  timestamp = {2020-09-04},
}

@Article{Xi2016,
  author    = {Xi, Xiangming and Huang, Xiaolin and Suykens, Johan A. K. and Wang, Shuning},
  journal   = {Neural Processing Letters},
  title     = {Coordinate descent algorithm for ramp loss linear programming support vector machines},
  year      = {2016},
  issn      = {1573-773X},
  month     = {7},
  note      = {July 10},
  number    = {3},
  pages     = {887--903},
  volume    = {43},
  abstract  = {In order to control the effects of outliers in training data and get sparse results, Huang et al. (J Mach Learn Res 15:2185--2211, 2014) proposed the ramp loss linear programming support vector machine. This combination of {\$}{\$}{\backslash}mathrm {\{}l{\}}{\_}1{\$}{\$}l1regularization and ramp loss does not only lead to the sparsity of parameters in decision functions, but also limits the effects of outliers with a maximal penalty. However, due to its non-convexity, the computational cost to achieve a satisfying solution is often expensive. In this paper, we propose a modified coordinate descent algorithm, which deals with a series of one-variable piecewise linear subproblems. Considering that the obtained subproblems are DC programming problems, we linearize the concave part of the objective functions and solve the obtained convex problems. To test the performances of the proposed algorithm, numerical experiments have been carried out and analysed on benchmark data sets. To enhance the sparsity and robustness, the experiments are initialized from C-SVM solutions. The results confirm its excellent performances in classification accuracy, robustness and efficiency in computation.},
  author+an = {1=highlight},
  comment   = {SCI，JCR Q3，1.62},
  day       = {01},
  doi       = {10.1007/s11063-015-9456-z},
  file      = {:FILES/2016 - Xi2016 - Coordinate Descent Algorithm for Ramp Loss Linear Programming Support Vector Machines.pdf:PDF},
  groups    = {my paper, optimization, SVM, Wang's Work},
  timestamp = {2020-08-30},
  url       = {https://doi.org/10.1007/s11063-015-9456-z},
}

@PhdThesis{xi2016thesis,
  author    = {Xi, Xiangming},
  school    = {Tsinghua University},
  title     = {Fast algorithm study on continuous piecewise linear optimization and its applications on classification and investment problems},
  year      = {2016},
  address   = {China},
  author+an = {1=highlight},
  groups    = {my paper, optimization},
}

@Article{Xi2018,
  author    = {Xi, Xiangming and Gong, Chao and Xu, Chunhui and Wang, Shuning},
  journal   = {Asian Journal of Management Science and Applications},
  title     = {Efficient optimisation for portfolio selections under prospect theory},
  year      = {2018},
  issn      = {2049-8691},
  month     = {10},
  note      = {Oct 4},
  number    = {3},
  pages     = {227--251},
  volume    = {3},
  abstract  = {The prospect theory (PT) is one of the most useful tools for portfolio optimisation. The main concept of PT is to use a S-shaped value function to depict how human beings' mental behaviour affect their investment decisions under different risk levels. However, the complexity in the theory results in the difficulty in the proposal of efficient algorithms for global optimisation. In order to make improvements, we first approximate the S-shaped value function in PT with a piecewise linear (PWL) surrogate model, and equivalently transform the resulted problem into a continuous concave piecewise linear maximisation problem. Despite of the non-smoothness and non-convexity of the problem, we propose two local search algorithms based on the interior point method, and present the theoretical analysis on the convergence. Moreover, we propose a global search algorithm based on the proposed local search algorithms and the γ valid cut method in concave optimisation. The numerical experiments on the historical data of different assets obtained from Yahoo concern the comparisons of the proposed algorithms and the existing methods in the literature. The results confirm the performances of the proposed algorithm on efficiency and accuracy.},
  author+an = {1=highlight},
  doi       = {10.1504/AJMSA.2018.095513},
  file      = {:FILES/2018 - Xi2018 - Efficient optimisation for portfolio selections under prospect theory.pdf:PDF},
  groups    = {my paper, Wang's Work, prospect theory},
  keywords  = {portfolio optimisation; prospect theory; interior point methods; global optimisation; management science.},
  timestamp = {2020-09-04},
}

@InProceedings{xi2019icca,
  author    = {Xi, Xiangming and Bai, Yu and Wang, Shuning and Lou, Yunjiang},
  booktitle = {2019 IEEE 15th International Conference on Control and Automation (ICCA)},
  title     = {Genetic algorithm based global optimization of {VaR}},
  year      = {2019},
  address   = {Edinburgh, UK},
  month     = {7},
  pages     = {1423--1428},
  abstract  = {As a measure of risks, value at risk (VaR) has been widely used in financial industry, while its optimization is still popular and attracting. In this paper, we will formulate the minimization of VaR as a piecewise linear (PWL) function, i.e. the k-th maximum function, and transform it into a PWL DC problem. In order to address the redundancy and nondifferentiability in the transformed problem, we propose a domain contraction algorithm which solves a series of linear programming problems and converges to a local optimum of the transformed problem. Further, considering that the equivalent problem is concave and multimodal, we carefully design an improved genetic algorithm for global search. Numerical experiments on the datasets collected from the Dow Jones Index confirm the global search capability and efficiency of the proposed algorithms.},
  author+an = {1=highlight},
  doi       = {10.1109/ICCA.2019.8899534},
  file      = {:FILES/2019 - xi2019icca - Genetic Algorithm based Global Optimization of var.pdf:PDF},
  groups    = {genetic algorithms, VaR, my paper, optimization, Wang's Work, TEC},
  issn      = {1948-3457},
  keywords  = {financial management;genetic algorithms;linear programming;piecewise linear techniques;global optimization;VaR;financial industry;piecewise linear function;maximum function;PWL DC problem;redundancy;nondifferentiability;transformed problem;domain contraction algorithm;linear programming problems;equivalent problem;improved genetic algorithm;global search capability;Value at Risk;Genetic Algorithm;Domain Contraction;Continuous Piecewise Linear Programming;k-th Maximum Function.},
  timestamp = {2020-09-05},
}

@Article{Xi2020,
  author   = {Xi, Xiangming and Lou, Yunjiang},
  journal  = {IEEE Transactions on Circuits and Systems II: Express Briefs},
  title    = {Sparse {FIR} filter design with $k$-max sparsity and peak error constraints},
  year     = {2021},
  issn     = {1558-3791},
  month    = apr,
  number   = {4},
  pages    = {1497--1501},
  volume   = {68},
  abstract = {FIR filters have boosted the development of digital signal processing, beamformers, and so on, due to their stability and low coefficient sensitivity. Generally, the design of FIR filters follows two main principles, i.e., the specification on the response error and the low implementation complexity. In this brief, we describe the sparsity of the filter coefficients using the k-maximum function, which equals to ℓ0-norm under mild conditions and has no restriction on the magnitude of nonzero coefficients. In order to avoid possible violation of specifications on response errors caused by frequency discretization, we estimate the frequencies at which the magnitude of the response error is maximized when constructing linear problems in the proposed algorithm. To address the nonlinearity and nonconvexity of the resulted optimization problem, we transform it into a piecewise linear concave optimization (PLCO) problem. Considering the fact that a PLCO problems is reduced to a linear programming (LP) problem locally, we outline an iterative algorithm by solving a series of LP problems and provide a brief complexity analysis. Numerical experiments on the propose method and some state-of-the-art methods are performed, the result of which shows the excellent performance of the propose method on balancing the sparsity and computational efficiency.},
  comment  = {SCI，JCR Q2,2.814，Date of Publication: 29 September 2020},
  doi      = {10.1109/TCSII.2020.3027704},
  file     = {:FILES/2020 - Xi2020 - Sparse FIR filter design with k-max sparsity and peak error constraints.PDF:PDF;:FILES/检索证明/2020 - Xi2020 - Sparse FIR Filter Design With k-Max Sparsity and Peak Error Constraints.pdf:PDF},
  groups   = {my paper, sparse},
  url      = {https://ieeexplore.ieee.org/document/9209055},
}

@InProceedings{Xi2020icca,
  author    = {Xi, Xiangming and Xu, Jun and Lou, Yunjiang},
  booktitle = {2020 IEEE 16th International Conference on Control and Automation (ICCA)},
  title     = {Log-sum-exp optimization based on continuous piecewise linearization techniques},
  year      = {2020},
  address   = {Singapore},
  month     = oct,
  note      = {Accepted},
  pages     = {600--605},
  publisher = {IEEE},
  comment   = {2020.10.09},
  doi       = {10.1109/ICCA51439.2020.9264376},
  file      = {:FILES/2020 - Xi2020icca - Log-sum-exp optimization based on continuous piecewise linearization techniques.pdf:PDF},
  groups    = {my paper, LSEO, optimization},
  url       = {https://ieeexplore.ieee.org/document/9264376},
}

@Article{xiang2007improved,
  author    = {Xiang, Tao and Liao, Xiaofeng and Wong, Kwok-wo},
  journal   = {Applied Mathematics and Computation},
  title     = {An improved particle swarm optimization algorithm combined with piecewise linear chaotic map},
  year      = {2007},
  number    = {2},
  pages     = {1637--1645},
  volume    = {190},
  groups    = {application, PSO},
  publisher = {Elsevier},
}

@Book{xie2016book,
  author    = {谢娟英},
  publisher = {电子工业出版社},
  title     = {无监督学习方法及其应用},
  year      = {2016},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@Article{Xu2002Half,
  author    = {徐绪松 and 杨小青 and 陈彦斌},
  journal   = {武汉大学学报:理学版},
  title     = {半绝对离差证券组合投资模型},
  year      = {2002},
  pages     = {297--300},
  groups    = {Portfolio Selection},
  issue     = {3},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@Article{xu2002portfolio,
  author    = {Xu, Xusong and Yang, Xiaoqing and Chen, Yanbin},
  journal   = {Journal of Wuhan University: Natural Science Edition},
  title     = {Portfolio model with semi-deviation risk measure},
  year      = {2002},
  number    = {3},
  pages     = {297--300},
  volume    = {48},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
}

@Article{xu2005elimination,
  author   = {Xu, Fei and Chang, Chip-Hong and Jong, Ching-Chuen},
  journal  = {IEEE Transactions on Circuits and Systems II: Express Briefs},
  title    = {Contention resolution algorithm for common subexpression elimination in digital filter design},
  year     = {2005},
  issn     = {1558-3791},
  month    = {10},
  number   = {10},
  pages    = {695--700},
  volume   = {52},
  abstract = {In this paper, a new algorithm, called contention resolution algorithm for weight-two subexpressions (CRA-2), based on an ingenious graph synthesis approach has been developed for the common subexpression elimination of the multiplication block of digital filter structures. CRA-2 provides a leeway to break away from the local minimum and the flexibility of varying optimization options through a new admissibility graph. It manages two-bit common subexpressions and aims at achieving the minimal logic depth as the primary goal. The performances of our proposed algorithm are analyzed and evaluated based on benchmarked finite-impulse-response filters and randomly generated data. It is demonstrated that CRA-2 achieves the shortest logic depth with significant reduction in the number of logic operators compared with other reported algorithms.},
  doi      = {10.1109/TCSII.2005.851776},
  file     = {:FILES/2005 - xu2005elimination - Contention resolution algorithm for common subexpression elimination in digital filter design.pdf:PDF},
  groups   = {pattern match},
  keywords = {IIR filters;graph theory;logic design;contention resolution algorithm;digital filter;graph synthesis;CRA-2;finite-impulse-response filters;logic operators;multiple constants multiplication;Digital filters;Algorithm design and analysis;Signal processing algorithms;Logic;Finite impulse response filter;Costs;Performance analysis;Performance evaluation;Digital signal processing;Common subexpression elimination (CSE);logic depth;multiple constants multiplication},
}

@InProceedings{xu2006robust,
  author    = {Xu, Linli and Crammer, Koby and Schuurmans, Dale},
  booktitle = {Proceedings of the 21st National Conference on Artificial Intelligence},
  title     = {Robust support vector machine training via convex outlier ablation},
  year      = {2006},
  pages     = {536--542},
  publisher = {AAAI Press},
  series    = {AAAI'06},
  groups    = {SVM},
  location  = {Boston, Massachusetts},
  numpages  = {7},
  timestamp = {2020-08-30},
}

@Article{Xu2009AHH,
  author  = {Xu, Jun and Huang, Xiaolin and Wang, Shuning},
  journal = {Automatica},
  title   = {Adaptive hinging hyperplanes and its applications in dynamic system identification},
  year    = {2009},
  number  = {10},
  pages   = {2325--2332},
  volume  = {45},
  file    = {:FILES/2009 - Xu2009AHH - adaptive hinging hyperplanes and its applications in dynamic system identification.pdf:PDF},
  groups  = {identification, Wang's Work},
}

@Misc{xu2012nfsc,
  note      = {240k RMB},
  title     = {Piecewise linear predictive control},
  year      = {{2012/01$\sim$2014/12}},
  address   = {National Natural Science Foundation of China (NSFC)(61104218). China. Participatant},
  groups    = {projects},
  keywords  = {project},
  timestamp = {2020-06-20},
}
@MISC{xu2012nfsc_cn,
 ADDRESS = {国家自然科学基金（青年科学基金项目）61104218，中国，参加},
 GROUPS = {projects},
 KEYWORDS = {project},
 TIMESTAMP = {2020-06-20},
 TITLE = {分片线性预测控制},
 YEAR = {{2012/01$\sim$2014/12}},
 note = {24万元，}
}

@Article{xu2013steady,
  author    = {Xu, Gongxian},
  journal   = {European Journal of Operational Research},
  title     = {Steady-state optimization of biochemical systems through geometric programming},
  year      = {2013},
  number    = {1},
  pages     = {12--20},
  volume    = {225},
  file      = {:FILES/2013 - xu2013steady - Steady-state optimization of biochemical systems through geometric programming.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@Article{Xu2013Tensor,
  author   = {Xu, Yangyang and Yin, Wotao},
  journal  = {SIAM Journal on imaging sciences},
  title    = {A block coordinate descent method for regularized multiconvex optimization with applications to nonnegative tensor factorization and completion},
  year     = {2013},
  issn     = {1936-4954},
  number   = {3},
  pages    = {1758--1789},
  volume   = {6},
  abstract = {This paper considers regularized block multiconvex optimization, where the feasible set and objective function are generally nonconvex but convex in each block of variables. It also accepts nonconvex blocks and requires these blocks to be updated by proximal minimization. We review some interesting applications and propose a generalized block coordinate descent method. Under certain conditions, we show that any limit point satisfies the Nash equilibrium conditions. Furthermore, we establish global convergence and estimate the asymptotic convergence rate of the method by assuming a property based on the Kurdyka--Łojasiewicz inequality. The proposed algorithms are tested on nonnegative matrix and tensor factorization, as well as matrix and tensor recovery from incomplete observations. The tests include synthetic data and hyperspectral data, as well as image sets from the CBCL and ORL databases. Compared to the existing state-of-the-art algorithms, the proposed algorithms demonstrate superior performance in both speed and solution quality. The MATLAB code of nonnegative matrix/tensor decomposition and completion, along with a few demos, are accessible from the authors' homepages.},
  doi      = {10.1137/120887795},
  file     = {:FILES/2013 - Xu2013Tensor - A block coordinate descent method for regularized multiconvex optimization with applications to nonnegative tensor factorization and completion.pdf:PDF},
  groups   = {interesting articles},
  url      = {https://epubs.siam.org/doi/10.1137/120887795},
}

@InProceedings{Xu2014,
  author    = {Xu, Jun and Xi, Xiangming and Wang, Shuning},
  booktitle = {2014 IEEE Congress on Evolutionary Computation (CEC)},
  title     = {Optimization based on adaptive hinging hyperplanes and genetic algorithm},
  year      = {2014},
  address   = {Beijing, China},
  month     = {7},
  pages     = {2040--2046},
  abstract  = {This paper describes an optimization strategy based on the model of adaptive hinging hyperplanes (AHH) and genetic algorithm (GA). The sample points of physical model are approximated by the AHH model, and the resulting model is minimized using a modified GA. In the modified GA, each chromosome corresponds to a local optimum. A criterion based on γ-valid cut is used to judge whether the global optimum is reached. Simulation results show that if the parameters are carefully chosen, the global optimum of AHH minimization is close to the optimum of the original function.},
  author+an = {2=highlight},
  doi       = {10.1109/CEC.2014.6900479},
  file      = {:FILES/2014 - Xu2014 - Optimization based on adaptive hinging hyperplanes and genetic algorithm.pdf:PDF},
  groups    = {my paper, genetic algorithms, optimization, Wang's Work},
  issn      = {1941-0026},
  keywords  = {approximation theory;genetic algorithms;genetic algorithm;adaptive hinging hyperplanes;optimization strategy;γ-valid cut;global optimum;AHH minimization global optimum;Optimization;Biological cells;Approximation methods;Atmospheric modeling;Linear programming;Computational modeling;Genetic algorithms},
}

@Article{xu2014global,
  author    = {Xu, Gongxian},
  journal   = {European Journal of Operational Research},
  title     = {Global optimization of signomial geometric programming problems},
  year      = {2014},
  number    = {3},
  pages     = {500--510},
  volume    = {233},
  file      = {:FILES/2014 - xu2014global - Global optimization of signomial geometric programming problems.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@InProceedings{xu2015tunneling,
  author    = {Xu, Zhiming and Liu, Kuangyu and Xi, Xiangming and Wang, Shuning},
  booktitle = {2015 54th IEEE Conference on Decision and Control (CDC)},
  title     = {Method of hill tunneling via simplex centroid for continuous piecewise linear programming},
  year      = {2015},
  month     = dec,
  pages     = {6609--6616},
  author+an = {3=highlight},
  file      = {:FILES/2015 - xu2015tunneling - Method of hill tunneling via simplex centroid for continuous piecewise linear programming.pdf:PDF},
  groups    = {my paper, optimization, Wang's Work},
}

@Article{xu2019locally,
  author    = {Xu, Baile and Shen, Shaofeng and Shen, Furao and Zhao, Jian},
  journal   = {Neural Networks},
  title     = {Locally linear {SVMs} based on boundary anchor points encoding},
  year      = {2019},
  groups    = {SVM},
  publisher = {Elsevier},
  timestamp = {2020-08-30},
}

@Article{xu2019superconvergence,
  author  = {Xu, YUAN and Meng, XIONG and Shu, CW and Zhang, QIANG},
  journal = {submitted to Mathematics of Computation},
  title   = {Superconvergence analysis of the {Runge--Kutta} discontinuous {Galerkin} methods for a linear hyperbolic equation},
  year    = {2019},
  groups  = {interesting articles},
}

@Article{Xu2020,
  author    = {Xu, Jun and Tao, Qinghua and Li, Zhen and Xi, Xiangming and Suykens, Johan A. K. and Wang, Shuning},
  journal   = {Automatica},
  title     = {Efficient hinging hyperplanes neural network and its application in nonlinear system identification},
  year      = {2020},
  issn      = {0005-1098},
  month     = jun,
  pages     = {108906},
  volume    = {116},
  abstract  = {In this paper, the efficient hinging hyperplanes (EHH) neural network is proposed, which is basically a single hidden layer neural network. Different from the dominant single hidden layer neural networks, the hidden layer in the EHH neural network can be seen as a directed acyclic graph (DAG) and all the nodes in the DAG contribute to the output. It is proved that for every EHH neural network, there is an equivalent adaptive hinging hyperplanes (AHH) tree, the model of which was proposed based on the hinging hyperplanes (HH) model and finds good applications in system identification. Analog to the proof for the AHH model, the universal approximation ability of the EHH neural network is provided. Different from other neural networks, the EHH neural network has interpretability, which can be easily obtained through its ANOVA decomposition (or interaction matrix). The interpretability can then be used as an indication for the importance of the input variables. The construction of the EHH neural network includes initial network generation and parameter optimization (including the structure and weights parameter optimization). A descent algorithm for searching the locally optimal EHH neural network is proposed and the worst-case complexity of the algorithm is also provided. The EHH neural network is applied in nonlinear system identification, the simulation results show that satisfactory accuracy can be achieved with relatively low computational cost, and at the same time, some insights into the importance of the regressors and the interactions among the regressors can be revealed.},
  author+an = {4=highlight},
  comment   = {SCI，JCR Q1，5.541，2020.03.06，WOS:000525866500002},
  doi       = {10.1016/j.automatica.2020.108906},
  file      = {:FILES/2020 - Xu2020 - Efficient hinging hyperplanes neural network and its application in nonlinear system identification.pdf:PDF},
  groups    = {my paper, identification, Wang's Work},
  keywords  = {Artificial neural networks, Hinging hyperplanes, Interpretability, Identification methods},
  url       = {http://www.sciencedirect.com/science/article/pii/S0005109820301047},
}

@InCollection{yaakob2010double,
  author    = {Yaakob, Shamshul Bahar and Watada, Junzo},
  booktitle = {Integrated Uncertainty Management and Applications},
  publisher = {Springer},
  title     = {Double-layered hybrid neural network approach for solving mixed integer quadratic bilevel problems},
  year      = {2010},
  pages     = {221--230},
  groups    = {bilevel, Neural Network},
}

@Article{yaari1965convexity,
  author    = {Yaari, Menahem E},
  journal   = {The Quarterly Journal of Economics},
  title     = {Convexity in the theory of choice under risk},
  year      = {1965},
  pages     = {278--290},
  groups    = {Portfolio Selection},
  publisher = {JSTOR},
  timestamp = {2020-09-04},
}

@Article{yajima1991efficient,
  author    = {Yajima, Yasutoshi and Konno, Hiroshi},
  journal   = {Journal of global optimization},
  title     = {Efficient algorithms for solving rank two and rank three bilinear programming problems},
  year      = {1991},
  number    = {2},
  pages     = {155--171},
  volume    = {1},
  groups    = {bilinear},
  publisher = {Springer},
}

@Article{Yamada2010outer,
  author    = {Yamada, S. and Tanaka, T. and Tanino, T.},
  journal   = {Journal of optimization theory and applications},
  title     = {Outer approximation method incorporating a quadratic approximation for a {DC} programming problem},
  year      = {2010},
  number    = {1},
  pages     = {156--183},
  volume    = {144},
  groups    = {global optimization},
  publisher = {Springer},
}

@Article{yamamura1998finding,
  author    = {Yamamura, Kiyotaka and Ohshima, Takayuki},
  journal   = {IEEE Transactions on Circuits and Systems {I}: {Fundamental} Theory and Applications},
  title     = {Finding all solutions of piecewise-linear resistive circuits using linear programming},
  year      = {1998},
  number    = {4},
  pages     = {434--445},
  volume    = {45},
  file      = {:FILES/1998 - yamamura1998finding - Finding all solutions of piecewise-linear resistive circuits using linear programming.pdf:PDF},
  groups    = {application},
  publisher = {IEEE},
}

@Article{yang1997investigation,
  author    = {Yang, {Hsu-Hao} and Bricker, Dennis L.},
  journal   = {European Journal of Operational Research},
  title     = {Investigation of path-following algorithms for signomial geometric programming problems},
  year      = {1997},
  number    = {1},
  pages     = {230--241},
  volume    = {103},
  file      = {:FILES/1997 - yang1997investigation - Investigation of path-following algorithms for signomial geometric programming problems.pdf:PDF},
  groups    = {SGP},
  publisher = {Elsevier},
  timestamp = {2020-07-16},
}

@InProceedings{yang2015fir,
  author     = {Yang, Y. and Zhu, W. and Wu, D.},
  booktitle  = {2015 IEEE International Conference on Digital Signal Processing (DSP)},
  title      = {Design of sparse {FIR} filters based on reweighted {L1} -norm minimization},
  year       = {2015},
  month      = {7},
  pages      = {858--862},
  abstract   = {As the implementation cost of a digital filter mainly depends on the number of filter coefficients, the filters with sparse coefficients are of great interest. In this paper, a reweighted l1 minimization procedure is proposed for the design of a class of linear-phase FIR filters with sparse coefficients. The proposed design algorithm is accomplished in two phases. In the first phase, we utilize the reweighted l1 norm to identify the zero coefficient positions. In the second phase, the sparse non-zero coefficients of the filter are re-optimized either in the mimimax sense or least-square sense. Numerical examples are given to show the effectiveness of the proposed method.},
  doi        = {10.1109/ICDSP.2015.7251998},
  file       = {:FILES/2015 - yang2015fir - Design of sparse FIR filters based on reweighted l1 -norm minimization.pdf:PDF},
  groups     = {sparse},
  issn       = {2165-3577},
  keywords   = {compressed sensing;FIR filters;least squares approximations;linear phase filters;minimax techniques;minimisation;sparse FIR filter design;reweighted l1-norm minimization;digital filter implementation cost;linear phase FIR filter design;zero coefficient position;sparse coefficient;filter coefficient;sparse nonzero coefficient;mimimax sense;least square sense;Algorithm design and analysis;Finite impulse response filters;Approximation algorithms;Minimization;Signal processing algorithms;Approximation error;Indexes;FIR filter;sparse;reweighted l1 norm, read},
  readstatus = {read},
}

@Article{Yang2019,
  author       = {Yang, Peng and Tang, Ke and Yao, Xin},
  title        = {A parallel divide-and-conquer-based evolutionary algorithm for large-scale optimization},
  year         = {2019},
  issn         = {2169-3536},
  pages        = {163105--163118},
  volume       = {7},
  abstract     = {Large-scale optimization problems that involve thousands of decision variables have extensively arisen from various industrial areas. As a powerful optimization tool for many real-world applications, evolutionary algorithms (EAs) fail to solve the emerging large-scale problems both effectively and computationally efficiently. In this paper, we propose a novel Divide-and-Conquer (DC) based EA that can not only produce high-quality solutions by solving sub-problems separately, but also benefits significantly from the power of parallel computing by solving the sub-problems simultaneously. Existing DC-based EAs that were thought to enjoy the same advantages of the proposed algorithm, are shown to be practically incompatible with the parallel computing scheme, unless some trade-offs are made by compromising the solution quality.},
  date         = {2019},
  doi          = {10.1109/ACCESS.2019.2938765},
  file         = {:FILES/2019 - Yang2019 - A Parallel Divide-and-Conquer-Based Evolutionary Algorithm for Large-Scale Optimization.pdf:PDF},
  groups       = {Evolutionary Algorithms},
  journaltitle = {IEEE Access},
  keywords     = {Optimization, Linear programming, Search problems, Sociology, Statistics, Evolutionary computation, Computational efficiency, Parallel evolutionary algorithms, large-scale optimization, divide-and-conquer, read},
  publisher    = {IEEE},
  readstatus   = {read},
  timestamp    = {2020-06-08},
}

@Article{yang2019adp,
  author   = {Yang, X. and He, H. and Zhong, X.},
  journal  = {IEEE Transactions on Cybernetics},
  title    = {Approximate dynamic programming for nonlinear-constrained optimizations},
  year     = {2019},
  issn     = {2168-2275},
  pages    = {1--14},
  doi      = {10.1109/TCYB.2019.2926248},
  groups   = {RL},
  keywords = {Optimal control;Interconnected systems;Optimization;Nonlinear systems;Dynamic programming;Approximation algorithms;Approximate dynamic programming;constrained optimization;neural networks;nonlinear interconnected system;optimal control},
}

@Article{YANJUN200589,
  author   = {Yanjun, Wang and Peiping, Shen and Zhian, Liang},
  journal  = {Applied Mathematics and Computation},
  title    = {A branch-and-bound algorithm to globally solve the sum of several linear ratios},
  year     = {2005},
  issn     = {0096-3003},
  number   = {1},
  pages    = {89 -- 101},
  volume   = {168},
  doi      = {https://doi.org/10.1016/j.amc.2004.08.016},
  groups   = {MILP},
  keywords = {Fractional programming, Branch and bound, Global optimization},
  url      = {http://www.sciencedirect.com/science/article/pii/S0096300304005880},
}

@Article{yanjun2009general,
  author    = {Yanjun, Wang and Tao, Li and Zhian, Liang},
  journal   = {Computational Optimization and Applications},
  title     = {A general algorithm for solving generalized geometric programming with nonpositive degree of difficulty},
  year      = {2009},
  number    = {1},
  pages     = {139},
  volume    = {44},
  file      = {:FILES/2009 - yanjun2009general - A general algorithm for solving generalized geometric programming with nonpositive degree of difficulty.pdf:PDF},
  groups    = {SGP},
  publisher = {Springer},
  timestamp = {2020-07-16},
}

@Article{Yazici2013lms,
  author    = {Kan, Bet\"{u}l and Alpu, \"{O}zlem and Yazıcı, Berna},
  journal   = {Journal of Applied Statistics},
  title     = {Robust ridge and robust {Liu} estimator for regression based on the {LTS} estimator},
  year      = {2013},
  number    = {3},
  pages     = {644--655},
  volume    = {40},
  abstract  = {In the multiple linear regression analysis, the ridge regression estimator and the Liu estimator are often used to address multicollinearity. Besides multicollinearity, outliers are also a problem in the multiple linear regression analysis. We propose new biased estimators based on the least trimmed squares (LTS) ridge estimator and the LTS Liu estimator in the case of the presence of both outliers and multicollinearity. For this purpose, a simulation study is conducted in order to see the difference between the robust ridge estimator and the robust Liu estimator in terms of their effectiveness; the mean square error. In our simulations, the behavior of the new biased estimators is examined for types of outliers: X-space outlier, Y-space outlier, and X-and Y-space outlier. The results for a number of different illustrative cases are presented. This paper also provides the results for the robust ridge regression and robust Liu estimators based on a real-life data set combining the problem of multicollinearity and outliers.},
  doi       = {10.1080/02664763.2012.750285},
  eprint    = {https://doi.org/10.1080/02664763.2012.750285},
  file      = {:FILES/2013 - Yazici2013lms - Robust ridge and robust Liu estimator for regression based on the LTS estimator.pdf:PDF},
  groups    = {LMS},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/02664763.2012.750285},
}

@Article{ye2015twostep,
  author   = {Ye, W. B. and Yu, Y. J.},
  journal  = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title    = {Two-step optimization approach for the design of multiplierless linear-phase {FIR} filters},
  year     = {2015},
  issn     = {1558-0806},
  month    = {5},
  number   = {5},
  pages    = {1279--1287},
  volume   = {62},
  abstract = {Deterministic tree search algorithms for the design of multiplierless linear phase finite impulse response filters are generally time consuming. Many researches therefore focus on how to restrict the number of discrete values assigned to each coefficient during a tree search. In this paper, a two-step tree search algorithm is proposed. In the first step, a polynomial-time tree search algorithm where each coefficient is fixed to a single one discrete value is introduced. Since the synthesis of large coefficients is dominant in the hardware cost over small coefficients, in the second step optimization, the small coefficients obtained in the first step is kept unaltered and the large coefficients are further divided into several groups and the coefficients are optimized group by group alternatingly. Such a two-step search strategy maximally utilizes the limited computational resources and can achieve lower hardware cost design in a shorter design time, compared with existing algorithms.},
  doi      = {10.1109/TCSI.2015.2415178},
  file     = {:FILES/2015 - ye2015twostep - Two-Step Optimization Approach for the Design of Multiplierless Linear-Phase FIR Filters.pdf:PDF},
  groups   = {FIR filter design},
  keywords = {computational complexity;deterministic algorithms;FIR filters;linear phase filters;optimisation;tree searching;two-step optimization approach;multiplierless linear-phase FIR filters;deterministic tree search algorithms;finite impulse response filters;discrete values;polynomial-time algorithm;hardware cost design;Optimization;Hardware;Adders;Algorithm design and analysis;Passband;Finite impulse response filters;Complexity theory;Average adder depth (AAD);finite impulse response (FIR);low hardware cost;multiplierless;polynomial time},
}

@Article{Ye2016Greedy,
  author     = {Ye, Wenbin and Yu, Ya Jun},
  journal    = {Circuits Systems \& Signal Processing},
  title      = {Greedy algorithm for the design of linear-phase {FIR} filters with sparse coefficients},
  year       = {2016},
  number     = {4},
  pages      = {1427--1436},
  volume     = {35},
  file       = {:FILES/2016 - Ye2016Greedy - Greedy Algorithm for the Design of Linear-Phase FIR Filters with Sparse Coefficients.pdf:PDF},
  groups     = {sparse},
  keywords   = {read},
  readstatus = {read},
}

@Article{YILMAZ2008620,
  author    = {Yilmaz, M\"{u}nevver Yildirim and Bektaş, Mehmet},
  journal   = {Chaos, Solitons \& Fractals},
  title     = {A survey on curvatures of {Hessian} manifolds},
  year      = {2008},
  issn      = {0960-0779},
  number    = {3},
  pages     = {620--630},
  volume    = {38},
  abstract  = {This paper deals with the relationship of curvatures between Hessian and Riemannian manifolds. By making use of the methods of Shima [Shima H. Hessian manifolds of constant Hessian sectional curvature. J Math Soc Jpn 1995;47(4):735-53] we investigate a new approach to the curvatures of a manifold. Finally, some results are mentioned in the concluding remarks.},
  doi       = {http://eproxy2.lib.tsinghua.edu.cn:80/rwt/33/https/MSYXTLUQPJUB/10.1016/j.chaos.2008.01.026},
  groups    = {interesting articles},
  timestamp = {2020-08-05},
  url       = {http://eproxy2.lib.tsinghua.edu.cn:80/rwt/33/http/P75YPLUUMNVXK5UDMWTGT6UFMN4C6Z5QNF/science/article/pii/S0960077908000453},
}

@Article{young1998minimax,
  author    = {Young, Martin R.},
  journal   = {Management Science},
  title     = {A minimax portfolio selection rule with linear programming solution},
  year      = {1998},
  number    = {5},
  pages     = {673--683},
  volume    = {44},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
}

@Article{Yu1992L1fir,
  author    = {Yu, Wen-Shyong and Fong, I-Kong and Chang, Kuang-Chiung},
  journal   = {IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing},
  title     = {An $\ell_1$-approximation based method for synthesizing {FIR} filters},
  year      = {1992},
  issn      = {1558-125X},
  month     = {8},
  number    = {8},
  pages     = {578--581},
  volume    = {39},
  abstract  = {A method is proposed for the synthesis of digital filters having approximately the desired linear phase frequency responses. A mathematical optimization problem is formulated from the synthesis objective, and a theorem from the theory of l/sub 2/-approximation is used to convert the optimization problem such that it can be solved by the linear programming technique. The method is successfully applied to the synthesis of a digital FIR equalizer for a given analog antialiasing filter.<>},
  doi       = {10.1109/82.168951},
  file      = {:FILES/1992 - Yu1992L1fir - An l1-approximation based method for synthesizing FIR filters.pdf:PDF},
  groups    = {FIR filter design},
  keywords  = {digital filters;filtering and prediction theory;frequency response;linear programming;synthesis method;l/sub 1/-approximation based method;FIR filters;digital filters;linear phase frequency responses;mathematical optimization problem;linear programming;digital FIR equalizer;Finite impulse response filter;Computer aided manufacturing;CADCAM;Circuit synthesis;Random access memory;Hardware;DRAM chips;Digital filters;Linear programming;Equalizers},
  timestamp = {2020-08-05},
}

@Article{yu2009subexp,
  author    = {Yu, Y. J. and Shi, D. and Lim, Y. C.},
  journal   = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title     = {Design of extrapolated impulse response {FIR} filters with residual compensation in subexpression space},
  year      = {2009},
  issn      = {1558-0806},
  month     = {12},
  number    = {12},
  pages     = {2621--2633},
  volume    = {56},
  abstract  = {In this paper, an extrapolated impulse response filter with residual compensation is proposed for the design of discrete coefficient finite-impulse response (FIR) filters using subexpression sharing. The proposed technique utilizes the quasi-periodic nature of the filter impulse response to approximate the filter coefficients. The reduced degree of freedom of filter coefficients due to the quasi-periodic approximation is perfectly restored by introducing a residual compensation technique. The resulting subexpression sharing synthesis of discrete coefficient FIR filters has lower complexities than that of the conventional synthesis techniques in terms of number of adders. To further reduce the synthesis complexity, filter coefficients and residuals may be optimized in subexpression spaces. Mixed integer linear programming is formulated for the optimization. Numerical examples show that the number of adders required by synthesizing the filters in the proposed structure is significantly reduced compared to that of the conventional synthesis schemes synthesized in direct or transposed direct form.},
  doi       = {10.1109/TCSI.2009.2016165},
  file      = {:FILES/2009 - yu2009subexp - Design of Extrapolated Impulse Response FIR Filters with Residual Compensation in Subexpression Space.pdf:PDF},
  groups    = {subexpression},
  keywords  = {computational complexity;extrapolation;FIR filters;integer programming;linear programming;extrapolated impulse response FIR filters;discrete coefficient finite-impulse response filters;subexpression sharing;quasi-periodic approximation;residual compensation technique;mixed integer linear programming;Finite impulse response filter;Adders;Mixed integer linear programming;Nonlinear filters;Very large scale integration;Signal generators;Delay;Algorithm design and analysis;Circuits;Common subexpression sharing;extrapolated impulse response;finite-impulse response (FIR) filters;mixed integer linear programming;residual compensation;subexpression space},
  timestamp = {2020-08-05},
}

@Article{Yu2013,
  author    = {Yu, Juntang and Mu, Xiaomu and Xi, Xiangming and Wang, Shuning},
  journal   = {Radioengineering},
  title     = {A memristor model with piecewise window function},
  year      = {2013},
  issn      = {1805-9600},
  month     = {12},
  number    = {4},
  pages     = {969--974},
  volume    = {22},
  author+an = {3=highlight},
  comment   = {0.796},
  file      = {:FILES/2013 - Yu2013 - A memristor model with piecewise window function.pdf:PDF},
  groups    = {my paper, application, Wang's Work},
  keywords  = {memristor;window function;mathematical model},
  timestamp = {2020-08-05},
}

@Article{Yu2017,
  author    = {Yu, Juntang and Xi, Xiangming and Wang, Shuning},
  journal   = {International Journal of Numerical Modelling: Electronic Networks, Devices and Fields},
  title     = {A flexible memristive model with simplex basis function},
  year      = {2017},
  issn      = {0894-9970},
  note      = {e2183 jnm.2183},
  number    = {3-4},
  pages     = {e2183},
  volume    = {30},
  abstract  = {Summary In this paper, we propose a flexible memristive model with simplex basis function. In the memristive model, a piecewise window function is applied to limit the physical range of the state variable, and a piecewise linear model (called simplex basis function model) is applied to describe the integral function of the current and charge. The expression of the state variable and the memristance can be almost analytically obtained. Thus, some serious errors occurring in the simulations of some existing memristive models can be avoided. The proposed memristive model shows great flexibility due to the good approximation capability of the simplex basis function model. Copyright © 2016 John Wiley \& Sons, Ltd.},
  author+an = {2=highlight},
  comment   = {SCI，JCR Q4，0.816},
  doi       = {10.1002/jnm.2183},
  eprint    = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/jnm.2183},
  file      = {:FILES/2017 - Yu2017 - A flexible memristive model with simplex basis function.pdf:PDF},
  groups    = {my paper, identification, Wang's Work},
  keywords  = {memristive model, window function, piecewise linear approximation},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jnm.2183},
}

@Misc{yu2020nfsc,
  note      = {255w},
  title     = {脑肢协同多模态干预的脑卒中专科型手部康复机器人},
  year      = {{2020/01$\sim$2023/12}},
  address   = {国家自然科学基金（联合基金项目）U1913208，参与},
  groups    = {projects},
  keywords  = {project},
  timestamp = {2020-06-20},
}

@Misc{yu2020nfsc_cn,
  note      = {deprecated},
  title     = {Specialized hand rehabilitation robot for stroke with multi-modal intervention of brain and limb},
  year      = {{2020/01$\sim$2023/12}},
  address   = {National Natural Science Foundation of China (NSFC) U1913208. China. Participatant},
  groups    = {projects},
  keywords  = {project},
  timestamp = {2020-06-20},
}

@Article{yuan2010comparison,
  author    = {Yuan, Guo-Xun and Chang, Kai-Wei and Hsieh, Cho-Jui and Lin, Chih-Jen},
  journal   = {Journal of Machine Learning Research},
  title     = {A comparison of optimization methods and software for large-scale {L1-regularized} linear classification},
  year      = {2010},
  issn      = {1532-4435},
  month     = jan,
  number    = {105},
  pages     = {3183--3234},
  volume    = {11},
  abstract  = {Large-scale linear classification is widely used in many areas. The L1-regularized form can be applied for feature selection; however, its non-differentiability causes more difficulties in training. Although various optimization methods have been proposed in recent years, these have not yet been compared suitably. In this paper, we first broadly review existing methods. Then, we discuss state-of-the-art software packages in detail and propose two efficient implementations. Extensive comparisons indicate that carefully implemented coordinate descent methods are very suitable for training large document data.},
  file      = {:FILES/2010 - yuan2010comparison - A comparison of optimization methods and software for large-scale {L1-regularized} linear classification.pdf:PDF},
  groups    = {SVM},
  timestamp = {2020-08-30},
  url       = {http://jmlr.org/papers/v11/yuan10c.html},
}

@Article{yuan2012improved,
  author     = {Yuan, Guo-Xun and Ho, Chia-Hua and Lin, Chih-Jen},
  journal    = {Journal of Machine Learning Research},
  title      = {An improved {GLMNET} for {L1}-regularized logistic regression},
  year       = {2012},
  number     = {1},
  pages      = {1999--2030},
  volume     = {13},
  acmid      = {2343708},
  groups     = {SVM},
  issue_date = {January 2012},
  keywords   = {L1 regularization, linear classification, logistic regression, optimization methods, support vector machines},
  numpages   = {32},
  publisher  = {JMLR.org},
  timestamp  = {2020-08-30},
}

@Article{zamora1999branch,
  author    = {Zamora, Juan M. and Grossmann, Ignacio E.},
  journal   = {Journal of Global Optimization},
  title     = {A branch and contract algorithm for problems with concave univariate, bilinear and linear fractional terms},
  year      = {1999},
  month     = may,
  number    = {3},
  pages     = {217--249},
  volume    = {14},
  abstract  = {A new deterministic branch and bound algorithm is presented in this paper for the global optimization of continuous problems that involve concave univariate, bilinear and linear fractional terms. The proposed algorithm, the branch and contract algorithm, relies on the use of a bounds-contraction subproblem that aims at reducing the size of the search region by eliminating portions of the domain in which the objective function takes only values above a known upper bound. The solution of contraction subproblems at selected branch and bound nodes is performed within a finite contraction operation that helps reducing the total number of nodes in the branch and bound solution tree. The use of the proposed algorithm is illustrated with several numerical examples.},
  doi       = {10.1023/A:1008312714792},
  file      = {:FILES/1999 - zamora1999branch - A branch and contract algorithm for problems with concave univariate, bilinear and linear fractional terms.pdf:PDF},
  groups    = {MILP},
  publisher = {Springer},
  url       = {https://link.springer.com/article/10.1023/A:1008312714792},
}

@ARTICLE{zener1961mathematical,
 AUTHOR = {Zener, Clarence},
 JOURNAL = {Proceedings of the National Academy of Sciences of the United States of America},
 NUMBER = {4},
 PAGES = {537},
 PUBLISHER = {National Academy of Sciences},
 TITLE = {A mathematical aid in optimizing engineering designs},
 VOLUME = {47},
 YEAR = {1961}
}

@ARTICLE{zener1962further,
 AUTHOR = {Zener, Clarence},
 JOURNAL = {Proceedings of the National Academy of Sciences of the United States of America},
 NUMBER = {4},
 PAGES = {518},
 PUBLISHER = {National Academy of Sciences},
 TITLE = {A further mathematical aid in optimizing engineering designs},
 VOLUME = {48},
 YEAR = {1962}
}

@MISC{zeng2012nfsc,
 ADDRESS = {National Natural Science Foundation of China (NSFC). China. Participatant},
 GROUPS = {projects},
 KEYWORDS = {project},
 TIMESTAMP = {2020-06-20},
 TITLE = {Dynamic information storage and acquisition theory and implementation techniques based on memrister},
 YEAR = {{2012/01$\sim$2016/12}},
 note = {deprecated}
}

@Article{Zhan2018accelerated,
  author     = {Zhan, Yiduo and Zheng, Qipeng P. and Tseng, Chung-Li and Pasiliao, Eduardo L.},
  journal    = {Journal of Global Optimization},
  title      = {An accelerated extended cutting plane approach with piecewise linear approximations for signomial geometric programming},
  year       = {2018},
  issn       = {1573-2916},
  month      = {3},
  number     = {3},
  pages      = {579--599},
  volume     = {70},
  abstract   = {This paper presents a global optimization approach for solving signomial geometric programming (SGP) problems. We employ an accelerated extended cutting plane (ECP) approach integrated with piecewise linear (PWL) approximations to solve the global optimization of SGP problems. In this approach, we separate the feasible regions determined by the constraints into convex and nonconvex ones in the logarithmic domain. In the nonconvex feasible regions, the corresponding constraint functions are converted into mixed integer linear constraints using PWL approximations, while the other constraints with convex feasible regions are handled by the ECP method. We also use pre-processed initial cuts and batched cuts to accelerate the proposed algorithm. Numerical results show that the proposed approach can solve the global optimization of SGP problems efficiently and effectively.},
  day        = {01},
  doi        = {10.1007/s10898-017-0563-4},
  file       = {:FILES/2018 - Zhan2018accelerated - An accelerated extended cutting plane approach with piecewise linear approximations for signomial geometric programming.pdf:PDF},
  groups     = {SGP, application},
  keywords   = {read},
  readstatus = {read},
  timestamp  = {2020-08-31},
  url        = {https://doi.org/10.1007/s10898-017-0563-4},
}

@Book{zhang2001rl,
  author    = {张汝波},
  publisher = {哈尔滨工程大学出版社},
  title     = {强化学习理论及应用},
  year      = {2001},
  groups    = {RL},
}

@Article{zhang2001text,
  author    = {Zhang, Tong and Oles, Frank J.},
  journal   = {Information Retrieval},
  title     = {Text categorization based on regularized linear classification methods},
  year      = {2001},
  number    = {1},
  pages     = {5--31},
  volume    = {4},
  abstract  = {A number of linear classification methods such as the linear least squares fit (LLSF), logistic regression, and support vector machines (SVM’s) have been applied to text categorization problems. These methods share the similarity by finding hyperplanes that approximately separate a class of document vectors from its complement. However, support vector machines are so far considered special in that they have been demonstrated to achieve the state of the art performance. It is therefore worthwhile to understand whether such good performance is unique to the SVM design, or if it can also be achieved by other linear classification methods. In this paper, we compare a number of known linear  lassification methods as well as some variants in the framework of regularized linear systems. We will discuss the statistical and numerical properties of these algorithms, with a focus on text categorization. We will also provide some numerical experiments to illustrate these algorithms on a number of datasets.},
  groups    = {SVM},
  publisher = {Springer},
  timestamp = {2020-08-30},
}

@Article{Zhang2006Separable,
  author    = {Zhang, H. and Wang, S.},
  journal   = {Journal of Computational and Applied Mathematics},
  title     = {Global optimization of separable objective functions on convex polyhedra via piecewise-linear approximation},
  year      = {2006},
  number    = {1},
  pages     = {212--217},
  volume    = {197},
  groups    = {global optimization, optimization},
  timestamp = {2020-08-05},
}

@Article{Zhang2008Nonseparable,
  author    = {Zhang, H. and Wang, S.},
  journal   = {Journal of Computational and Applied Mathematics},
  title     = {Linearly constrained global optimization via piecewise-linear approximation},
  year      = {2008},
  number    = {1},
  pages     = {111--120},
  volume    = {214},
  groups    = {global optimization, optimization},
  timestamp = {2020-08-05},
}

@InProceedings{Zhang2016vehicle,
  author    = {Zhang, T. and Kahn, G. and Levine, S. and Abbeel, P.},
  booktitle = {2016 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Learning deep control policies for autonomous aerial vehicles with {MPC}-guided policy search},
  year      = {2016},
  month     = {5},
  pages     = {528--535},
  abstract  = {Model predictive control (MPC) is an effective method for controlling robotic systems, particularly autonomous aerial vehicles such as quadcopters. However, application of MPC can be computationally demanding, and typically requires estimating the state of the system, which can be challenging in complex, unstructured environments. Reinforcement learning can in principle forego the need for explicit state estimation and acquire a policy that directly maps sensor readings to actions, but is difficult to apply to unstable systems that are liable to fail catastrophically during training before an effective policy has been found. We propose to combine MPC with reinforcement learning in the framework of guided policy search, where MPC is used to generate data at training time, under full state observations provided by an instrumented training environment. This data is used to train a deep neural network policy, which is allowed to access only the raw observations from the vehicle's onboard sensors. After training, the neural network policy can successfully control the robot without knowledge of the full state, and at a fraction of the computational cost of MPC. We evaluate our method by learning obstacle avoidance policies for a simulated quadrotor, using simulated onboard sensors and no explicit state estimation at test time.},
  doi       = {10.1109/ICRA.2016.7487175},
  groups    = {RL},
  keywords  = {autonomous aerial vehicles;collision avoidance;helicopters;learning (artificial intelligence);neural nets;predictive control;deep control policies;autonomous aerial vehicles;MPC-guided policy search;model predictive control;quadcopters;reinforcement learning;explicit state estimation;deep neural network policy;obstacle avoidance policies;quadrotor;Training;Robot sensing systems;Neural networks;Heuristic algorithms;Trajectory optimization;Vehicles},
  timestamp = {2020-08-05},
}

@InCollection{Zhang2018,
  author    = {Zhang, Zhilu and Sabuncu, Mert},
  booktitle = {Advances in Neural Information Processing Systems 31},
  publisher = {Curran Associates, Inc.},
  title     = {Generalized cross entropy loss for training deep neural networks with noisy labels},
  year      = {2018},
  editor    = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
  pages     = {8778--8788},
  file      = {:FILES/2018 - Zhang2018 - Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels.pdf:PDF},
  groups    = {Neural Network},
  timestamp = {2020-08-31},
  url       = {http://papers.nips.cc/paper/8094-generalized-cross-entropy-loss-for-training-deep-neural-networks-with-noisy-labels.pdf},
}

@Article{Zhang2020a,
  author  = {Zhang, Xiao and Wu, Dongrui},
  journal = {arXiv preprint arXiv:2001.01072},
  title   = {Empirical studies on the properties of linear regions in deep neural networks},
  year    = {2020},
  file    = {:FILES/2020 - Zhang2020a - Empirical studies on the properties of linear regions in deep neural networks.pdf:PDF},
  groups  = {Neural Network},
  url     = {https://arxiv.org/abs/2001.01072#:~:text=Empirical Studies on the Properties of Linear Regions,linear regions, where different linear functions are fitted.},
}

@InProceedings{Zhao2013firGA,
  author     = {Zhao, H. and Ye, W. B. and Yu, Y. J.},
  booktitle  = {2013 IEEE International Symposium on Circuits and Systems (ISCAS)},
  title      = {Sparse {FIR} filter design based on genetic algorithm},
  year       = {2013},
  month      = {5},
  pages      = {97--100},
  abstract   = {Sparse patterns for digital filters have been suggested to reduce the computational cost. However, the minimization of the number of non-zero coefficients under required filter order and frequency domain constraints is difficult to be accomplished in polynomial time in many cases. In this paper, a two-stage design based on Genetic Algorithm (GA) is proposed to search for the optimal solution with a given specification. A preliminary optimization stage is introduced to enhance the efficiency of the proposed GA. The proposed algorithm is evaluated through two sets of examples, which generate better results than existing algorithms.},
  doi        = {10.1109/ISCAS.2013.6571791},
  file       = {:FILES/2013 - Zhao2013firGA - Sparse FIR filter design based on Genetic Algorithm.pdf:PDF},
  groups     = {genetic algorithms, sparse},
  issn       = {2158-1525},
  keywords   = {costing;FIR filters;frequency-domain analysis;genetic algorithms;network synthesis;polynomials;sparse FIR filter design;genetic algorithm;digital filter;nonzero coefficient;frequency domain constraint;filter order constraint;polynomial time;GA;two-stage design;preliminary optimization stage;Genetic algorithms;Biological cells;Algorithm design and analysis;Optimization;Finite impulse response filters;Indexes;Sociology, read},
  readstatus = {read},
  timestamp  = {2020-06-05},
}

@Article{zhao2018semi,
  author    = {Zhao, Jian and Li, Yihao and Zhang, Fengdeng and Zhu, Songming and Liu, Ying and Lu, Huanda and Ye, Zhangying},
  journal   = {Transactions of the ASABE},
  title     = {Semi-supervised learning-based live fish identification in aquaculture using modified deep convolutional generative adversarial networks},
  year      = {2018},
  number    = {2},
  pages     = {699--710},
  volume    = {61},
  file      = {:FILES/2018 - zhao2018semi - Semi-supervised learning-based live fish identification in aquaculture using modified deep convolutional generative adversarial networks.pdf:PDF},
  groups    = {Neural Network},
  timestamp = {2020-08-31},
}

@InProceedings{zheng2017fir,
  author     = {Zheng, L. and Jiang, Aimin and Kwan, Hon Keung},
  booktitle  = {2017 IEEE International Symposium on Circuits and Systems (ISCAS)},
  title      = {Sparse {FIR} filter design via partial {L1} optimization},
  year       = {2017},
  month      = {5},
  pages      = {1--4},
  abstract   = {In this paper, a new algorithm is proposed for the design of sparse FIR filters. Traditional l1-optimization-based methods take all the coefficients into l1-norm minimization. However, it is unnecessary since some of them can only take nonzero values to satisfy design specifications. Furthermore, minimizing l1 norm of all the coefficients could drive the design results to deviate from the optimal ones. The proposed algorithm aims to identify nonzero coefficients at some crucial positions in each iteration to minimize the number of nonzero coefficients. Simulation results demonstrate that the proposed algorithm can achieve better design results than traditional l1-optimization methods.},
  doi        = {10.1109/ISCAS.2017.8050776},
  file       = {:FILES/2017 - zheng2017fir - Sparse FIR filter design via partial L1 optimization.pdf:PDF},
  groups     = {sparse},
  issn       = {2379-447X},
  keywords   = {FIR filters;logic design;minimisation;sparse FIR filter design;partial L1 optimization;l1-norm minimization;nonzero coefficients;Finite impulse response filters;Algorithm design and analysis;Minimization;Passband;Signal processing algorithms;Approximation algorithms;Optimization, read},
  readstatus = {read},
}

@Article{zheng2018reducibility,
  author    = {Zheng, Yue and Zhang, Guangquan and Zhang, Zhen and Lu, Jie},
  journal   = {Information Sciences},
  title     = {A reducibility method for the weak linear bilevel programming problems and a case study in principal-agent},
  year      = {2018},
  pages     = {46--58},
  volume    = {454},
  file      = {:FILES/2018 - zheng2018reducibility - A reducibility method for the weak linear bilevel programming problems and a case study in principal-agent.pdf:PDF},
  groups    = {bilinear},
  publisher = {Elsevier},
}

@Article{Zhou2003mv,
  author    = {Zhou, Xun Yu and Yin, George},
  journal   = {SIAM Journal on Control and Optimization},
  title     = {Markowitz's mean-variance portfolio selection with regime switching: {A} continuous-time model},
  year      = {2003},
  number    = {4},
  pages     = {1466--1482},
  volume    = {42},
  groups    = {mean variance},
  timestamp = {2020-09-04},
  type      = {Journal Article},
}

@InCollection{zhu20041,
  author    = {Zhu, Ji and Rosset, Saharon and Tibshirani, Robert and Hastie, Trevor J.},
  booktitle = {Advances in neural information processing systems 16},
  publisher = {MIT Press},
  title     = {1-norm support vector machines},
  year      = {2004},
  pages     = {49--56},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@Article{zhu2010pwl,
  author  = {Ying Zhu and Qiyue Liu and Wenxiang Lv and Yongheng Jiang and Dexian Huang},
  journal = {Journal of Chemical Industry and Engineering},
  title   = {Inferential estimation of kerosene dry point via piecewise linear approximation},
  year    = {2010},
  pages   = {2035--2039},
  groups  = {application},
  issue   = {8},
}

@Article{zou2008fo,
  author    = {Zou, Hui and Yuan, Ming},
  journal   = {Statistica Sinica},
  title     = {The $F_\infty$ norm support vector machine},
  year      = {2008},
  pages     = {379--398},
  volume    = {18},
  groups    = {SVM},
  timestamp = {2020-08-30},
}

@Article{Zalinescu2019,
  author    = {Z\v{a}linescu, C.},
  journal   = {Optimization},
  title     = {On unconstrained optimization problems solved using the canonical duality and triality theories},
  year      = {2019},
  pages     = {1--26},
  file      = {:FILES/2019 - Zalinescu2019 - On unconstrained optimization problems solved using the canonical duality and triality theories.pdf:PDF},
  groups    = {LSEO, mathematical basis},
  publisher = {Taylor \& Francis},
  timestamp = {2020-08-31},
}

@Article{zwart1973nonlinear,
  author    = {Zwart, Philip B},
  journal   = {Operations Research},
  title     = {Nonlinear programming: {Counterexamples} to two global optimization algorithms},
  year      = {1973},
  number    = {6},
  pages     = {1260--1266},
  volume    = {21},
  groups    = {global optimization},
  publisher = {INFORMS},
}

@InProceedings{Baran2007,
  author    = {Baran, T. A. and Oppenheim, A. V.},
  booktitle = {2007 Conference Record of the Forty-First Asilomar Conference on Signals, Systems and Computers},
  title     = {Design and implementation of discrete-time filters for efficient rate-conversion systems},
  year      = {2007},
  month     = {11},
  pages     = {1088--1092},
  abstract  = {Oversampled A-to-D converters commonly rely on sharp-cutoff, discrete-time filters that operate at fast input sampling rates. Filter design techniques for such filters typically use the length of the impulse response as an indicator of computational cost, assuming that each filter tap requires a multiplier in Parks, T. W., et al, (1972). This paper describes methods for designing zero-phase filters with sparse impulse responses, i.e., with many zero-valued coefficients, and presents rate-conversion structures for efficiently implementing these designs. By combining polyphase methods and delay-line folding, the structures presented require only one multiplier for each unique value in the impulse response of the filter.},
  doi       = {10.1109/ACSSC.2007.4487390},
  groups    = {FIR filter design},
  issn      = {1058-6393},
  keywords  = {analogue-digital conversion;discrete time filters;transient response;discrete-time filters;rate-conversion systems;A-to-D converters;filter design techniques;zero-phase filters;sparse impulse responses;zero-valued coefficients;rate-conversion structures;polyphase methods;delay-line folding;Finite impulse response filter;Computational efficiency;Algorithm design and analysis;Digital filters;Design methodology;Design optimization;Nonlinear filters;Signal design;Digital signal processing;Signal sampling},
  timestamp = {2020-08-07},
}

@Article{Boudreaux1983,
  author    = {Boudreaux, G. and Parks, T.},
  journal   = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  title     = {Thinning digital filters: {A} piecewise-exponential approximation approach},
  year      = {1983},
  issn      = {0096-3518},
  month     = {2},
  number    = {1},
  pages     = {105--113},
  volume    = {31},
  abstract  = {An algorithm is presented for designing finite impulse response (FIR) recursive digital filters that require few multiplies to produce good frequency response, The process of reducing the number of multiplies needed to implement a digital filter is called thinning. This thinning algorithm uses dynamic programming techniques to find the best least-squares piecewise-exponential approximation to a desired impulse response of length P. Because these filters are implemented recursively, the number of arithmetic operations is independent of the model filter length P and is dependent only on the number of pieces or segments S used in the approximation (S \ll P). Examples of thinned narrow-band, broad-band, lowpass, and bandpass filters are given. Several of these thinned filters require fewer than one-third the number of multiplications required for the corresponding model filter, while still retaining desirable frequency response characteristics. The effects of coefficient quantization and finite precision arithmetic are also discussed.},
  doi       = {10.1109/TASSP.1983.1164058},
  groups    = {FIR filter design, sparse},
  keywords  = {Digital filters;Finite impulse response filter;Band pass filters;Frequency response;Arithmetic;Algorithm design and analysis;Approximation algorithms;Heuristic algorithms;Dynamic programming;Narrowband},
  timestamp = {2020-08-07},
}

@InProceedings{Chen2018,
  author    = {Chen, W. and Huang, M. and Lou, X.},
  booktitle = {2018 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS)},
  title     = {A branch-and-bound algorithm with reduced search space for sparse filter design},
  year      = {2018},
  month     = {10},
  pages     = {329--332},
  abstract  = {This paper presents a branch-and-bound algorithm with reduced search space for sparse FIR filter design. To estimate the possibilities of zero positions, the second-order zero coefficients combinations are evaluated. The search space is reduced by keeping the potential zero positions (with high probabilities) and removing the non-potential positions (with low probabilities). The reduced search space is applied in branch-and- bound algorithm to heuristically search for the sparse solutions. A weighted least squares (WLS) technique for quasi equiripple design is further proposed to efficiently solve the subproblems in branch-and-bound search. Simulation results demonstrate the effectiveness of the proposed algorithm.},
  doi       = {10.1109/APCCAS.2018.8605638},
  groups    = {sparse},
  keywords  = {FIR filters;least squares approximations;reduced search space;sparse filter design;sparse FIR filter design;second-order zero coefficients combinations;potential zero positions;nonpotential positions;branch-and-bound search;Asia;Conferences;Circuits and systems;Sparse FIR filter;branch-and-bound;weighted least squares (WLS) technique;quasi equiripple design},
  timestamp = {2020-08-07},
}

@InProceedings{Chen2018a,
  author    = {Chen, W. and Huang, M. and Lou, X.},
  booktitle = {2018 IEEE 23rd International Conference on Digital Signal Processing (DSP)},
  title     = {Sparse {FIR} filter design based on interpolation technique},
  year      = {2018},
  month     = {11},
  pages     = {1--5},
  abstract  = {In this paper, a design method based on interpolation technique is proposed to design narrow-band sparse FIR filters and centrosymmetric bandpass filters. The design method is realized by cascading a model filter with a masking filter. The model filter is first designed and then interpolated to generate the desired impulse response replica. A sparse masking filter is used to mask the extra unwanted passbands. Unlike the interpolated FIR filter technique, both subfilters are designed as sparse filters by multiplierless algorithms to improve the overall sparsity of the filter. Simulation results show that the proposed cascaded realization of FIR filters results a significant improvement of sparsity than the conventional direct form or transposed direct form. It is also shown that the proposed method generates sparser solutions than the interpolated FIR filter technique due to the sparse design of subfilters.},
  doi       = {10.1109/ICDSP.2018.8631685},
  groups    = {sparse},
  issn      = {2165-3577},
  keywords  = {FIR filters;interpolation;transient response;interpolated FIR filter technique;sparse filters;sparse design;sparse FIR filter design;interpolation technique;narrow-band sparse FIR filters;centrosymmetric bandpass filters;model filter;sparse masking filter;Finite impulse response filters;Passband;Delays;Interpolation;Design methodology;Band-pass filters;Approximation algorithms;Interpolation technique;sparse FIR filters;centrosymmetric bandpass filters;cascaded realization},
  timestamp = {2020-08-07},
}

@InProceedings{Chen2019,
  author    = {Chen, W. and Huang, M. and Lou, X.},
  booktitle = {2019 IEEE International Symposium on Circuits and Systems (ISCAS)},
  title     = {Sparse {FIR} filter design based on cascaded compensation structure},
  year      = {2019},
  month     = {5},
  pages     = {1--5},
  abstract  = {In this paper, a sparse FIR filter design method based on cascaded compensation structure is proposed. The proposed method is a two-stage filter design approach with novel attenuation and transition controls of the subfllters. The model filter is elaborately designed with decreasing stopband attenuation to improve the sparsity of the filter. A compensating filter with careful transition band and stopband design is cascaded with the model filter to compensate the decreasing stopband attenuation of the model filter so as to synthesize the desired uniform attenuation. Simulation results show that the proposed cascaded compensation design of sparse FIR filters leads to a significant improvement of sparsity than the exiting conventional direct form or transposed direct form filter designs.},
  doi       = {10.1109/ISCAS.2019.8702703},
  groups    = {sparse},
  issn      = {2158-1525},
  keywords  = {filtering theory;FIR filters;compensating filter;stopband design;cascaded compensation design;cascaded compensation structure;sparse FIR filter design method;two-stage filter design approach;attenuation control;transition control;transition band;model filter design;Finite impulse response filters;Low pass filters;Band-pass filters;Filtering algorithms;Attenuation;Approximation error;Passband;Sparse FIR filters;Compensation structure;Nonuniform attenuation;Cascaded realization},
  timestamp = {2020-08-07},
}

@Article{Liang1985,
  author    = {Liang, Junn-Kuen and de Figueiredo, R. and Lu, F.},
  journal   = {IEEE Transactions on Circuits and Systems},
  title     = {Design of optimal {Nyquist}, partial response, {nth} band, and nonuniform tap spacing {FIR} digital filters using linear programming techniques},
  year      = {1985},
  issn      = {1558-1276},
  month     = {4},
  number    = {4},
  pages     = {386--392},
  volume    = {32},
  abstract  = {The design of a (FIR) finite-impulse-response digital filter with some of the coefficients constrained to zero is formulated as a linear programming (LP) problem and the Steiglitz's program [1] is modified and then used to design a class of constrained FIR digital filters. This class includes pulse shaping filters,Nth band filters and nonuniform tap spacing filters, where some of the filter coefficients are constrained to zero. The advantage of the present approach, as compared to other methods, with regard to design speed and filter optimality and performance, are described, and illustrated by means of examples.},
  doi       = {10.1109/TCS.1985.1085702},
  groups    = {FIR filter design},
  keywords  = {FIR (finite-duration impulse-response) digital filters;Linear programming;Finite impulse response filter;Digital filters;Linear programming;Low pass filters;Frequency response;Pulse shaping methods;Nonlinear filters;Time factors;Data communication;Filtering},
  timestamp = {2020-08-07},
}

@Article{Lu2016,
  author    = {Lu, W. and Hinamoto, T.},
  journal   = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title     = {A unified approach to the design of interpolated and frequency-response-masking {FIR} filters},
  year      = {2016},
  issn      = {1558-0806},
  month     = {12},
  number    = {12},
  pages     = {2257--2266},
  volume    = {63},
  abstract  = {We present a unified approach to the design of two well-known classes of computationally efficient digital filters, namely the interpolated and frequency-response-masking (FRM) FIR filters, that are optimized in minimax sense. The highly nonconvex minimax designs of these filters are carried out by jointly optimizing the subfilters involved using a convex-concave procedure (CCP) that yields an iterative and converging process where each iteration involves a convex problem of minimizing a linear function subject to convex quadratic constraints. We present an analysis to explain why CCP is well-suited for the design problems at hand. We also show that the CCP-based design framework is flexible to allow extension to the design of FRM filters that simultaneously promotes sparsity of the filter coefficients to reduce implementation complexity. Design examples with comparisons are presented to demonstrate the performance of the proposed design methods.},
  doi       = {10.1109/TCSI.2016.2613880},
  groups    = {FRM},
  keywords  = {concave programming;convex programming;FIR filters;frequency response;interpolation;iterative methods;minimax techniques;minimisation;quadratic programming;frequency-response-masking FIR filters;interpolated FIR filters;digital filter design;FRM FIR filters;nonconvex minimax designs;convex-concave procedure;converging process;iterative process;convex quadratic constraints;linear function minimization;CCP-based design framework;filter coefficient sparsity;minimax optimization;Finite impulse response filters;Design methodology;Linear programming;Convex functions;Transfer functions;Frequency-domain analysis;Passband;Convex-concave procedure;frequency-response-masking FIR filters;interpolated FIR filters},
  timestamp = {2020-08-07},
}

@InProceedings{Naseer2016,
  author    = {Naseer, Muzammal and Harb, Kamal and Nuseirat, Ahmad},
  booktitle = {The Eighth International Conference on Advances in Satellite and Space Communications (SPACOMM 2016)},
  title     = {The design of sparse and non-sparse {FIR} filters using linear complementarity problem approach},
  year      = {2016},
  month     = {02},
  pages     = {7--12},
  file      = {:FILES/2016 - Naseer2016 - The Design of Sparse and Non-Sparse FIR Filters using Linear Complementarity Problem Approach.pdf:PDF},
  groups    = {complementary problem},
  timestamp = {2020-08-07},
}

@Article{Shi2011,
  author    = {Shi, Dong and Yu, Ya Jun},
  journal   = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title     = {Design of discrete-valued linear phase {FIR} filters in cascade form},
  year      = {2011},
  issn      = {1558-0806},
  month     = {7},
  number    = {7},
  pages     = {1627--1636},
  volume    = {58},
  abstract  = {Digital filters in cascade form enjoy many advantages over their equivalent single-stage realizations in that lower coefficient sensitivity, higher throughput, reduced computational and smaller implementation cost can be achieved. However, the numerical design and optimization of such structure are of much more difficulty than the single-stage case if the filter coefficients are restricted to be of discrete values. This is mainly due to the non-convexity of the constraints, which rules out the possibility of employing sophisticated convex optimization techniques as well as the guaranteed global optimality. In this work, a general-purpose algorithm is proposed for the design of linear phase finite impulse response (FIR) filters in cascade form with discrete coefficients. The proposed algorithm decomposes the overall filter into subfilters during the traverse of a tree search of the overall filter. Discrete-valued linear phase FIR filters are able to be searched and decomposed into both symmetric and non-symmetric subfilters. The optimization complexity is of the same order as the single-stage filter optimization. Design examples have shown that the proposed algorithm is capable of achieving notable reduction in both implementation cost and adder depth compared with their single-stage optimum designs.},
  doi       = {10.1109/TCSI.2011.2143250},
  file      = {:FILES/2011 - Shi2011 - Design of discrete-valued linear phase {FIR} filters in cascade form.pdf:PDF},
  groups    = {discrete},
  keywords  = {cascade systems;convex programming;FIR filters;linear phase filters;tree searching;discrete-valued linear phase FIR filters;digital filters;cascade form;numerical design;convex optimization;finite impulse response filters;tree search;optimization complexity;single-stage filter optimization;Finite impulse response filter;Algorithm design and analysis;Adders;Optimization;Convolution;Frequency response;Maximum likelihood detection;Cascade form;digital filters;linear phase;linear programming;subexpression space},
  timestamp = {2020-08-07},
}

@InProceedings{Smith1981,
  author    = {Smith, M. and Farden, D.},
  booktitle = {ICASSP '81. IEEE International Conference on Acoustics, Speech, and Signal Processing},
  title     = {Thinning the impulse response of {FIR} digital filters},
  year      = {1981},
  month     = {3},
  pages     = {240--242},
  volume    = {6},
  abstract  = {The design and performance of finite duration impulse response (FIR) digital filters with nonuniform tap spacings is examined. It is shown that a reduction in filter order can be achieved with a relatively small sacrifice in performance by thinning a high order uniformly spaced impulse response. The process of optimally selecting the tap spacings to minimize the statistical mean-squared estimation error is discussed and alternative procedures for implementation of the selection mechanism are mentioned. The results apply to more general estimation problems where control can be exercised over the selection of data to be incorporated into the estimator structure.},
  doi       = {10.1109/ICASSP.1981.1171101},
  groups    = {FIR filter design},
  keywords  = {Finite impulse response filter;Digital filters;Delay estimation;Estimation error;Least squares methods;Signal processing;Design engineering;Process design;Least squares approximation;Sampling methods},
  timestamp = {2020-08-07},
}

@Article{Ye2014,
  author    = {Ye, W. B. and Yu, Y. J.},
  journal   = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title     = {Bit-level multiplierless {FIR} filter optimization incorporating sparse filter technique},
  year      = {2014},
  issn      = {1558-0806},
  month     = {11},
  number    = {11},
  pages     = {3206--3215},
  volume    = {61},
  abstract  = {Multiplierless FIR filter optimization has been extensively studied in the past decades to minimize the number of adders. A more accurate measurement of the implementation complexity is the number of full adders counted at bit-level. However, the high computational complexity of the optimization at bit-level hinders the technique from practical applications. In this paper, the sparse filter technique is exploited and makes the search space at bit-level significantly reduced. Thus, the bit-level optimization of multiplierless FIR filters for the first time becomes possible. When the sparse filter technique is employed for the multiplierless filter design, the sparsity of the filter is properly controlled so that the feasibility of the bit-level optimization in discrete space is maintained. Thereafter, in the reduced search space, a tree search algorithm is formulated at bit-level, and techniques to estimate the bit level hardware cost and to accelerate the search are presented. Design examples show that the proposed bit-level optimization method generates designs with lower hardware cost and power consumption than that of the best word-level optimization methods, while the design time is still at an acceptable level. The average power savings to 3 recent published techniques are 13.6\%, 8.0\% and 26.1\%, respectively.},
  doi       = {10.1109/TCSI.2014.2327287},
  groups    = {sparse},
  keywords  = {adders;circuit optimisation;computational complexity;FIR filters;power consumption;tree searching;finite impulse response filter;bit-level multiplierless FIR filter optimization;sparse filter technique;adders;computational complexity;multiplierless filter design;search space;tree search algorithm;bit level hardware cost;bit-level optimization method;power consumption;power savings;Finite impulse response filters;Optimization;Adders;Hardware;Algorithm design and analysis;Passband;Power demand;Bit-level optimization;finite impulse response (FIR);multiplierless;sparsity},
  timestamp = {2020-08-07},
}

@Article{Yiu2013,
  author    = {Yiu, K. F.C. and Gao, M. J. and Shiu, T. J. and Wu, S. Y. and Tran, T. and Claesson, I.},
  journal   = {Optimization Methods and Software},
  title     = {A fast algorithm for the optimal design of high accuracy windows in signal processing},
  year      = {2013},
  number    = {4},
  pages     = {900--916},
  volume    = {28},
  abstract  = {This paper presents a new optimal window design method with a general window design specification for the passband and stopband. The design problem is formulated as a semi-infinite linear programming problem. With suitable discretizations, an exchange algorithm is employed. The convergence of the proposed algorithm is established. In the formulation, since the stopband is minimized, the method can be employed for the design of very highly optimized windows.},
  doi       = {10.1080/10556788.2012.681659},
  eprint    = {https://doi.org/10.1080/10556788.2012.681659},
  groups    = {window design},
  publisher = {Taylor \& Francis},
  timestamp = {2020-08-07},
  url       = {https://doi.org/10.1080/10556788.2012.681659},
}

@Article{Feng2015,
  author     = {Mingbin Feng and Andreas W{\"{a}}chter and Jeremy Staum},
  journal    = {Quantitative Finance Letters},
  title      = {Practical algorithms for value-at-risk portfolio optimization problems},
  year       = {2015},
  number     = {1},
  pages      = {1--9},
  volume     = {3},
  abstract   = {This article compares algorithms for solving portfolio optimization problems involving value-at-risk (VaR). These problems can be formulated as mixed integer programs (MIPs) or as chance-constrained mathematical programs (CCMPs). We propose improvements to their state-of-the-art MIP formulations. We also specialize an algorithm for solving general CCMPs, featuring practical interpretations. We present numerical experiments on practical-scale VaR problems using various algorithms and provide practical advice for solving these problems.},
  comment    = {discuss the value of M in MILP formulation, and propose a modified BB algorithm originated from chance constrained problems.},
  doi        = {10.1080/21649502.2014.995214},
  eprint     = {https://doi.org/10.1080/21649502.2014.995214},
  file       = {:FILES/2015 - Feng2015 - Practical algorithms for value-at-risk portfolio optimization problems.pdf:PDF},
  groups     = {VaR},
  keywords   = {skimmed},
  publisher  = {Taylor \& Francis},
  readstatus = {skimmed},
  timestamp  = {2020-09-06},
  url        = {https://doi.org/10.1080/21649502.2014.995214},
}

@Article{Cesarone2015,
  author    = {Cesarone, Francesco and Scozzari, Andrea and Tardella, Fabio},
  journal   = {Computational Management Science},
  title     = {Linear vs. quadratic portfolio selection models with hard real-world constraints},
  year      = {2015},
  issn      = {1619-6988},
  month     = jul,
  number    = {3},
  pages     = {345--370},
  volume    = {12},
  abstract  = {Several risk–return portfolio models take into account practical limitations on the number of assets to be included in the portfolio and on their weights. We present here a comparative study, both from the efficiency and from the performance viewpoint, of the Limited Asset Markowitz (LAM), the Limited Asset mean semi-absolute deviation (LAMSAD), and the Limited Asset conditional value-at-risk (LACVaR) models, where the assets are limited with the introduction of quantity and of cardinality constraints.The mixed integer linear LAMSAD and LACVaR models are solved with a state of the art commercial code, while the mixed integer quadratic LAM model is solved both with a commercial code and with a more efficient new method, recently proposed by the authors. Rather unexpectedly, for medium to large sizes it is easier to solve the quadratic LAM model with the new method, than to solve the linear LACVaR and LAMSAD models with the commercial solver. Furthermore, the new method has the advantage of finding all the extreme points of a more general tri-objective problem at no additional computational cost.We compare the out-of-sample performances of the three models and of the equally weighted portfolio. We show that there is no apparent dominance relation among the different approaches and, in contrast with previous studies, we find that the equally weighted portfolio does not seem to have any advantage over the three proposed models. Our empirical results are based on some new and old publicly available data sets often used in the literature.},
  doi       = {10.1007/s10287-014-0210-1},
  file      = {:FILES/2015 - Cesarone2015 - Linear vs. quadratic portfolio selection models with hard real-world constraints.pdf:PDF},
  groups    = {VaR, mean variance, TEC},
  publisher = {Springer Science and Business Media LLC},
  timestamp = {2020-09-05},
  url       = {http://dx.doi.org/10.1007/s10287-014-0210-1},
}

@Book{Mansini2015,
  author    = {Mansini, Renata and Ogryczak, Włodzimierz and Grazia, M.},
  publisher = {Springer International Publishing},
  title     = {Linear and mixed integer programming for portfolio optimization},
  year      = {2015},
  isbn      = {978-3-319-18481-4},
  series    = {EURO Advanced Tutorials on Operational Research},
  file      = {:FILES/2015 - Mansini2015 - Linear and mixed integer programming for portfolio optimization.pdf:PDF},
  groups    = {VaR, Portfolio Selection},
  timestamp = {2020-09-04},
}

@Article{Romero2014,
  author    = {Romero, Pilar Abad and Muela, Sonia Benito and Martin, Carmen L\'{o}pez},
  journal   = {The Spanish Review of Financial Economics},
  title     = {A comprehensive review of value at risk methodologies},
  year      = {2014},
  issn      = {2173-1268},
  number    = {1},
  pages     = {15 -- 32},
  volume    = {12},
  abstract  = {In this article we present a theoretical review of the existing literature on Value at Risk (VaR) specifically focussing on the development of new approaches for its estimation. We effect a deep analysis of the State of the Art, from standard approaches for measuring VaR to the more evolved, while highlighting their relative strengths and weaknesses. We will also review the backtesting procedures used to evaluate VaR approach performance. From a practical perspective, empirical literature shows that approaches based on the Extreme Value Theory and the Filtered Historical Simulation are the best methods for forecasting VaR. The Parametric method under skewed and fat-tail distributions also provides promising results especially when the assumption that standardised returns are independent and identically distributed is set aside and when time variations are considered in conditional high-order moments. Lastly, it appears that some asymmetric extensions of the CaViaR method provide results that are also promising.},
  doi       = {https://doi.org/10.1016/j.srfe.2013.06.001},
  file      = {:FILES/2014 - Romero2014 - A Comprehensive Review of Value at Risk Methodologies.pdf:PDF},
  groups    = {VaR},
  keywords  = {Value at Risk, Volatility, Risk management},
  timestamp = {2020-09-04},
  url       = {http://www.sciencedirect.com/science/article/pii/S217312681300017X},
}

@Article{Acerbi2002,
  author    = {Acerbi, Carlo and Tasche, Dirk},
  journal   = {Economic Notes},
  title     = {Expected shortfall: {A} natural coherent alternative to value at risk},
  year      = {2002},
  number    = {2},
  pages     = {379--388},
  volume    = {31},
  abstract  = {We discuss the coherence properties of expected shortfall (ES) as a financial risk measure. This statistic arises in a natural way from the estimation of the ‘average of the 100\% worst losses’ in a sample of returns to a portfolio. Here p is some fixed confidence level. We also compare several alternative representations of ES which turn out to be more appropriate for certain purposes (J.E.L.: G20, C13, C14).},
  doi       = {10.1111/1468-0300.00091},
  eprint    = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1468-0300.00091},
  file      = {:FILES/2002 - Acerbi2002 - Expected shortfall - a natural coherent alternative to value at risk.pdf:PDF},
  groups    = {VaR, utility theory},
  timestamp = {2020-09-05},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1468-0300.00091},
}

@Article{Adler2007,
  author    = {Adler, Timothy and Kritzman, Mark},
  journal   = {Journal of Asset Management},
  title     = {Mean--variance versus full-scale optimisation: {In} and out of sample},
  year      = {2007},
  issn      = {1479-179X},
  month     = {1},
  number    = {5},
  pages     = {302--311},
  volume    = {7},
  abstract  = {We present a recent innovation to portfolio construction called full-scale optimisation. In contrast to mean--variance analysis, which assumes that returns are normally distributed or that investors have quadratic utility, full-scale optimisation identifies the optimal portfolio given any set of return distributions and any description of investor preferences. It therefore yields the truly optimal portfolio in sample, whereas mean--variance analysis provides an approximation to the in-sample truth. Both approaches, however, suffer from estimation error. We employ a bootstrapping procedure to compare the estimation error of full-scale optimisation to the combined approximation and estimation error of mean--variance analysis. We find that, to a significant degree, the in-sample superiority of full-scale optimisation prevails out of sample.},
  day       = {01},
  doi       = {10.1057/palgrave.jam.2250042},
  file      = {:FILES/2007 - Adler2007 - Mean–variance versus full-scale optimisation In and out of sample.pdf:PDF},
  groups    = {VaR, mean variance},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1057/palgrave.jam.2250042},
}

@Article{AlfaroCid2011,
  author    = {Alfaro-Cid, Eva and Baixauli-Soler, J. Samuel and Fernandez-Blanco, Matilde O.},
  journal   = {International Journal of Risk Assessment and Management},
  title     = {Minimising value-at-risk in a portfolio optimisation problem using a multi-objective genetic algorithm},
  year      = {2011},
  month     = {11},
  number    = {5/6},
  pages     = {453--477},
  volume    = {15},
  abstract  = {In this paper, we develop a general framework for market risk optimisation that focuses on VaR. The reason for this choice is the complexity and problems associated with risk return optimisation (non-convex and non-differential objective function). Our purpose is to obtain VaR efficient frontiers using a multi-objective genetic algorithm (GA) and to show the potential utility of the algorithm to obtain efficient portfolios when the risk measure does not allow calculating an optimal solution. Furthermore, we measure differences between VaR efficient frontiers and variance efficient frontiers in VaR-return space and we evaluate out-sample capacity of portfolios on both bullish and bearish markets. The results indicate the reliability of VaR-efficient portfolios on both bullish and bearish markets and a significant improvement over Markowitz efficient portfolios in the VaR-return space. The improvement decreases as the portfolios level of risk increases. In this particular case, efficient portfolios do not depend on the risk measure minimised.},
  day       = {14},
  doi       = {10.1504/IJRAM.2011.043701},
  file      = {:FILES/2011 - AlfaroCid2011 - Minimizing Value-at-Risk in a portfolio optimization problem using a multiobjective genetic algorithm.pdf:PDF},
  groups    = {VaR, TEC},
  keywords  = {artificial intelligence; investment criteria; portfolio selection; genetic algorithms; value at risk; VaR; market risk; risk minimisation; portfolio optimisation; multi-objective algorithms; complexity; risk return; on-convex objective functions; non-differential objective functions; efficient portfolios; optimal solutions; variance efficient frontiers; bull markets; bear markets; Harry Markowitz; stock indices; United States; USA; Canada; Japan; UK; United Kingdom; France; Germany; Spain; Netherlands; Holland; Sweden; risk assessment; risk management.},
  timestamp = {2020-09-05},
  url       = {https://www.inderscience.com/info/inarticle.php?artid=43701},
}

@Article{Angelidis2007,
  author    = {Angelidis, Timotheos and Benos, Alexandros and Degiannakis, Stavros},
  journal   = {Review of Quantitative Finance and Accounting},
  title     = {A robust {VaR} model under different time periods and weighting schemes},
  year      = {2007},
  issn      = {1573-7179},
  month     = {2},
  number    = {2},
  pages     = {187--201},
  volume    = {28},
  abstract  = {This paper analyses several volatility models by examining their ability to forecast Value-at-Risk (VaR) for two different time periods and two capitalization weighting schemes. Specifically, VaR is calculated for large and small capitalization stocks, based on Dow Jones (DJ) Euro Stoxx indices and is modeled for long and short trading positions by using non parametric, semi parametric and parametric methods. In order to choose one model among the various forecasting methods, a two-stage backtesting procedure is implemented. In the first stage the unconditional coverage test is used to examine the statistical accuracy of the models. In the second stage a loss function is applied to investigate whether the differences between the models, that calculated accurately the VaR, are statistically significant. Under this framework, the combination of a parametric model with the historical simulation produced robust results across the sample periods, market capitalization schemes, trading positions and confidence levels and therefore there is a risk measure that is reliable.},
  day       = {01},
  doi       = {10.1007/s11156-006-0010-y},
  file      = {:FILES/2007 - Angelidis2007 - A Robust VaR Model under Different Time Periods and Weighting Schemes.pdf:PDF},
  groups    = {VaR},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1007/s11156-006-0010-y},
}

@InBook{CobandagGuloglu2017,
  author     = {Cobandag Guloglu, Zeynep and Weber, Gerhard Wilhelm},
  editor     = {Pinto, Alberto and Zilberman, David},
  pages      = {133--145},
  publisher  = {Springer International Publishing},
  title      = {Risk modeling in optimization problems via value at risk, conditional value at risk, and its robustification},
  year       = {2017},
  address    = {Cham},
  isbn       = {978-3-319-55235-4},
  series     = {Springer Proceedings in Mathematics \& Statistics},
  booktitle  = {Modeling, Dynamics, Optimization and Bioeconomics II},
  comment    = {The contributions:
1. compare properties of VaR and CVaR
2. extend results on robust VaR[11] to Robust CVaR
3. offer an optimization method

the focus is on CVaR},
  doi        = {10.1007/978-3-319-55236-1},
  file       = {:FILES/2017 - CobandagGuloglu2017 - Risk Modeling in Optimization Problems via Value at Risk, Conditional Value at Risk, and Its Robustification.pdf:PDF},
  groups     = {VaR, cvar},
  keywords   = {skimmed},
  readstatus = {skimmed},
  timestamp  = {2020-09-06},
  url        = {https://www.springer.com/gp/book/9783319552354},
}

@TechReport{Barendse2019,
  author      = {Barendse, Sander and Kole, Erik and van Dijk, Dick J. C.},
  institution = {Tinbergen Institute Discussion Paper 2019-058/III},
  title       = {Backtesting value-at-risk and expected shortfall in the presence of estimation error},
  year        = {2019},
  month       = {8},
  file        = {:FILES/2019 - Barendse2019 - Backtesting Value-at-Risk and Expected Shortfall in the Presence of Estimation Error.pdf:PDF},
  groups      = {parametric approach},
  keywords    = {skimmed},
  readstatus  = {skimmed},
  timestamp   = {2020-09-06},
  url         = {http://dx.doi.org/10.2139/ssrn.3439309},
}

@Misc{Biswas2019,
  author        = {Biswas, Subhojit and Ghosh, Mrinal K. and Mukherjee, Diganta},
  title         = {Portfolio optimization managing value at risk under heavy tail distribution},
  year          = {2019},
  archiveprefix = {arXiv},
  comment       = {parametric method of computing VaR},
  eprint        = {1908.03905},
  file          = {:FILES/2019 - Biswas2019 - Portfolio Optimization managing Value at Risk under heavy tail distribution.pdf:PDF},
  groups        = {parametric approach},
  primaryclass  = {q-fin.PM},
  timestamp     = {2020-09-06},
}

@Misc{Biswas2019a,
  author        = {Biswas, Subhojit and Mukherjee, Diganta},
  title         = {Portfolio optimization while controlling value at risk, when returns are heavy tailed},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1908.03907},
  file          = {:FILES/2019 - Biswas2019a - Portfolio optimization while controlling Value at Risk, when returns are heavy tailed.pdf:PDF},
  groups        = {parametric approach},
  primaryclass  = {q-fin.PM},
  timestamp     = {2020-09-04},
}

@TechReport{Blazsek2019,
  author      = {Blazsek, Szabolcs and Escribano, Álvaro and Ayala, Astrid},
  institution = {Universidad Carlos III de Madrid. Departamento de Econom{\'{i}}a},
  title       = {Maximum likelihood estimation of score-driven models with dynamic shape parameters: {An} application to {Monte} {Carlo} value-at-risk},
  year        = {2019},
  month       = {7},
  number      = {28638},
  type        = {UC3M Working papers. Economics},
  abstract    = {Dynamic conditional score (DCS) models with time-varying shape parameters provide a exible method for volatility measurement. The new models are estimated by using the maximum likelihood (ML) method, conditions of consistency and asymptotic normality of ML are presented, and Monte Carlo simulation experiments are used to study the precision of ML. Daily data from the Standard \& Poor's 500 (S\&P 500) for the period of 1950 to 2017 are used. The performances of DCS models with constant and dynamic shape parameters are compared. In-sample statistical performance metrics and out-of-sample value-at-risk backtesting support the use of DCS models with dynamic shape.},
  file        = {:FILES/2019 - Blazsek2019 - Maximum likelihood estimation of score-driven models with dynamic shape parameters  an application to Monte Carlo value-at-risk.pdf:PDF},
  groups      = {Monte Carlo},
  keywords    = {Outliers},
  timestamp   = {2020-09-04},
  url         = {https://ideas.repec.org/p/cte/werepe/28638.html},
}

@Misc{Chow2015,
  author        = {Chow, Yinlam and Tamar, Aviv and Mannor, Shie and Pavone, Marco},
  title         = {Risk-sensitive and robust decision-making: {A} {CVaR} optimization approach},
  year          = {2015},
  archiveprefix = {arXiv},
  eprint        = {1506.02188},
  file          = {:FILES/2015 - Chow2015 - Risk-Sensitive and Robust Decision-Making a CVaR Optimization Approach_supplement.pdf:PDF},
  groups        = {cvar},
  primaryclass  = {cs.AI},
  timestamp     = {2020-09-04},
}

@Article{Dallagnol2009,
  author     = {Dallagnol, V. A. F. and Berg, J. and Mous, L.},
  journal    = {International Journal of Intelligent Systems},
  title      = {Portfolio management using value at risk: {A} comparison between genetic algorithms and particle swarm optimization},
  year       = {2009},
  number     = {7},
  pages      = {766--792},
  volume     = {24},
  abstract   = {Abstract In this paper, it is shown a comparison of the application of particle swarm optimization and genetic algorithms to portfolio management, in a constrained portfolio optimization problem where no short sales are allowed. The objective function to be minimized is the value at risk calculated using historical simulation where several strategies for handling the constraints of the problem were implemented. The results of the experiments performed show that, generally speaking, the methods are capable of consistently finding good solutions quite close to the best solution found in a reasonable amount of time. In addition, it is demonstrated statistically that the algorithms, on average, do not all consistently achieve the same best solution. PSO turned out to be faster than GA, both in terms of number of iterations and in terms of total running time. However, PSO appears to be much more sensitive to the initial position of the particles than GA. Tests were also made regarding the number of particles needed to solve the problem, and 50 particles/chromosomes seem to be enough for problems up to 20 assets. © 2009 Wiley Periodicals, Inc.},
  doi        = {10.1002/int.20360},
  eprint     = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/int.20360},
  file       = {:FILES/2009 - Dallagnol2009 - Portfolio management using value at risk - A comparison between genetic algorithms and particle swarm optimization.pdf:PDF},
  groups     = {VaR, genetic algorithms, PSO, TEC},
  keywords   = {read},
  readstatus = {read},
  timestamp  = {2020-09-06},
  url        = {https://onlinelibrary.wiley.com/doi/abs/10.1002/int.20360},
}

@MastersThesis{PereiraDomingues2019,
  author    = {Pereira Domingues, Miguel},
  school    = {Universidade do Minho},
  title     = {Backtesting value-at-risk on portfolios of lottery-like stocks},
  year      = {2019},
  month     = {4},
  file      = {:FILES/2019 - PereiraDomingues2019 - backtesting value-at-risk on portfolios of lottery-like stocks.pdf:PDF},
  groups    = {parametric approach},
  timestamp = {2020-09-04},
}

@TechReport{Dyer1981,
  author      = {Dyer, James S. and Sarin, Rakesh K.},
  institution = {Western Management Science Institute},
  title       = {Relative risk aversion},
  year        = {1981},
  month       = {1},
  number      = {310},
  type        = {Working paper},
  file        = {:FILES/1981 - Dyer1981 - Relative risk aversion.pdf:PDF},
  groups      = {Portfolio Selection},
  timestamp   = {2020-09-04},
  url         = {http://economics.mit.edu/files/15026},
}

@Article{Fontana2019,
  author    = {Fontana, Roberto and Luciano, Elisa and Semeraro, Patrizia},
  journal   = {SSRN Electronic Journal},
  title     = {Model risk in credit risk},
  year      = {2019},
  issn      = {1556-5068},
  doi       = {10.2139/ssrn.3556396},
  file      = {:FILES/2019 - Fontana2019 - Model Risk in Credit Risk.pdf:PDF},
  groups    = {Portfolio Selection},
  publisher = {Elsevier BV},
  timestamp = {2020-09-04},
  url       = {http://dx.doi.org/10.2139/ssrn.3556396},
}

@TechReport{Goorbergh1999,
  author      = {Goorbergh, Rob and Vlaar, Peter},
  institution = {Netherlands Central Bank},
  title       = {Value-at-risk analysis of stock returns historical simulation,variance techniques or tail index estimation?},
  year        = {1999},
  type        = {DNB Staff Reports (discontinued)},
  abstract    = {In this paper various Value-at-Risk techniques are applied to the Dutch stock market index AEX and to the Dow Jones Industrial Average. The main conclusion are: (1) Changing volatility over time is the most important characteristic of stock returns when modelling value-at-risk; (2) For low confidence levels, the fat tails of the distribution can best be mod- eled by means of the t-distribution; (3) Tail index estimators are not successful, due to the fact that they can not cope with the volatility clustering phenomenon.},
  file        = {:FILES/1999 - Goorbergh1999 - Value-at-Risk Analysis of Stock Returns Historical Simulation,Variance Techniques or Tail Index Estimation.pdf:PDF},
  groups      = {VaR},
  keywords    = {Value-at-Risk; AEX; Dow Jones; Capital Requirements},
  timestamp   = {2020-09-04},
  url         = {https://EconPapers.repec.org/RePEc:dnb:staffs:40},
}

@Misc{He2019,
  author        = {He, Zhijian},
  title         = {Sensitivity estimation of conditional value at risk using randomized {quasi-monte carlo}},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1908.07232},
  file          = {:FILES/2019 - He2019 - Sensitivity estimation of conditional value at risk using randomized quasi-Monte Carlo.pdf:PDF},
  groups        = {cvar},
  primaryclass  = {math.NA},
  timestamp     = {2020-09-04},
}

@Article{Hsieh2020,
  author    = {Hsieh, C. and Barmish, B. R. and Gubner, J. A.},
  journal   = {IEEE Transactions on Automatic Control},
  title     = {On positive solutions of a delay equation arising when trading in financial markets},
  year      = {2020},
  issn      = {1558-2523},
  month     = {7},
  number    = {7},
  pages     = {3143--3149},
  volume    = {65},
  abstract  = {We consider a discrete-time linear state equation with delay, which arises as a model for a trader's account value when buying and selling a risky asset in a financial market. The state equation includes a nonnegative feedback gain $\alpha$ and a sequence $v(k)$, which models asset returns that are within known bounds but otherwise arbitrary. We introduce two thresholds, $\alpha _-$ and $\alpha _+$, depending on these bounds, and prove that for $\alpha < \alpha _-$, state positivity is guaranteed for all time and all asset-return sequences, i.e., bankruptcy is ruled out and positive solutions of the state equation are continuable indefinitely. On the other hand, for $\alpha > \alpha _+$, we show that there is always a sequence of asset returns for which the state fails to be positive for all time, i.e., along this sequence, bankruptcy occurs and the solution of the state equation ceases to be meaningful after some finite time. Finally, this article also includes a conjecture, which says that for the “gap” interval $\alpha _- \leq \alpha \leq \alpha _+,$ state positivity is also guaranteed for all time. Support for the conjecture, both theoretical and computational, is provided.},
  doi       = {10.1109/TAC.2019.2945885},
  file      = {:FILES/2020 - Hsieh2020 - On Positive Solutions of a Delay Equation Arising When Trading in Financial Markets.pdf:PDF},
  groups    = {Portfolio Selection},
  keywords  = {Mathematical model;Delays;Bankruptcy;Difference equations;Currencies;Eigenvalues and eigenfunctions;Financial engineering;stochastic systems;time-varying systems;uncertain systems},
  timestamp = {2020-09-04},
}

@Misc{Hu2019,
  author        = {Hu, Wentao},
  title         = {Calculation worst-case value-at-risk prediction using empirical data under model uncertainty},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1908.00982},
  file          = {:FILES/2019 - Hu2019 - Calculating worst-case Value-at-Risk prediction using empirical data under model uncertainty.pdf:PDF},
  groups        = {VaR},
  primaryclass  = {q-fin.RM},
  timestamp     = {2020-09-04},
}

@Article{Kouri2020,
  author    = {Kouri, Drew P. and Surowiec, Thomas M.},
  journal   = {Mathematics of Operations Research},
  title     = {Epi-regularization of risk measures},
  year      = {2020},
  number    = {2},
  pages     = {774--795},
  volume    = {45},
  abstract  = {Uncertainty pervades virtually every branch of science and engineering, and in many disciplines, the underlying phenomena can be modeled by partial differential equations (PDEs) with uncertain or random inputs. This work is motivated by risk-averse stochastic programming problems constrained by PDEs. These problems are posed in infinite dimensions, which leads to a significant increase in the scale of the (discretized) problem. In order to handle the inherent nonsmoothness of, for example, coherent risk measures and to exploit existing solution techniques for smooth, PDE-constrained optimization problems, we propose a variational smoothing technique called epigraphical (epi-)regularization. We investigate the effects of epi-regularization on the axioms of coherency and prove differentiability of the smoothed risk measures. In addition, we demonstrate variational convergence of the epi-regularized risk measures and prove the consistency of minimizers and first-order stationary points for the approximate risk-averse optimization problem. We conclude with numerical experiments confirming our theoretical results.},
  doi       = {10.1287/moor.2019.1013},
  eprint    = {https://doi.org/10.1287/moor.2019.1013},
  file      = {:FILES/2020 - Kouri2020 - Epi-Regularization of Risk Measures.pdf:PDF},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1287/moor.2019.1013},
}

@Article{Kumar2012a,
  author    = {Kumar, R. and Bhattacharya, S.},
  journal   = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  title     = {Cooperative search using agents for cardinality constrained portfolio selection problem},
  year      = {2012},
  issn      = {1558-2442},
  month     = {11},
  number    = {6},
  pages     = {1510--1518},
  volume    = {42},
  abstract  = {This paper presents an agent-based model to select an investment portfolio with a restriction on the number of stocks in it. Daily movements of all the stocks in the market for the past few years are assumed to be available. The scheme deploys a federally structured consortium of agents in the stock market at the start of the historical period. Each agent starts with a pseudorandom portfolio and follows individual investment strategies as it walks through the past data. The agents are designed to emulate some of the characteristics of human investors-adjusting the weights of the stocks based on its own attitude toward risk, occasionally dropping and adding stocks to the portfolio, etc. Periodically, the agents share information about their performances and can switch portfolios. A final cardinality constrained portfolio is constructed by consolidating individual portfolios arrived at by the agents working on the historical data of the stocks. When tested in real markets of the U.K. and Japan, the model suggested portfolios that were quite competitive to, and frequently better than, the portfolios suggested by the mean-variance models.},
  comment   = {cardinality constraints},
  doi       = {10.1109/TSMCC.2012.2197388},
  file      = {:FILES/2012 - Kumar2012a - Cooperative Search Using Agents for Cardinality Constrained Portfolio Selection Problem.pdf:PDF},
  groups    = {Portfolio Selection},
  keywords  = {investment;multi-agent systems;stock markets;cooperative search;agent-based model;cardinality constrained portfolio selection problem;investment portfolio selection;federal structured consortium;stock market;pseudorandom portfolio;individual investment strategies;U.K;Japan;Portfolios;Investments;Stock markets;Computational modeling;Current measurement;Multiagent systems;Switches;Agent-based systems;cooperative search;portfolio selection;social learning, prio1},
  priority  = {prio1},
  timestamp = {2020-09-04},
}

@Misc{Light2019,
  author        = {Light, Bar and Perlroth, Andres},
  title         = {The family of alpha,[a,b] stochastic orders: {Risk} vs. expected value},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1908.06398},
  file          = {:FILES/2019 - Light2019 - The Family of Alpha,[a,b] Stochastic Orders Risk vs. Expected Value.pdf:PDF},
  groups        = {Portfolio Selection},
  primaryclass  = {math.PR},
  timestamp     = {2020-09-04},
}

@Article{Linsmeier2000,
  author    = {Linsmeier, Thomas J. and Pearson, Neil D.},
  journal   = {Financial Analysts Journal},
  title     = {Value at risk},
  year      = {2000},
  number    = {2},
  pages     = {47--67},
  volume    = {56},
  abstract  = {This article is a self-contained introduction to the concept and methodology of value at risk (VAR), a recently developed tool for measuring an entity's exposure to market risk. We explain the concept of VAR and then describe in detail the three methods for computing it—historical simulation, the delta-normal method, and Monte Carlo simulation. We also discuss the advantages and disadvantages of the three methods for computing VAR. Finally, we briefly describe stress testing and two alternative measures of market risk.},
  doi       = {10.2469/faj.v56.n2.2343},
  eprint    = {https://doi.org/10.2469/faj.v56.n2.2343},
  file      = {:FILES/2000 - Linsmeier2000 - value at risk.pdf:PDF},
  groups    = {VaR},
  publisher = {Routledge},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.2469/faj.v56.n2.2343},
}

@Article{Lwin2017,
  author     = {Lwin, Khin T. and Qu, Rong and MacCarthy, Bart L.},
  journal    = {European Journal of Operational Research},
  title      = {Mean-{VaR} portfolio optimization: {A} nonparametric approach},
  year       = {2017},
  issn       = {0377-2217},
  number     = {2},
  pages      = {751 -- 766},
  volume     = {260},
  abstract   = {Portfolio optimization involves the optimal assignment of limited capital to different available financial assets to achieve a reasonable trade-off between profit and risk. We consider an alternative Markowitz’s mean–variance model in which the variance is replaced with an industry standard risk measure, Value-at-Risk (VaR), in order to better assess market risk exposure associated with financial and commodity asset price fluctuations. Realistic portfolio optimization in the mean-VaR framework is a challenging problem since it leads to a non-convex NP-hard problem which is computationally intractable. In this work, an efficient learning-guided hybrid multi-objective evolutionary algorithm (MODE-GL) is proposed to solve mean-VaR portfolio optimization problems with real-world constraints such as cardinality, quantity, pre-assignment, round-lot and class constraints. A learning-guided solution generation strategy is incorporated into the multi-objective optimization process to promote efficient convergence by guiding the evolutionary search towards promising regions of the search space. The proposed algorithm is compared with the Non-dominated Sorting Genetic Algorithm (NSGA-II) and the Strength Pareto Evolutionary Algorithm (SPEA2). Experimental results using historical daily financial market data from S \& P 100 and S \& P 500 indices are presented. The results show that MODE-GL outperforms two existing techniques for this important class of portfolio investment problems in terms of solution quality and computational time. The results highlight that the proposed algorithm is able to solve the complex portfolio optimization without simplifications while obtaining good solutions in reasonable time and has significant potential for use in practice.},
  doi        = {https://doi.org/10.1016/j.ejor.2017.01.005},
  file       = {:FILES/2017 - Lwin2017 - mean-var portfolio optimization a nonparametric approach.pdf:PDF},
  groups     = {VaR, TEC},
  keywords   = {Evolutionary computations, Multi-objective constrained portfolio optimization, Value at risk, Nonparametric historical simulation, read},
  readstatus = {read},
  timestamp  = {2020-09-06},
  url        = {http://www.sciencedirect.com/science/article/pii/S0377221717300103},
}

@Article{Gilli2006,
  author    = {Gilli, Manfred and K\"{e}llezi, Evis and Hysi, Hilda},
  journal   = {Journal of Risk},
  title     = {A data-driven optimization heuristic for downside risk minimization},
  year      = {2006},
  month     = {2},
  number    = {3},
  pages     = {1--18},
  volume    = {8},
  abstract  = {In practical portfolio choice models risk is often defined as value-at-risk (VAR), expected shortfall, maximum loss, Omega function, etc, and is computed from simulated future scenarios of the portfolio value. It is well known that the minimization of these functions cannot, in general, be performed with standard methods. We present a multipurpose data-driven optimization heuristic capable of dealing efficiently with a variety of risk functions and practical constraints on the positions in the portfolio. The efficiency and robustness of the heuristic is illustrated by solving a collection of real-world portfolio optimization problems using different risk functions such as VAR, expected shortfall, maximum loss and Omega function with the same algorithm.},
  comment   = {practical constraints. threshold accepting to minimized VaR and expected shortfall},
  doi       = {10.21314/JOR.2006.129},
  file      = {:FILES/2006 - Gilli2006 - A Data-Driven Optimization Heuristic for Downside Risk Minimization.pdf:PDF},
  groups    = {VaR, TEC},
  timestamp = {2020-09-12},
  url       = {https://www.risk.net/journal-of-risk/2161028/a-data-driven-optimization-heuristic-for-downside-risk-minimization},
}

@Article{Meghwani2018,
  author     = {Meghwani, Suraj S. and Thakur, Manoj},
  journal    = {Applied Soft Computing},
  title      = {Multi-objective heuristic algorithms for practical portfolio optimization and rebalancing with transaction cost},
  year       = {2018},
  issn       = {1568-4946},
  pages      = {865 -- 894},
  volume     = {67},
  abstract   = {Portfolio optimization is the process of allocating capital among a universe of assets to achieve better risk–return trade-off. Due to the dynamic nature of financial markets, the portfolio needs to be rebalanced to retain the desired risk–return characteristics. The process of rebalancing requires buying or selling of assets that incur transaction costs. This study proposes a tri-objective portfolio optimization model with risk, return and transaction cost as the objectives. Various practical constraints like cardinality, self-financing, quantity, pre-assignment and cost related constraints are included in the proposed model. Three popular risk measures namely variance, Value-At-Risk (VaR) and Conditional Value-At-Risk (CVaR) are studied in the proposed work. The emphasis of the study is on handling equality constraints like self-financing constraint and the constraints arising from the inclusion of transaction cost models using multi-objective evolutionary algorithms (MOEAs). A novel repair algorithm is proposed that can effectively handle equality constraints without any requirement of any constraint handling technique. The proposed repair algorithm is suitable for a larger class of separable transaction cost model. The theoretical proof is given to ensure the validity of our claim. To verify the effectiveness of the proposed approach three algorithms from different multi-objective evolutionary frameworks are adapted and compared. In empirical study, we discuss the performances of algorithms over both in-sample and out-sample data.},
  doi        = {https://doi.org/10.1016/j.asoc.2017.09.025},
  file       = {:FILES/2018 - Meghwani2018 - Multi-objective heuristic algorithms for practical portfolio optimization and rebalancing with transaction cost.pdf:PDF},
  groups     = {VaR, cvar, multi-objective},
  keywords   = {Multi-objective portfolio optimization, Cardinality constrained portfolio problem, Transaction cost, Repair mechanism, Portfolio rebalancing, Value-At-Risk, Conditional Value-At-Risk, read},
  readstatus = {read},
  timestamp  = {2020-09-04},
  url        = {http://www.sciencedirect.com/science/article/pii/S1568494617305641},
}

@Article{Meng2020,
  author     = {Meng, Xiaochun and Taylor, James W.},
  journal    = {European Journal of Operational Research},
  title      = {Estimating value-at-risk and expected shortfall using the intraday low and range data},
  year       = {2020},
  issn       = {0377-2217},
  number     = {1},
  pages      = {191 -- 202},
  volume     = {280},
  abstract   = {Value-at-Risk (VaR) is a popular measure of market risk. To convey information regarding potential exceedances beyond the VaR, Expected Shortfall (ES) has become the risk measure for trading book bank regulation. However, the estimation of VaR and ES is challenging, as it requires the estimation of the tail behaviour of daily returns. In this paper, we take advantage of recent research that develops joint scoring functions for VaR and ES. Using these functions, we present a novel approach to estimating the two risk measures based on intraday data. We focus on the intraday range, which is the difference between the highest and lowest intraday log prices. In contrast to intraday observations, the intraday low and high are widely available for many financial assets. To alleviate the challenge of modelling extreme risk measures, we propose the use of the intraday low series. We draw on a theoretical result for Brownian motion to show that a quantile of the daily returns can be estimated as the product of a constant term and a less extreme quantile of the intraday low returns, which we define as the difference between the lowest log price of the day and the log closing price of the previous day. In view of this, we use estimates of the VaR and ES of the intraday low returns to estimate the VaR and ES of the daily returns. We provide empirical support for the new proposals using data for five stock indices and five individual stocks.},
  comment    = {It estimates VaR and ES jointly. Improvement on existing methods and some theoretical results. Brief look into.},
  doi        = {https://doi.org/10.1016/j.ejor.2019.07.011},
  file       = {:FILES/2020 - Meng2020 - Estimating Value-at-Risk and Expected Shortfall using the intraday low and range data.pdf:PDF},
  groups     = {parametric approach},
  keywords   = {Finance, Value-at-Risk, Expected Shortfall, Intraday low, Joint scoring functions, skimmed},
  readstatus = {skimmed},
  timestamp  = {2020-09-06},
  url        = {http://www.sciencedirect.com/science/article/pii/S0377221719305752},
}

@Article{Metawa2017,
  author    = {Metawa, Noura and Hassan, M. Kabir and Elhoseny, Mohamed},
  journal   = {Expert Systems with Applications},
  title     = {Genetic algorithm based model for optimizing bank lending decisions},
  year      = {2017},
  issn      = {0957-4174},
  pages     = {75 -- 82},
  volume    = {80},
  abstract  = {To avoid the complexity and time consumption of traditional statistical and mathematical programming, intelligent techniques have gained great attention in different financial research areas, especially in banking decisions’ optimization. However, choosing optimum bank lending decisions that maximize the bank profit in a credit crunch environment is still a big challenge. For that, this paper proposes an intelligent model based on the Genetic Algorithm (GA) to organize bank lending decisions in a highly competitive environment with a credit crunch constraint (GAMCC). GAMCC provides a framework to optimize bank objectives when constructing the loan portfolio, by maximizing the bank profit and minimizing the probability of bank default in a search for a dynamic lending decision. Compared to the state-of-the art methods, GAMCC is considered a better intelligent tool that enables banks to reduce the loan screening time by a range of 12\%–50\%. Moreover, it greatly increases the bank profit by a range of 3.9\%–8.1\%.},
  doi       = {https://doi.org/10.1016/j.eswa.2017.03.021},
  file      = {:FILES/2017 - Metawa2017 - Genetic algorithm based model for optimizing bank lending decisions.pdf:PDF},
  groups    = {genetic algorithms, Portfolio Selection},
  keywords  = {Lending decision, Genetic algorithm, Loan portfolio, Bank objectives},
  timestamp = {2020-09-04},
  url       = {http://www.sciencedirect.com/science/article/pii/S0957417417301677},
}

@Article{Moazeni2015,
  author    = {Moazeni, S. and Powell, W. B. and Hajimiragha, A. H.},
  journal   = {IEEE Transactions on Power Systems},
  title     = {Mean-conditional value-at-risk optimal energy storage operation in the presence of transaction costs},
  year      = {2015},
  issn      = {1558-0679},
  month     = {5},
  number    = {3},
  pages     = {1222--1232},
  volume    = {30},
  abstract  = {This paper addresses the formulation and solution of an optimal energy storage management problem under risk consideration and transaction costs of trading energy with the power grid. The price evolves as a stochastic process, capable of correctly explaining the seasonality effects as well as the tail fatness and spikiness in its distribution. Transaction costs capture the price impact of the storage operation on the electricity spot price. A risk analysis of an optimal risk neutral deterministic policy as well as the simple myopic policy indicates that the realized operational cost may notably differ from the expected cost by a considerable probability. This difference suggests that we need to consider risk. Using the downside risk measure of conditional value-at-risk, an optimal risk averse conversion and transmission strategy, among the grid, the renewable power generation source, and an energy storage is proposed to fully satisfy the electricity demand and minimize the expected operational cost as well as the risk. Our numerical study using data from NYISO demonstrates the impacts of risk consideration and the transaction cost parameters on the optimal strategy structure, its expected cost, and its risk.},
  doi       = {10.1109/TPWRS.2014.2341642},
  file      = {:FILES/2013 - Moazeni2015 - Mean-conditional value-at-risk optimal energy storage operation in the presence of transaction costs.pdf:PDF},
  groups    = {cvar},
  keywords  = {costing;energy storage;power grids;power transmission economics;pricing;risk management;mean-conditional value-at-risk optimal energy storage operation;power grid;electricity spot price;risk analysis;optimal risk neutral deterministic policy;conditional value-at-risk;optimal risk averse conversion;transmission strategy;NYISO;transaction cost parameters;optimal strategy structure;Energy storage;Electricity;Stochastic processes;Load modeling;Wind power generation;Wind speed;Conditional value-at-risk (CVaR) optimization;energy storage;risk, prio2},
  priority  = {prio2},
  timestamp = {2020-09-12},
}

@InBook{Mukherjee2019,
  author    = {Mukherjee, Soumen and Deyasi, Arpan and Bhattacharjee, Arup Kumar and Mondal, Arindam and Mukherjee, Anirban},
  chapter   = {9},
  editor    = {Ray, Jhuma and Mukherjee, Anirban and Dey, Sadhan Kumar and Klepac, Goran},
  pages     = {198--220},
  publisher = {IGI Global},
  title     = {Role of metaheuristic optimization in portfolio management for the banking sector: {A} case study},
  year      = {2019},
  isbn      = {9781522581031},
  series    = {Springer Proceedings in Mathematics \& Statistics},
  abstract  = {In this chapter, the importance of optimization technique, more specifically metaheuristic optimization in banking portfolio management, is reviewed. Present work deals with interactive bank marketing campaign of a specific Portugal bank, taken from UCI dataset archive. This dataset consists of 45,211 samples with 17 features including one response/output variable. The classification work is carried out with all data using decision tree (DT), support vector machine (SVM), and k-nearest neighbour (k-NN), without any feature optimization. Metaheuristic genetic algorithm (GA) is used as a feature optimizer to find only 5 features out of the 16 features. Finally, the classification work with the optimized feature shows relatively good accuracy in comparison to classification with all feature set. This result shows that with a smaller number of optimized features better classification can be achieved with less computational overhead.},
  booktitle = {Metaheuristic Approaches to Portfolio Optimization},
  doi       = {10.4018/978-1-5225-8103-1.ch009},
  file      = {:FILES/2019 - Mukherjee2019 - Role of Metaheuristic Optimization in Portfolio Management for the Banking Sector- A Case Study.pdf:PDF},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
  url       = {https://www.igi-global.com/chapter/role-of-metaheuristic-optimization-in-portfolio-management-for-the-banking-sector/233179},
}

@Article{Park2019,
  author    = {Park, Seyoung and Song, Hyunson and Lee, Sungchul},
  journal   = {The European Journal of Finance},
  title     = {Linear programing models for portfolio optimization using a benchmark},
  year      = {2019},
  number    = {5},
  pages     = {435--457},
  volume    = {25},
  abstract  = {ABSTRACTWe consider the problem of constructing a perturbed portfolio by utilizing a benchmark portfolio. We propose two computationally efficient portfolio optimization models, the mean-absolute deviation risk and the Dantzig-type, which can be solved using linear programing. These portfolio models push the existing benchmark toward the efficient frontier through sparse and stable asset selection. We implement these models on two benchmarks, a market index and the equally-weighted portfolio. We carry out an extensive out-of-sample analysis with 11 empirical datasets and simulated data. The proposed portfolios outperform the benchmark portfolio in various performance measures, including the mean return and Sharpe ratio.},
  doi       = {10.1080/1351847X.2018.1536070},
  eprint    = {https://doi.org/10.1080/1351847X.2018.1536070},
  file      = {:FILES/2019 - Park2019 - Linear programing models for portfolio optimization using a benchmark.pdf:PDF},
  groups    = {Portfolio Selection},
  publisher = {Routledge},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1080/1351847X.2018.1536070},
}

@Article{Perignon2010,
  author    = {P\'{e}rignon, Christophe and Smith, Daniel R.},
  journal   = {Journal of Banking \& Finance},
  title     = {The level and quality of value-at-risk disclosure by commercial banks},
  year      = {2010},
  issn      = {0378-4266},
  number    = {2},
  pages     = {362 -- 377},
  volume    = {34},
  abstract  = {In this paper we study both the level of Value-at-Risk (VaR) disclosure and the accuracy of the disclosed VaR figures for a sample of US and international commercial banks. To measure the level of VaR disclosures, we develop a VaR Disclosure Index that captures many different facets of market risk disclosure. Using panel data over the period 1996–2005, we find an overall upward trend in the quantity of information released to the public. We also find that Historical Simulation is by far the most popular VaR method. We assess the accuracy of VaR figures by studying the number of VaR exceedances and whether actual daily VaRs contain information about the volatility of subsequent trading revenues. Unlike the level of VaR disclosure, the quality of VaR disclosure shows no sign of improvement over time. We find that VaR computed using Historical Simulation contains very little information about future volatility.},
  doi       = {https://doi.org/10.1016/j.jbankfin.2009.08.009},
  file      = {:FILES/2010 - Perignon2010 - The level and quality of value-at-risk disclosure by commercial banks.pdf:PDF},
  groups    = {VaR},
  keywords  = {Value-at-Risk, Disclosure, Market risk, Proprietary risk management},
  timestamp = {2020-09-04},
  url       = {http://www.sciencedirect.com/science/article/pii/S0378426609001940},
}

@InBook{Pflug2000,
  author    = {Pflug, Georg Ch.},
  editor    = {Uryasev, Stanislav P.},
  pages     = {272--281},
  publisher = {Springer US},
  title     = {Some remarks on the value-at-risk and the conditional value-at-risk},
  year      = {2000},
  address   = {Boston, MA},
  isbn      = {978-1-4757-3150-7},
  abstract  = {The value-at-risk (VaR) and the conditional value-at-risk (CVaR) are two commonly used risk measures. We state some of their properties and make a comparison. Moreover, the structure of the portfolio optimization problem using the VaR and CVaR objective is studied.},
  booktitle = {Probabilistic Constrained Optimization: Methodology and Applications},
  doi       = {10.1007/978-1-4757-3150-7_15},
  file      = {:FILES/2000 - Pflug2000 - SOME REMARKS ON THE VALUE AT RISK AND THE CONDITIONAL VALUE AT RISK.pdf:PDF},
  groups    = {VaR, cvar},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1007/978-1-4757-3150-7_15},
}

@Article{Pritsker1997,
  author    = {Pritsker, Matthew},
  journal   = {Journal of Financial Services Research},
  title     = {Evaluating value at risk methodologies: {Accuracy} versus computational time},
  year      = {1997},
  issn      = {1573-0735},
  month     = {10},
  number    = {2},
  pages     = {201--242},
  volume    = {12},
  abstract  = {Recent research has shown that different methods of computing Value at Risk (VAR) generate widely varying results, suggesting the choice of VAR method is very important. This article examines six VAR methods, and compares their computational time requirements and their accuracy when the sole source of inaccuracy is errors in approximating nonlinearity. Simulations using portfolios of foreign exchange options showed fairly wide variation in accuracy and unsurprisingly wide variation in computational time. When the computational time and accuracy of the methods were examined together, four methods were superior to the others. The article also presents a new method for using order statistics to create confidence intervals for the errors and errors as a per cent of true value at risk for each VAR method. This makes it possible to easily interpret the implications of VAR errors for the size of shortfalls or surpluses in a firm's risk-based capital.},
  day       = {01},
  doi       = {10.1023/A:1007978820465},
  file      = {:FILES/1997 - Pritsker1997 - Evaluating value at risk methodologies - accuracy versus computational time.pdf:PDF},
  groups    = {VaR, TEC},
  timestamp = {2020-09-05},
  url       = {https://doi.org/10.1023/A:1007978820465},
}

@InBook{Ray2019,
  author    = {Ray, Jhuma and Bhattacharyya, Siddhartha and Singh, N. Bhupendro},
  chapter   = {4},
  editor    = {Ray, Jhuma and Mukherjee, Anirban and Dey, Sadhan Kumar and Klepac, Goran},
  pages     = {82--108},
  publisher = {IGI Global},
  title     = {Conditional value-at-risk-based portfolio optimization: {An} ant colony optimization approach},
  year      = {2019},
  isbn      = {9781522581031},
  abstract  = {Over the past few decades, an extensive research on the multi-objective decision making and combinatorial optimization of real world’s financial transactions has taken place. The modern capital market theory problem of portfolio optimization stands to be a multi-objective problem aiming at the maximization of the expected return of the portfolio in turn minimizing portfolio risk. The conditional value-at-risk (CVaR) is a widely used measure for determining the risk measures of a portfolio in volatile market conditions. A heuristic approach to portfolio optimization problem using ant colony optimization (ACO) technique centering on optimizing the conditional value-at-risk (CVaR) measure in different market conditions based on several objectives and constraints has been reported in this paper. The proposed ACO approach is proved to be reliable on a collection of several real-life financial instruments as compared to its value-at-risk (VaR) counterpart. The results obtained show encouraging avenues in determining optimal portfolio returns.},
  booktitle = {Metaheuristic Approaches to Portfolio Optimization},
  doi       = {10.4018/978-1-5225-8103-1},
  file      = {:FILES/2019 - Ray2019 - Conditional Value-at-Risk-Based Portfolio Optimization- An Ant Colony Optimization Approach.pdf:PDF},
  groups    = {cvar},
  timestamp = {2020-09-04},
  url       = {https://www.igi-global.com/book/metaheuristic-approaches-portfolio-optimization/214496},
}

@Article{Rossello2015,
  author    = {Rossello, Damiano},
  journal   = {European Journal of Operational Research},
  title     = {Ranking of investment funds: {Acceptability} versus robustness},
  year      = {2015},
  issn      = {0377-2217},
  number    = {3},
  pages     = {828 -- 836},
  volume    = {245},
  abstract  = {Within the class of performance ratios, the Sharpe measure can lead to misleading evaluation and various modifications have been investigated. As a starting point, we consider the axiomatic approach based on the notion of acceptable index of performance. Our goal is to show how the promising properties possessed by alternative measures such as the Gain–Loss ratio or the Average-Value-at-Risk ratio are not compatible with the statistical robustness of their estimated counterparts. This clearly affects the ranking of funds and consequently the performance persistence. We study the qualitative robustness along with the quantitative resistance of the corresponding estimators in a nonparametric setting. We include the Value-at-Risk ratio which is not an acceptability index of performance. These measures do not possess qualitative robustness, nonetheless we show how some degree of resistance to data contamination restricted to bounded intervals can be recovered. Using the relationship between the influence function of estimators and their bias for large samples, we suggest the Average-Value-at-Risk ratio and the Value-at-Risk ratio as the less sensitive to outliers. As a consequence, acceptability is no longer a prerequisite for performance evaluation. To limit the alteration of a given ranking among alternative investment funds, one can use the not acceptable Value-at-Risk ratio as well. Eventually, we propose a modified ratio either of the α-trimmed mean or of the median to the Value-at-Risk.},
  doi       = {https://doi.org/10.1016/j.ejor.2015.03.045},
  file      = {:FILES/2015 - Rossello2015 - Ranking of investment funds- Acceptability versus robustness.pdf:PDF},
  groups    = {VaR, Portfolio Selection},
  keywords  = {(P) Investment analysis, Acceptability indexes, Fund ranking, Statistical robustness, Estimation error},
  timestamp = {2020-09-04},
  url       = {http://www.sciencedirect.com/science/article/pii/S0377221715002672},
}

@Article{Sharma2012,
  author    = {Sharma, Meera},
  journal   = {Risk Management eJournal},
  title     = {The historical simulation method for value-at-risk: {A} research based evaluation of the industry favorite},
  year      = {2012},
  abstract  = {This paper surveys the literature relating to the historical simulation method of calculating VaR. The historical simulation method is the most popular method for VaR calculation in the banking industry. Thirty Eight papers are surveyed to understand the performance measures for VaR methods and the comparative performance of Historical Simulation VaR methods. The performance measures are broadly divided into unconditional coverage and conditional coverage measures. While regulatory requirements are limited to unconditional coverage measures, conditional coverage measures have been developed to spot the phenomenon of exception clustering. The performance of historical simulation - the basic and modified methods - in comparison with other methods is surveyed through available studies. The historical simulation approach is found to provide superior unconditional coverage among a wide variety of alternate methods ranging from the simple variance covariance approach to the sophisticated GARCH, explaining its popularity in the industry. This superiority translates into lesser likelihood of regulatory penalties since the regulatory back testing framework is based on unconditional coverage. The advantage of superior performance by historical simulation is lost when it is measured on conditional coverage measures (joint tests of unconditional coverage and independence). However, the sophisticated conditional volatility models like GARCH are not much better than the historical simulation in conditional coverage. A modification to the historical simulation method, the filtered historical simulation method emerges as the best performer using conditional coverage criteria. This study has an important contribution to make to available research. First it compiles the performance measures of VaR methods. Second it surveys the modifications to the historical simulation approach. Third and most important it presents a comparative picture of the most popular approach vis a vis other methods on a variety of performance parameters.},
  comment   = {it surveys the methods for computing VaR based on historical data.},
  file      = {:FILES/2012 - Sharma2012 - The Historical Simulation Method for Value-at-Risk A Research Based Evaluation of the Industry Favorite.pdf:PDF},
  groups    = {VaR},
  keywords  = {Historical Simulation, Conditional coverage, Market risk, Unconditional coverage, Var, Value at Risk},
  timestamp = {2020-09-04},
  url       = {http://dx.doi.org/10.2139/ssrn.2042594},
}

@Article{Soltanpour2020,
  author     = {Soltanpour, Akram and Baroughi, Fahimeh and Alizadeh, Behrooz},
  journal    = {Information Sciences},
  title      = {The inverse 1-median location problem on uncertain tree networks with tail value at risk criterion},
  year       = {2020},
  issn       = {0020-0255},
  pages      = {383 -- 394},
  volume     = {506},
  abstract   = {In an inverse 1-median location problem on a tree network, the goal is to modify the vertex weights of the underlying tree network at the minimum total cost such that a predetermined vertex becomes the 1-median. This paper investigates the case that the vertex weights and modification costs are considered as uncertain variables. We first obtain a necessary and sufficient condition for the α-1-median on uncertain trees. Based on this condition, we transform the problem into a linear programming model with deterministic constraints. Finally, we consider the proposed model with tail value at risk objective under the weighted l1 norm and present a solution algorithm for the problem with time complexity of O(nlog n).},
  comment    = {The inverse 1-median location problem is to adjust the weight of a tree network so that a vertex is the 1-median. The tail value at risk is actually the expected short fall.  Brief read.

This may be helpful for identification or training of EHH?},
  doi        = {https://doi.org/10.1016/j.ins.2019.08.018},
  file       = {:FILES/2020 - Soltanpour2020 - The inverse 1-median location problem on uncertain tree networks with tail value at risk criterion.pdf:PDF},
  groups     = {others},
  keywords   = {Median location, Inverse optimization, Uncertain programming, Tail value at risk, Time complexity, skimmed, prio2},
  priority   = {prio2},
  readstatus = {skimmed},
  timestamp  = {2020-09-06},
  url        = {http://www.sciencedirect.com/science/article/pii/S0020025519307522},
}

@Article{Staino2020,
  author    = {Staino, Alessandro and Russo, Emilio},
  journal   = {European Journal of Operational Research},
  title     = {Nested conditional value-at-risk portfolio selection: {A} model with temporal dependence driven by market-index volatility},
  year      = {2020},
  issn      = {0377-2217},
  number    = {2},
  pages     = {741 -- 753},
  volume    = {280},
  abstract  = {In a multistage stochastic programming framework, we develop a new method for finding an approximated portfolio allocation solution to the nested Conditional Value-at-Risk model when asset log returns are stagewise dependent. We describe asset log returns through a single-factor model where the driving factor is the market-index log return modeled by a Generalized Autoregressive Conditional Heteroskedasticity process to take into account the serial dependence usually observed. To solve the nested Conditional Value-at-Risk model, we implement a backward induction scheme coupled with cubic spline interpolation that reduces the computational complexity of the optimal portfolio allocation and allows to treat problems otherwise unmanageable.},
  doi       = {https://doi.org/10.1016/j.ejor.2019.07.032},
  file      = {:FILES/2020 - Staino2020 - Nested Conditional Value-at-Risk portfolio selection- A model with temporal dependence driven by market-index volatility.pdf:PDF},
  groups    = {cvar},
  keywords  = {Stochastic programming, Portfolio selection, Time-consistency, Cubic spline interpolation, Conditional value-at-risk},
  timestamp = {2020-09-04},
  url       = {http://www.sciencedirect.com/science/article/pii/S037722171930596X},
}

@PhdThesis{Strub2018,
  author    = {Strub, Oliver},
  school    = {University of Bern},
  title     = {Optimization of index-based portfolios},
  year      = {2018},
  file      = {:FILES/2018 - Strub2018 - Optimization of Index-Based Portfolios.pdf:PDF},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
}

@Article{Sukono2019,
  author    = {Sukono and Susanti, D. and Hasbullah, E. S. and Hidayat, Y. and Subiyanto},
  journal   = {{IOP} Conference Series: Materials Science and Engineering},
  title     = {Expansion of the investment portfolio performance assessment model based on value-at-risk using a time series approach},
  year      = {2019},
  month     = {8},
  pages     = {012015},
  volume    = {567},
  abstract  = {Portfolio performance assessment needs to be carried out before or after the investment decision is taken, in order to minimize the possibility of risk loss. This paper discusses the expansion of the investment portfolio performance appraisal model based on Value-at-Risk, where the analyzed stock returns on mean and volatility is non-constant.The aim is to increase the likelihood of achieving investment objectives by investors. In this paper the mean is estimated using autoregressive moving average models, while the non-constant volatility is estimated using generally autoregressive conditional heteroscedastic models. The estimator’s ofmean and non-constant volatility are then used for the analysis of investment portfolio optimization. Portfolio optimization issues are followed based on the basic framework of the Mean-Value-at-Risk model. The solution to the investment portfolio optimization problem is done by using the Lagrange multiplier technique and the Kuhn-Tucker method.Assessment of investment portfolio performance is based on Reward to Value-at-Risk, which is then used to compare the two investment portfolios A and B are analyzed. The results of the analysis show that portfolio A has better performance than portfolio B. So it is recommended to investors to choose an investment portfolio A, to achieve a better level of success.},
  doi       = {10.1088/1757-899x/567/1/012015},
  file      = {:FILES/2019 - Sukono2019 - Expansion of the investment portfolio performance assessment model based on value-at-risk using a time series approach.pdf:PDF},
  groups    = {VaR},
  publisher = {{IOP} Publishing},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1088%2F1757-899x%2F567%2F1%2F012015},
}

@InProceedings{Thavaneswaran2019,
  author    = {Thavaneswaran, A. and Thulasiram, R. K. and Zhu, Z. and Hoque, M. E. and Ravishanker, N.},
  booktitle = {2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)},
  title     = {Fuzzy value-at-risk forecasts using a novel data-driven neuro volatility predictive model},
  year      = {2019},
  month     = {7},
  pages     = {221--226},
  volume    = {2},
  abstract  = {Quantitative finance has been evolving over last several decades and combining randomness and fuzziness of the parameters has found growing interest among researchers to solve forecasting problems. Superiority of the fuzzy forecasting method over the minimum mean square forecasting had been demonstrated for fuzzy coefficient (linear as well as nonlinear) time series models in Thavaneswaran et al. [5]. However, many proposed fuzzy forecasting methods remain difficult to use in practice and there is a need for data-driven approach to fit the fuzzy coefficient volatility models. A neural network (NN) system can uniformly approximate any real nonlinear function on a compact domain to any degree of accuracy. Artificial NN (ANNs) have been applied to finance problems such as stock index prediction and bankruptcy prediction. In this paper, we introduce a novel direct data-driven neuro predictive model for conditional volatility and study the fuzzy value-at-risk (VaR) forecasts. We apply this model to forecast VaR with actual financial data. Our model shows considerable promise as a decision making and risk managing tool.},
  doi       = {10.1109/COMPSAC.2019.10210},
  file      = {:FILES/2019 - Thavaneswaran2019 - Fuzzy Value-at-Risk Forecasts Using a Novel Data-Driven Neuro Volatility Predictive Model.pdf:PDF},
  groups    = {VaR},
  issn      = {0730-3157},
  keywords  = {decision making;economic forecasting;fuzzy set theory;neural nets;risk management;stock markets;time series;neural network system;finance problems;stock index prediction;direct data-driven neuro predictive model;value-at-risk forecasts;quantitative finance;fuzzy forecasting method;minimum mean square forecasting;data-driven approach;fuzzy coefficient volatility models;randomness;data-driven neuro volatility predictive model;Predictive models;Reactive power;Artificial neural networks;Forecasting;Autoregressive processes;Neurons;Biological neural networks;Volatility, Fuzzy Value-at-Risk Forecasts, Neuro Volatility Predictive Models, Backtesting},
  timestamp = {2020-09-04},
}

@Article{Torsen2019,
  author     = {Torsen, Emmanuel and Mwita, Peter N. and Mung’atu, Joseph K.},
  journal    = {Journal of Statistical and Econometric Methods},
  title      = {A three-step nonparametric estimation of conditional value-at-risk admitting a location-scale model},
  year       = {2019},
  issn       = {1792-6602},
  number     = {4},
  pages      = {1--24},
  volume     = {8},
  abstract   = {Financial institutions owners and regulators are concerned majorly about risk analysis, Value-at-Risk (VaR) is one of the most popular and common measures of risk used in finance, measures the down-side risk and is determined for a given probability level. In this paper, we consider the problem of estimating conditional Value-at-Risk via the nonparametric method and have proposed a three-step nonparametric estimator for conditional Value-at-Risk. The returns are assumed to have a location-scale model where the function of the error innovations is assumed unknown. The asymptotic properties of the proposed estimator were established, a simulation study was also conducted to confirm the properties. Application to real data was carried out, TOTAL stocks quoted on the Nigerian Stock Exchange using daily closing prices for covering the period between January 02, 2008 to December 29, 2017 trading days was used to illustrate the applicability of the estimator.},
  file       = {:FILES/2019 - Torsen2019 - A Three-Step Nonparametric Estimation of Conditional Value-At-Risk Admitting a Location-Scale Model.pdf:PDF},
  groups     = {cvar},
  keywords   = {Location-Scale Model; Nonparametric Estimation; Three-Step; Conditional Value-at-Risk, skimmed},
  readstatus = {skimmed},
  timestamp  = {2020-09-06},
  url        = {http://www.scienpress.com/journal_focus.asp?Main_Id=68&Sub_id=IV&Issue=1090271},
}

@Article{TRABELSI2019,
  author    = {TRABELSI, Mohamed Ali},
  journal   = {Turkish Economic Review},
  title     = {The new models of decision in risk: {A} critical review of the literature},
  year      = {2019},
  number    = {2},
  pages     = {1--11},
  volume    = {6},
  abstract  = {The aim of the risk decision theory is to describe the behavior of agents in the face of several random prospects. Since it is difficult to describe these preferences, we seek to represent them. The use of a representative function of preferences has been for a long time, the usual method of describing behavior in a random context. The obvious advantage of this method is that it allows including these data in a formalized model and, by extension, to understand the optimization process underlying any decision. The determination of the representative function of preferences must be based on an axiomatic basis. From these axioms, an accurate specification of the value function will be derived. The purpose of this article is to examine the history of theories that have sought to determine a satisfactory criterion for responding to the risk decision problem and to analyze the contribution of these models.},
  doi       = {http://dx.doi.org/10.1453/ter.v6i2.1856},
  file      = {:FILES/2019 - TRABELSI2019 - The new models of decision in risk A critical review of the literature.pdf:PDF},
  groups    = {Portfolio Selection},
  keywords  = {Risk aversion, Expected Utility (EU), Rank Dependent Expected Utility (RDEU), Gamble.},
  timestamp = {2020-09-04},
  url       = {http://kspjournals.org/index.php/TER/article/view/1856},
}

@Article{Vyrost2019,
  author    = {Výrost, Tomas and Ly\'{o}csa, Štefan and Baum\"{o}hl, Eduard},
  journal   = {The North American Journal of Economics and Finance},
  title     = {Network-based asset allocation strategies},
  year      = {2019},
  issn      = {1062-9408},
  pages     = {516 -- 536},
  volume    = {47},
  abstract  = {In this study, we construct financial networks in which nodes are represented by assets and where edges are based on long-run correlations. We construct four networks (complete graph, a minimum spanning tree, a planar maximally filtered graph, and a threshold significance graph) and use three centrality measures (betweenness, eigenvalue centrality, and the expected force). To improve risk-return characteristics of well-known return maximization and risk minimization benchmark portfolios, we propose simple adjustments to portfolio selection strategies that utilize centralization measures from financial networks. From a sample of 45 assets (stock market indices, bond and money market instruments, commodities, and foreign exchange rates) and from data for 1999 to 2015, we show that irrespective of the network and centrality employed, the proposed network-based asset allocation strategies improve key portfolio return characteristics in an out-of-sample framework, most notably, risk and left-tail risk-adjusted returns. Resolving portfolio model selection uncertainties further improves risk-return characteristics. Improvements made to portfolio strategies based on risk minimization are also robust to transaction costs.},
  doi       = {https://doi.org/10.1016/j.najef.2018.06.008},
  file      = {:FILES/2018 - Vyrost2019 - Network-based asset allocation strategies.pdf:PDF},
  groups    = {asset allocation},
  keywords  = {Networks, Portfolio, Centrality, Risk-return profile},
  timestamp = {2020-09-04},
  url       = {http://www.sciencedirect.com/science/article/pii/S106294081830072X},
}

@Article{Wied2016,
  author     = {Wied, Dominik and Wei\ss, Gregor N. F. and Ziggel, Daniel},
  journal    = {Journal of Banking \& Finance},
  title      = {Evaluating value-at-risk forecasts: {A} new set of multivariate backtests},
  year       = {2016},
  issn       = {0378-4266},
  pages      = {121 -- 132},
  volume     = {72},
  abstract   = {We propose two new tests for detecting clustering in multivariate Value-at-Risk (VaR) forecasts. First, we consider CUSUM-tests to detect non-constant expectations in the matrix of VaR-violations. Second, we propose χ2-tests for detecting cross-sectional and serial dependence in the VaR-forecasts. Moreover, we combine our new backtests with a test of unconditional coverage to yield two new backtests of multivariate conditional coverage. Results from a simulation study underline the usefulness of our new backtests for controlling portfolio risks across a bank’s business lines. In an empirical study, we show how our multivariate backtests can be employed by regulators to backtest a banking system.},
  comment    = {They propose new backtests for multivariate VaR. It is to make hypothesis whether the expectations of return with respect to different portfolios equal to each other.},
  doi        = {https://doi.org/10.1016/j.jbankfin.2016.07.014},
  file       = {:FILES/2016 - Wied2016 - Evaluating Value-at-Risk forecasts- A new set of multivariate backtests.pdf:PDF},
  groups     = {VaR},
  keywords   = {Model risk, Multivariate backtesting, Value-at-Risk, Systemic risk, skimmed},
  readstatus = {skimmed},
  timestamp  = {2020-09-06},
  url        = {http://www.sciencedirect.com/science/article/pii/S0378426616301339},
}

@InCollection{Xie2018,
  author    = {Xie, Tengyang and Liu, Bo and Xu, Yangyang and Ghavamzadeh, Mohammad and Chow, Yinlam and Lyu, Daoming and Yoon, Daesub},
  booktitle = {Advances in Neural Information Processing Systems 31},
  publisher = {Curran Associates, Inc.},
  title     = {A block coordinate ascent algorithm for mean-variance optimization},
  year      = {2018},
  editor    = {Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.},
  pages     = {1065--1075},
  comment   = {mean variance model using Reinforcement learning},
  file      = {:FILES/2018 - Xie2018 - A Block Coordinate Ascent Algorithm for Mean-Variance Optimization.pdf:PDF},
  groups    = {RL, mean variance},
  timestamp = {2020-09-06},
  url       = {http://papers.nips.cc/paper/7384-a-block-coordinate-ascent-algorithm-for-mean-variance-optimization.pdf},
}

@InProceedings{Xie2019,
  author    = {Xie, Lanting},
  booktitle = {Proceedings of the 4th International Conference on Contemporary Education, Social Sciences and Humanities (ICCESSH 2019)},
  title     = {Value and risk: {Concern} and perfection of criminal expeditious adjudication procedure},
  year      = {2019},
  month     = {7},
  pages     = {1928--1933},
  publisher = {Atlantis Press},
  doi       = {https://doi.org/10.2991/iccessh-19.2019.413},
  file      = {:FILES/2019 - Xie2019 - value at wisk - concerns and perfection of criminal expeditious adjudication procedure.pdf:PDF},
  groups    = {VaR},
  isbn      = {978-94-6252-752-2},
  issn      = {2352-5398},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.2991/iccessh-19.2019.413},
}

@Article{Xue2017,
  author    = {Xue, Meng and Shi, Yun and Sun, Hailin},
  journal   = {Journal of Industrial \& Management Optimization},
  title     = {Portfolio optimization with relaxation of stochastic second order dominance constraints via conditional value at risk},
  year      = {2017},
  issn      = {1547-5816},
  number    = {1547-5816_2017_5_328},
  pages     = {1--22},
  volume    = {13},
  abstract  = {A portfolio optimization model with relaxed second order stochastic dominance (SSD) constraints is presented. The proposed model uses Conditional Value at Risk (CVaR) constraints at probability level $ \\beta\\in(0,1) $ to relax SSD constraints. The relaxation is justified by theoretical convergence results based on sample average approximation (SAA) method when sample size $ N\\to\\infty $and CVaR probability level $ \\beta $ tends to 1. SAA method is used to reduce infinite number of inequalities of SSD constraints to finite ones and also to calculate the expectation value. The proposed relaxation on the SSD constraints in portfolio optimization problem is achieved when the probability level $ \\beta $ of CVaR takes value less than but close to 1, and the model can then be solved by cutting plane method. The performance and characteristics of the portfolios constructed by solving the proposed model are tested empirically on three sets of market data, and the experimental results are analyzed and discussed. Furthermore, it is shown that with appropriate choices of CVaR probability level $ \\beta $, the constructed portfolios are sparse and outperform the portfolios constructed by solving portfolio optimization problems with SSD constraints, with either index portfolios or mean-variance (MV) portfolios as benchmarks.},
  doi       = {10.3934/jimo.2019071},
  file      = {:FILES/2017 - Xue2017 - Portfolio optimization with relaxation of stochastic second order dominance constraints via conditional value at risk.pdf:PDF},
  groups    = {cvar},
  keywords  = {Stochastic optimization, portfolio selection, second order dominance, CVaR approximation, sample average approximation},
  timestamp = {2020-09-04},
  url       = {http://aimsciences.org//article/id/db1c4347-da67-43ae-8107-b836f3d7b54c},
}

@Article{Yang2015,
  author    = {Yang, L. and Couillet, R. and McKay, M. R.},
  journal   = {IEEE Transactions on Signal Processing},
  title     = {A robust statistics approach to minimum variance portfolio optimization},
  year      = {2015},
  issn      = {1941-0476},
  month     = {12},
  number    = {24},
  pages     = {6684--6697},
  volume    = {63},
  abstract  = {We study the design of portfolios under a minimum risk criterion. The performance of the optimized portfolio relies on the accuracy of the estimated covariance matrix of the portfolio asset returns. For large portfolios, the number of available market returns is often of similar order to the number of assets, so that the sample covariance matrix performs poorly as a covariance estimator. Additionally, financial market data often contain outliers which, if not correctly handled, may further corrupt the covariance estimation. We address these shortcomings by studying the performance of a hybrid covariance matrix estimator based on Tyler's robust M-estimator and on Ledoit-Wolf's shrinkage estimator while assuming samples with heavy-tailed distribution. Employing recent results from random matrix theory, we develop a consistent estimator of (a scaled version of) the realized portfolio risk, which is minimized by optimizing online the shrinkage intensity. Our portfolio optimization method is shown via simulations to outperform existing methods both for synthetic and real market data.},
  doi       = {10.1109/TSP.2015.2474298},
  file      = {:FILES/2015 - Yang2015 - A Robust Statistics Approach to Minimum Variance Portfolio Optimization.pdf:PDF},
  groups    = {Portfolio Selection},
  keywords  = {covariance matrices;investment;optimisation;statistical analysis;robust statistics approach;minimum variance portfolio optimization;minimum risk criterion;covariance matrix;portfolio asset returns;covariance estimator;random matrix theory;portfolio risk;shrinkage intensity;portfolio optimization method;Portfolios;Covariance matrices;Robustness;Optimization;Eigenvalues and eigenfunctions;Estimation;Symmetric matrices;Minimum variance portfolio;Tyler's M-estimator;shrinkage estimator;random matrix theory},
  timestamp = {2020-09-04},
}

@InCollection{Chow2014,
  author    = {Chow, Yinlam and Ghavamzadeh, Mohammad},
  booktitle = {Advances in Neural Information Processing Systems 27},
  publisher = {Curran Associates, Inc.},
  title     = {Algorithms for {CVaR} optimization in mdps},
  year      = {2014},
  editor    = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
  pages     = {3509--3517},
  file      = {:FILES/2014 - Chow2014 - Algorithms for CVaR Optimization in MDPs.pdf:PDF},
  groups    = {cvar},
  timestamp = {2020-09-04},
  url       = {http://papers.nips.cc/paper/5246-algorithms-for-cvar-optimization-in-mdps.pdf},
}

@TechReport{Zhang2019,
  author      = {Zhang, Xuehai},
  institution = {Paderborn University, CIE Center for International Economics},
  title       = {Value at risk and expected shortfall under general semi-parametric {GARCH} models},
  year        = {2019},
  month       = {8},
  number      = {126},
  type        = {Working Papers CIE},
  abstract    = {Risk management has been emphasized by financial institutions and the Basel Com- mittee on Banking Supervision (BCBS). The core issue in risk management is the mea- surement of the risks. Value at Risk (VaR) and Expected Shortfall (ES) are the widely used tools in quantitative risk management. Due to the ineptitude of VaR on tail risk performances, ES is recommended as the financial risk management metrics by BCBS. In this paper, we generate general SemiGARCH class models with a time-varying scale function. GARCH class models, based on the conditional t-distribution, are parametric extensions. Besides, backtesting with the semiparametric approach is also discussed. Fol- lowing Basel III, the trac light tests are applied in the model validation. Finally, we propose the loss functions with the views from regulators and firms, combing a power transformation in the model selection and it is shown that semiparametric models are a necessary option in practical financial risk management.},
  file        = {:FILES/2019 - Zhang2019 - Value at Risk and Expected Shortfall under General Semi-parametric GARCH models.pdf:PDF},
  groups      = {VaR},
  timestamp   = {2020-09-04},
  url         = {https://ideas.repec.org/p/pdn/ciepap/126.html},
}

@Article{Benati2015,
  author     = {Benati, Stefano},
  journal    = {Journal of the Operational Research Society},
  title      = {Using medians in portfolio optimization},
  year       = {2015},
  number     = {5},
  pages      = {720--731},
  volume     = {66},
  abstract   = {Some new portfolio optimization models are formulated by adopting the sample median instead of the sample mean as the investment efficiency measure. The median is a robust statistic, which is less affected by outliers than the mean, and in portfolio models this is particularly relevant as data are often characterized by attributes such as skewness, fat tails and jumps, which may strongly bias the mean estimate. As in mean/variance optimization, the portfolio problems are formulated as finding the optimal weights, for example, wealth allocation, which maximize the portfolio median, with risk constrained by some risk measure, respectively, the Value-at-Risk, the Conditional Value-at-Risk, the Mean Absolute Deviation and the Maximum Loss, for a whole of four different models. All these models are formulated as mixed integer linear programming problems, which, at least for moderate sized problems, are efficiently solved by standard software. Models are tested on real financial data, compared to some benchmark portfolios, and found to give good results in terms of realized profits. An important feature is greater portfolio diversification than that obtained with other portfolio models.},
  comment    = {MILP solved via commercial solvers, for VaR, CVaR, MAD, and maximum loss model.},
  doi        = {10.1057/jors.2014.57},
  eprint     = {https://doi.org/10.1057/jors.2014.57},
  file       = {:FILES/2015 - Benati2015 - Using medians in portfolio optimization.pdf:PDF},
  groups     = {VaR, algorithms, cvar, mean variance},
  keywords   = {skimmed},
  publisher  = {Taylor \& Francis},
  readstatus = {skimmed},
  timestamp  = {2020-09-06},
  url        = {https://doi.org/10.1057/jors.2014.57},
}

@InProceedings{Ibrahim2016,
  author    = {Ibrahim, Mai A. and El-Beltagy, Mohammed and Khorshid, Motaz},
  booktitle = {Applications of Evolutionary Computation},
  title     = {Evolutionary multiobjective optimization for portfolios in emerging markets: {Contrasting} higher moments and median models},
  year      = {2016},
  address   = {Cham},
  editor    = {Squillero, Giovanni and Burelli, Paolo},
  pages     = {73--87},
  publisher = {Springer International Publishing},
  abstract  = {Multi-objective Evolutionary algorithms are well suited to Portfolio Optimization and hence have been applied in complex situations were traditional mathematical programming falls short. Often they were used in portfolios scenario of classical Mean-Variance which are not applicable to the Emerging Markets. Emerging Markets are characterized by return distributions that have shown to exhibit significance departure from normality and are characterized by skewness and fat tails. Therefore higher moments models and median models have been suggested in the literature for asset allocation in this case. Three higher moment models namely the Mean-Variance-Skewness, Mean-Variance-Skewness-Kurtosis, Mean-Variance-Skewness-Kurtosis for return and liquidity and three median models namely the Median-Value at Risk, Median-Conditional Value at Risk and Median-Mean Absolute Deviation are formulated as a multi-objective problem and solved using a multi-objective evolutionary algorithm namely the non-dominated sorting genetic algorithm II. The six models are compared and tested on real financial data of the Egyptian Index EGX. The median models were found in general to outperform the higher moments models. The performance of the median models was found to be better as the out-sample time increases.},
  file      = {:FILES/2016 - Ibrahim2016 - Evolutionary multiobjective optimization for portfolios in emerging markets- {Contrasting} higher moments and median models.pdf:PDF},
  groups    = {algorithms, mean variance},
  isbn      = {978-3-319-31204-0},
  timestamp = {2020-09-04},
}

@Article{Xu2016,
  author    = {Xu, Jun and Boom, Ton J. J. and De Schutter, Bart and Luo, Xionglin},
  journal   = {IEEE Transactions on Automatic Control},
  title     = {Minimal conjunctive normal expression of continuous piecewise affine functions},
  year      = {2016},
  issn      = {1558-2523},
  month     = {5},
  number    = {5},
  pages     = {1340--1345},
  volume    = {61},
  abstract  = {Continuous piecewise affine (PWA) functions arise in many aspects of control. For this kind of function, we propose the minimal conjunctive normal expression (CNE). The CNE can be expressed as the minimum of a collection of terms, each of which is the maximum of a set of affine functions. The minimal CNE is defined to contain the smallest number of parameters. Analogous to Boolean algebra, we propose implicants and prime implicants for continuous PWA functions. After obtaining all prime implicants, the problem of finding minimal CNEs can then be cast as a binary programming problem. A sharp bound on the number of boolean variables in the binary programming problem is given. In two worked examples, minimal CNEs are derived for given continuous PWA functions.},
  doi       = {10.1109/TAC.2015.2465212},
  file      = {:FILES/2016 - Xu2016 - Minimal conjunctive normal expression of continuous piecewise affine functions.pdf:PDF},
  groups    = {identification, Wang's Work},
  keywords  = {affine transforms;Boolean functions;continuous systems;predictive control;continuous piecewise affine functions;minimal conjunctive normal expression;CNE;Boolean algebra;prime implicants;continuous PWA functions;binary programming problem;Indexes;Complexity theory;Programming;Optimization;Linear programming;Integrated circuit modeling;Control systems;Continuous piecewise affine;minimal expression;conjunctive normal expression;Conjunctive normal expression;continuous piecewise affine;minimal expression},
  timestamp = {2020-08-31},
}

@Article{Huang2014,
  author    = {Huang, Xiaolin and Shi, Lei and Pelckmans, Kristiaan and Suykens, Johan A.K.},
  journal   = {Computational Statistics \& Data Analysis},
  title     = {Asymmetric $\nu$-tube support vector regression},
  year      = {2014},
  issn      = {0167-9473},
  pages     = {371 -- 382},
  volume    = {77},
  abstract  = {Finding a tube of small width that covers a certain percentage of the training data samples is a robust way to estimate a location: the values of the data samples falling outside the tube have no direct influence on the estimate. The well-known ν-tube Support Vector Regression (ν-SVR) is an effective method for implementing this idea in the context of covariates. However, the ν-SVR considers only one possible location of this tube: it imposes that the amount of data samples above and below the tube are equal. The method is generalized such that those outliers can be divided asymmetrically over both regions. This extension gives an effective way to deal with skewed noise in regression problems. Numerical experiments illustrate the computational efficacy of this extension to the ν-SVR.},
  doi       = {https://doi.org/10.1016/j.csda.2014.03.016},
  file      = {:FILES/2014 - Huang2014 - Asymmetric -tube support vector regression.pdf:PDF},
  groups    = {Wang's Work, SVM},
  keywords  = {Robust regression, -tube support vector regression, Asymmetric loss, Quantile regression},
  timestamp = {2020-08-31},
  url       = {http://www.sciencedirect.com/science/article/pii/S0167947314000930},
}

@Article{Cesarone2018,
  author    = {Cesarone, Francesco and Colucci, Stefano},
  journal   = {Journal of the Operational Research Society},
  title     = {Minimum risk versus capital and risk diversification strategies for portfolio construction},
  year      = {2018},
  number    = {2},
  pages     = {183--200},
  volume    = {69},
  abstract  = {AbstractIn this paper, we propose an extensive empirical analysis on three categories of portfolio selection models with very different objectives: minimization of risk, maximization of capital diversification, and uniform distribution of risk allocation. The latter approach, also called Risk Parity or Equal Risk Contribution (ERC), is a recent strategy for asset allocation that aims at equally sharing the risk among all the assets of the selected portfolio. The risk measure commonly used to select ERC portfolios is volatility. We propose here new developments of the ERC approach using Conditional Value-at-Risk (CVaR) as a risk measure. Furthermore, under appropriate conditions, we also provide an approach to find a CVaR ERC portfolio as a solution of a convex optimization problem. We investigate how these classes of portfolio models (Minimum-Risk, Capital-Diversification, and Risk-Diversification) work on seven investment universes, each with different sources of risk, including equities, bonds, and mixed assets. Then, we highlight some strengths and weaknesses of all portfolio strategies in terms of various performance measures.},
  doi       = {10.1057/s41274-017-0216-5},
  eprint    = {https://doi.org/10.1057/s41274-017-0216-5},
  file      = {:FILES/2018 - Cesarone2018 - Minimum risk versus capital and risk diversification strategies for portfolio construction.pdf:PDF},
  groups    = {cvar},
  publisher = {Taylor \& Francis},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1057/s41274-017-0216-5},
}

@Article{Pavlikov2018,
  author     = {Pavlikov, Konstantin and Veremyev, Alexander and Pasiliao, Eduardo L.},
  journal    = {Journal of the Operational Research Society},
  title      = {Optimization of value-at-risk: {Computational} aspects of {MIP} formulations},
  year       = {2018},
  number     = {5},
  pages      = {676--690},
  volume     = {69},
  abstract   = {AbstractOptimization of Value-at-Risk is an important problem both from theoretical and practical standpoints. It can be represented through a class of chance-constrained optimization problems, which are generally hard to solve. Mixed integer problem formulations with big M constants is a standard way to approach such problems, where tightness of these constants is a crucial factor for good performance of a solver. This study aims to improve the tightness of existing big Ms by explicitly incorporating bounds on the optimal value of VaR into the problem formulation. Moreover, the lower bound is demonstrated to play an especially important role in obtaining tight big M constants, and a procedure to lift this bound is discussed. Finally, a “two-stage” solution approach is proposed, where the first stage solely deals with tightening the bounds, and the second stage employs improved bounds to redefine big Ms and solves the problem to optimality. Numerical experiments suggest that proposed solution methods can decrease solution time by up to 75\% compared to the most recent benchmark, which may allow to handle larger problem instances while using the same hardware.},
  comment    = {investigate the influence of M in MILP solvers},
  doi        = {10.1057/s41274-017-0197-4},
  eprint     = {https://doi.org/10.1057/s41274-017-0197-4},
  file       = {:FILES/2018 - Pavlikov2018 - Optimization of Value-at-Risk- computational aspects of MIP formulations.pdf:PDF},
  groups     = {VaR},
  keywords   = {read},
  publisher  = {Taylor \& Francis},
  readstatus = {read},
  timestamp  = {2020-09-06},
  url        = {https://doi.org/10.1057/s41274-017-0197-4},
}

@Article{Gabrel2018,
  author    = {Gabrel, Virginie and Murat, C\'{e}cile and Thiele, Aur\'{e}lie},
  journal   = {EURO Journal on Computational Optimization},
  title     = {Portfolio optimization with pw-robustness},
  year      = {2018},
  issn      = {2192-4414},
  month     = {9},
  number    = {3},
  pages     = {267--290},
  volume    = {6},
  abstract  = {This paper investigates a portfolio optimization problem under uncertainty on the stock returns, where the manager seeks to achieve an appropriate trade-off between the expected portfolio return and the risk of loss. The uncertainty set consists of a finite set of scenarios occurring with equal probability. We introduce a new robustness criterion, called pw-robustness, which seeks to maximize the portfolio return in a proportion p of scenarios and guarantees a minimum return over all scenarios. We model this optimization problem as a mixed-integer programming problem. Through extensive numerical experiments, we identify the instances that can be solved to optimality in an acceptable time using off-the-shelf software. For the instances that cannot be solved to optimality within the time frame, we propose and test a heuristic that exhibits excellent practical performance in terms of computation time and solution quality for the problems we consider. This new criterion and our heuristic methods therefore exhibit great promise to tackle robustness problems when the uncertainty set consists of a large number of scenarios.},
  day       = {01},
  doi       = {10.1007/s13675-018-0096-8},
  file      = {:FILES/2018 - Gabrel2018 - portfolio optimization with pw-robustness.pdf:PDF},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1007/s13675-018-0096-8},
}

@InProceedings{Ibrahim2019,
  author       = {Ibrahim, Mai A. and El-Beltagy, Mohammed and Khorshid, Motaz},
  booktitle    = {Eurooean Financial Systems 2019},
  title        = {Investing in emerging markets: {Contrasted} mean and median models in {Egyptian} stock markets},
  year         = {2019},
  address      = {ZEROTINOVO NAM 617-9, BRNO 601 77, CZECH REPUBLIC},
  editor       = {Nesleha, J and Marek, L and Svoboda, M and Rakovska, Z},
  note         = {16th Annual International Scientific Conference on European Financial Systems, Brno, CZECH REPUBLIC, JUN 24-25, 2019},
  organization = {Masaryk Univ, Fac Econ \& Adm, Dept Finance; Inst Financial Market},
  pages        = {184--191},
  publisher    = {MASARYKOVA UNIV},
  abstract     = {Emerging Markets return distributions have shown significance departure from normality were they are characterized by fatter tails relative to the normal distribution and exhibit levels of skewness and kurtosis that constitute a significant departure from normality. Therefore the classical Markowitz Mean-Variance is not the most suitable portfolio optimization model to apply for emerging markets since it assumes normally-distributed returns and a quadratic utility function. Alternative models were suggested in the literature, higher moments models have been introduced to account for the insufficiency of the description of a portfolio by only its first two moments while the median model has been introduced as a robust statistic which is less affected by outliers than the mean. Alternative risk measures have been introduced instead of variance to capture the effect of risk. The purpose of this paper is to investigate the performance of different portfolio models in an emerging market such as the Egyptian Market to decide which can suit better the characteristics of this market. Higher moment models including Mean-Variance-Skewness and Mean-Variance-Skewness-Kurtosis and median models including Median Value-at-Risk and Median Mean-Absolute-Deviation are compared to the Markowitz model. The formulation of the models varied between single-objective nonlinear programming problems (NLP), single-objective mixed-integer linear programming (MILP) problems and single-objective quadratic programming problems. All the models are tested on real financial data in the Egyptian main Index EGX30. In general, median models have shown better performance than higher moments models and specifically the MedianVaR model. The MedianVaR model has provided the higher final wealth for the investor over the entire period of study. These findings can guide the decision making process for portfolio optimization in the Egyptian market were one can barely find any study on the portfolio optimization problem for the Egyptian Market in specific and the MENA region in general.},
  da           = {2020-08-10},
  file         = {:FILES/2019 - Ibrahim2019 - Investing in emerging markets- {Contrasted} mean and median models in egyptian stock markets.pdf:PDF},
  groups       = {Portfolio Selection},
  isbn         = {978-80-210-9338-6},
  keywords     = {Emerging markets; higher moment models; median models; mixed-Integer linear programming; non-Linear programming},
  language     = {English},
  timestamp    = {2020-09-04},
  type         = {Proceedings Paper},
}

@Article{Grossi2020,
  author    = {Grossi, Luigi and Laurini, Fabrizio},
  journal   = {Applied Stochastic Models in Business and Industry},
  title     = {Robust asset allocation with conditional value at risk using the forward search},
  year      = {2020},
  number    = {3},
  pages     = {335--352},
  volume    = {36},
  abstract  = {Abstract The well-known Markowitz approach to portfolio allocation, based on expected returns and their covariance, seems to provide questionable results in financial management. One motivation for the pitfall is that financial returns have heavier than Gaussian tails, so the covariance of returns, used in the Markowitz model as a measure of portfolio risk, is likely to provide a loose quantification of the effective risk. Additionally, the Markowitz approach is very sensitive to small changes in either the expected returns or their correlation, often leading to irrelevant portfolio allocations. More recent allocation techniques are based on alternative risk measures, such as value at risk (VaR) and conditional VaR (CVaR), which are believed to be more accurate measures of risk for fat-tailed distributions. Nevertheless, both VaR and CVaR estimates can be influenced by the presence of extreme returns. In this paper, we discuss sensitivity to the presence of extreme returns and outliers when optimizing the allocation, under the constraint of keeping CVaR to a minimum. A robust and efficient approach, based on the forward search, is suggested. A Monte Carlo simulation study shows the advantages of the proposed approach, which outperforms both robust and nonrobust alternatives under a variety of specifications. The performance of the method is also thoroughly evaluated with an application to a set of US stocks.},
  doi       = {10.1002/asmb.2492},
  eprint    = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/asmb.2492},
  file      = {:FILES/2020 - Grossi2020 - Robust asset allocation with conditional value at risk using the forward search.pdf:PDF},
  groups    = {cvar, asset allocation},
  keywords  = {asset allocation, CVaR, forward search, influential observations, robustness, sensitivity analysis},
  timestamp = {2020-09-04},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asmb.2492},
}

@Article{Li2001,
  author   = {Li, Xingye and Wang, Shuning and Yin, Wenjun},
  journal  = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title    = {A canonical representation of high-dimensional continuous piecewise-linear functions},
  year     = {2001},
  issn     = {1558-1268},
  month    = {11},
  number   = {11},
  pages    = {1347--1351},
  volume   = {48},
  abstract = {A canonical representation of high-dimensional continuous piecewise-linear (PWL) functions has not been perfectly solved until now. In this brief, a constructive model of high-dimensional continuous PWL functions is proposed by using an iterative method and it is proved that the model can represent all high-dimensional continuous PWL functions.},
  doi      = {10.1109/81.964426},
  file     = {:FILES/2001 - Li2001 - a conanical representation of high-dimensional continuous piecewise-linear function.pdf:PDF},
  groups   = {identification, Wang's Work},
  keywords = {piecewise linear techniques;iterative methods;nonlinear systems;nonlinear network analysis;multidimensional systems;canonical representation;high-dimensional continuous piecewise-linear functions;constructive model;iterative method;nesting absolute value representation;n-dimensional functions;Piecewise linear techniques;Iterative methods;Automation;Equations;Two dimensional displays;Circuits},
}

@InProceedings{Li2001discrete,
  author    = {Li, Xiaoli and Wang, Wei and Wang, Shuning},
  booktitle = {Proceedings of the 2001 American Control Conference. (Cat. No.01CH37148)},
  title     = {Multi-model adaptive control for discrete time systems},
  year      = {2001},
  month     = {6},
  pages     = {4820--4825},
  volume    = {6},
  abstract  = {A multi-model adaptive control approach is proposed to improve the performance of adaptive control of discrete time invariant plant or time variant plant with jumping parameters and bounded disturbances. Multiple models of the plant are set up to cover the uncertainties of the plant dynamics. The localization method is used to reduce the computation burden of the multiple model algorithm. It is proved that the closed loop system is stable when multi-model pole assignment controller is used to a linear time-invariant plant with unknown parameters. The simulation results are given to show the usefulness of the proposed method.},
  doi       = {10.1109/ACC.2001.945745},
  file      = {:FILES/2001 - Li2001discrete - Multi-model adaptive control for discrete time systems.pdf:PDF},
  groups    = {application, Wang's Work},
  issn      = {0743-1619},
  keywords  = {discrete time systems;linear systems;stability;closed loop systems;adaptive control;pole assignment;multiple model control;SISO systems;adaptive control;jumping parameters;pole assignment;linear time invariant systems;stability;closed loop system;discrete time system;Adaptive control;Discrete time systems;Closed loop systems;Stability;Control systems;Programmable control;Automation;Computational modeling;Error correction;State estimation},
}

@Article{Wang2010shh,
  author   = {Wang, S. and Huang, X. and Yam, Y.},
  journal  = {IEEE Transactions on Neural Networks},
  title    = {A neural network of smooth hinge functions},
  year     = {2010},
  issn     = {1941-0093},
  month    = {9},
  number   = {9},
  pages    = {1381--1395},
  volume   = {21},
  abstract = {Smooth hinging hyperplane (SHH) has been proposed as an improvement over the well-known hinging hyperplane (HH) by the fact that it retains the useful features of HH while overcoming HH's drawback of nondifferentiability. This paper introduces a formal characterization of smooth hinge function (SHF), which can be used to generate SHH as a neural network. A method for the general construction of SHF is also given. Furthermore, the work proves that SHH is better than HH in functional approximation, i.e., the optimal error of SHH approximating a general function is always smaller or equal to that of HH. Particularly, in the case that the SHF is generated via the integration of a class of sigmoidal functions, it is further proven that the corresponding SHH of the 2m SHFs would outperform a neural network with m of the sigmoidal function from which the SHF is derived. Any upper bound established on the approximation error of a neural network of m sigmoidal activation functions can hence be translated to the SHH of m SHFs by replacing m with m/2. The work also includes an algorithm for the identification of SHH making use of its differentiability property. Simulation experiments are presented to validate the theoretical conclusions to possible extent.},
  doi      = {10.1109/TNN.2010.2053383},
  file     = {:FILES/2010 - Wang2010shh - A Neural Network of Smooth Hinge Functions.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {geometry;neural nets;regression analysis;splines (mathematics);neural network;smooth hinging hyperplane;smooth hinge function;sigmoidal function;Neural networks;Fasteners;Upper bound;Automation;Function approximation;Character generation;Approximation error;Vectors;Educational programs;Function approximation;hinging hyperplanes (HHs);neural networks;nonlinear identification;sigmoidal functions;smooth hinging hyperplanes (SHHs);Algorithms;Models, Neurological;Neural Networks (Computer);Nonlinear Dynamics},
}

@Article{Agullo1997,
  author    = {Agull\'{o}, Jos\'{e}},
  journal   = {Lecture Notes-Monograph Series},
  title     = {Exact algorithms for computing the least median of squares estimate in multiple linear regression},
  year      = {1997},
  issn      = {07492170},
  month     = {08},
  note      = {Full publication date: 1997},
  pages     = {133--146},
  volume    = {31},
  abstract  = {[We propose two finite algorithms to compute the exact least median of squares (LMS) estimates of parameters of a linear regression model with p coefficients. The first algorithm is similar to Stromberg's (1993) exact algorithm. It is based on the exact fit to subsets of p cases and uses impossibility conditions to avoid unnecessary calculations. The second one is based on a branch and bound (BAB) technique. Empirical results suggest that the proposed algorithms are faster than the finite exact algorithms described earlier in the literature.]},
  file      = {:FILES/1997 - Agullo1997 - Exact Algorithms for Computing the Least Median of Squares Estimate in Multiple Linear Regression.pdf:PDF},
  groups    = {LMS},
  publisher = {Institute of Mathematical Statistics},
  url       = {www.jstor.org/stable/4355973},
}

@Article{Stromberg1993,
  author  = {Stromberg, Arnold J.},
  journal = {SIAM Journal on Scientific Computing},
  title   = {Computing the exact least median of squares estimate and stability diagnostics in multiple linear regression},
  year    = {1993},
  number  = {6},
  pages   = {1289--1299},
  volume  = {14},
  doi     = {10.1137/0914076},
  eprint  = {https://doi.org/10.1137/0914076},
  file    = {:FILES/1993 - Stromberg1993 - Computing the Exact Least Median of Squares Estimate and Stability Diagnostics in Multiple Linear Regression.pdf:PDF},
  groups  = {LMS},
  url     = {https://doi.org/10.1137/0914076},
}

@Article{Tichavsky1991,
  author  = {Tichavsk\'{y}, Petr},
  journal = {Computational Statistics Quarterly},
  title   = {Algorithms for and geometrical characterization of solutions in the {LMS} and lts linear regression},
  year    = {1991},
  issn    = {0723-712X},
  note    = {this paper can not be downloaded.},
  number  = {2},
  pages   = {139--151},
  volume  = {6},
  comment = {cannot be found online},
  groups  = {LMS},
}

@Article{Bocek1995,
  author   = {Bo\v{c}ek, P. and Lachout, P.},
  journal  = {Computational Statistics \& Data Analysis},
  title    = {Linear programming approach to {LMS-estimation}},
  year     = {1995},
  issn     = {0167-9473},
  number   = {2},
  pages    = {129 -- 134},
  volume   = {19},
  abstract = {In the paper a probabilistic algorithm, based on the Simplex Method, is suggested for minimization of the k-th smallest value of absolute residuals in linear regression. In particular it is suitable for computation of the Least Median of Squares (LMS) estimator of P.J. Rousseeuw, A.M. Leroy [4]. Numerical results indicate that the algorithm represents an improvement in comparison with those put forward earlier.},
  doi      = {https://doi.org/10.1016/0167-9473(93)E0051-5},
  file     = {:FILES/1995 - Bocek1995 - Linear programming approach to LMS-estimation.pdf:PDF},
  groups   = {LMS},
  keywords = {Order statistics, Regression residuals, LMS estimator, The Simplex Method},
  url      = {http://www.sciencedirect.com/science/article/pii/0167947393E00515},
}

@TechReport{Winker2008,
  author      = {Winker, Peter and Lyra, Marianna and Sharpe, Chris},
  institution = {COMISEF},
  title       = {{least median of squares estimation by optimization heuristics with an application to the {CAPM} and multi factor models}},
  year        = {2008},
  month       = {8},
  number      = {006},
  type        = {Working Papers},
  abstract    = {For estimating the parameters of models for financial market data, the use of robust techniques is of particular interest. Conditional forecasts, based on the capital asset pricing model, and a factor model are considered. It is proposed to consider least median of squares estimators as one possible alternative to ordinary least squares. Given the complexity of the objective function for the least median of squares estimator, the estimates are obtained by means of optimization heuristics. The performance of two heuristics is compared, namely differential evolution and threshold accepting. It is shown that these methods are well suited to obtain least median of squares estimators for real world problems. Furthermore, it is analyzed to what extent parameter estimates and conditional forecasts differ between the two estimators. The empirical analysis considers daily and monthly data on some stocks from the Dow Jones Industrial Average Index (DJIA).},
  file        = {:FILES/2008 - Winker2008 - Least Median of Squares Estimation by Optimization Heuristics with an Application to the CAPM and Multi Factor Models.pdf:PDF},
  groups      = {algorithms, LMS, differential evolution},
  keywords    = {LMS; CAPM; Multi Factor Model; Differential Evolution; Threshold Accepting, read},
  readstatus  = {read},
  timestamp   = {2020-09-04},
  url         = {https://ideas.repec.org/p/com/wpaper/006.html},
}

@Article{Verardi2009,
  author     = {Verardi, Verardi and Croux, Christophe},
  journal    = {The Stata Journal},
  title      = {Robust regression in stata},
  year       = {2009},
  number     = {3},
  pages      = {439--453},
  volume     = {9},
  abstract   = {In regression analysis, the presence of outliers in the dataset can strongly distort the classical least-squares estimator and lead to unreliable results. To deal with this, several robust-to-outliers methods have been proposed in the statistical literature. In Stata, some of these methods are available through the rreg and qreg commands. Unfortunately, these methods resist only some specific types of outliers and turn out to be ineffective under alternative scenarios. In this article, we present more effective robust estimators that we implemented in Stata. We also present a graphical tool that recognizes the type of detected outliers.},
  address    = {College Station, TX},
  file       = {:FILES/2009 - Verardi2009 - Robust Regression in Stata.pdf:PDF},
  groups     = {LMS},
  keywords   = {read},
  publisher  = {Stata Press},
  readstatus = {read},
  timestamp  = {2020-08-10},
  url        = {http://www.stata-journal.com/article.html?article=st0173},
}

@Article{Olson1997,
  author   = {Olson, Clark F.},
  journal  = {Information Processing Letters},
  title    = {An approximation algorithm for least median of squares regression},
  year     = {1997},
  issn     = {0020-0190},
  number   = {5},
  pages    = {237 -- 241},
  volume   = {63},
  abstract = {Least median of squares (LMS) regression is a robust method to fit equations to observed data (typically in a linear model). This paper describes an approximation algorithm for LMS regression. The algorithm generates a regression solution with median residual no more than twice the optimal median residual. Random sampling is used to provide a simple O(n log2 n) expected time algorithm in the two-dimensional case that is successful with high probability. This algorithm is also extended to arbitrary dimension d with O(nd − 1 log n) worst-case complexity for fixed d > 2.},
  doi      = {https://doi.org/10.1016/S0020-0190(97)00132-4},
  file     = {:FILES/1997 - Olson1997 - An approximation algorithm for least median of squares regression.pdf:PDF},
  groups   = {LMS},
  keywords = {Least median of squares regression, Approximation algorithms, Computational geometry, Design of algorithms},
  url      = {http://www.sciencedirect.com/science/article/pii/S0020019097001324},
}

@Book{Rousseeuw1987,
  author    = {Peter J. Rousseeuw and Annick M. Leroy},
  publisher = {Wiley},
  title     = {Robust regression and outlier detection},
  year      = {1987},
  isbn      = {9780471725374},
  series    = {Wiley series in probability and mathematical statistics. Applied probability and statistics},
  file      = {:FILES/1987 - Rousseeuw1987 - Robust regression and outlier detection-Wiley (1987).pdf:PDF},
  groups    = {LMS},
}

@InBook{Rousseeuw1997,
  author     = {Rousseeuw, Peter and Hubert, Mia},
  editor     = {Dodge, Y.},
  pages      = {201--214},
  publisher  = {Institute of Mathematical Statistics},
  title      = {Recent developments in {PROGRESS}},
  year       = {1997},
  address    = {Hayward, California},
  month      = {01},
  series     = {Lecture Notes-Monograph Series Vol 31},
  volume     = {31},
  booktitle  = {L1-Statistical Procedures and Related Topics},
  doi        = {10.1214/lnms/1215454138},
  file       = {:FILES/1997 - Rousseeuw1997 - recents developments in PROGRESS.pdf:PDF},
  groups     = {LMS},
  keywords   = {read},
  readstatus = {read},
}

@Article{Chakraborty2008,
  author     = {Chakraborty, Biman and Chaudhuri, Probal},
  journal    = {Journal of Computational and Graphical Statistics},
  title      = {On an optimization problem in robust statistics},
  year       = {2008},
  issn       = {10618600},
  month      = {08},
  note       = {Full publication date: Sep., 2008},
  number     = {3},
  pages      = {683--702},
  volume     = {17},
  abstract   = {[In this article, we consider a large class of computational problems in robust statistics that can be formulated as selection of optimal subsets of data based on some criterion function. To solve such problems, there are broadly two classes of algorithms available in the literature. One is based on purely random search, and the other is based on deterministically guided strategies. Though these methods can achieve satisfactory results in some specific examples, none of them can be used satisfactorily for a large class of similar problems either due to their very long expected waiting time to hit the true optimum or due to their failure to come out of a local optimum when they get trapped there. Here, we propose two probabilistic search algorithms, and under some conditions on the parameters of the algorithms, we establish the convergence of our algorithms to the true optimum. We also show some results on the probability of hitting the true optimum if the algorithms are run for a finite number of iterations. Finally, we compare the performance of our algorithms to some commonly available algorithms for computing some popular robust multivariate statistics using real datasets.]},
  file       = {:FILES/2008 - Chakraborty2008 - On an Optimization Problem in Robust Statistics.pdf:PDF},
  groups     = {LMS},
  keywords   = {read},
  publisher  = {[American Statistical Association, Taylor {\&} Francis, Ltd., Institute of Mathematical Statistics, Interface Foundation of America]},
  readstatus = {read},
  url        = {http://www.jstor.org/stable/27594331},
}

@Article{Xu2006soft,
  author     = {Xu, Chunhui and Ng, Peggy},
  journal    = {European Journal of Operational Research},
  title      = {A soft approach for hard continuous optimization},
  year       = {2006},
  issn       = {0377-2217},
  number     = {1},
  pages      = {18 -- 29},
  volume     = {173},
  abstract   = {This paper is to introduce a soft approach for solving continuous optimizations models where seeking an optimal solution is theoretically or practically impossible. We first review methods for solving continuous optimization models, and argue that only a few optimization models with some good structure are solved. To solve a larger class of optimization problems, we suggest a soft approach by softening the goal in solving a model, and propose a two-stage process for implementing the soft approach. Furthermore, we offer an algorithm for solving optimization models with a convex feasible set, and verify the validity of the soft approach with numerical experiments.},
  doi        = {https://doi.org/10.1016/j.ejor.2005.01.004},
  file       = {:FILES/2006 - Xu2006soft - A soft approach for hard continuous optimization.pdf:PDF},
  groups     = {global optimization},
  keywords   = {Optimization, Optimal solution, Soft approach, Sampling, skimmed},
  readstatus = {skimmed},
  timestamp  = {2020-09-04},
  url        = {http://www.sciencedirect.com/science/article/pii/S0377221705000299},
}

@Article{Barber2016,
  author  = {Barber, Rina Foygel and Sidky, Emil Y.},
  journal = {Journal of Machine Learning Research},
  title   = {{MOCCA}: {Mirrored} convex/concave optimization for nonconvex composite functions},
  year    = {2016},
  number  = {144},
  pages   = {1--51},
  volume  = {17},
  groups  = {nonsmooth optimization},
  url     = {http://jmlr.org/papers/v17/15-583.html},
}

@InProceedings{Koren2013,
  author    = {Koren, Tomer},
  booktitle = {Proceedings of the 26th Annual Conference on Learning Theory},
  title     = {Open problem: {Fast} stochastic exp-concave optimization},
  year      = {2013},
  address   = {Princeton, NJ, USA},
  editor    = {Shalev-Shwartz, Shai and Steinwart, Ingo},
  month     = {6},
  pages     = {1073--1075},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {30},
  abstract  = {Stochastic exp-concave optimization is an important primitive in machine learning that captures several fundamental problems, including linear regression, logistic regression and more. The exp-concavity property allows for fast convergence rates, as compared to general stochastic optimization. However, current algorithms that attain such rates scale poorly with the dimension n and run in time O(n^4), even on very simple instances of the problem. The question we pose is whether it is possible to obtain fast rates for exp-concave functions using more computationally-efficient algorithms.},
  groups    = {nonsmooth optimization},
  keywords  = {prio1},
  pdf       = {http://proceedings.mlr.press/v30/Koren13.pdf},
  priority  = {prio1},
  url       = {http://proceedings.mlr.press/v30/Koren13.html},
}

@Book{Atkinson2000,
  author    = {Atkinson, Anthony and Riani, Marco},
  publisher = {Springer-Verlag},
  title     = {Robust diagnostic regression analysis},
  year      = {2000},
  address   = {New York},
  note      = {下不到},
  groups    = {LMS},
  language  = {English},
}

@InBook{Weisberg1991,
  author    = {Weisberg, Sanford and Atkinson, A. C.},
  editor    = {Stahel, W. and Weisberg, S.},
  pages     = {7--20},
  publisher = {Springer-Verlag},
  title     = {Simulated annealing for the detection of multiple outliers using least squares and least median of squares fitting},
  year      = {1991},
  address   = {New York},
  booktitle = {Directions in Robust Statistics and Diagnostics, Part I},
  comment   = {can not be found online},
  groups    = {LMS, Simulated Annealing},
  language  = {English},
}

@Article{Hawkins1993,
  author   = {Hawkins, Douglas M.},
  journal  = {Computational Statistics \& Data Analysis},
  title    = {The feasible set algorithm for least median of squares regression},
  year     = {1993},
  issn     = {0167-9473},
  note     = {下不到},
  number   = {1},
  pages    = {81---101},
  volume   = {16},
  abstract = {The Least Median of Squares (LMS) criterion is a current standard method of analysis of data when the possibility of severe badly-placed outliers makes an estimate with high breakdown point desirable. Sometimes the LMS criterion is used in its own right, and sometimes it is the starting point for other follow-up analyses. Difficulties have arisen in its use, however, in that until recently there was no known way to obtain an exact LMS fit to a data set with more than one predictor. This has confused the discussion of LMS, since there is no way of knowing to what extent particular features seen in analysis really are properties of the LMS estimator and to what extent they are manifestations of the fact that the computed LMS fits are only approximations (and of unknown quality) to the exact solution. A recent algorithm by Stromberg has alleviated this difficulty by providing the mechanism for obtaining an exact fit. Unfortunately this approach is computationally intractable for all but quite small problems. The present paper proposes a probabilistic algorithm called the ‘Feasible Set Algorithm’ which produces only trial values satisfying the necessary condition for the optimum and which provides the exact solution with probability 1 as the number of iterations increases. The method's good performance on real data sets is verified by example.},
  doi      = {https://doi.org/10.1016/0167-9473(93)90246-P},
  groups   = {LMS},
  keywords = {Linear programming, Chebyshev criterion, High breakdown regression, Elemental sets},
  url      = {http://www.sciencedirect.com/science/article/pii/016794739390246P},
}

@Article{Hawkins1999,
  author   = {Hawkins, Douglas M. and Olive, David J.},
  journal  = {Computational Statistics \& Data Analysis},
  title    = {Improved feasible solution algorithms for high breakdown estimation},
  year     = {1999},
  issn     = {0167-9473},
  number   = {1},
  pages    = {1---11},
  volume   = {30},
  abstract = {High breakdown estimation allows one to get reasonable estimates of the parameters from a sample of data even if that sample is contaminated by large numbers of awkwardly placed outliers. Two particular application areas in which this is of interest are multiple linear regression, and estimation of the location vector and scatter matrix of multivariate data. Standard high breakdown criteria for the regression problem are the least median of squares (LMS) and least trimmed squares (LTS); those for the multivariate location/scatter problem are the minimum volume ellipsoid (MVE) and minimum covariance determinant (MCD). All of these present daunting computational problems. The ‘feasible solution algorithms’ for these criteria have been shown to have excellent performance for text-book sized problems, but their performance on much larger data sets is less impressive. This paper points out a computationally cheaper feasibility condition for LTS, MVE and MCD, and shows how the combination of the criteria leads to improved performance on large data sets. Algorithms incorporating these improvements are available from the first author's Web site.},
  doi      = {https://doi.org/10.1016/S0167-9473(98)00082-6},
  file     = {:FILES/1999 - Hawkins1999 - Improved feasible solution algorithms for high breakdown estimation.pdf:PDF},
  groups   = {LMS},
  keywords = {Linear model, Outliers, High breakdown estimation, Least trimmed squares, Minimum volume ellipsoid, Minimum covariance determinant},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167947398000826},
}

@InProceedings{Banerjee2007,
  author     = {Banerjee, A. and Louis, S. J.},
  booktitle  = {2007 IEEE International Fuzzy Systems Conference},
  title      = {A genetic algorithm implementation of the fuzzy least trimmed squares clustering},
  year       = {2007},
  month      = {7},
  pages      = {1--6},
  abstract   = {This paper describes a new approach to finding a global solution for the fuzzy least trimmed squares clustering. The least trimmed squares (LTS) estimator is known to be a high breakdown estimator, in both regression and clustering. From the point of view of implementation, the feasible solution algorithm is one of the few known techniques that guarantees a global solution for the LTS estimator. The feasible solution algorithm divides a noisy data set into two parts -the non-noisy retained set and the noisy trimmed set, by implementing a pairwise swap of datum between the two sets until a least squares estimator provides the best fit on the retained set. We present a novel genetic algorithm-based implementation of the feasible solution algorithm for fuzzy least trimmed squares clustering, and also substantiate the efficacy of our method by three examples.},
  doi        = {10.1109/FUZZY.2007.4295399},
  file       = {:FILES/2007 - Banerjee2007 - A Genetic Algorithm Implementation of the Fuzzy Least Trimmed Squares Clustering.pdf:PDF},
  groups     = {LMS, Clustering, genetic algorithms},
  issn       = {1098-7584},
  keywords   = {genetic algorithms;least squares approximations;pattern clustering;genetic algorithm;fuzzy least trimmed square clustering;high breakdown estimator;noisy data set;nonnoisy retained set;noisy trimmed set;Genetic algorithms;Clustering algorithms;Electric breakdown;Least squares approximation;Partitioning algorithms;Noise robustness;Laboratories;Computer science;Minimization methods;Prototypes, skimmed},
  readstatus = {skimmed},
}

@Article{Beale1969,
  author  = {Beale, E. and Tomlin, John},
  journal = {Operational Research},
  title   = {Special facilities in a general mathematical programming system for nonconvex problems using ordered sets of variables},
  year    = {1969},
  month   = {01},
  pages   = {447--454},
  volume  = {69},
  comment = {SOS-1},
  file    = {:FILES/1969 - Beale1969 - Special facilities in a general mathematical programming system for nonconvex problems using ordered sets of variables.pdf:PDF},
  groups  = {optimization},
}

@Article{Farias2008,
  author   = {{de Farias}, I. R. and Zhao, M. and Zhao, H.},
  journal  = {Operations Research Letters},
  title    = {A special ordered set approach for optimizing a discontinuous separable piecewise linear function},
  year     = {2008},
  issn     = {0167-6377},
  number   = {2},
  pages    = {234--238},
  volume   = {36},
  abstract = {We give a special ordered set (SOS) approach that optimizes a discontinuous separable piecewise linear function, even when a mixed-integer programming (MIP) model is not available for it. When a MIP model is available, our SOS model gives a linear programming relaxation bound that is as good as the MIPs.},
  doi      = {https://doi.org/10.1016/j.orl.2007.05.004},
  file     = {:FILES/2008 - Farias2008 - A special ordered set approach for optimizing a discontinuous separable piecewise linear function.pdf:PDF},
  groups   = {optimization},
  keywords = {Piecewise linear optimization, Special ordered set},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167637707000788},
}

@Misc{Bertsimas2017,
  author        = {Bertsimas, Dimitris and Copenhaver, Martin S. and Mazumder, Rahul},
  title         = {The trimmed lasso: {Sparsity} and robustness},
  year          = {2017},
  archiveprefix = {arXiv},
  eprint        = {1708.04527},
  file          = {:FILES/2017 - Bertsimas2017 - The Trimmed Lasso- Sparsity and Robustness.pdf:PDF},
  groups        = {LMS},
  primaryclass  = {stat.ME},
}

@TechReport{Gomez2019,
  author      = {G\'{o}mez, Andr\'{e}s},
  institution = {University of Southern California},
  title       = {Outlier detection in time series via mixed-integer conic quadratic optimization},
  year        = {2019},
  month       = {11},
  type        = {Research report AG 19.05},
  abstract    = {We consider the problem of estimating the true values of a Wiener process given noisy observations corrupted by outliers. The problem considered is closely related to the Trimmed Least Squares estimation problem, a robust estimation procedure well-studied from a statistical standpoint but poorly understood from an optimization perspective. In this paper we show how to improve existing mixed-integer quadratic optimization formulations for this problem. Specifically, we convexify the existing formulations via lifting, deriving new mixed-integer conic quadratic reformulations. The proposed reformulations are stronger and substantially faster when used with current mixed-integer optimization solvers. In our experiments, solution times are improved by at least two orders-of-magnitude.},
  comment     = {1. leave-k-out diagnostics [21] used in time series analysis},
  file        = {:FILES/2019 - Gomez2019 - Outlier detection in time series via mixed-integer conic quadratic optimization.pdf:PDF},
  groups      = {LMS, MINLP},
  keywords    = {Trimmed Least Squares, outlier detection, mixed-integer optimization, conic quadratic optimization, convexification, lifting, skimmed},
  readstatus  = {skimmed},
  url         = {http://www.optimization-online.org/DB_HTML/2019/11/7488.html},
}

@Article{Mount2014,
  author   = {Mount, David M. and Netanyahu, Nathan S. and Piatko, Christine D. and Silverman, Ruth and Wu, Angela Y.},
  journal  = {Algorithmica},
  title    = {On the least trimmed squares estimator},
  year     = {2014},
  issn     = {1432-0541},
  month    = {5},
  number   = {1},
  pages    = {148--183},
  volume   = {69},
  abstract = {The linear least trimmed squares (LTS) estimator is a statistical technique for fitting a linear model to a set of points. Given a set of n points in ℝdand given an integer trimming parameter h≤n, LTS involves computing the (d−1)-dimensional hyperplane that minimizes the sum of the smallest h squared residuals. LTS is a robust estimator with a 50 {\%}-breakdown point, which means that the estimator is insensitive to corruption due to outliers, provided that the outliers constitute less than 50 {\%} of the set. LTS is closely related to the well known LMS estimator, in which the objective is to minimize the median squared residual, and LTA, in which the objective is to minimize the sum of the smallest 50 {\%} absolute residuals. LTS has the advantage of being statistically more efficient than LMS. Unfortunately, the computational complexity of LTS is less understood than LMS. In this paper we present new algorithms, both exact and approximate, for computing the LTS estimator. We also present hardness results for exact and approximate LTS. A number of our results apply to the LTA estimator as well.},
  day      = {01},
  doi      = {10.1007/s00453-012-9721-8},
  file     = {:FILES/2014 - Mount2014 - On the least trimmed squares estimator.pdf:PDF},
  groups   = {LMS},
  url      = {https://doi.org/10.1007/s00453-012-9721-8},
}

@InCollection{Shen2019,
  author    = {Shen, Yanyao and Sanghavi, Sujay},
  booktitle = {Advances in Neural Information Processing Systems 32},
  publisher = {Curran Associates, Inc.},
  title     = {Iterative least trimmed squares for mixed linear regression},
  year      = {2019},
  editor    = {Wallach, H. and Larochelle, H. and Beygelzimer, A. and Alch\'{e}-Buc, F. and Fox, E. and Garnett, R.},
  pages     = {6078--6088},
  file      = {:FILES/2019 - Shen2019 - Iterative Least Trimmed Squares for Mixed Linear Regression.pdf:PDF},
  groups    = {LMS},
  url       = {http://papers.nips.cc/paper/8840-iterative-least-trimmed-squares-for-mixed-linear-regression.pdf},
}

@InProceedings{Noeel2016,
  author    = {No\"{e}l, J. P. and Schoukens, M.},
  booktitle = {Workshop on Nonlinear System Identification Benchmark: April 11-13, 2016, Liege, Belgium},
  title     = {Hysteretic benchmark with a dynamic nonlinearity},
  year      = {2016},
  month     = {4},
  note      = {2016 Workshop on Nonlinear System Identification Benchmarks ; Conference date: 25-04-2016 Through 27-04-2016},
  pages     = {7--14},
  abstract  = {Hysteresis is a phenomenology commonly encountered in very diverse engineering and science disciplines, ranging from solid mechanics, electromagnetism and aerodynamics [1, 2, 3] to biology, ecology and psychology [4, 5, 6]. The defining property of a hysteretic system is the persistence of an input-output loop as the input frequency approacheszero [7]. Hysteretic systems are inherently nonlinear, as the quasi-static existence of a loop requires an input-output phase shift different from and 180 degrees, which are the only two options offered by linear theory. The root cause of hysteresis is multistability [8].A hysteretic system possesses multiple stable equilibria, attracting the output depending on the input history. In this sense, it is appropriate to refer hysteresis as system nonlinear memory.This document describes the synthesis of noisy data exhibiting hysteresis behaviour carried out by combining the Bouc-Wen differential equations (Section 2) and the Newmark integration rules (Section 3). User guidelines to an accurate simulation are provided in Section 4. The test signals and the figures of merit that are used in this benchmark are presented in Section 5. Anticipated nonlinear system identification challenges associated with the present benchmark are listed in Section 6.},
  groups    = {benchmark},
  language  = {English},
  timestamp = {2020-08-12},
}

@Misc{Bache2013,
  author      = {Bache, Kevin and Lichman, Moche},
  title       = {{UCI} machine learning repository},
  year        = {2013},
  bdsk-url-1  = {http://archive.ics.uci.edu/ml},
  groups      = {data},
  institution = {University of California, Irvine, School of Information and Computer Sciences},
  url         = {http://archive.ics.uci.edu/ml},
}

@Article{AndersForsgren2002,
  author    = {Anders Forsgren, Margaret H. Wright},
  journal   = {SIAM Review},
  title     = {Interior methods for nonlinear optimization},
  year      = {2002},
  number    = {4},
  pages     = {525--597},
  volume    = {44},
  groups    = {global optimization},
  publisher = {Society for Industrial and Applied Mathematics},
}

@InBook{Schmidt2007,
  author        = {Schmidt, Mark and Fung, Glenn and Rosales, R\'{o}mer},
  chapter       = {Fast Optimization Methods for {L}1 Regularization: A Comparative Study and Two New Approaches},
  editor        = {Kok, Joost N. and Koronacki, Jacek and Mantaras, Raomon Lopez de and Matwin, Stan and Mladeni\v{c}, Dunja and Skowron, Andrzej},
  pages         = {286--297},
  publisher     = {Springer Berlin Heidelberg},
  title         = {Machine learning: {ECML} 2007: 18th {European} conference on machine learning, {Warsaw}, {Poland}, {September} 17-21, 2007. proceedings},
  year          = {2007},
  address       = {Berlin, Heidelberg},
  volume        = {4701},
  booktitle     = {Machine Learning: European Conference on Machine Learning 2007},
  date-modified = {2016-03-03 05:35:52 +0000},
  groups        = {machine learning},
}

@Misc{Loefberg2015,
  author        = {L\"{o}fberg, Johan},
  howpublished  = {http://users.isy.liu.se/johanl/yalmip/pmwiki.php},
  month         = {9},
  title         = {Yalmip {Wiki}},
  year          = {2015},
  date-added    = {2016-04-02 08:16:55 +0000},
  date-modified = {2016-04-02 08:22:22 +0000},
  groups        = {softwares},
  url           = {https://yalmip.github.io/},
}

@Book{Antoniou2000,
  author    = {Antoniou, Andreas},
  publisher = {McGraw-Hill Science},
  title     = {Digital filters: {Analysis}, design, and applications},
  year      = {2000},
  edition   = {2nd},
  groups    = {DSP},
}

@Article{Feng2015a,
  author  = {Feng, Zhi Guo and Yiu, Ka Fai and Nordholm, Sven Erik},
  journal = {Journal of Optimization Theory and Applications},
  title   = {Performance limit of broadband beamformer designs in space and frequency},
  year    = {2015},
  issn    = {0022-3239},
  month   = jan,
  number  = {1},
  pages   = {316--341},
  volume  = {164},
  doi     = {10.1007/s10957-014-0543-5},
  file    = {:FILES/2015 - Feng2015a - Performance limit of broadband beamformer designs in space.pdf:PDF},
  groups  = {FIR filter design},
  url     = {https://link.springer.com/article/10.1007/s10957-014-0543-5},
}

@PhdThesis{Xu2018phd,
  author   = {Xu, Zhiming},
  school   = {Tsinghua University},
  title    = {Searching methods of piecewise linear optimization and the applications in aerial cyber-physical systems},
  year     = {2018},
  address  = {Beijing},
  month    = oct,
  type     = {phdthesis},
  abstract = {The piecewise linear programming is a special kind of nonlinear programming, of 
which the objective and the constraints are all linear or piecewise linear functiones. The 
global flexibility gives it arbitrary approximation ability on any nonlinear function, and 
the local linearity enables us to propose pretty efficient algorithms. The various 
optimization problems derived from the aerial cyber physical systems (CPS) are often 
characterized by distinct continuous picewise smoothness, thus the continuous picewise 
linear programming (CPLP) possesses great potential for these problems. In this 
dissertation, local and global optimization methods for CPLP are studied, corresponding 
deterministic algorithms are designed, and relevant technologies are applied in solving 
some optimization problems faced by aerial CPS. The main contribution of this 
dissertation can be summarized as follows. 
Firstly, due to the existence of exact penalty and the complete representation 
capability of the generalized hinging hyperplane model, any continuous piecewise linear 
optimization problem can be equivalently transformed into a concave minimazation 
problem over a polyhedron. Based on this, a pertinent local optimal algorithm, the 
sequential global linear programming (SGLP) algorithm, is put forward by utilizing the 
characteristics of concavity and combining with the mature technology of linear 
programming. Simulation results show superior comprehensive performance of the 
proposed algorithm in single local optimization process. 
Secondly, in view of the difficulties in global optimizing a general nonconvex 
nonseparable CPLP, the hill tunneling (HT) method is proposed, inspired by the 
"contour surface searching" strategy, to search for the global optimal of the equivalent 
concave minimazation problem. Following this HT method, two global optimization 
algorithms are proposed, named hill tunneling via peak subpoint (HTPS) and hill 
tunneling via simplex centroid (HTSC). In addition, a sufficient criterion for the global 
optimality of the obtained solution is designed, with both effectiveness and ease of use. 
Experiments and comparisons with other methods show excellent performance of the 
proposed HT method on problems in all scales. 
Thirdly, the k-th maximum minimuzation problem is a peculiar CPLP, and the 
Abstract 
III
proposed HT method can not be applied directly in finding the global optimal solution. 
In this dissertation, the duality technology is introduced, to express the constraints of the 
equivalent concave optimization problem compactly and explicitly. Then, the global 
optimization algorithm for minimizing the k-th maximum function, named hill 
tunneling based on transform with dual technique (HTTDT), is given, and the 
performance of the algorithm is verified by numberical experiments. 
Lastly, two cases of unmanned aerial vehicle (UAV) intelligent formation flight 
control and air fleet cooperative detection are tanken as examples to show the 
applications of CPLP in aerial CPS. In these two cases, by using the CPLP technology, 
the problem of massive sample sets generating for formation control strategy training, 
as well as the problem of formation optimization for bistatic cooperative detection in air 
fleet, are succesfully solved. The effectiveness of the both are verified by numberical 
simulations, then. The research shows the applicability of the CPLP model for the 
optimization problems in aerial CPS.},
  groups   = {Wang's Work},
}

@PhdThesis{xu2018phdCN,
  author   = {续志明},
  school   = {清华大学},
  title    = {分片线性优化方法及其在航空{CPS}系统中的应用},
  year     = {2018},
  address  = {北京},
  month    = oct,
  type     = {phdthesis},
  abstract = {分片线性规划是一类重要而特殊的非线性规划，其目标函数与约束条件均为
线性或分片线性函数。其局部上的线性性带来了结构和解法上的优势，而全局上
的灵活性又使其可以逼近任意连续非线性问题。航空信息物理融合系统（CPS）
所面临的各类优化问题，往往具有鲜明的连续分片光滑性，因此连续分片线
性规划在其中潜力巨大。本文对连续分片线性规划的局部和全局寻优方法进
行了深入的研究，设计了相应的确定性算法，并将相关技术应用于解决航空
CPS 所面临的一些优化问题。本文完成的工作主要包括以下几个方面：
第一，由于精确罚的存在性和广义链接超平面模型的完全表示能力，一般的
连续分片线性优化问题可以被等价转化为一个定义在凸多面体上的凹分片线性规
划问题。本文以此为基础，利用线性规划的成熟技术并结合凹分片线性规划自身
的特点，设计了具有很强针对性的局部最优算法——序列全局线性规划法。仿真
实验表明了所提出的算法在单次局部最优过程中具有良好的综合性能。
第二，针对一般的非凸非可分的连续分片线性优化问题的全局寻优困难，本
文在“等值面搜索”策略的启发下，提出了对等价凹分片线性规划问题进行全局
寻优的穿山法思想，然后在此基础上设计了两种全局寻优算法——山顶投影穿山
法和单纯形穿山法。此外，针对所得解的全局最优性判别问题，巧妙设计了一种
兼具有效性与易用性的充分性判别条件。大规模的仿真实验，表明了穿山法在不
同规模问题上都具有优良的性能。
第三，k 位最大值函数作为一种特殊的连续分片线性函数，其极小化问题无法
直接应用之前设计的穿山法进行全局寻优。本文通过引入对偶转化技术，让等价
凹优化问题的约束集被显式化地紧凑表达，然后在此基础上给出了极小化 k 位最
大值函数的全局寻优算法——基于对偶转化技术的穿山法，并通过仿真实验验证
了算法性能。
第四，本文分别以无人机智能编队飞行控制和机群协同探测两个领域为例，
讨论了连续分片线性规划问题在航空 CPS 中的应用。在这两个案例中，通过应用
分片线性优化技术，成功解决了编队控制策略的学习训练集的大规模生成问题和
机群收发分置协同探测的编队优化问题，并通过仿真验证了其有效性。研究表明
了分片线性模型对航空 CPS 中的优化问题的良好适用性},
  groups   = {Wang's Work},
}

@Article{Hastings1970,
  author    = {Hastings, W. K.},
  journal   = {Biometrika},
  title     = {Monte {Carlo} sampling methods using {Markov} chains and their applications},
  year      = {1970},
  issn      = {00063444},
  number    = {1},
  pages     = {97--109},
  volume    = {57},
  abstract  = {A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.},
  groups    = {mathematical basis},
  publisher = {[Oxford University Press, Biometrika Trust]},
  url       = {http://www.jstor.org/stable/2334940},
}

@Article{Metropolis1953,
  author  = {Metropolis, Nicholas and Rosenbluth, Arianna W. and Rosenbluth, Marshall N. and Teller, Augusta H. and Teller, Edward},
  journal = {The Journal of Chemical Physics},
  title   = {Equation of state calculations by fast computing machines},
  year    = {1953},
  number  = {6},
  pages   = {1087--1092},
  volume  = {21},
  doi     = {10.1063/1.1699114},
  eprint  = {https://doi.org/10.1063/1.1699114},
  groups  = {mathematical basis},
  url     = {https://doi.org/10.1063/1.1699114},
}

@Article{Geman1984,
  author   = {Geman, S. and Geman, D.},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title    = {Stochastic relaxation, {Gibbs} distributions, and the {Bayesian} restoration of images},
  year     = {1984},
  issn     = {1939-3539},
  month    = {11},
  number   = {6},
  pages    = {721--741},
  volume   = {PAMI-6},
  abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios.},
  doi      = {10.1109/TPAMI.1984.4767596},
  groups   = {mathematical basis},
  keywords = {Stochastic processes;Bayesian methods;Image restoration;Degradation;Markov random fields;Additive noise;Deformable models;Temperature distribution;Energy states;Annealing;Annealing;Gibbs distribution;image restoration;line process;MAP estimate;Markov random field;relaxation;scene modeling;spatial degradation},
}

@Article{Dueck1990,
  author    = {Dueck, Gunter and Scheuer, Tobias},
  journal   = {Journal of Computational Physics},
  title     = {Threshold accepting: {A} general purpose optimization algorithm appearing superior to simulated annealing},
  year      = {1990},
  issn      = {0021-9991},
  number    = {1},
  pages     = {161--175},
  volume    = {90},
  abstract  = {A new general purpose algorithm for the solution of combinatorial optimization problems is presented. The new threshold accepting method is even simpler structured than the wellknown simulated annealing approach. The power of the new algorithm is demonstrated by computational results concerning the traveling salesman problem and the problem of the construction of error-correcting codes. Moreover, deterministic (!) versions of the new heuristic turn out to perform nearly equally well, consuming only a fraction of the computing time of the stochastic versions. As an example, the deterministic threshold accepting method yields very-near-to-optimum tours for the famous 442-cities traveling salesman problem of Grötschel within 1 to 2 s of CPU time.},
  doi       = {https://doi.org/10.1016/0021-9991(90)90201-B},
  groups    = {Simulated Annealing},
  timestamp = {2020-09-04},
  url       = {http://www.sciencedirect.com/science/article/pii/002199919090201B},
}

@Article{Hager1989,
  author    = {Hager, William W.},
  journal   = {SIAM Review},
  title     = {Updating the inverse of a matrix},
  year      = {1989},
  issn      = {00361445},
  number    = {2},
  pages     = {221--239},
  volume    = {31},
  abstract  = {The Sherman--Morrison--Woodbury formulas relate the inverse of a matrix after a small-rank perturbation to the inverse of the original matrix. The history of these formulas is presented and various applications to statistics, networks, structural analysis, asymptotic analysis, optimization, and partial differential equations are discussed. The Sherman--Morrison--Woodbury formulas express the inverse of a matrix after a small rank perturbation in terms of the inverse of the original matrix. This paper surveys the history of these formulas and we examine some applications where these formulas are helpful.},
  file      = {:FILES/1989 - Hager1989 - Updating the Inverse of a Matrix.pdf:PDF},
  groups    = {mathematical basis},
  publisher = {Society for Industrial and Applied Mathematics},
  url       = {http://www.jstor.org/stable/2030425},
}

@InProceedings{huang2012robust,
  author    = {Huang, Dong and Cabral, Ricardo Silveira and De la Torre, Fernando},
  booktitle = {Computer Vision -- ECCV 2012},
  title     = {Robust regression},
  year      = {2012},
  address   = {Berlin, Heidelberg},
  editor    = {Fitzgibbon, Andrew and Lazebnik, Svetlana and Perona, Pietro and Sato, Yoichi and Schmid, Cordelia},
  pages     = {616--630},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Discriminative methods (e.g., kernel regression, SVM) have been extensively used to solve problems such as object recognition, image alignment and pose estimation from images. Regression methods typically map image features (X) to continuous (e.g., pose) or discrete (e.g., object category) values. A major drawback of existing regression methods is that samples are directly projected onto a subspace and hence fail to account for outliers which are common in realistic training sets due to occlusion, specular reflections or noise. It is important to notice that in existing regression methods, and discriminative methods in general, the regressor variables X are assumed to be noise free. Due to this assumption, discriminative methods experience significant degrades in performance when gross outliers are present.},
  file      = {:FILES/2012 - huang2012robust - Robust Regression.pdf:PDF},
  groups    = {LMS},
  isbn      = {978-3-642-33765-9},
}

@Article{Knapp2009,
  author    = {Knapp, Michael P.},
  journal   = {Mathematics Magazine},
  title     = {Sines and cosines of angles in arithmetic progression},
  year      = {2009},
  number    = {5},
  pages     = {371-372},
  volume    = {82},
  doi       = {10.4169/002557009X478436},
  eprint    = {https://doi.org/10.4169/002557009X478436},
  file      = {:FILES/2009 - Knapp2009 - Sines and Cosines of Angles in Arithmetic Progression.pdf:PDF},
  groups    = {mathematical basis},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.4169/002557009X478436},
}

@Book{Horst1995,
  editor    = {Horst, Reiner and Pardalos, Panos M.},
  publisher = {Springer-Science+Business Media},
  title     = {Handbook of global optimization},
  year      = {1995},
  series    = {Nonconvex optimization and its applications},
  volume    = {2},
  file      = {:FILES/1995 - Horst1995 - Handbook of Global Optimization.pdf:PDF},
  groups    = {global optimization},
}

@Article{Li2015,
  author    = {Li, Zhaokai and Liu, Xiaomei and Xu, Nanyang and Du, Jiangfeng},
  journal   = {Physical Review Letters},
  title     = {Experimental realization of a quantum support vector machine},
  year      = {2015},
  month     = {Apr},
  pages     = {140504},
  volume    = {114},
  abstract  = {The fundamental principle of artificial intelligence is the ability of machines to learn from previous experience and do future work accordingly. In the age of big data, classical learning machines often require huge computational resources in many practical cases. Quantum machine learning algorithms, on the other hand, could be exponentially faster than their classical counterparts by utilizing quantum parallelism. Here, we demonstrate a quantum machine learning algorithm to implement handwriting recognition on a four-qubit NMR test bench. The quantum machine learns standard character fonts and then recognizes handwritten characters from a set with two candidates. Because of the wide spread importance of artificial intelligence and its tremendous consumption of computational resources, quantum speedup would be extremely attractive against the challenges of big data.},
  doi       = {10.1103/PhysRevLett.114.140504},
  file      = {:FILES/2015 - Li2015 - Experimental Realization of a Quantum Support Vector Machine.pdf:PDF},
  groups    = {SVM},
  issue     = {14},
  keywords  = {prio1},
  numpages  = {5},
  priority  = {prio1},
  publisher = {American Physical Society},
  timestamp = {2020-08-30},
  url       = {https://link.aps.org/doi/10.1103/PhysRevLett.114.140504},
}

@Article{Takahama2004,
  author   = {Takahama, Tetsuyuki and Sakai, Setsuko},
  journal  = {Systems and Computers in Japan},
  title    = {Constrained optimization by α constrained genetic algorithm {($\alpha$GA)}},
  year     = {2004},
  month    = mar,
  number   = {5},
  pages    = {11-22},
  volume   = {35},
  abstract = {Abstract In this study, α constrained genetic algorithm (αGA) which solves constrained optimization problems is proposed. Constrained optimization problems, where the objective functions are minimized under given constraints, are very important and frequently appear in the real world. Recently, researches on constrained optimization using genetic algorithm (GA) have been widely carried out, and their results are equivalent to those by existing mathematical methods. αGA is a method which combines the α constrained method with GA. In the α constrained method, the satisfaction level of constraints to express how much a search point satisfies the constraints is introduced. The α level comparison which compares the search points based on the satisfaction level of constraints is also introduced. The α constrained method can convert constrained problems to unconstrained problems using α level comparison. In αGA, the individuals who satisfy the constraints will evolve to optimize the objective function and the individuals who do not satisfy the constraints will evolve to satisfy the constraints, naturally. In this paper, the effectiveness of αGA is shown by comparing αGA with GENOCOP 5.0 on various types of test problems, such as a linear programming problem, nonlinear programming problems, and problems with nonconvex constraints. © 2004 Wiley Periodicals, Inc. Syst Comp Jpn, 35(5): 11–22, 2004; Published online in Wiley InterScience (www.interscience.wiley.com). DOI 10.1002/scj.10562},
  doi      = {10.1002/scj.10562},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/scj.10562},
  file     = {:FILES/2004 - Takahama2004 - Constrained optimization by α constrained genetic algorithm (αGA).pdf:PDF},
  groups   = {genetic algorithms},
  keywords = {constrained optimization, nonlinear optimization, real-coded genetic algorithm, α constrained method},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/scj.10562},
}

@TechReport{Herrera1998,
  author      = {Herrera, F. and Lozano, M.},
  institution = {Universidad de Granada},
  title       = {Adaptive genetic algorithms based on coevolution with fuzzy behaviors},
  year        = {1998},
  address     = {18071 Granada, Spain},
  number      = {DECSAI-98-01-05},
  type        = {techreport},
  abstract    = {Adaptive genetic algorithms dynamically adjust the genetic algorithm configuration during the course of evolving a problem solution in order to offer an appropriate balance between exploration (overall search in the solution space) and exploitation (localized search in the promising regions discovered in that space). One promising way followed for building adaptive genetic algorithms involves the application of fuzzy logic controllers for tuning genetic algorithm control parameters. In this paper, a general model based on fuzzy logic controllers is presented for adapting parameters that control the application of any genetic operator. Our proposal is called coevolution with fuzzy behaviors. A fuzzy behavior is a vector with the linguistic values of the fuzzy rule consequent of a fuzzy logic controller, that encodes its fuzzy rule base. Control parameter values are computed for each set of parents that undergo the genetic operator, using a fuzzy logic controller that considers particular
features associated with the parents as inputs. On the other hand, fuzzy behaviors (fuzzy rule bases)
are implicitly learnt by means of an additional genetic algorithm that coevolves with the main one
(coevolution). The goal of coevolution with fuzzy behaviors is to obtain fuzzy rule bases producing
suitable control parameter values for al lowing the genetic operator to show an adequate performance.
In order to analyze the eectiveness of the model, an instance is implemented for the adaptation
of the fuzzy recombination, a crossover operator proposed for real-coded genetic algorithms. An empirical study of the instance is made from two dierent points of view, one of performance and one of
adaptation itself (based on the distributions of fuzzy behaviors appearing during the runs). The results
show that the instance has an adaptation ability which al lows signicant performance to be achieved
for test functions with dierent diculties.},
  file        = {:FILES/1998 - Herrera1998 - Adaptive Genetic Algorithms Based on Coevolution with Fuzzy Behaviors.pdf:PDF},
  groups      = {genetic algorithms},
}

@Article{Nandan2005,
  author    = {Nandan, R. and Rai, R. and Jayakanth, R. and Moitra, S. and Chakraborti, N. and Mukhopadhyay, A.},
  journal   = {Materials and Manufacturing Processes},
  title     = {Regulating crown and flatness during hot rolling: {A} multiobjective optimization study using genetic algorithms},
  year      = {2005},
  number    = {3},
  pages     = {459--478},
  volume    = {20},
  abstract  = {ABSTRACT A genetic algorithms-based multioptimization study has been carried out for the hot rolling practice in an integrated steel plant. The aim is to identify the parameter settings and rolling schedules that would result in the optimum values of crown and flatness–-two major parameters related to the geometric tolerances in the rolled sheet. Two objective functions and some appropriate constraints have been formulated for this purpose, and two different evolutionary algorithms are tried out on them. The optimized results are presented in the forms of Pareto fronts and discussed in the context of the actual process.},
  doi       = {10.1081/AMP-200053462},
  eprint    = {https://doi.org/10.1081/AMP-200053462},
  file      = {:FILES/2005 - Nandan2005 - Regulating Crown and Flatness During Hot Rolling A Multiobjective Optimization Study Using Genetic Algorithms.pdf:PDF},
  groups    = {genetic algorithms},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1081/AMP-200053462},
}

@Article{Kieffer2020,
  author   = {E. Kieffer and G. Danoy and M. R. Brust and P. Bouvry and A. Nagih},
  journal  = {IEEE Transactions on Evolutionary Computation},
  title    = {Tackling large-scale and combinatorial bi-level problems with a genetic programming hyper-heuristic},
  year     = {2020},
  issn     = {1941-0026},
  month    = {Feb},
  number   = {1},
  pages    = {44--56},
  volume   = {24},
  abstract = {Combinatorial bi-level optimization remains a challenging topic, especially when the lower-level is an NP-hard problem. In this paper, we tackle large-scale and combinatorial bi-level problems using GP hyper-heuristics, i.e., an approach that permits to train heuristics like a machine learning model. Our contribution aims at targeting the intensive and complex lower-level optimizations that occur when solving a large-scale and combinatorial bi-level problem. For this purpose, we consider hyper-heuristics through heuristic generation. Using a GP hyper-heuristic approach, we train greedy heuristics in order to make them more reliable when encountering unseen lower-level instances that could be generated during bi-level optimization. To validate our approach referred to as GA+AGH, we tackle instances from the bi-level cloud pricing optimization problem (BCPOP) that model the trading interactions between a cloud service provider and cloud service customers. Numerical results demonstrate the abilities of the trained heuristics to cope with the inherent nested structure that makes bi-level optimization problems so hard. Furthermore, it has been shown that training heuristics for lower-level optimization permits to outperform human-based heuristics and metaheuristics which constitute an excellent outcome for bi-level optimization.},
  doi      = {10.1109/TEVC.2019.2906581},
  file     = {:FILES/2020 - Kieffer2020 -Tackling Large-Scale and Combinatorial Bi-Level Problems With a Genetic Programming Hyper-Heuristic.pdf:PDF},
  groups   = {genetic algorithms, bilevel},
  keywords = {computational complexity;genetic algorithms;search problems;lower-level optimization;heuristic generation;GP hyper-heuristic approach;greedy heuristics;bi-level cloud pricing optimization problem;bi-level optimization problems;combinatorial bi-level problems;genetic programming hyper-heuristic;NP-hard problem;GP hyper-heuristics;Optimization;Cloud computing;Pricing;Linear programming;Decision making;Complexity theory;Genetic programming;Bi-level optimization;genetic programming;hyper-heuristics;pricing in the cloud;Stackelberg games},
}

@Article{YANG2019quantile,
  author     = {Yang, Liming and Dong, Hongwei},
  journal    = {Applied Soft Computing},
  title      = {Robust support vector machine with generalized quantile loss for classification and regression},
  year       = {2019},
  issn       = {1568-4946},
  pages      = {105483},
  volume     = {81},
  abstract   = {A new robust loss function (called Lq-loss) is proposed based on the concept of quantile and correntropy, which can be seen as an improved version of quantile loss function. The proposed Lq-loss has some important properties such as asymmetry, non-convexity and boundedness, which has received a lot of attention recently. The Lq-loss includes and extends the traditional loss functions such as pinball loss, rescaled hinge loss, L1-norm loss and zero-norm loss. Additionally, we demonstrate that the Lq-loss is a kernel-induced loss by reproducing piecewise kernel function. Further, two robust SVM frameworks are presented to handle robust classification and regression problems by applying Lq-loss to support vector machine, respectively. Last but not least, we demonstrate that the proposed classification framework satisfies Bayes’ optimal decision rule. However, the non-convexity of the proposed Lq-loss makes it difficult to optimize. A non-convex optimization method, concave–convex procedure (CCCP) technique, is used to solve the proposed models, and the convergence of the algorithms is proved theoretically. For classification and regression tasks, experiments are carried out on three databases including UCI benchmark datasets, artificial datasets and a practical application dataset. Compared to some classical and advanced methods, numerical simulations under different noise setting and different evaluation criteria show that the proposed methods have good robustness to feature noise and outliers in both classification and regression applications.},
  doi        = {https://doi.org/10.1016/j.asoc.2019.105483},
  file       = {:FILES/2019 - YANG2019quantile - Robust support vector machine with generalized quantile loss for classification and regression.pdf:PDF},
  groups     = {SVM},
  keywords   = {Robustness, Quantile, Correntropy, Non-convex loss, Support vector machines, read},
  readstatus = {read},
  timestamp  = {2020-08-30},
  url        = {http://www.sciencedirect.com/science/article/pii/S1568494619302534},
}

@Article{Lin2020,
  author     = {Lin, Jie and Zhang, Dan-Bo and Zhang, Shuo and Li, Tan and Wang, Xiang and Bao, Wan-Su},
  journal    = {Physics Letters A},
  title      = {Quantum-enhanced least-square support vector machine: {Simplified }quantum algorithm and sparse solutions},
  year       = {2020},
  issn       = {0375-9601},
  number     = {25},
  pages      = {126590},
  volume     = {384},
  abstract   = {Quantum algorithms can enhance machine learning in different aspects. Here, we study quantum-enhanced least-square support vector machine (LS-SVM). Firstly, a novel quantum algorithm that uses continuous variable to assist matrix inversion is introduced to simplify the algorithm for quantum LS-SVM, while retaining exponential speed-up. Secondly, we propose a hybrid quantum-classical version for sparse solutions of LS-SVM. By encoding a large dataset into a quantum state, a much smaller transformed dataset can be extracted using quantum matrix toolbox, which is further processed in classical SVM. We also incorporate kernel methods into the above quantum algorithms, which uses both exponential growth Hilbert space of qubits and infinite dimensionality of continuous variable for quantum feature maps. The quantum LS-SVM exploits quantum properties to explore important themes for SVM such as sparsity and kernel methods, and stresses its quantum advantages ranging from speed-up to the potential capacity to solve classically difficult machine learning tasks.},
  doi        = {https://doi.org/10.1016/j.physleta.2020.126590},
  file       = {:FILES/2020 - Lin2020 - Quantum-enhanced least-square support vector machine- Simplified quantum algorithm and sparse solutions.pdf:PDF},
  groups     = {SVM},
  keywords   = {Support vector machine, Hybrid variables, Kernel method, skimmed},
  readstatus = {skimmed},
  timestamp  = {2020-08-30},
  url        = {http://www.sciencedirect.com/science/article/pii/S0375960120304576},
}

@Article{Teo1994,
  author    = {Teo, K. L. and Cantoni, A. and Lin, X. G.},
  journal   = {IEEE Transactions on Signal Processing},
  title     = {A new approach to the optimization of envelope-constrained filters with uncertain input},
  year      = {1994},
  issn      = {1941-0476},
  month     = {2},
  number    = {2},
  pages     = {426--429},
  volume    = {42},
  abstract  = {In envelope-constrained filtering, the filter is optimized subject to the constraint that the filter response to a given signal lies within a specified envelope or mask. In a number of signal processing applications, the envelope-constrained filtering problem is more directly relevant than least squares approximation-based approaches. The present authors develop an efficient method for solving an extended version of the envelope-constrained filtering problem in which the input pulse is not known exactly but is known to lie within a specified mask. This envelope-constrained problem with uncertain input (ECUI) has been examined elsewhere, but the algorithm proposed there for its solution has, in general, inferior convergence characteristics.<>},
  doi       = {10.1109/78.275618},
  file      = {:FILES/1994 - Teo1994 - A new approach to the optimization of envelope-constrained filters with uncertain input.pdf:PDF},
  groups    = {FIR filter design},
  keywords  = {digital filters;filtering and prediction theory;quadratic programming;optimization;envelope-constrained filters;uncertain input;signal processing application;extended version;input pulse;mask;ECUI;convergence characteristics;Finite impulse response filter;Filtering;Constraint optimization;Signal processing algorithms;Pulse shaping methods;Shape;Least squares approximation;Radar signal processing;Radar antennas;Australia},
  timestamp = {2020-08-31},
}

@Article{Sheikh2012,
  author    = {Sheikh, Z. U. and Gustafsson, O.},
  journal   = {IEEE Transactions on Circuits and Systems II: Express Briefs},
  title     = {Linear programming design of coefficient decimation {FIR} filters},
  year      = {2012},
  issn      = {1558-3791},
  month     = {1},
  number    = {1},
  pages     = {60--64},
  volume    = {59},
  abstract  = {The coefficient decimation technique for reconfigurable FIR filters was recently proposed as a filter structure with low computational complexity. In this brief, we propose to design these filters using linear programming taking all configuration modes into account, instead of only considering the initial reconfiguration mode as in previous works. Minimax solutions with significantly lower approximation errors compared to the straightforward design method in earlier works are obtained. In addition, some new insights that are useful when designing coefficient decimation filters are provided.},
  doi       = {10.1109/TCSII.2011.2173965},
  file      = {:FILES/2012 - Sheikh2012 - Linear Programming Design of Coefficient Decimation FIR Filters.pdf:PDF},
  groups    = {FIR filter design},
  keywords  = {computational complexity;FIR filters;linear programming;minimax techniques;linear programming design;coefficient decimation FIR filters;reconfigurable finite impulse response filters;filter structure;low computational complexity;initial reconfiguration mode;minimax solutions;approximation errors;Finite impulse response filter;Approximation error;Linear programming;Interpolation;Multiaccess communication;Passband;Adaptation models;Approximation error;coefficient decimation;finite impulse response (FIR) filters;linear programming;reconfigurability},
  timestamp = {2020-08-31},
}

@Article{Zang1999,
  author    = {Zang, Zhuquan and Cantoni, A. and Teo, Kok Lay},
  journal   = {IEEE Transactions on Circuits and Systems I: Fundamental Theory and Applications},
  title     = {Envelope-constrained {IIR} filter design via {$H_\infty$} optimization methods},
  year      = {1999},
  issn      = {1558-1268},
  month     = {6},
  number    = {6},
  pages     = {649--653},
  volume    = {46},
  abstract  = {Previously, the envelope-constrained (EC) filtering problem was formulated as designing an infinite impulse response (IIR) filter such that the filter's l/sub 2/ norm is minimized, subject to the constraint that its response to a specified input pulse lies within a prescribed envelope. In this paper we recast this filter design problem as a frequency-domain H/sub /spl infin// optimization problem with time-domain constraints. Motivations for solving this problem are given. Then, the recently developed H/sub /spl infin// optimization techniques are used for the design of the required IIR filter. For illustration, we apply the approach to two numerical examples which deal with the design of equalization filters for digital transmission channels.},
  doi       = {10.1109/81.768821},
  file      = {:FILES/1999 - Zang1999 - Envelope-constrained IIR filter design via H_inf optimization methods.pdf:PDF},
  groups    = {FIR filter design},
  keywords  = {IIR filters;H/sup /spl infin optimisation;circuit optimisation;frequency-domain synthesis;digital filters;envelope-constrained IIR filter;filter design;H/sub /spl infin// optimization methods;input pulse;frequency-domain problem;time-domain constraints;equalization filters;digital transmission channels;IIR filters;Optimization methods;Finite impulse response filter;Filtering;Noise shaping;Design optimization;Digital filters;Signal design;Pulse shaping methods;Shape},
  timestamp = {2020-08-31},
}

@Article{Tan2000,
  author    = {Tan, Zhiqiang and Soh, Y. C. and Xie, Lihua},
  journal   = {IEEE Transactions on Circuits and Systems II: Analog and Digital Signal Processing},
  title     = {Envelope-constrained {$H_\infty$} {FIR} filter design},
  year      = {2000},
  issn      = {1558-125X},
  month     = {1},
  number    = {1},
  pages     = {79--82},
  volume    = {47},
  abstract  = {In this paper, we are concerned with the design of a finite-impulse response (FIR) filter, such that the H/sub /spl infin// norm of the filtering error-transfer function is minimized subject to the constraint that the filter output with a given input to the signal system is contained or bounded in a prescribed envelope. The filter design problem is formulated as a standard optimization problem with linear matrix inequalities (LMIs) constraint. Furthermore, by relaxing the H/sub /spl infin// norm constraint, we propose a robust envelope constrained FIR design algorithm based on the LMI approach.},
  doi       = {10.1109/82.818899},
  file      = {:FILES/2000 - Tan2000 - Envelope-constrained H_infty FIR filter design.pdf:PDF},
  groups    = {FIR filter design},
  keywords  = {H/sup /spl infin optimisation;FIR filters;transfer functions;digital filters;envelope-constrained H/sub /spl infin// FIR filter design;filtering error-transfer function;filter output;standard optimization problem;linear matrix inequalities;Finite impulse response filter;Filtering;Time domain analysis;Deconvolution;Signal processing;Statistics;Noise measurement;Interference constraints;Radar signal processing;Nonlinear filters},
  timestamp = {2020-08-31},
}

@Article{Roy2019,
  author    = {Roy, S. and Chandra, A.},
  journal   = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title     = {On the order minimization of interpolated bandpass method based narrow transition band {FIR} filter design},
  year      = {2019},
  issn      = {1558-0806},
  month     = {11},
  number    = {11},
  pages     = {4287--4295},
  volume    = {66},
  abstract  = {Design of hardware efficient digital systems has drawn appreciable attention of researchers over the last few decades. To this aim, this paper considers the design of a narrow transition band finite impulse response (FIR) filter operated in an interpolated bandpass filtering approach. An optimization problem is formulated that minimizes the complexity measure of the narrow transition band FIR filter under the constraints of length of the filter and normalized peak ripple magnitude (NPRM) threshold. Closed-form expressions for the optimal interpolation factor as well as the passband and stopband edges to obtain the narrow transition band are derived. A designed filter is subsequently implemented on Altera's Cyclone IV field programmable gate array (FPGA) chip and supremacy of the suggested design has strongly been established by correlating its hardware cost with many of the state-of-the-art FIR filters.},
  doi       = {10.1109/TCSI.2019.2928052},
  file      = {:FILES/2019 - Roy2019 - On the Order Minimization of Interpolated Bandpass Method Based Narrow Transition Band FIR Filter Design.pdf:PDF},
  groups    = {FIR filter design},
  keywords  = {band-pass filters;field programmable gate arrays;FIR filters;interpolation;minimisation;optimal interpolation factor;state-of-the-art FIR filters;interpolated bandpass method;narrow transition band FIR filter design;hardware efficient digital systems;narrow transition band finite impulse response filter;interpolated bandpass filtering approach;Finite impulse response filters;Complexity theory;Hardware;Interpolation;Field programmable gate arrays;Minimization;Optimization;Bernstein polynomial;Chebyshev polynomial;field programmable gate array (FPGA);interpolated bandpass method;narrow transition band finite impulse response (FIR) filter},
  timestamp = {2020-08-31},
}

@Article{Kumar2019,
  author    = {Kumar, A. and Yadav, S. and Purohit, N.},
  journal   = {IEEE Access},
  title     = {Exploiting coefficient symmetry in conventional polyphase {FIR} filters},
  year      = {2019},
  issn      = {2169-3536},
  pages     = {162883--162897},
  volume    = {7},
  abstract  = {The conventional polyphase architecture for linear-phase finite impulse response (FIR) filter loses its coefficient symmetry property due to the inefficient arrangement of the filter coefficients among its subfilters. Although, existing polyphase structures can avail the benefits of coefficient symmetry property, at the cost of versatility and complex subfilters arrangement of the conventional polyphase structure. To address these issues, in this paper, we first present the mathematical expressions for inherent characteristics of the conventional polyphase structure. Thereafter, we use these expressions to develop a generalized mathematical framework which exploits coefficient symmetry by retaining the direct use of conventional FIR filter coefficients. Further, the transfer function expressions for the proposed Type-1/transposed Type-1 polyphase structures using coefficient symmetry are derived. The proposed structures can reduce the requirement of multiplier units in polyphase FIR filters by half. We also demonstrate the decimator design using the proposed Type-1 polyphase structure and the interpolator design using the proposed transposed Type-1 polyphase structure. Moreover, the phase and magnitude characteristics of the proposed Type-1/transposed Type-1 polyphase structures are presented. It is revealed via numerical examples that all subfilters of the proposed symmetric polyphase structure possess linear-phase characteristics.},
  doi       = {10.1109/ACCESS.2019.2951706},
  file      = {:FILES/2019 - Kumar2019 - Exploiting Coefficient Symmetry in Conventional Polyphase FIR Filters.pdf:PDF},
  groups    = {FIR filter design},
  keywords  = {FIR filters;interpolation;transfer functions;transposed Type-1 polyphase structure;symmetric polyphase structure;conventional polyphase FIR filters;conventional polyphase architecture;linear-phase finite impulse response filter;coefficient symmetry property;polyphase structures;complex subfilters arrangement;conventional polyphase structure;conventional FIR filter coefficients;Finite impulse response filters;Indexes;Adders;Periodic structures;Complexity theory;Mirrors;Transfer functions;Coefficient symmetry;frequency response;polyphase FIR structures;pre/post processing;sampling rate conversion},
  timestamp = {2020-08-31},
}

@Article{Zahradnik2020,
  author    = {Zahradnik, P.},
  journal   = {IEEE Signal Processing Letters},
  title     = {Robust analytical design of optimal equiripple lowpass {FIR} filters},
  year      = {2020},
  issn      = {1558-2361},
  pages     = {755--759},
  volume    = {27},
  abstract  = {For the first time, an analytical design of optimal equiripple lowpass finite impulse response filters is presented. An analytical filter design, which is based on formulas, stands in contrast to the Parks-McClellan approach which is based on a numerical optimization. An advantage of evaluating impulse response coefficients using formulas over a numerical optimization is the robustness of the analytical design. Equiripple filters are optimal in terms of a minimal filter length for an arbitrary filter specification. The novel design is based on an equiripple approximating polynomial which approximates two constants in two disjoint intervals in optimal equiripple sense. A recursive formula for evaluating the impulse response of the filter is also introduced. The algorithm provides not only robust formulas for evaluating the impulse response, but also an analytical view on its coefficients. An example demonstrates the efficiency of the design. Its superiority in terms of robustness over the Parks-McClellan approach is emphasized.},
  doi       = {10.1109/LSP.2020.2989679},
  file      = {:FILES/2020 - Zahradnik2020 - Robust Analytical Design of Optimal Equiripple Lowpass FIR Filters.pdf:PDF},
  groups    = {FIR filter design},
  keywords  = {equiripple filters;filtering theory;FIR filters;low-pass filters;optimisation;polynomial approximation;minimal filter length;arbitrary filter specification;equiripple approximating polynomial;optimal equiripple sense;recursive formula;robust formulas;analytical view;Parks-McClellan approach;robust analytical design;optimal equiripple lowpass FIR filters;optimal equiripple lowpass finite impulse response filters;analytical filter design;numerical optimization;impulse response coefficients;equiripple filters;Digital filters;equiripple approximation;finite impulse response filters;low-pass filters;optimal filters},
  timestamp = {2020-08-31},
}

@Article{Liu2019,
  author    = {Liu, Q. and Lim, Y. C. and Lin, Z.},
  journal   = {IEEE Transactions on Circuits and Systems II: Express Briefs},
  title     = {Design of pipelined iir filters using two-stage frequency-response masking technique},
  year      = {2019},
  issn      = {1558-3791},
  month     = {5},
  number    = {5},
  pages     = {873--877},
  volume    = {66},
  abstract  = {A pipelined, high-speed infinite impulse response (IIR) filter based on the frequency-response masking (FRM) technique has been proposed by Johansson and Wanhammar. In their method, the bandedge shaping filters are a pair of IIR power complementary filters whose z-transform functions are functions of zM and the masking filters are linear phase finite impulse response (FIR) filters. The IIR bandedge shaping filters have M delays in the feedback loop and can be pipelined by M stages. In this brief, we present a two-stage FRM method for reducing the number of multipliers of the pipelined IIR filter proposed by Johansson and Wanhammar for a given magnitude response specification and a given number of pipeline stages in the feedback loop. In our design, all the subfilters are optimized jointly. We show that our two-stage masking design requires fewer multipliers if the number of pipeline stages in the feedback loop is larger than four.},
  doi       = {10.1109/TCSII.2019.2908229},
  file      = {:FILES/2019 - Liu2019 - Design of Pipelined IIR Filters Using Two-Stage Frequency-Response Masking Technique.pdf:PDF},
  groups    = {FRM},
  keywords  = {FIR filters;frequency response;IIR filters;transforms;feedback loop;pipelined IIR filter;two-stage frequency-response masking technique;high-speed infinite impulse response filter;IIR power complementary filters;masking filters;linear phase finite impulse response filters;IIR bandedge shaping filters;two-stage FRM method;pipeline stages;two-stage masking design;magnitude response specification;Feedback loop;Finite impulse response filters;Pipelines;Optimization;Passband;Delays;Frequency response;Infinite impulse response (IIR) filter;pipelined implementation;frequency-response masking (FRM);sharp filter;optimization},
  timestamp = {2020-08-31},
}

@Article{Karmarkar1984,
  author    = {Karmarkar, N.},
  journal   = {Combinatorica},
  title     = {A new polynomial-time algorithm for linear programming},
  year      = {1984},
  issn      = {1439-6912},
  number    = {4},
  pages     = {373--395},
  volume    = {4},
  abstract  = {We present a new polynomial-time algorithm for linear programming. In the worst case, the algorithm requiresO(n3.5L) arithmetic operations onO(L) bit numbers, wheren is the number of variables andL is the number of bits in the input. The running-time of this algorithm is better than the ellipsoid algorithm by a factor ofO(n2.5). We prove that given a polytopeP and a strictly interior point a εP, there is a projective transformation of the space that mapsP, a toP′, a′ having the following property. The ratio of the radius of the smallest sphere with center a′, containingP′ to the radius of the largest sphere with center a′ contained inP′ isO(n). The algorithm consists of repeated application of such projective transformations each followed by optimization over an inscribed sphere to create a sequence of points which converges to the optimal solution in polynomial time.},
  doi       = {10.1007/BF02579150},
  file      = {:FILES/1984 - Karmarkar1984 - A new polynomial-time algorithm for linear programming.pdf:PDF},
  groups    = {mathematical basis},
  refid     = {Karmarkar1984},
  timestamp = {2020-08-31},
  url       = {https://doi.org/10.1007/BF02579150},
}

@Article{Solodovnikov1985,
  author    = {Solodovnikov, V. I.},
  journal   = {Journal of Soviet Mathematics},
  title     = {Upper bounds on the complexity of solving systems of linear equations},
  year      = {1985},
  issn      = {1573-8795},
  number    = {4},
  pages     = {1482--1501},
  volume    = {29},
  abstract  = {The article is of the nature of a survey and is devoted to direct (exact) methods of solving systems of linear equations examined from the point of view of their computational complexity. The construction of most of the algorithms is outlined. The paper consists of two parts. Series methods of solving systems of linear equations are examined in the first part. It includes the algorithms of Gauss and of Konoval'tsev, Strassen's algorithm and its modifications, the YunGustavson results for Toeplitz systems, etc. The second part is devoted to parallel methods of solving systems of linear equations. Examined here are the parallelization of the Gauss algorithm, the results of Hyafil and Kung on complexity estimate of the parallel solution of triangular systems, Csanky's results based on the parallelization of Leverrier's method, Hyabil's general result on the parallelization of a straight-line program for computing polynomials, Stone's algorithm for the parallel solving of tridiagonal systems. Several new bounds are derived. In particular, if a pair of (n×n) -matrices can be multiplied sequentially by a straight-line program of complexity O(nd), then it is possible to solve an arbitrary system of m linear equations in n unknowns on p processors with the complexity$$0\left( {\frac{{max(m, n)min(m, n)^{\alpha  - 1} }}{p} + min(m, n)log_2 max(m, n)} \right),$$, and to solve a triangular system of sizen with the complexity$$0\left( {\frac{{n^2 }}{p} + \frac{n}{{p^{1/\alpha } }}log_2^{1 - \tfrac{1}{\alpha }} n + log_2^2 n} \right).$$},
  doi       = {10.1007/BF02104747},
  file      = {:FILES/1985 - Solodovnikov1985 - Upper bounds on the complexity of solving systems of linear equations.pdf:PDF},
  groups    = {mathematical basis},
  refid     = {Solodovnikov1985},
  timestamp = {2020-08-31},
  url       = {https://doi.org/10.1007/BF02104747},
}

@Article{Carcamo2020,
  author    = {Javier Cárcamo and Antonio Cuevas and Luis-Alberto Rodríguez},
  journal   = {Bernoulli},
  title     = {Directional differentiability for supremum-type functionals: {Statistical} applications},
  year      = {2020},
  issn      = {1350-7265},
  number    = {3},
  pages     = {2143--2175},
  volume    = {26},
  abstract  = {We show that various functionals related to the supremum of a real function defined on an arbitrary set or a measure space are Hadamard directionally differentiable. We specifically consider the supremum norm, the supremum, the infimum, and the amplitude of a function. The (usually non-linear) derivatives of these maps adopt simple expressions under suitable assumptions on the underlying space. As an application, we improve and extend to the multidimensional case the results in Raghavachari (Ann. Statist. 1 (1973) 67–73) regarding the limiting distributions of Kolmogorov–Smirnov type statistics under the alternative hypothesis. Similar results are obtained for analogous statistics associated with copulas. We additionally solve an open problem about the Berk–Jones statistic proposed by Jager and Wellner (In A Festschrift for Herman Rubin (2004) 319–331 IMS). Finally, the asymptotic distribution of maximum mean discrepancies over Donsker classes of functions is derived.},
  doi       = {10.3150/19-bej1188},
  file      = {:FILES/2019 - Carcamo2020 - Directional differentiability for supremum-type functionals- statistical applications.pdf:PDF},
  groups    = {mathematical basis},
  timestamp = {2020-08-31},
}

@InProceedings{Tao2018a,
  author    = {Tao, Qinghua and Xu, Jun and Wang, Shuning and Li, Li},
  booktitle = {Proceedings of the 2018 10th International Conference on Computer and Automation Engineering},
  title     = {An improved coordinate update method for the identification of adaptive hinging hyperplanes model},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {102–106},
  publisher = {Association for Computing Machinery},
  series    = {ICCAE 2018},
  abstract  = {Adaptive hinging hyperplanes (AHH) is a popular continuous piecewise linear (CPWL) model. It has been proved that any continuous nonlinear function can be approximated by a CPWL function with arbitrary precision. The existing identification of AHH simply traverses all the dimensions on the pre-given splitting points to select the best, which fails to consider all the parameters synchronously and the randomness in the splitting, thus the identified model may not be optimal. In this paper, we propose an improved method to identify AHH model with coordinate update strategy. We first use the existing identification method of AHH to initially obtain a basic model structure, and afterwards alternatively optimize the parameters to improve accuracy. Specifically, to explore the interactive and global effects among all the nonlinear parameters, adaptive block coordinate DIRECT (ABCD) algorithm is employed to simultaneously optimize the nonlinear parameters, while the linear parameters can be calculated by least squares (LS) method. Besides, the proposed method is promising to conduct extensions to identify different CWPL models or other nonlinear models even with various error criteria. Numerical experiments show that the proposed method improves the accuracy and stability in identifying AHH and it can even achieve higher accuracy with simpler model structure.},
  doi       = {10.1145/3192975.3192985},
  file      = {:FILES/2018 - Tao2018a- an improved coordinate update method for the identification of adaptive  hinging hyperplanes model.pdf:PDF},
  groups    = {Wang's Work},
  isbn      = {9781450364102},
  keywords  = {Coordinate Update, Piecewise Linear, Adaptive Hinging Hyperplanes, System Identification},
  location  = {Brisbane, Australia},
  numpages  = {5},
  timestamp = {2020-08-31},
  url       = {https://doi.org/10.1145/3192975.3192985},
}

@Article{Huang2018,
  author    = {Huang, X. and Suykens, J. A. K. and Wang, S. and Hornegger, J. and Maier, A.},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  title     = {Classification with truncated $\ell _{1}$ distance kernel},
  year      = {2018},
  issn      = {2162-2388},
  month     = {5},
  number    = {5},
  pages     = {2025--2030},
  volume    = {29},
  abstract  = {This brief proposes a truncated ℓ1 distance (TL1) kernel, which results in a classifier that is nonlinear in the global region but is linear in each subregion. With this kernel, the subregion structure can be trained using all the training data and local linear classifiers can be established simultaneously. The TL1 kernel has good adaptiveness to nonlinearity and is suitable for problems which require different nonlinearities in different areas. Though the TL1 kernel is not positive semidefinite, some classical kernel learning methods are still applicable which means that the TL1 kernel can be directly used in standard toolboxes by replacing the kernel evaluation. In numerical experiments, the TL1 kernel with a pregiven parameter achieves similar or better performance than the radial basis function kernel with the parameter tuned by cross validation, implying the TL1 kernel a promising nonlinear kernel for classification tasks.},
  doi       = {10.1109/TNNLS.2017.2668610},
  file      = {:FILES/2018 - Huang2018 - classification with truncated l1 distance kernel.pdf:PDF},
  groups    = {Wang's Work},
  keywords  = {learning (artificial intelligence);pattern classification;TL1 kernel;kernel learning methods;distance kernel;classification tasks;Kernel;Additives;Training;Learning systems;Training data;Support vector machines;Electronic mail;Classification;indefinite kernel;piecewise linear (PWL)},
  timestamp = {2020-08-31},
}

@InProceedings{Qin2018,
  author    = {Qin, L. and Xu, J. and Luo, X.},
  booktitle = {2018 37th Chinese Control Conference (CCC)},
  title     = {Fast adaptive classifier based on a stepwise algorithm},
  year      = {2018},
  month     = {7},
  pages     = {9136--9141},
  abstract  = {In order to design a classifier that is not only fast and accurate, but also adaptive, the fast adaptive classifier (FAC) based on the model of Adaptive Hinging Hyperplanes (AHH) is proposed. The algorithm for training FAC is developed based on the AHH algorithm, and the training speed is greatly improved. Results of numerical experiments are reported, and these results demonstrate that FAC can achieve good classification accuracy on most data sets. In addition, FAC enjoys a greater advantage that it combines feature selection and classification together, i.e., feature selection is also fulfilled in the classification process. Moreover, thanks the stepwisely training strategy, FAC also enjoys the unique property of adaptiveness, which results in a simple model structure.},
  doi       = {10.23919/ChiCC.2018.8483161},
  file      = {:FILES/2018 - Qin2018 - Fast Adaptive Classifier based on a Stepwise algorithm.pdf:PDF},
  groups    = {application},
  issn      = {1934-1768},
  keywords  = {feature extraction;feature selection;image classification;learning (artificial intelligence);piecewise linear techniques;regression analysis;stepwise algorithm;Adaptive Hinging Hyperplanes;training FAC;AHH algorithm;feature selection;adaptive classifier;Adaptation models;Classification algorithms;Training;Numerical models;Computational modeling;Electronic mail;Pattern recognition;classifier;adaptiveness},
  timestamp = {2020-08-31},
}

@Article{Xu2019,
  author    = {Xu, Z. and Bai, Y. and Liu, K. and Wang, S.},
  journal   = {Tsinghua Science and Technology},
  title     = {Method of hill tunneling via weighted simplex centroid for continuous piecewise linear programming},
  year      = {2019},
  issn      = {1007-0214},
  month     = {6},
  number    = {3},
  pages     = {301--316},
  volume    = {24},
  abstract  = {This paper works on a heuristic algorithm with determinacy for the global optimization of Continuous PieceWise Linear (CPWL) programming. The widely applied CPWL programming can be equivalently transformed into D.C. programming and concave optimization over a polyhedron. Considering that the super-level sets of concave piecewise linear functions are polyhedra, we propose the Hill Tunneling via Weighted Simplex Centroid (HTWSC) algorithm, which can escape a local optimum to reach the other side of its contour surface by cutting across the super-level set. The searching path for hill tunneling is established via the weighted centroid of a constructed simplex. In the numerical experiments, different weighting methods are studied first, and the best is chosen for the proposed HTWSC algorithm. Then, the HTWSC algorithm is compared with the hill detouring method and the software CPLEX for the equivalent mixed integer programming, with results indicating its superior performance in terms of numerical efficiency and the global search capability.},
  doi       = {10.26599/TST.2018.9010089},
  file      = {:FILES/2019 - Xu2019 - Method of Hill Tunneling via Weighted Simplex Centroid for Continuous Piecewise Linear Programming.pdf:PDF},
  groups    = {Wang's Work},
  keywords  = {integer programming;linear programming;piecewise linear techniques;search problems;hill tunneling;continuous piecewise linear programming;heuristic algorithm;global optimization;concave optimization;super-level set;concave piecewise linear functions;constructed simplex;HTWSC algorithm;hill detouring method;equivalent mixed integer programming;global search capability;weighted simplex centroid algorithm;CPWL programming;software CPLEX;numerical efficiency;Tunneling;Linear programming;Programming;Minimization;Heuristic algorithms;Fats;Optimization;global optimization;piecewise linear;concave minimization;cutting plane method;hill tunneling},
  timestamp = {2020-08-31},
}

@InProceedings{Xu2018,
  author    = {Xu, Z. and Bai, Y. and Wang, S.},
  booktitle = {2018 13th World Congress on Intelligent Control and Automation (WCICA)},
  title     = {Sequential global linear programming algorithm for continuous piecewise linear programming*},
  year      = {2018},
  month     = {7},
  pages     = {240--245},
  abstract  = {This paper works on a descent algorithm for continuous piecewise linear (CPWL) minimization problems. CPWL minimization is a widely applied nonlinear programming, which can be equivalently transformed into a difference of convex functions (DC) programming, and then, a concave optimization over a polyhedron. By utilizing the concavity of the objective function, the sequential global linear programming (SGLP) algorithm is proposed. The SGLP algorithm makes use of global information of the polyhedral feasible domain to gain superior optimizing capacity, while applies the mature linear programming technique to insure a rapid algorithm speed. In the numerical experiments, SGLP is compared with two other algorithms of DCA and DALPT, and shows its superior optimization efficiency.},
  doi       = {10.1109/WCICA.2018.8630336},
  file      = {:FILES/2018 - Xu2018 - Sequential Global Linear Programming Algorithm for Continuous Piecewise Linear Programming.pdf:PDF},
  groups    = {Wang's Work},
  keywords  = {linear programming;minimisation;nonlinear programming;nonlinear programming;mature linear programming technique;global information;SGLP algorithm;objective function;concave optimization;convex functions;CPWL minimization;continuous piecewise linear minimization problems;continuous piecewise linear programming;sequential global linear programming algorithm;Programming;Linear programming;Minimization;Automation;Optimization;Information science;Convex functions},
  timestamp = {2020-08-31},
}

@InProceedings{Bai2018,
  author    = {Bai, Y. and Xu, Z. and Wang, S.},
  booktitle = {2018 13th World Congress on Intelligent Control and Automation (WCICA)},
  title     = {A solution approach to the nonconvex piecewise linear network flow problems*},
  year      = {2018},
  month     = {7},
  pages     = {1332--1337},
  abstract  = {In this work, we concentrate on the Nonconvex Piecewise Linear Network Flow Problems (NPLNFP) with discontinuous piecewise linear cost functions. Based on the piecewise linearity and discontinuity of the cost functions, we equivalently transform the NPLNFP into a range of linear Minimum Cost Network Flow Problem (MCNFP) in subdomains, and propose an approach based on a network simplex method (NSM) and a Dynamic Domain Contraction (DDC) technique. Experiment results show that the proposed approach has higher optimization efficiency compared with the other relevant algorithms.},
  doi       = {10.1109/WCICA.2018.8630372},
  file      = {:FILES/2018 - Bai2018 - A Solution Approach to the Nonconvex Piecewise Linear Network Flow Problems.pdf:PDF},
  groups    = {Wang's Work},
  keywords  = {concave programming;linear network analysis;piecewise linear techniques;discontinuous piecewise linear cost functions;piecewise linearity;network simplex method;Nonconvex Piecewise Linear Network Flow Problems;linear minimum cost network flow problem;NPLNFP;MCNFP;dynamic domain contraction technique;DDC technique;optimization efficiency;cost functions;Cost function;Heuristic algorithms;Linear programming;Approximation algorithms;Automation;Linearity;Transforms},
  timestamp = {2020-08-31},
}

@Article{Yu2018,
  author    = {Yu, J. and Wang, S. and Li, L.},
  journal   = {IEEE Transactions on Neural Networks and Learning Systems},
  title     = {Incremental design of simplex basis function model for dynamic system identification},
  year      = {2018},
  issn      = {2162-2388},
  month     = {10},
  number    = {10},
  pages     = {4758--4768},
  volume    = {29},
  abstract  = {In this paper, we propose a novel adaptive piecewise linear model for dynamic system identification. It has four unique features. First, the model designs a new kind of basis function for function approximation. It maintains the uniform shape for each basis function, so as to achieve a satisfactory tradeoff between generalization ability and model complexity. Second, the model takes the structure of basis functions as decision variables to optimize the formulated identification problems instead of taking expansion coefficients as decision variables as proposed by many existing approaches. Third, we establish an incremental design strategy to solve the system identification problems. In each step of the identification, the selection of optimal basis function is a Lipschitz continuous optimization problem that is likely to be easily handled with some mature toolboxes. This incremental design strategy greatly reduces the estimation cost. Fourth, we introduce a smoothing mechanism to avoid overfitting, when the output of dynamic systems is disturbed by noise. Tests on several benchmark dynamic systems demonstrate the potential of the proposed model.},
  doi       = {10.1109/TNNLS.2017.2765201},
  file      = {:FILES/2018 - Yu2018 - Incremental Design of Simplex Basis Function Model for Dynamic System Identification.pdf:PDF},
  groups    = {Wang's Work},
  keywords  = {function approximation;identification;optimisation;piecewise linear techniques;simplex basis function model;dynamic system identification;function approximation;decision variables;incremental design strategy;optimal basis function;Lipschitz continuous optimization problem;adaptive piecewise linear model;smoothing mechanism;Adaptation models;Computational modeling;Numerical models;Fasteners;Optimization;Adaptive systems;Complexity theory;Hinge function;identification method;incremental learning;piecewise linear},
  timestamp = {2020-08-31},
}

@Article{Huang2013,
  author    = {Huang, Xiaolin and Mehrkanoon, Siamak and Suykens, Johan A. K.},
  journal   = {Neurocomputing},
  title     = {Support vector machines with piecewise linear feature mapping},
  year      = {2013},
  issn      = {0925-2312},
  pages     = {118--127},
  volume    = {117},
  abstract  = {As the simplest extension to linear classifiers, piecewise linear (PWL) classifiers have attracted a lot of attention, because of their simplicity and classification capability. In this paper, a PWL feature mapping is introduced by investigating the property of the PWL classification boundary. Then support vector machines (SVM) with PWL feature mappings are proposed, called PWL-SVMs. In this paper, it is shown that some widely used PWL classifiers, such as k-nearest-neighbor, adaptive boosting of linear classifier and intersection kernel support vector machine, can be represented by the proposed feature mapping. That means the proposed PWL-SVMs at least can achieve the performance of the above PWL classifiers. Moreover, PWL-SVMs enjoy good properties of SVM and the performance on numerical experiments illustrates the effectiveness. Then some extensions are discussed and the application of PWL-SVMs can be expected.},
  doi       = {https://doi.org/10.1016/j.neucom.2013.01.023},
  file      = {:FILES/2013 - Huang2013 - Support vector machines with piecewise linear feature mapping.pdf:PDF},
  groups    = {Wang's Work},
  keywords  = {Support vector machine, Piecewise linear classifier, Nonlinear feature mapping},
  timestamp = {2020-08-31},
  url       = {http://www.sciencedirect.com/science/article/pii/S0925231213001963},
}

@Article{Xu2016a,
  author    = {Xu, Jun and van den Boom, Ton J.J. and De Schutter, Bart and Wang, Shuning},
  journal   = {Automatica},
  title     = {Irredundant lattice representations of continuous piecewise affine functions},
  year      = {2016},
  issn      = {0005-1098},
  pages     = {109--120},
  volume    = {70},
  abstract  = {In this paper, we revisit the full lattice representation of continuous piecewise affine (PWA) functions and give a formal proof of its representation ability. Based on this, we derive the irredundant lattice PWA representations through removal of redundant terms and literals. Necessary and sufficient conditions for irredundancy are proposed. Besides, we explain how to remove terms and literals in order to ensure irredundancy. An algorithm is given to obtain an irredundant lattice PWA representation. In the worked examples, the irredundant lattice PWA representations are used to express the optimal solution of explicit model predictive control problems, and the results turn out to be much more compact than those given by a state-of-the-art algorithm.},
  doi       = {https://doi.org/10.1016/j.automatica.2016.03.018},
  file      = {:FILES/2016 - Xu2016a - Irredundant lattice representations of continuous piecewise affine functions.pdf:PDF},
  groups    = {Wang's Work},
  keywords  = {Piecewise affine function, Irredundant representation, Lattice representation},
  timestamp = {2020-08-31},
  url       = {http://www.sciencedirect.com/science/article/pii/S000510981630098X},
}

@Article{Zhiming2017,
  author    = {Zhiming Xu and Kuangyu Liu and Yu bai and Shuning Wand},
  journal   = {Journal of Tsinghua University(Science and Technology)},
  title     = {Hill tunneling method via peak subpoints for continuous piecewise linear programming},
  year      = {2017},
  number    = {12},
  pages     = {1265},
  volume    = {57},
  doi       = {10.16511/j.cnki.qhdxxb.2017.25.059},
  file      = {:FILES/2017 - Zhiming2017 - Hill tunneling method via peak subpoints for continuous piecewise linear programming.pdf:PDF},
  groups    = {Wang's Work},
  keywords  = {global optimization;piecewise linear;concave minimization;cutting plane method;hill tunneling},
  numpages  = {6},
  publisher = {Journal of Tsinghua University(Science and Technology)},
  timestamp = {2020-08-31},
  url       = {http://jst.tsinghuajournals.com/EN/abstract/article_152153.shtml},
}

@Article{Shehab2020,
  author   = {Shehab, Mohammad and Alshawabkah, Hanadi and Abualigah, Laith and AL-Madi, Nagham},
  journal  = {Engineering with Computers},
  title    = {Enhanced a hybrid moth-flame optimization algorithm using new selection schemes},
  year     = {2020},
  issn     = {1435-5663},
  abstract = {This paper presents two levels of enhancing the basic Moth flame optimization (MFO) algorithm. The first step is hybridizing MFO and the local-based algorithm, hill climbing (HC), called MFOHC. The proposed algorithm takes the advantages of HC to speed up the searching, as well as enhancing the learning technique for finding the generation of candidate solutions of basic MFO. The second step is the addition of six popular selection schemes to improve the quality of the selected solution by giving a chance to solve with high fitness value to be chosen and increase the diversity. In both steps of enhancing, thirty benchmark functions and five IEEE CEC 2011 real-world problems are used to evaluate the performance of the proposed versions. In addition, well-known and recent meta-heuristic algorithms are applied to compare with the proposed versions. The experiment results illustrate that the proportional selection scheme with MFOHC, namely (PMFOHC) is outperforming the other proposed versions and algorithms in the literature.},
  doi      = {10.1007/s00366-020-00971-7},
  file     = {:FILES/2020 - Shehab2020 - Enhanced a hybrid moth-flame optimization algorithm using new selection schemes.pdf:PDF},
  groups   = {Swarm algorithms},
  refid    = {Shehab2020},
  url      = {https://doi.org/10.1007/s00366-020-00971-7},
}

@Article{Barshandeh2020,
  author   = {Barshandeh, Saeid and Haghzadeh, Maryam},
  journal  = {Engineering with Computers},
  title    = {A new hybrid chaotic atom search optimization based on tree-seed algorithm and {Levy} flight for solving optimization problems},
  year     = {2020},
  issn     = {1435-5663},
  abstract = {Optimizing the high computational real-world problems is a challenging task that has taken a great deal of efforts in the last decade. The meta-heuristic algorithms have brought countless benefits. As a result, numerous meta-heuristic algorithms have been developed by getting inspired from natural phenomena. The atom search optimization (ASO) is a physics-based meta-heuristic, which has been developed little while ago. Although ASO is capable of solving various problems, due to low convergence speed and lack of proper balance between exploration and exploitation, it is not efficient enough in sorting out real-world convoluted problems. In the present paper, the convergence speed of ASO is improved using chaotic maps and Levy flight random walk. In addition, ASO is hybridized with the tree-seed algorithm (TSA) to improve exploration and exploitation capabilities and make a proper balance between them. TSA is an innovative intelligent meta-heuristic algorithm that has been inspired by the growth of trees and spreading their seeds and has a decent exploration ability. Furthermore, a novel technique has been applied on the proposed hybrid algorithm as a solution for departure of local optimums. Besides, the effectiveness of our contributions is validated by testing the proposed hybrid algorithm on a vast set of benchmark functions comprising unimodal, multimodal, fixed dimension, shifted-rotated and composite. The obtained results have been compared with several other new and powerful meta-heuristic algorithms in terms of descriptive and inferential statistics. In addition, the algorithms are tested on seven real-life engineering problems. The results of the experiments indicated the effectiveness of contributions and the superiority of the proposed hybrid algorithm over its akin counterparts.},
  doi      = {10.1007/s00366-020-00994-0},
  file     = {:FILES/2020 - Barshandeh2020 - A new hybrid chaotic atom search optimization based on tree-seed algorithm and Levy flight for solving optimization problems.pdf:PDF},
  groups   = {Swarm algorithms},
  refid    = {Barshandeh2020},
  url      = {https://doi.org/10.1007/s00366-020-00994-0},
}

@Article{Khosravi2020,
  author   = {Khosravi, Habibeh and Zakeri, Ehsan and Xie, Wen-Fang and Ahmadi, Bahar},
  journal  = {Engineering with Computers},
  title    = {Adaptive multi-tracker optimization algorithm for global optimization problems: {Emphasis} on applications in chemical engineering},
  year     = {2020},
  issn     = {1435-5663},
  abstract = {This paper presents an adaptive multi-tracker optimization algorithm (AMTOA) for global optimization problems with an emphasis on applications in chemical engineering. To obtain the AMTOA, first, several modifications are performed on the conventional multi-tracker optimization algorithm (MTOA). Then a number of its parameters are considered to be adaptive. The modifications include a novel way of determining the search radius of each global tracker ($$G_{\text{T}}$$GT), and introducing a more efficacious technique of searching for a new solution by $$G_{\text{T}}$$GTs. $$G_{\text{T}}$$GTs are the main components of the MTOA which look for the global optimal point ($${\text{GOP}}$$GOP). Additionally, the adaptation rules are employed for $$G_{\text{T}}$$GTs search radii and their searching parameters. These modifications lead to increasing the precision of the solution and reliability of the algorithm, both of which are the most important properties of an optimizer. Reducing the number of parameters of MTOA is another advantage of AMTOA. The results of applying this algorithm to several unconstrained and constrained general benchmarks along with several chemical engineering optimization problems reveal that AMTOA outperforms other well-known methods such as genetic algorithm (GA), particle swarm optimization (PSO), gray wolf optimizer (GWO), whale optimization algorithm (WOA), and conventional MTOA. Additionally, comparing the results of AMTOA to other advanced optimization algorithms such as LSHADE44, MA-ES, and IUDE show its superiority for chemical engineering optimization problems. Thus, the development of AMTOA could be advantageous to the area of chemical engineering.},
  doi      = {10.1007/s00366-020-01101-z},
  file     = {:FILES/2020 - Khosravi2020 - Adaptive multi-tracker optimization algorithm for global optimization problems- emphasis on applications in chemical engineering.pdf:PDF},
  groups   = {Swarm algorithms},
  refid    = {Khosravi2020},
  url      = {https://doi.org/10.1007/s00366-020-01101-z},
}

@Article{Kaur2020,
  author   = {Kaur, Satnam and Awasthi, Lalit K. and Sangal, A. L.},
  journal  = {Engineering with Computers},
  title    = {{HMOSHSSA}: {A} hybrid meta-heuristic approach for solving constrained optimization problems},
  year     = {2020},
  issn     = {1435-5663},
  abstract = {This paper proposes a novel hybrid multi-objective optimization algorithm named HMOSHSSA by synthesizing the strengths of Multi-objective Spotted Hyena Optimizer (MOSHO) and Salp Swarm Algorithm (SSA). HMOSHSSA utilizes the exploration capability of MOSHO to explore the search space effectively and leader and follower selection mechanism of SSA to achieve global best solution with faster convergence. The proposed algorithm is evaluated on 24 benchmark test functions, and its performance is compared with seven well-known multi-objective optimization algorithms. The experimental results demonstrate that HMOSHSSA acquires very competitive results and outperforms other algorithms in terms of convergence speed, search-ability and accuracy. Additionally, HMOSHSSA is also applied on seven well-known engineering problems to further verify its efficacy. The results reveal the effectiveness of proposed algorithm toward solving real-life multi-objective optimization problems.},
  doi      = {10.1007/s00366-020-00989-x},
  file     = {:FILES/2020 - Kaur2020 - HMOSHSSA- a hybrid meta-heuristic approach for solving constrained optimization problems.pdf:PDF},
  groups   = {Swarm algorithms},
  refid    = {Kaur2020},
  url      = {https://doi.org/10.1007/s00366-020-00989-x},
}

@Article{Senel2019,
  author   = {\c{S}enel, Fatih Ahmet and G\"{o}k\c{c}e, Fatih and Y\"{u}ksel, Asım Sinan and Yi\v{g}it, Tuncay},
  journal  = {Engineering with Computers},
  title    = {A novel hybrid {PSO-GWO} algorithm for optimization problems},
  year     = {2019},
  issn     = {1435-5663},
  number   = {4},
  pages    = {1359--1373},
  volume   = {35},
  abstract = {In this study, we propose a new hybrid algorithm fusing the exploitation ability of the particle swarm optimization (PSO) with the exploration ability of the grey wolf optimizer (GWO). Our approach combines two methods by replacing a particle of the PSO with small possibility by a particle partially improved with the GWO. We have evaluated our approach on five different benchmark functions and on three different real-world problems, namely parameter estimation for frequency-modulated sound waves, process flowsheeting problem, and leather nesting problem (LNP). The LNP is one of the hard industrial problems, where two-dimensional irregular patterns are placed on two-dimensional irregular-shaped leather material such that a minimum amount of the material is wasted. In our evaluations, we compared our approach with the conventional PSO and GWO algorithms, artificial bee colony and social spider algorithm, and as well as with three different hybrid approaches of the PSO and GWO algorithms. Our experimental results reveal that our hybrid approach successfully merges the two algorithms and performs better than all methods employed in the comparisons. The results also indicate that our approach converges to more optimal solutions with fewer iterations.},
  doi      = {10.1007/s00366-018-0668-5},
  file     = {:FILES/2019 - Senel2019 - A novel hybrid PSO–GWO algorithm for optimization problems.pdf:PDF},
  groups   = {Swarm algorithms},
  refid    = {Şenel2019},
  url      = {https://doi.org/10.1007/s00366-018-0668-5},
}

@Article{Gupta2020,
  author   = {Gupta, Shubham and Deep, Kusum and Moayedi, Hossein and Foong, Loke Kok and Assad, Assif},
  journal  = {Engineering with Computers},
  title    = {Sine cosine grey wolf optimizer to solve engineering design problems},
  year     = {2020},
  issn     = {1435-5663},
  abstract = {Balancing the exploration and exploitation in any nature-inspired optimization algorithm is an essential task, while solving the real-world global optimization problems. Therefore, the search agents of an algorithm always try to explore the unvisited domains of a search space in a balanced manner. The sine cosine algorithm (SCA) is a recent addition to the field of metaheuristics that finds the solution of an optimization problem using the behavior of sine and cosine functions. However, in some cases, the SCA skips the true solutions and trapped at sub-optimal solutions. These problems lead to the premature convergence, which is harmful in determining the global optima. Therefore, in order to alleviate the above-mentioned issues, the present study aims to establish a comparatively better synergy between exploration and exploitation in the SCA. In this direction, firstly, the exploration ability of the SCA is improved by integrating the social and cognitive component, and secondly, the balance between exploration and exploitation is maintained through the grey wolf optimizer (GWO). The proposed algorithm is named as SC-GWO. For the performance evaluation, a well-known set of benchmark problems and engineering test problems are taken. The dimension of benchmark test problems is varied from 30 to 100 to observe the robustness of the SC-GWO on scalability of problems. In the paper, the SC-GWO is also used to determine the optimal setting for overcurrent relays. The analysis of obtained numerical results and its comparison with other metaheuristic algorithms demonstrate the superior ability of the proposed SC-GWO.},
  doi      = {10.1007/s00366-020-00996-y},
  file     = {:FILES/2020 - Gupta2020 - Sine cosine grey wolf optimizer to solve engineering design problems.pdf:PDF},
  groups   = {Swarm algorithms},
  refid    = {Gupta2020},
  url      = {https://doi.org/10.1007/s00366-020-00996-y},
}

@Article{Seyyedabbasi2019,
  author   = {Seyyedabbasi, Amir and Kiani, Farzad},
  journal  = {Engineering with Computers},
  title    = {{I-GWO} and {Ex-GWO}: improved algorithms of the {Grey} {Wolf} optimizer to solve global optimization problems},
  year     = {2019},
  issn     = {1435-5663},
  abstract = {In this paper, two novel meta-heuristic algorithms are introduced to solve global optimization problems inspired by the Grey Wolf Optimizer (GWO) algorithm. In the GWO algorithm, wolves are likely to be located in regions close to each other. Therefore, as they catch the hunt (approaching the solution), they may create an intensity in the same or certain regions. In this case, the mechanism to prevent the escape of the hunt may not work well. First, the proposed algorithm is the expanded model of the GWO algorithm that is called expanded Grey Wolf Optimizer. In this method, the same as GWO, alpha, beta, and delta play the role of the main three wolves. However, the next wolves select and update their positions according to the previous and the first three wolves in each iteration. Another proposed algorithm is based on the incremental model and is, therefore, called incremental Grey Wolf Optimizer. In this method, each wolf updates its own position based on all the wolves selected before it. There is the possibility of finding solutions (hunts) quicker than according to other algorithms in the same category. However, they may not always guarantee to find a good solution because of their act dependent on each other. Both algorithms focus on exploration and exploitation. In this paper, the proposed algorithms are simulated over 33 benchmark functions and the related results are compared with well-known optimization algorithms. The results of the proposed algorithms seem to be good solutions for various problems.},
  doi      = {10.1007/s00366-019-00837-7},
  file     = {:FILES/2019 - Seyyedabbasi2019 - I-GWO and Ex-GWO- improved algorithms of the Grey Wolf Optimizer to solve global optimization problems.pdf:PDF},
  groups   = {Swarm algorithms},
  refid    = {Seyyedabbasi2019},
  url      = {https://doi.org/10.1007/s00366-019-00837-7},
}

@Article{ShojaeeGhandeshtani2019,
  author   = {Shojaee Ghandeshtani, Kambiz and Mashhadi, Habib Rajabi},
  journal  = {Engineering with Computers},
  title    = {An entropy-based self-adaptive simulated annealing},
  year     = {2019},
  issn     = {1435-5663},
  abstract = {Simulated annealing (SA) algorithms are capable of solving discrete and continuous problems. However, they are less efficient than other algorithms in solving applied problems because of their dependency on controlling parameters definition method. In the current work, a self-adaptive simulated annealing (SASA) method is presented based on entropy concept and thermodynamic laws in order to optimize the setting parameters. To provide a dynamic cooling rate and Markov chain length with a comparative relation to problem conditions, the proposed schedule utilizes thermodynamic concepts of entropy and ensemble average energy. In the proposed algorithm, simulation of the atomic motion is implemented based on velocity definition in thermodynamics and time definition in probabilistic processes. The SASA is evaluated by CEC2015 problem and compared with three other adaptive simulated annealing algorithms, a standard SA and four other metaheuristic methods using three different comparison criteria: Wilcoxon test, median, mean and standard deviation. The SASA has shown satisfactory outcomes in most unimodal, multimodal, and hybrid functions in CEC2015. It has proved to be more explorative, has obtained far better solutions, and has showed the best convergence speed compared with other algorithms when engaged in exploitation.},
  doi      = {10.1007/s00366-019-00887-x},
  file     = {:FILES/2019 - ShojaeeGhandeshtani2019 - An entropy-based self-adaptive simulated annealing.pdf:PDF},
  groups   = {Swarm algorithms},
  refid    = {Shojaee Ghandeshtani2019},
  url      = {https://doi.org/10.1007/s00366-019-00887-x},
}

@Article{ShiraniFaradonbeh2016,
  author   = {Shirani Faradonbeh, Roohollah and Monjezi, Masoud and Jahed Armaghani, Danial},
  journal  = {Engineering with Computers},
  title    = {Genetic programing and non-linear multiple regression techniques to predict backbreak in blasting operation},
  year     = {2016},
  issn     = {1435-5663},
  number   = {1},
  pages    = {123--133},
  volume   = {32},
  abstract = {In addition to all benefits of blasting in mining and civil engineering applications, it has some undesirable environmental impacts. Backbreak is an unwanted phenomenon of blasting which can cause instability of mine walls, decreasing efficiency of drilling, falling down of machinery, etc. Recently, the use of new approaches such as artificial intelligence (AI) is greatly recommended by many researchers. In this paper, a new AI technique namely genetic programing (GP) was developed to predict BB. To prepare a sufficient database, 175 blasting works were investigated in Sungun copper mine, Iran. In these operations, the most influential parameters on BB including burden, spacing, stemming length, powder factor and stiffness ratio were measured and used to develop BB predictive models. To demonstrate capability of GP technique, a non-linear multiple regression (NLMR) model was also employed for prediction of BB. Value account for (VAF), root mean square error (RMSE) and coefficient of determination (R2) were used to control the capacity performance of the predictive models. The performance indices obtained by GP approach indicate the higher reliability of GP compared to NLMR model. RMSE and VAF values of 0.327 and 97.655, respectively, for testing datasets of GP approach reveal the superiority of this model in predicting BB, while these values were obtained as 0.865 and 81.816, respectively, for NLMR model.},
  doi      = {10.1007/s00366-015-0404-3},
  file     = {:FILES/2016 - ShiraniFaradonbeh2016 - Genetic programing and non-linear multiple regression techniques to predict backbreak in blasting operation.pdf:PDF},
  groups   = {Swarm algorithms},
  refid    = {Shirani Faradonbeh2016},
  url      = {https://doi.org/10.1007/s00366-015-0404-3},
}

@Article{Abualigah2020,
  author   = {Abualigah, Laith and Shehab, Mohammad and Diabat, Ali and Abraham, Ajith},
  journal  = {Engineering with Computers},
  title    = {Selection scheme sensitivity for a hybrid {Salp Swarm Algorithm}: {Analysis} and applications},
  year     = {2020},
  issn     = {1435-5663},
  abstract = {This paper proposes a hybrid version of the Salp Swarm Algorithm (SSA) and the hill climbing (HC) technique using various selection schemes to solve engineering design problems. The proposed algorithm consists of two stages. In the first stage, the basic SSA is hybridized with HC local search to improve its exploitation capabilities; we refer to the hybridized algorithm as HSSA. In the second stage, a selection scheme is applied to enhance the exploration capabilities of the hybrid SSA. Six popular selection schemes were investigated, and the proportional selection scheme was selected as it yielded the best performance. We refer to the hybridized SSA along with the proportional selection scheme as PHSSA. To validate the performance of the proposed algorithms, a series of experiments were conducted using thirty benchmark functions and four engineering design problems. The investigations using benchmark functions revealed that HSSA overcame the weaknesses of the local search in the basic SSA. Moreover, PHSSA enhanced performance by providing an appropriate balance between exploration and exploitation as well as maintaining the diversity of the solutions and avoiding premature convergence. Finally, PHSSA produced results on engineering design problems that were at least comparable and in many cases superior to SSA and similar algorithms in the literature.},
  doi      = {10.1007/s00366-020-01067-y},
  file     = {:FILES/2020 - Abualigah2020 - Selection scheme sensitivity for a hybrid Salp Swarm Algorithm- analysis and applications.pdf:PDF},
  groups   = {Swarm algorithms},
  refid    = {Abualigah2020},
  url      = {https://doi.org/10.1007/s00366-020-01067-y},
}

@Article{Wang2020a,
  author   = {Wang, Zhongmin and Luo, Qifang and Zhou, Yongquan},
  journal  = {Engineering with Computers},
  title    = {Hybrid metaheuristic algorithm using butterfly and flower pollination base on mutualism mechanism for global optimization problems},
  year     = {2020},
  issn     = {1435-5663},
  abstract = {The butterfly optimization algorithm (BOA) is a new metaheuristic algorithm that is inspired from food foraging behavior of the butterflies. Because of its simplicity and effectiveness, the algorithm has been proved to be effective in solving global optimization problems and applied to practical problems. However, BOA is prone to local optimality and may lose its diversity, thus suffering losses of premature convergence. In this work, a hybrid metaheuristic algorithm using butterfly and flower pollination base on mutualism mechanism called MBFPA was proposed. Firstly, the flower pollination algorithm has good exploration ability and the hybrid butterfly optimization algorithm and the flower pollination algorithms greatly improve the exploration ability of the algorithm; secondly, the symbiosis organisms search has a strong exploitation capability in the mutualism phase. By introducing the mutualism phase, the algorithm's exploitation capability is effectively increased and the algorithm's convergence speed is accelerated. Finally, the adaptive switching probability is increased to increase the algorithm's balance in exploration and exploitation capabilities. In order to evaluate the effectiveness of the algorithm, in the 49 standard test functions, the proposed algorithm was compared with six basic metaheuristic algorithms and five hybrid metaheuristic algorithms. MBFPA has also been used to solve five classic engineering problems (three-bar truss design problem; multi-plate disc clutch brake design; welded beam design; pressure vessel design problem; and speed reducer design). The results show that the proposed method is feasible and has good application prospect and competitiveness.},
  doi      = {10.1007/s00366-020-01025-8},
  file     = {:FILES/2020 - Wang2020a - Hybrid metaheuristic algorithm using butterfly and flower pollination base on mutualism mechanism for global optimization problems.pdf:PDF},
  groups   = {Swarm algorithms},
  refid    = {Wang2020},
  url      = {https://doi.org/10.1007/s00366-020-01025-8},
}

@Article{Moghdani2020,
  author   = {Moghdani, Reza and Elaziz, Mohamed Abd and Mohammadi, Davood and Neggaz, Nabil},
  journal  = {Engineering with Computers},
  title    = {An improved volleyball premier league algorithm based on sine cosine algorithm for global optimization problem},
  year     = {2020},
  issn     = {1435-5663},
  abstract = {Volleyball premier league (VPL) simulating some phenomena of volleyball game has been presented recently. This powerful algorithm uses such racing and interplays between teams within a season. Furthermore, the algorithm imitates the coaching procedure within a game. Therefore, some volleyball metaphors, including substitution, coaching, and learning, are used to find a better solution prepared by the VPL algorithm. However, the learning phase has the largest effect on the performance of the VPL algorithm, in which this phase can lead to making the VPL stuck in optimal local solution. Therefore, this paper proposed a modified VPL using sine cosine algorithm (SCA). In which the SCA operators have been applied in the learning phase to obtain a more accurate solution. So, we have used SCA operators in VPL to grasp their advantages resulting in a more efficient approach for finding the optimal solution of the optimization problem and avoid the limitations of the traditional VPL algorithm. The propounded VPLSCA algorithm is tested on the 25 functions. The results captured by the VPLSCA have been compared with other metaheuristic algorithms such as cuckoo search, social-spider optimization algorithm, ant lion optimizer, grey wolf optimizer, salp swarm algorithm, whale optimization algorithm, moth flame optimization, artificial bee colony, SCA, and VPL. Furthermore, the three typical optimization problems in the field of designing engineering have been solved using the VPLSCA. According to the obtained results, the proposed algorithm shows very reasonable and promising results compared to others.},
  doi      = {10.1007/s00366-020-00962-8},
  file     = {:FILES/2020 - Moghdani2020 - An improved volleyball premier league algorithm based on sine cosine algorithm for global optimization problem.pdf:PDF},
  groups   = {Swarm algorithms},
  refid    = {Moghdani2020},
  url      = {https://doi.org/10.1007/s00366-020-00962-8},
}

@Article{Petridis1998,
  author    = {Petridis, V. and Kazarlis, S. and Bakirtzis, A.},
  journal   = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  title     = {Varying fitness functions in genetic algorithm constrained optimization: {The} cutting stock and unit commitment problems},
  year      = {1998},
  issn      = {1941-0492},
  month     = {10},
  number    = {5},
  pages     = {629--640},
  volume    = {28},
  abstract  = {We present a specific varying fitness function technique in genetic algorithm (GA) constrained optimization. This technique incorporates the problem's constraints into the fitness function in a dynamic way. It consists of forming a fitness function with varying penalty terms. The resulting varying fitness function facilitates the GA search. The performance of the technique is tested on two optimization problems: the cutting stock, and the unit commitment problems. Also, new domain-specific operators are introduced. Solutions obtained by means of the varying and the conventional (nonvarying) fitness function techniques are compared. The results show the superiority of the proposed technique.},
  doi       = {10.1109/3477.718514},
  file      = {:FILES/1998 - Petridis1998 - Varying fitness functions in genetic algorithm constrained optimization- the cutting stock and unit commitment problems.pdf:PDF},
  groups    = {genetic algorithms, TEC},
  keywords  = {genetic algorithms;search problems;operations research;load distribution;load dispatching;varying fitness functions;genetic algorithm constrained optimization;cutting stock;unit commitment problems;varying fitness function technique;GA constrained optimization;varying penalty terms;GA search;optimization problems;domain-specific operators;nonvarying fitness function techniques;Genetic algorithms;Constraint optimization;Testing;Performance evaluation;Shape;Genetic mutations;Waste materials;Encoding;Production;Cost function},
  timestamp = {2020-09-05},
}

@InProceedings{Safe2004,
  author    = {Safe, Mart\'{i}n and Carballido, Jessica and Ponzoni, Ignacio and Brignole, N\'{e}lida},
  booktitle = {Advances in Artificial Intelligence -- SBIA 2004},
  title     = {On stopping criteria for genetic algorithms},
  year      = {2004},
  address   = {Berlin, Heidelberg},
  editor    = {Bazzan, Ana L. C. and Labidi, Sofiane},
  pages     = {405--413},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {In this work we present a critical analysis of various aspects associated with the specification of termination conditions for simple genetic algorithms. The study, which is based on the use of Markov chains, identifies the main difficulties that arise when one wishes to set meaningful upper bounds for the number of iterations required to guarantee the convergence of such algorithms with a given confidence level. The latest trends in the design of stopping rules for evolutionary algorithms in general are also put forward and some proposals to overcome existing limitations in this respect are suggested.},
  file      = {:FILES/2004 - Safe2004 - on stopping criteria for genetic algorithms.pdf:PDF},
  groups    = {genetic algorithms, TEC},
  isbn      = {978-3-540-28645-5},
  timestamp = {2020-09-05},
}

@Article{zhiming2017cn,
  author   = {续志明 and 刘匡宇 and 白宇 and 王书宁},
  journal  = {清华大学学报(自然科学版)},
  title    = {连续分片线性规划问题的山顶投影穿山法},
  year     = {2017},
  number   = {12},
  pages    = {1265--1271},
  volume   = {57},
  abstract = {连续分片线性规划是一类应用广泛的重要规划,寻找连续分片线性规划的全局最优解是研究这类规划的重点和难点。该文研究的是一种对此类规划进行全局寻优的确定性启发式算法。由于此类规划问题可以转化为凸多面体上的凹优化问题进行求解,因此利用凹函数的上水平集的凸性,该文提出可以通过直接穿透目标函数上水平集在其等值面上进行搜索,以逃离当前局部最优解进行全局寻优。该方法中每次逃离的搜索方向都通过山形凹目标函数的顶点投影来确定,因此称为山顶投影穿山法。在数值实验中,将所提出的山顶投影穿山法与CPLEX以及绕山法进行了比较,结果表明该算法在计算速度与全局寻优能力上性能优越。},
  file     = {:FILES/2017 - zhiming2017cn - 连续分片线性规划问题的山顶投影穿山法_续志明.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {全局优化;分片线性;凹优化;割平面;穿山},
}

@InProceedings{gaolin2000,
  author    = {高林 and 王书宁 and 王伟},
  booktitle = {第十九届中国控制会议},
  title     = {基于邻区域搜索的分片线性函数的最优化方法},
  year      = {2000},
  address   = {中国香港},
  pages     = {4},
  abstract  = {本文针对规范型分片线性函数的寻优问题,提出了一种基于分片的邻区域搜索算法,可保证获得局部最优解;并将它和遗传算法相结合以实现全局优化。它的优点是既吸取进化算法的探索能力, 又充分利用模型信息。仿真结果表明,它具有很好的搜索性能。},
  file      = {:FILES/2000 - gaolin2000 - 基于邻区域搜索的分片线性函数的最优化方法_高林.pdf:PDF},
  groups    = {Wang's Work},
  keywords  = {搜索算法;定义域;分片线性函数;局部寻优;局部最优解;交叉因子;最优化方法;最优点;改进遗传算法;非线性函数;区域搜索;},
}

@InProceedings{Wang2012,
  author    = {Wang, Jing and Mu, Xiaomu and Xu, Jun and Wang, Shuning},
  booktitle = {2012 IEEE International Conference on Information Science and Technology},
  title     = {Design and optimization of dispatching rules for elevator group control aiming at energy saving},
  year      = {2012},
  month     = {3},
  pages     = {124--127},
  abstract  = {In buildings with many elevators, elevator group control algorithm is used to efficiently dispatch the elevators to serve each hall call generated from different floors. Recent researches for energy saving of elevator system have attracted widespread interest, most of which achieve energy saving by minimizing the estimated energy consumption. This paper propose a rule-based algorithm for elevator group control, which focuses on design of dispatching rules for energy saving based on the inner mechanism of the elevator system. As the weights and other parameters for the rules matters a lot to the performance of the algorithm, coarse-to-fine searching strategy is used for optimization. It can overcome the combinatorial explosion of feasible set and the limitation of simulation platform. The proposed algorithm is tested on a very practical simulation platform. The result is reliable, and shows the efficiency of the algorithm on energy saving.},
  doi       = {10.1109/ICIST.2012.6221620},
  file      = {:FILES/2012 - Wang2012 - Design and optimization of dispatching rules for elevator group control aiming at energy saving.pdf:PDF},
  groups    = {Wang's Work},
  issn      = {2164-4357},
  keywords  = {combinatorial mathematics;dispatching;energy conservation;lifts;optimisation;search problems;dispatching rule design;dispatching rule optimization;energy saving;elevator group control algorithm;elevator dispatch;hall call;elevator system;energy consumption minimization;rule-based algorithm;coarse-to-fine searching strategy;combinatorial explosion;Elevators;Dispatching;Algorithm design and analysis;Optimization;Floors;Energy consumption;Control systems},
}

@Article{Huang2012,
  author   = {Huang, Xiaolin and Xu, Jun and Wang, Shuning},
  journal  = {Neurocomputing},
  title    = {Nonlinear system identification with continuous piecewise linear neural network},
  year     = {2012},
  issn     = {0925-2312},
  number   = {1},
  pages    = {167--177},
  volume   = {77},
  abstract = {This paper considers system identification using domain partition based continuous piecewise linear neural network (DP-CPLNN), which is newly proposed. DP-CPLNN has the capability of representing any continuous piecewise linear (CPWL) function, hence its identification performance can be expected. Another attractive feature of DP-CPLNN is the geometrical property of its parameters. Applying this property, this paper proposes an identification method including domain partition and parameter training. In numerical experiments, DP-CPLNN with this method outperforms hinging hyperplanes and high-level canonical piecewise linear representation, which are two widely used CPWL models, showing the flexibility of DP-CPLNN and the effectiveness of the proposed algorithm in nonlinear identification.},
  doi      = {https://doi.org/10.1016/j.neucom.2011.09.001},
  file     = {:FILES/2012 - Huang2012 - Nonlinear system identification with continuous piecewise linear neural network.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {Piecewise linear neural network, Domain partition, Nonlinear system identification},
  url      = {http://www.sciencedirect.com/science/article/pii/S0925231211005078},
}

@Article{Huang2012a,
  author   = {Huang, Xiaolin and Mu, Xiaomu and Wang, Shuning},
  journal  = {IFAC Proceedings Volumes},
  title    = {Continuous piecewise linear identification with moderate number of subregions},
  year     = {2012},
  issn     = {1474-6670},
  note     = {16th IFAC Symposium on System Identification},
  number   = {16},
  pages    = {535--540},
  volume   = {45},
  abstract = {A continuous piecewise linear (CPWL) function equals an affine function in each of the subregions which tessellate the domain. By CPWL identification, one nonlinear system can be approached by a set of linear systems and then linear techniques are applicable. For the convenience of further application, the number of subregions should be moderate. However, because the relation between the subregions and parameters of a CPWL model is very complicated, existing identification methods usually lead to a lot of unexpected subregions, when training the parameters of traditional CPWL models. In this paper, domain partition based CPWL neural network, which is recently proposed, is utilized to solve the problem above. The relation between parameters and subregion structure of such model is analyzed. Then an algorithm of adjusting vertices is proposed to improve approximation precision with moderate number of subregions. Compared with some prior identification methods, the proposed algorithm uses much less subregions and achieves satisfactory precision in numerical study.},
  doi      = {https://doi.org/10.3182/20120711-3-BE-2027.00251},
  file     = {:FILES/2012 - Huang2012a - Continuous Piecewise Linear Identification with Moderate Number of Subregions.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {piecewise linear, identification, number of subregions},
  url      = {http://www.sciencedirect.com/science/article/pii/S147466701538006X},
}

@Article{Ma2011,
  author   = {Ma, Yifei and Li, Li and Huang, Xiaolin and Wang, Shuning},
  journal  = {IFAC Proceedings Volumes},
  title    = {Robust support vector machine using least median loss penalty},
  year     = {2011},
  issn     = {1474-6670},
  note     = {18th IFAC World Congress},
  number   = {1},
  pages    = {11208--11213},
  volume   = {44},
  abstract = {Abstract It is found that data points used for training may contain outliers that can generate unpredictable disturbance for some Support Vector Machines (SVMs) classification problems. No theoretical limit for such bad influence is held in traditional convex SVM methods. We present a novel robust misclassification penalty function for SVM which is inspired by the concept of “Least Median Regression”. In our approach, total loss penalty in training is measured by the summation of two median hinge losses, each for a different class. We also propose a “Rank and Convex Procedure” to optimize our tasks. Though our approach is heuristic, it is faster than other known robust methods, such as SVM with Ramp Loss Penalty.},
  doi      = {https://doi.org/10.3182/20110828-6-IT-1002.03467},
  file     = {:FILES/2011 - Ma2011 - Robust support vector machine using least median loss penalty.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {Statistical data analysis, Learning theory, Pattern recognition, Robust identification, Support vector machine},
  url      = {http://www.sciencedirect.com/science/article/pii/S1474667016454157},
}

@Article{Xu2011,
  author   = {Xu, Jun and Huang, Xiaolin and Wang, Shuning},
  journal  = {IFAC Proceedings Volumes},
  title    = {Local optimality for hinging hyperplanes-based model predictive control},
  year     = {2011},
  issn     = {1474-6670},
  note     = {18th IFAC World Congress},
  number   = {1},
  pages    = {5519--5524},
  volume   = {44},
  abstract = {Abstract The model predictive control based on hinging hyperplanes (HH) model is considered in this paper. Compared with previous work (Chikkula and Lee (1998)), in which a global optimum is obtained, here, we are dedicated to finding the local optima to lessen the computational burden. The necessary and sufficient conditions for a point to be locally optimal are given and based on these conditions, a multi-start algorithm searching for sufficiently good local optimum is proposed. Simulation results show the effectiveness of the proposed control strategy.},
  doi      = {https://doi.org/10.3182/20110828-6-IT-1002.03286},
  file     = {:FILES/2011 - Xu2011- Local optimality for hinging hyperplanes-based model predictive control.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {Predictive control, piecewise linear, local optimality},
  url      = {http://www.sciencedirect.com/science/article/pii/S147466701644485X},
}

@Article{Xu2012,
  author   = {Xu, Jun and Huang, Xiaolin and Mu, Xiaomu and Wang, Shuning},
  journal  = {Journal of Process Control},
  title    = {Model predictive control based on adaptive hinging hyperplanes model},
  year     = {2012},
  issn     = {0959-1524},
  number   = {10},
  pages    = {1821--1831},
  volume   = {22},
  abstract = {The model of adaptive hinging hyperplanes (AHH) is used in model predictive control (MPC). The nonlinear dynamic system is approximated by the continuous piecewise affine (CPWA) model AHH and the controller design problem becomes a continuous piecewise quadratic programming. The necessary and sufficient conditions for a point to be locally optimal for such a problem are established, based on which, a descent algorithm is developed to find a local optimum. Issues concerning feasibility and stability are also discussed. Simulations are conducted to confirm the effectiveness of the proposed MPC strategy.},
  doi      = {https://doi.org/10.1016/j.jprocont.2012.10.007},
  file     = {:FILES/2012 - Xu2012 - Model predictive control based on adaptive hinging hyperplanes model.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {Model predictive control, Adaptive hinging hyperplanes, Piecewise affine, Local optimum},
  url      = {http://www.sciencedirect.com/science/article/pii/S0959152412002363},
}

@Article{Huang2011,
  author   = {Huang, Xiaolin and Xu, Jun and Wang, Shuning},
  journal  = {International Journal of Control, Automation and Systems},
  title    = {Parameters estimation of hinging hyperplanes using median squared error criterion},
  year     = {2011},
  issn     = {2005-4092},
  number   = {4},
  pages    = {627},
  volume   = {9},
  abstract = {This paper considers parameter estimation for nonlinear model using median squared error (MSE) criterion, which is limited to linear model in the past. It is shown that applying MSE, the essence of estimating parameters for hinging hyperplanes (HH) and linear model are the same. Motivated by this fact, MSE estimation is discussed for HH. A local optimality condition is given and based on this condition, an algorithm using linear programming technique is proposed. Numerical experiments show the good performance of the proposed estimation strategy and algorithm.},
  doi      = {10.1007/s12555-011-0402-1},
  file     = {:FILES/2011 - Huang2011 - Parameters estimation of hinging hyperplanes using median squared error criterion.pdf:PDF},
  groups   = {Wang's Work},
  refid    = {Huang2011},
  url      = {https://doi.org/10.1007/s12555-011-0402-1},
}

@Article{Wang2004,
  author   = {Wang, Shuning},
  journal  = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title    = {General constructive representations for continuous piecewise-linear functions},
  year     = {2004},
  issn     = {1558-0806},
  month    = {9},
  number   = {9},
  pages    = {1889--1896},
  volume   = {51},
  abstract = {The problem of constructing a canonical representation for an arbitrary continuous piecewise-linear (PWL) function in any dimension is considered in this paper. We solve the problem based on a general lattice PWL representation, which can be determined for a given continuous PWL function using existing methods. We first transform the lattice PWL representation into the difference of two convex functions, then propose a constructive procedure to rewrite the latter as a canonical representation that consists of at most n-level nestings of absolute-value functions in n dimensions, hence give a thorough solution to the problem mentioned above. In addition, we point out that there exist notable differences between a lattice representation and the two novel general constructive representations proposed in this paper, and explain that these differences make all the three representations be of their particular interests.},
  doi      = {10.1109/TCSI.2004.834521},
  file     = {:FILES/2004 - Wang2004 - General constructive representations for continuous piecewise-linear functions.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {difference equations;piecewise linear techniques;lattice networks;convex programming;transforms;continuous piecewise-linear functions;general lattice PWL representation;convex functions;most n-level nestings;absolute-value functions;general piecewise-linear expression;lattice PWL function;Piecewise linear techniques;Lattices;Circuit analysis;Nonlinear circuits;Vectors;Counting circuits;Automation},
}

@InProceedings{Li2005,
  author    = {Li, Feng and Wang, Shuning},
  booktitle = {IEEE Proceedings. Intelligent Vehicles Symposium, 2005.},
  title     = {Determining route traffic flows for traffic assignment problem with frank-wolfe algorithm},
  year      = {2005},
  month     = {6},
  pages     = {669--673},
  abstract  = {In this paper we consider how to determine route traffic flows for traffic assignment problem (TAP). A new approach is proposed for this purpose. It determines the route traffic flows indirectly. It solves the problem based on the solution of the link based model for the user equilibrium TAP given by LeBlanc but without enumerating all routes of the concerned traffic network explicitly. In this approach a modified Frank-Wolfe algorithm is first applied to obtain link traffic flows with different destinations for TAP, which are then used to determine the route traffic flows by a new algorithm. A simple numerical example is given to illustrate the availability of the new approach. A comparison between the new approach and the other algorithms are made.},
  doi       = {10.1109/IVS.2005.1505180},
  file      = {:FILES/2005 - Li2005 - Determining route traffic flows for traffic assignment problem with Frank-Wolfe algorithm.pdf:PDF},
  groups    = {Wang's Work},
  issn      = {1931-0587},
  keywords  = {road traffic;transportation;convex programming;automated highways;road vehicles;route traffic flow;traffic assignment problem;link based model;user equilibrium;Frank-Wolfe algorithm;path based algorithm;origin based algorithm;Telecommunication traffic;Traffic control;Transportation;Mathematical programming;Acceleration;Automation;Projection algorithms;Urban planning;Equations;Costs},
}

@InProceedings{Junaid2006,
  author    = {Junaid, K. M. and Wang, Shuning},
  booktitle = {2006 IEEE Intelligent Transportation Systems Conference},
  title     = {Automatic cruise control modeling- a lattice {PWL} approximation approach},
  year      = {2006},
  month     = {9},
  pages     = {1370--1375},
  abstract  = {Approximation and control of nonlinear systems is a very important field of research for systems analysis and design. Although there is a growing interest in modeling and compact representation of piecewise linear functions as seen in the recent research, however only limited applications exist in the literature. In this paper a systematic procedure is outlined for modeling a nonlinear system with continuous piecewise linear function. The scheme is applied to approximate the nonlinear vehicle following model, where a third-order nonlinear system is considered to model the vehicle and power train dynamics. It is shown that without facing the problem of curse of dimensionality in linear models, the approximated model is compact, captures essential vehicle dynamics and is suitable for further control by linear methods. The control is implemented on local linear models based on gain scheduling technique. Simulation examples show that the designed system not only guarantees asymptotic tracking of the desired trajectories, but also ensures safety and ride comfort under the constraints of physical limitations inherent in the system. Various issues of vehicle following e.g. convergence of error in the inter-vehicle spacing, velocity following and control saturation are addressed in this paper. The performance analysis reveals that the new strategy yields valid results},
  doi       = {10.1109/ITSC.2006.1707414},
  file      = {:FILES/2006 - Junaid2006 - Automatic cruise control modeling- a lattice PWL approximation approach.pdf:PDF},
  groups    = {Wang's Work},
  issn      = {2153-0017},
  keywords  = {continuous systems;motion control;nonlinear control systems;piecewise linear techniques;vehicle dynamics;automatic cruise control modeling;lattice PWL approximation;continuous piecewise linear function;nonlinear vehicle following model;third-order nonlinear system;vehicle dynamics;power train dynamics;local linear model;gain scheduling;Automatic control;Lattices;Power system modeling;Piecewise linear approximation;Nonlinear systems;Piecewise linear techniques;Vehicle dynamics;Nonlinear control systems;Control systems;System analysis and design},
}

@InProceedings{Wang2008a,
  author    = {Wang, Y. and Wang, S. and Junaid, K. M. and Chen, Y.},
  booktitle = {2008 IEEE International Symposium on Intelligent Control},
  title     = {Approximation and inverse control of nonlinear system using standard continuous piecewise linear neural networks},
  year      = {2008},
  month     = {9},
  pages     = {1302--1307},
  abstract  = {The main difficulty for standard continuous piecewise linear neural networks (SCPLNN) approximation is how to partition the definitional domain into several simplices, which is called a triangulation. In this paper, we firstly propose a method of triangulation to perform SCPLNN approximation. Our scheme starts with an initial, coarse triangulation of the given data and subdivides simplex until the error of the SCPLNN approximation is smaller than some tolerance. Then SCPLNN based on triangulation is identified. The proposed method involving triangulation and identification of SCPLNN is shown to be useful in approximating nonlinear systems. In addition, for each simplex, the local inverse model can easily be calculated for each local model of SCPLNN is linear. From control perspective, we exploit the advantage of the piecewise linear property of SCPLNN and design controllers for each approximate model. The validity of this control scheme using inverse of the local linear model is tested by using a NARX model.},
  doi       = {10.1109/ISIC.2008.4635942},
  file      = {:FILES/2008 - Wang2008a - Approximation and Inverse Control of Nonlinear System using Standard Continuous Piecewise Linear Neural Networks.pdf:PDF},
  groups    = {Wang's Work},
  issn      = {2158-9879},
  keywords  = {approximation theory;autoregressive processes;continuous systems;control system synthesis;identification;neurocontrollers;nonlinear control systems;piecewise linear techniques;inverse control;standard continuous piecewise linear neural network approximation;triangulation;identification;nonlinear system;local inverse model;control design;NARX model;Intelligent control;Control systems;USA Councils},
}

@InProceedings{Xu2009,
  author    = {Xu, J. and Huang, X. and Wang, S.},
  booktitle = {Proceedings of the 48h IEEE Conference on Decision and Control (CDC) held jointly with 2009 28th Chinese Control Conference},
  title     = {Nonlinear model predictive control using adaptive hinging hyperplanes model},
  year      = {2009},
  month     = {12},
  pages     = {2598--2603},
  abstract  = {This paper deals with the problem of nonlinear model predictive control using a piecewise linear predictive model: the adaptive hinging hyperplanes (AHH). The AHH model is adaptive and efficient, thus depicts the relationship of the nonlinear system very well. Thanks to the piecewise linear property of the predictive model, a series of convex quadratic programming are constructed in the controller design step. The existence of a global optimum is guaranteed and a descent search algorithm is performed to get a reasonable control sequence within the sampling interval. Simulation results are also presented to illustrate the potential of the proposed methodologies.},
  doi       = {10.1109/CDC.2009.5400027},
  file      = {:FILES/2009 - Xu2009 - Nonlinear model predictive control using adaptive hinging hyperplanes model.pdf:PDF},
  groups    = {Wang's Work},
  issn      = {0191-2216},
  keywords  = {adaptive control;control system synthesis;convex programming;nonlinear control systems;piecewise linear techniques;predictive control;quadratic programming;search problems;nonlinear model predictive control;adaptive hinging hyperplanes model;piecewise linear predictive model;nonlinear system;convex quadratic programming;controller design;descent search algorithm;Predictive models;Predictive control;Programmable control;Adaptive control;Piecewise linear techniques;Sequences;Automation;Flowcharts;Inductors;Mathematical model},
}

@InProceedings{Xu2010,
  author    = {Xu, J. and Huang, X. and Wang, S.},
  booktitle = {Proceedings of the 2010 American Control Conference},
  title     = {Stability analysis of planar continuous piecewise linear systems},
  year      = {2010},
  month     = {6},
  pages     = {2505--2510},
  abstract  = {In this paper, planar continuous piecewise linear (PCPWL) systems composed of more than two linear subsystems are investigated. Instead of using Lyapunov method, we study the behavior of the PCPWL system directly to give the stability analysis. When there exist eigenvectors for the PCPWL system, the subsystem stability ensures the global stability. If there are no eigenvectors, the one-circle-gain determines the global stability. Besides, we claim that PCPWL system with three stable subsystems is always globally stable if each subsystem has distinct real eigenvalues. Simulation results illustrate the proposed stability tests.},
  doi       = {10.1109/ACC.2010.5530702},
  file      = {:FILES/2010 - Xu2010 - Stability analysis of planar continuous piecewise linear systems.pdf:PDF},
  groups    = {Wang's Work},
  issn      = {2378-5861},
  keywords  = {continuous systems;eigenvalues and eigenfunctions;piecewise linear techniques;stability;stability analysis;planar continuous piecewise linear systems;Lyapunov method;eigenvectors;global stability;one-circle-gain;eigenvalues;Stability analysis;Piecewise linear techniques;Lyapunov method;Bismuth;Linear systems;Automation;Control systems;Eigenvalues and eigenfunctions;Testing;Systems engineering and theory},
}

@InProceedings{Huang2010,
  author    = {Huang, X. and Xu, J. and Wang, S.},
  booktitle = {Proceedings of the 2010 American Control Conference},
  title     = {Identification algorithm for standard continuous piecewise linear neural network},
  year      = {2010},
  month     = {6},
  pages     = {4931--4936},
  abstract  = {Standard continuous piecewise linear neural network (SCPLNN) is a new continuous piecewise linear (CPL) model. It can represent all the CPL functions and approximate any continuous nonlinear function with arbitrary precision. Moreover, the parameters of SCPLNN are directly related to the expression of the subregions, in each of which SCPLNN equals to a linear function. Based on this property, this paper proposes an identification algorithm for SCPLNN, including domain partition and parameters optimization. In numerical experiments, SCPLNN with this algorithm outperforms hinging hyperplanes which is a widely used CPL model, showing the power and flexibility of SCPLNN in approximation.},
  doi       = {10.1109/ACC.2010.5530927},
  file      = {:FILES/2010 - Huang2010 - Identification algorithm for standard continuous piecewise linear neural network.pdf:PDF},
  groups    = {Wang's Work},
  issn      = {2378-5861},
  keywords  = {approximation theory;continuous systems;identification;neurocontrollers;nonlinear functions;optimisation;piecewise linear techniques;identification algorithm;standard continuous piecewise linear neural network;continuous nonlinear function;parameters optimization;Piecewise linear techniques;Neural networks;Piecewise linear approximation;Partitioning algorithms;Approximation algorithms;Educational programs;Automation},
}

@Article{Xu2008,
  author   = {Xu, Jun and Huang, Xiaolin and Wang, Shuning},
  journal  = {IFAC Proceedings Volumes},
  title    = {Adaptive hinging hyperplanes},
  year     = {2008},
  issn     = {1474-6670},
  note     = {17th IFAC World Congress},
  number   = {2},
  pages    = {4036--4041},
  volume   = {41},
  abstract = {The model of adaptive hinging hyperplanes (AHH) is proposed in this paper for black-box modeling. It is based on Multivariate Adaptive Regression Splines (MARS) and Generalized Hinging Hyperplanes (GHH) and shares attractive properties of the two. By making a modification to the basis function of MARS, AHH shows linear property in each subarea. It is proved that AHH model is identical to a special case of the Generalized Hinging Hyperplanes (GHH) model, which has a universal representation capability for continuous piecewise linear functions. AHH algorithm is developed similar to MARS algorithm. It is adaptive and can be executed quickly, hence has power and flexibility to model unknown relationships. In addition, due to the piecewise-linear property, AHH is preferred to MARS when modeling high-dimensional dynamic systems, especially when the sample size is small and under noise conditions.},
  doi      = {https://doi.org/10.3182/20080706-5-KR-1001.00679},
  file     = {:FILES/2008 - Xu2008 - adpative hinging hyperplanes.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {Systems and signals, black-box modeling, adaptive regression, piecewise-linear},
  url      = {http://www.sciencedirect.com/science/article/pii/S1474667016395775},
}

@Article{muxiaomu2011,
  author   = {牟晓牧 and 黄晓霖 and 王书宁},
  journal  = {清华大学学报(自然科学版)},
  title    = {分片线性逼近的动态特性分析},
  year     = {2011},
  number   = {07},
  pages    = {879--883},
  volume   = {51},
  abstract = {为了合理地应用分片线性逼近方法解决非线性动态系统问题,对非线性动态特性在分片线性逼近下的一致性问题展开研究。在对典型的混沌映射Logistic映射进行分片线性逼近时,分片线性系统会表现出一些不同于原系统的动态特性。即使在静态逼近精度很高的情况下,逼近所得的分片线性系统的分岔图与原系统的分岔图也会有很大的差异。分析表明分片线性系统与原系统光滑性的差异是导致动态特性差异的原因。继而使用光滑化的分片线性模型作逼近,逼近结果的动态特性能够保持与原系统一致。光滑化的分片线性模型适用于逼近非线性动态系统。},
  file     = {:FILES/2011 - muxiaomu2011 - 分片线性逼近的动态特性分析_牟晓牧.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {非线性动力学;分片线性逼近;Logistic映射;光滑链接超平面},
}

@Article{xu2010comp,
  author   = {许鋆 and 王晶 and 王书宁},
  journal  = {清华大学学报(自然科学版)},
  title    = {自适应链接超平面及其与高阶典范模型的比较},
  year     = {2010},
  number   = {10},
  pages    = {1747--1751},
  volume   = {50},
  abstract = {自适应链接超平面模型(AHH)是一种自适应的分片线性模型,可以作为一种人工神经网络用于非线性函数逼近。通过代数等价变换,该文证明,基于单纯形划分的高阶典范模型(HL-CPWL)的基函数等价于AHH模型的一种基函数,HL-CPWL模型是AHH模型的一个特例。较之HL-CPWL模型,AHH模型的定义域划分更为灵活,使得其更适合于函数逼近。AHH的通用逼近性也由HL-CPWL具有通用逼近能力而直接得到。仿真结果表明,较之HL-CPWL,AHH能够以较少的参数给出较好的逼近结果,具有更好的模型质量。},
  file     = {:FILES/2010 - xu2010comp - 自适应链接超平面及其与高阶典范模型的比较_许鋆.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {神经网络;非线性逼近;分片线性;自适应;链接超平面},
}

@Article{huang2010cn,
  author   = {黄晓霖 and 许鋆 and 王书宁},
  journal  = {控制工程},
  title    = {分片线性规划及应用},
  year     = {2010},
  number   = {S1},
  pages    = {66--68+72},
  volume   = {17},
  abstract = {提出通过分片线性逼近和分片线性规划,将非线性优化问题转化为一系列的线性规划进行求解的方法。讨论了分片线性规划的性质,证明了分片线性规划问题可以通过有限次线性规划得到求解,同时,给出了分片线性规划问题局部最优解的充要条件,并基于此构造了求解分片线性规划问题的下降算法。该算法与自适应链接超平面模型相结合,成功地对离心式冷水机组的工作点进行了优化。通过优化,机组的能耗比之当前工作点有了明显的下降,表明通过分片线性规划求解非线性优化问题的有效性。},
  file     = {:FILES/2010 - huang2010cn - 分片线性规划及应用_黄晓霖.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {非线性优化;分片线性逼近;分片线性规划;离心式冷水机组},
}

@Article{xu2010cn,
  author   = {许鋆 and 黄晓霖 and 王书宁},
  journal  = {控制工程},
  title    = {分片线性逼近及其在预测控制中的应用},
  year     = {2010},
  number   = {S1},
  pages    = {69--72},
  volume   = {17},
  abstract = {介绍了分片线性逼近的相关理论并将其应用于预测控制。自适应链接超平面模型(AHH)是一种具有应用潜力的分片线性模型。采用AHH模型对被控制系统进行建模,由于AHH模型的辨识算法是自适应的,整个过程简单易实现。随后,在线解一个开环优化问题得到最优控制序列并应用滚动优化控制策略对系统进行控制。并且证明此开环优化问题实质上可以看成一系列子问题,每个子问题都是二次规划问题,因此,全局最优解的存在性得以保证。对于实际问题,提出了一个下降算法用以搜索局部最优解,仿真结果表明,基于AHH模型的预测控制具有一定的应用前景。},
  file     = {:FILES/2010 - xu2010cn - 分片线性逼近及其在预测控制中的应用_许鋆.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {非线性系统;分片线性逼近;自适应链接超平面;预测控制;二次规划},
}

@Article{liying2009,
  author   = {李颖 and 黄晓霖 and 王书宁},
  journal  = {清华大学学报(自然科学版)网络.预览},
  title    = {运用改进的线性规划算法求解分片线性方程组},
  year     = {2009},
  number   = {10},
  pages    = {17--20},
  volume   = {49},
  abstract = {为了提高求解分片线性方程组的线性规划算法的计算效率,提出基于线性规划算法的改进算法。首先找出若干线性区域组成的超立方体,使得方程组函数在此超立方体上表现为凸函数或凹函数,然后在超立方体上求解一次特定的线性规划问题并判断此超立方体是否含有方程组的解。该文给出的数例中改进线性规划算法需要求解的线性规划问题数目仅为线性规划算法的1/4。改进线性规划算法无需在全部线性区域上求解线性规划,因此相对线性规划算法提高了计算效率,提高程度取决于方程组函数的性质。},
  file     = {:FILES/2009 - liying2009 - 运用改进的线性规划算法求解分片线性方程组_李颖.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {电路求解;分片线性方程组;线性规划},
}

@Article{wangyongli2009,
  author   = {王勇莉 and 李力 and 李颖 and 王书宁},
  journal  = {控制与决策},
  title    = {基于分片线性函数逼近的非线性观测器设计},
  year     = {2009},
  number   = {02},
  pages    = {279--283+288},
  volume   = {24},
  abstract = {综合分片线性函数模型辨识/逼近和鲁棒观测器设计方法,研究了一大类非线性鲁棒观测器设计方法.所提出的算法能有效解决非线性系统的辨识/建模问题,并保证在一定的逼近精度下观测误差可以控制在一定的范围内,且观测误差随着逼近精度的提高而减小.},
  file     = {:FILES/2009 - wangyongli2009 - 基于分片线性函数逼近的非线性观测器设计_王勇莉.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {非线性系统;分片线性;鲁棒观测器设计},
}

@Article{wangyongli2008,
  author   = {王勇莉 and 王书宁},
  journal  = {清华大学学报(自然科学版)},
  title    = {分片线性神经网络逆系统方法的内模控制},
  year     = {2008},
  number   = {S2},
  pages    = {1766--1770},
  abstract = {为提高传统逆系统方法的跟踪精度和抗干扰能力,提出了基于连续分片线性神经网络α阶逆系统方法的非线性内模控制方法。利用标准连续分片神经网络逼近非线性系统的α阶逆模型,将它串连在原系统之前,得到复合的伪线性系统,对该伪线性系统应用内模控制策略进行控制,并分析了闭环系统的性能。仿真结果表明:该方法跟踪效果好、抑制干扰能力强,且设计简单,是解决非线性系统控制的一种可行的方法。},
  file     = {:FILES/2008 - wangyongli2008 - 分片线性神经网络逆系统方法的内模控制_王勇莉.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {连续分片线性神经网络;逆系统方法;非线性内模控制},
}

@Article{wangyongli2008a,
  author   = {王勇莉 and 李颖 and 黄晓霖 and 王书宁},
  journal  = {电机与控制学报},
  title    = {构造性分片线性神经网络逼近},
  year     = {2008},
  number   = {03},
  pages    = {319--323},
  abstract = {针对非线性系统建模中用标准连续分片线性神经网络(SCPLNN)模型拟合二维平面上离散点的问题,依据逼近误差最小化的原则,提出了一种优化的三角形剖分算法进行区域划分。采用特征点代替采样点进行剖分,并给出了基于这种区域划分的SCPLNN模型逼近算法。将此逼近算法与基于Delaunay剖分SCPLNN模型逼近算法、典范分片线性表示的链接超平面逼近算法进行比较。实验结果表明,基于最优三角形剖分SCPLNN模型逼近算法可以有效和快速提高拟合精确度。},
  file     = {:FILES/2008 - wangyongli2008a - 构造性分片线性神经网络逼近_王勇莉.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {神经网络;分片线性神经网络;三角形剖分;逼近算法},
}

@Article{zhanghao2008,
  author   = {章浩 and 王书宁},
  journal  = {中国科学技术大学学报},
  title    = {分片线性逼近在电厂机组负荷分配中的应用},
  year     = {2008},
  number   = {03},
  pages    = {257--260},
  abstract = {机组负荷优化分配是电厂提高经济效益的一种重要手段,已经成为经济调度领域内非常受关注的研究课题.针对该问题中机组发电费用为凸函数的特点,利用分片线性逼近技术建立了一种新的0-1线性混合整数规划模型.该模型既保证了求解的精度,又避免了非线性混合整数规划问题难以确定全局最优解的缺点.文章最后用一个具体的数值仿真例子说明该方法的有效性.},
  file     = {:FILES/2008 - zhanghao2008 - 分片线性逼近在电厂机组负荷分配中的应用_章浩.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {电力系统;负荷分配;分片线性;混合整数规划},
}

@Article{zhanghao2008a,
  author   = {章浩 and 王书宁},
  journal  = {清华大学学报(自然科学版)},
  title    = {基于超立方体分割的分片线性逼近},
  year     = {2008},
  number   = {01},
  pages    = {153--156},
  abstract = {为了解决复杂非线性系统的建模问题,提出一种基于超立方体分割的分片线性逼近模型。该模型将定义域分割成超立方体,在每个超立方体内用一个线性函数描述原来的非线性函数。再借助格表示形式,通过选择合适的连接得到由这些局部线性函数构成的连续分片线性函数。证明对于任何二阶可导的非线性函数,该模型都能任意精度逼近。因为不用再把每个超立方体都分割成单纯形,该模型有助于构造出更加简单的连续分片线性函数,并能处理复杂的高维问题。},
  file     = {:FILES/2008 - zhanghao2008a - 基于超立方体分割的分片线性逼近_章浩.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {非线性函数逼近;复杂系统;分片线性},
}

@Article{wen2005,
  author   = {温成涛 and 王书宁 and 孙旭昇 and 李峰 and 章浩},
  journal  = {清华大学学报(自然科学版)},
  title    = {三维连续分片线性函数紧凑表示模型},
  year     = {2005},
  number   = {04},
  pages    = {533--535},
  abstract = {为了解决三维分片线性函数的表示问题,提出一个基于三维基函数的绝对值表示理论,建立了一个紧凑绝对值表示模型并构造性地证明了其一般表示能力。因为基函数是比最小退化交更基本的结构函数,所以该模型可以视为建立在最小退化交基础上的Chua模型的修正和推广。该模型给出三维绝对值表示模型中绝对值嵌套层数的下界,这为建立高维表示理论提供了新的理论依据。三维表示模型与"找链接算法"相结合,可以构造一种新的三维非线性函数逼近算法。},
  file     = {:FILES/2005 - wen2005 - 三维连续分片线性函数紧凑表示模型_温成涛.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {分片线性函数;紧凑表示;三维基函数;非线性函数逼近},
}

@Article{feng2003,
  author   = {冯云方 and 王书宁 and 王伟},
  journal  = {清华大学学报(自然科学版)},
  title    = {分片合并模型树光滑逼近算法},
  year     = {2003},
  number   = {07},
  pages    = {869--872},
  abstract = {针对已知样本数据建立非线性函数模型的问题,提出了分片合并模型树光滑逼近算法。在区域线性模型树算法的基础上,采用区域分片和区域合并两个算法将输入空间划分为若干子区域,对每个子区域使用线性函数进行逼近,并构建该子区域上的加权函数,生成基函数展开方式的全局表达,从而获得光滑的任意精度逼近结果。分片合并算法使得相同的线性函数可以在非凸甚至非连通的区域上起作用。在参数数量相同的情况下,其逼近精度比区域线性模型树算法有显著提高。仿真结果表明:该算法是解决这类建模问题的有效方法。},
  file     = {:FILES/2003 - feng2003 - 分片合并模型树光滑逼近算法_冯云方.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {非线性系统;分片线性;非线性逼近;光滑逼近;区域线性模型树},
}

@Article{wang2003lattice,
  author   = {王书宁},
  journal  = {清华大学学报(自然科学版)},
  title    = {格分片线性函数的辨识和优化},
  year     = {2003},
  number   = {04},
  pages    = {548--552},
  abstract = {格分片线性模型由一个实数矩阵和一个 0 - 1矩阵所确定 ,能够表示任意维变量的全体连续分片线性函数 ,其实数矩阵完全由它的局部线性函数的参数向量所组成。这些特点为辨识分片线性函数和利用线性模型的分析方法解决分片线性模型描述的非线性问题提供了极大的便利。该文引入格分片线性模型解决非线性函数的辨识问题。给出了辨识格分片线性函数的实用算法。并对线性约束下的格分片线性函数优化问题提出了通过线性规划算法确定全局最优解的简单方法。这些工作表明 ,用格分片线性函数建模是解决非线性问题的一种有效途径},
  file     = {:FILES/2003 - wang2003lattice - 格分片线性函数的辨识和优化_王书宁.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {格分片线性模型;分片线性逼近;非线性辨识;全局优化},
}

@Article{gaolin2002,
  author   = {高林 and 王书宁 and 王伟},
  journal  = {控制理论与应用},
  title    = {鲁棒辨识的$l_1$和{$H_\infty$}误差上界的估计算法},
  year     = {2002},
  number   = {06},
  pages    = {975--976+980},
  abstract = {对有限参数线性系统辨识问题的l1误差上界估计和时域H∞ 插值算法误差上界估计等问题转化为一类分片线性函数的最优化问题 ,提出基于分片的混合遗传算法 .吸取进化算法的探索能力 ,并充分利用模型信息 .仿真实验结果表明了它的寻优性能 .},
  file     = {:FILES/2002 - gaolin2002 - 鲁棒辨识的l_1和H_误差上界的估计算法_高林.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {鲁棒辨识;误差上界;分片线性函数;最优化;遗传算法},
}

@Article{lixingye2002,
  author   = {李星野 and 王书宁 and 王万宾},
  journal  = {清华大学学报(自然科学版)},
  title    = {二维连续分片线性绝对值模型},
  year     = {2002},
  number   = {09},
  pages    = {1233--1236},
  abstract = {因为连续分片线性常规模型使用过多参数 ,所以研究它的紧凑模型很有必要。通过分析连续分片线性函数本身而不仅仅分析函数的定义域 ,采用分解叠加的方式构造出函数的新绝对值紧凑模型。模型的有效性被严格证明。证明过程中还给出表示已有连续分片线性函数的算法。新模型有两个明显的优点 :一是可以直观简便地表示所有二维空间上连续分片线性函数 ;二是便于给出用连续分片线性函数逼近连续非线性函数的算法。},
  file     = {:FILES/2002 - lixingye2002 - 二维连续分片线性绝对值模型_李星野.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {分片线性函数;紧凑表示;非线性系统},
}

@Article{wangwanbin2002,
  author   = {王万宾 and 王书宁 and 李星野},
  journal  = {清华大学学报(自然科学版)},
  title    = {改进的链接超平面逼近算法},
  year     = {2002},
  number   = {03},
  pages    = {377--379+390},
  abstract = {提出了一种新的链接超平面逼近算法。“链接超平面”算法作为非线性逼近方法以链接函数为基函数 ;由于基函数的局限性 ,使“链接超平面”算法不可能达到最佳逼近。论文在二维空间上将双层 maxim in函数扩充为逼近中的基函数 ,经扩充后的模型可表示二维空间上所有的分片线性函数 ,从而其逼近能力强于仅用单层 maximin函数作为基函数的算法。仿真实验表明 ,在参数个数相同的情况下 ,新的逼近算法在逼近精度与预测误差两方面都优于仅用单层maximin函数作为基函数的逼近算法},
  file     = {:FILES/2002 - wangwanbin2002 - 改进的链接超平面逼近算法_王万宾.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {分片线性;非线性逼近;链接超平面},
}

@Article{lixingye2002a,
  author   = {李星野 and 王书宁 and 王万宾},
  journal  = {自然科学进展},
  title    = {高维空间上连续分片线性函数的绝对值表示},
  year     = {2002},
  number   = {02},
  pages    = {82--86},
  abstract = {高维空间上连续分片线性函数的绝对值表示是一个一直没有能很好解决的问题.在一维空间上连续分片线性函数的绝对值表示基础之上,采用递推的方法,给出了高维空间上连续分片线性函数的绝对值表示;同时证明了该绝对值表示对所有高维空间上连续分片线性函数有效.},
  file     = {:FILES/2002 - lixingye2002a - 高维空间上连续分片线性函数的绝对值表示_李星野.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {分片线性函数;绝对值表示;高维空间;递推方法},
}

@Article{lixiaoli2002,
  author   = {李晓理 and 王书宁},
  journal  = {控制与决策},
  title    = {基于分片线性化方法的非线性系统多模型自适应控制},
  year     = {2002},
  number   = {01},
  pages    = {45--48+52},
  abstract = {基于分片线性化方法辨识一类非线性系统 ,给出了非线性系统的多线性模型表示。基于线性模型建立多个控制器 ,基于最大最小指标切换函数构成多模型自适应控制器。给出了非线性系统多模型自适应控制算法的优化模型集建立方法 ,解决了多模型自适应控制模型多、计算量大的问题。仿真结果证明了算法的有效性},
  file     = {:FILES/2002 - lixiaoli2002 - 基于分片线性化方法的非线性系统多模型自适应控制_李晓理.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {分片线性;非线性系统;多模型},
}

@Article{wangwei2001,
  author   = {王伟 and 高林 and 王书宁},
  journal  = {清华大学学报(自然科学版)},
  title    = {具有线性约束的分片线性函数的最优化方法},
  year     = {2001},
  number   = {09},
  pages    = {102--105},
  abstract = {分片线性模型有着广泛应用范围 ,对分片线性模型及其最优化问题的研究具有普遍的意义。该文以规范型分片线性函数为例 ,提出了基于分片的邻区域搜索算法 ,通过定义相邻区域 ,应用线性规划寻找最优解。通过该算法和遗传算法相结合 ,可利用进化算法的探索能力和模型信息以实现全局优化。在仿真实验中 ,采用随机生成的分片线性函数对这种算法和传统遗传算法进行了对比 ,结果表明 ,它具有很好的搜索性能 ,当搜索空间很大或具有边界约束时 ,它较传统遗传算法更优越},
  file     = {:FILES/2001 - wangwei2001 - 具有线性约束的分片线性函数的最优化方法_王伟.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {分片线性函数;最优化;遗传算法},
}

@Article{lixingye2001,
  author   = {李星野 and 王书宁 and 王万宾},
  journal  = {计算机工程},
  title    = {基于分片线性函数的图象压缩方法},
  year     = {2001},
  number   = {08},
  pages    = {38--39+42},
  abstract = {使用了一种新的分片线性逼近算法。算法首先对极大极小这一分片线性函数的紧凑表示形式做了改进，然后以线性规划方法作为主要工具，以极小化拟合误差为准绳，同时确定全部参数；实现了分片线性函数对非线性样本数据的整体拟合；充分发挥了分片线性逼近的优势。在此基础上，提出了一种基于分片线性逼近的图象压缩编码方法。这种方法具有解压缩速度快的优点，与其它的图象压缩方法（例如ＤＣＴ）相结合，能够提高图象的压缩效率。},
  file     = {:FILES/2001 - lixingye2001 - 基于分片线性函数的图象压缩方法_李星野.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {图象压缩编码;分片线性函数;非线性逼近},
}

@InProceedings{wangwei2001a,
  author    = {王伟 and 王书宁 and 高林},
  booktitle = {第二十届中国控制会议},
  title     = {连续分片线性函数的优化},
  year      = {2001},
  address   = {中国辽宁大连},
  pages     = {4},
  abstract  = {凸可分分片线性目标函数下的优化问题得到了广泛的研究,但是任意的连续分片线性函数的优化问题尚没有得到较好的解决。本文通过引入任意的连续分片线性函数的一般紧凑表达形式minimax 方式,将分片线性函数优化问题转化为线性规划问题,从而获得优化问题的全局最优解。对于任意的连续函数优化问题,通过使用minimax表达模型的分片线性函数逼近连续函数,可望获得连续函数优化问题的近似解。},
  file      = {:FILES/2001 - wangwei2001a - 连续分片线性函数的优化_王伟.pdf:PDF},
  groups    = {Wang's Work},
  keywords  = {分片线性;优化;线性规划},
}

@InProceedings{lixingye2000,
  author    = {李星野 and 王书宁 and 王万宾},
  booktitle = {第十九届中国控制会议},
  title     = {连续分片线性函数的紧凑表示},
  year      = {2000},
  address   = {中国香港},
  pages     = {5},
  abstract  = {用分片线性函数去描述非线性系统易于分析了解系统的内部行为特征。而且分片线性函数的复合函数和反函数(如果存在的话)仍为分片线性函数,这一封闭性在电路分析中非常有用。然而传统的分片线性函数表示形式涉及过多的参数, 因此对分片线性函数的紧凑表示形式的研究就显得非常重要。本文给出了一般二维空间上连续分片线性函数的一个紧凑表示并证明了这一表示的有效性。可以说比较好地解决了二维空间上连续分片线性函数的紧凑表示问题。},
  file      = {:FILES/2000 - lixingye2000 - 连续分片线性函数的紧凑表示_李星野.pdf:PDF},
  groups    = {Wang's Work},
  keywords  = {分片线性函数;紧凑表示;非线性系统},
}

@InProceedings{Wang2002,
  author    = {Wang, Shuning and Narendra, K. S.},
  booktitle = {Proceedings of the 2002 American Control Conference (IEEE Cat. No.CH37301)},
  title     = {Nonlinear system identification with lattice piecewise-linear functions},
  year      = {2002},
  month     = {5},
  pages     = {388--393 vol.1},
  volume    = {1},
  abstract  = {A lattice piecewise-linear function is introduced for modeling nonlinear systems. A systematic procedure is proposed for building a lattice piecewise-linear model from the given input-output data. The objective of the paper is to demonstrate that modeling a nonlinear system using a lattice piecewise-linear function is a practically viable and very effective method of applying linear techniques to nonlinear dynamical systems.},
  doi       = {10.1109/ACC.2002.1024835},
  file      = {:FILES/2002 - Wang2002 - Nonlinear system identification with lattice piecewise-linear functions.pdf:PDF},
  groups    = {Wang's Work},
  issn      = {0743-1619},
  keywords  = {identification;piecewise linear techniques;nonlinear dynamical systems;nonlinear system identification;lattice piecewise-linear functions;input-output data;I/O data;lattice piecewise-linear function;nonlinear dynamical systems;Nonlinear systems;Lattices;Piecewise linear techniques;Ear;Mathematical model;Automation;Nonlinear dynamical systems;Linear systems;Approximation methods;Vectors},
}

@InProceedings{Li2003,
  author    = {Li, Feng and Wang, Shuning},
  booktitle = {Proceedings of the 2003 IEEE International Conference on Intelligent Transportation Systems},
  title     = {A nonlinear complementary model for traffic assignment problem},
  year      = {2003},
  month     = {10},
  pages     = {1044--1048 vol.2},
  volume    = {2},
  abstract  = {The concept of network system equilibrium is defined in this paper, based on which the traffic assignment problem is modeled as a nonlinear complementary problem. It is proven that the solution of this model can be obtained by solving a mathematical programming and there is a unique solution to the related mathematical programming. Two examples are studied to verify the new approach, which shows that more reasonable results can be obtained in this way.},
  doi       = {10.1109/ITSC.2003.1252645},
  file      = {:FILES/2003 - Li2003 - A nonlinear complementary model for traffic assignment problem.pdf:PDF},
  groups    = {Wang's Work},
  keywords  = {road traffic;nonlinear programming;nonlinear complementary model;traffic assignment problem;network system equilibrium;mathematical programming;first order conditions;Traffic control;Telecommunication traffic;Mathematical programming;Mathematical model;Automation;Stochastic processes;Logic programming;Telephony;Transportation},
}

@Article{Wang1999,
  author   = {Wang, Shuning and Dai, Jianshe and Tanaka, Masahiro},
  journal  = {IEEE Transactions on Automatic Control},
  title    = {A parametric approach for $l_1$ robust identification},
  year     = {1999},
  issn     = {1558-2523},
  month    = {6},
  number   = {6},
  pages    = {1282--1286},
  volume   = {44},
  abstract = {A convergent algorithm for l/sub 1/ robust identification of a stable rational transfer function with known order is proposed, which is implemented by solving a linear programming problem and can produce a rational transfer function with a fixed order. An explicit upper bound on its worst case identification error is given. Its performance is proven to be close to that of an interpolation algorithm if a high-order Galois sequence is taken as the input signal.},
  doi      = {10.1109/9.769391},
  file     = {:FILES/1999 - Wang1999 - A parametric approach for l_sub 1_robust identification.pdf:PDF},
  groups   = {Wang's Work},
  keywords = {identification;transfer functions;linear programming;interpolation;convergence of numerical methods;robust identification;rational transfer function;convergence;linear programming;upper bound;identification;interpolation;Galois sequence;Robustness;Transfer functions;Upper bound;Parameter estimation;System identification;Robust control;Linear programming;Educational institutions;Stochastic resonance;Uncertainty},
}

@InProceedings{Xu2014a,
  author    = {Xu, Jun and van den Boom, T. J. J. and De Schutter, B.},
  booktitle = {Proceedings of the 53rd IEEE Conference on Decision and Control (CDC)},
  title     = {Irredundant lattice piecewise affine representations and their applications in explicit model predictive control},
  year      = {2014},
  address   = {Los Angeles, CA, USA},
  month     = dec,
  pages     = {4416--4421},
  publisher = {IEEE},
  abstract  = {In this paper, we derive the irredundant lattice piecewise affine (PWA) representation, which is capable of representing any continuous PWA function. Necessary and sufficient conditions for irredundancy are proposed. Besides, we discuss how to remove redundant terms and literals and propose corresponding necessary and sufficient conditions. In a worked example, the irredundant lattice PWA representation is used to express the explicit model predictive controller of a linear system, and the result turns out to be much more compact than that given by the state-of-the-art algorithm.},
  doi       = {10.1109/CDC.2014.7040078},
  file      = {:FILES/2014 - Xu2014a - Irredundant lattice piecewise affine representations and their applications in explicit model predictive control.pdf:PDF},
  groups    = {Wang's Work, identification},
  issn      = {0191-2216},
  keywords  = {linear systems;predictive control;irredundant lattice piecewise affine representations;explicit model predictive control;PWA representation;continuous PWA function;predictive controller model;linear system;Lattices;Indexes;Optimization;Vectors;Predictive models;Educational institutions;Boolean algebra},
  url       = {https://ieeexplore.ieee.org/document/7040078},
}

@Article{Wen2009,
  author   = {Wen, Chengtao and Ma, Xiaoyan and Erik Ydstie, B.},
  journal  = {Automatica},
  title    = {Analytical expression of explicit {MPC} solution via lattice piecewise-affine function},
  year     = {2009},
  issn     = {0005-1098},
  number   = {4},
  pages    = {910--917},
  volume   = {45},
  abstract = {An analytical expression of the explicit solution to linear model predictive control (MPC) is proposed by the introduction of a lattice piecewise-affine (PWA) function. A systematic procedure is developed for building a lattice PWA representation from a continuous explicit MPC solution obtained by a multi-parametric program. A simple method is presented to remove the redundant parameters in the lattice expression of MPC control laws. The effectiveness of this approach is supported by the study of three benchmark MPC problems. The proposed analytical expression provides a very efficient and practically viable method for implementing the explicit MPC solutions regarding its online calculation and memory space requirements.},
  doi      = {https://doi.org/10.1016/j.automatica.2008.11.023},
  file     = {:FILES/2012 - Wen2009 - Reply to “Comments on ‘Analytical expression of explicit MPC solution via lattice piecewise-affine function’ [Automatica 45 (2009) 910–917]”.pdf:PDF;:FILES/2009 - Wen2009 - Analytical expression of explicit MPC solution via lattice piecewise-affine function.pdf:PDF;:FILES/2012 - Wen2009 - Comments on “Analytical expression of explicit MPC solution via lattice piecewise-affine function” [Automatica 45 (2009) 910–917].pdf:PDF},
  groups   = {application},
  keywords = {Explicit MPC solution, Lattice piecewise-affine function, General piecewise-affine expression, Multi-parametric program, Canonical representation},
  url      = {http://www.sciencedirect.com/science/article/pii/S0005109808005633},
}

@Article{Gounaris2008,
  author   = {Gounaris, Chrysanthos E. and Floudas, Christodoulos A.},
  journal  = {Journal of Global Optimization},
  title    = {Tight convex underestimators for {${\mathcal{C}^2}$}-continuous problems: {II}. multivariate functions},
  year     = {2008},
  issn     = {1573-2916},
  number   = {1},
  pages    = {69--89},
  volume   = {42},
  abstract = {In Part I (Gounaris, C.E., Floudas, C.A.: Tight convex understimators for $${\mathcal {C}^{2}}$$-continuous functions: I: Univariate functions. J. Global Optim. (2008). doi: 10.007/s10898-008-9287-9), we introduced a novel approach for the underestimation of univariate functions which was based on a piecewise application of the well-known αBB underestimator. The resulting underestimators were shown to be very tight and, in fact, can be driven to coincide with the convex envelopes themselves. An approximation by valid linear supports, resulting in piecewise linear underestimators was also presented. In this paper, we demonstrate how one can make use of the high quality results of the approach in the univariate case so as to extend its applicability to functions with a higher number of variables. This is achieved by proper projections of the multivariate αBB underestimators into select two-dimensional planes. Furthermore, since our method utilizes projections into lower-dimensional spaces, we explore ways to recover some of the information lost in this process. In particular, we apply our method after having transformed the original problem in an orthonormal fashion. This leads to the construction of even tighter underestimators, through the accumulation of additional valid linear cuts in the relaxation.},
  doi      = {10.1007/s10898-008-9288-8},
  file     = {:FILES/2008 - Gounaris2008 - Tight convex underestimators for   C2  -continuous problems- II. multivariate functions.pdf:PDF},
  groups   = {identification},
  refid    = {Gounaris2008},
  url      = {https://doi.org/10.1007/s10898-008-9288-8},
}

@Article{wicaksono2008piecewise,
  author    = {Wicaksono, Danan Suryo and Karimi, Iftekhar A.},
  journal   = {AIChE Journal},
  title     = {Piecewise {MILP} under-and overestimators for global optimization of bilinear programs},
  year      = {2008},
  number    = {4},
  pages     = {991--1008},
  volume    = {54},
  abstract  = {Abstract Many practical problems of interest in chemical engineering and other fields can be formulated as bilinear programs (BLPs). For such problems, a local nonlinear programming solver often provides a suboptimal solution or even fails to locate a feasible one. Numerous global optimization algorithms devised for bilinear programs rely on linear programming (LP) relaxation, which is often weak, and, thus, slows down the convergence rate of the global optimization algorithm. An interesting recent development is the idea of using an ab initio partitioning of the search domain to improve the relaxation quality, which results in a relaxation problem that is a mixed-integer linear program (MILP) rather than LP, called as piecewise MILP relaxation. However, much work is in order to fully exploit the potential of such approach. Several novel formulations are developed for piecewise MILP under- and overestimators for BLPs via three systematic approaches, and two segmentation schemes. As is demonstrated and evaluated the superiority of the novel models is shown, using a variety of examples. In addition, metrics are defined to measure the effectiveness of piecewise MILP relaxation within a two-level-relaxation framework, and several theoretical results are presented, as well as valuable insights into the properties of such relaxations, which may prove useful in developing global optimization algorithms. © 2008 American Institute of Chemical Engineers AIChE J, 2008},
  doi       = {10.1002/aic.11425},
  eprint    = {https://aiche.onlinelibrary.wiley.com/doi/pdf/10.1002/aic.11425},
  file      = {:FILES/2008 - wicaksono2008piecewise - Piecewise MILP under‐ and overestimators for global optimization of bilinear programs.pdf:PDF},
  groups    = {Approximation, bilevel},
  keywords  = {global optimization, bilinear programming, mixed-integer linear programming, piecewise under- and overestimators, process network synthesis},
  publisher = {Wiley Online Library},
  url       = {https://aiche.onlinelibrary.wiley.com/doi/abs/10.1002/aic.11425},
}

@Article{Mansoori2018,
  author   = {Mansoori, A. and Eshaghnezhad, M. and Effati, S.},
  journal  = {IEEE Transactions on Circuits and Systems II: Express Briefs},
  title    = {An efficient neural network model for solving the absolute value equations},
  year     = {2018},
  issn     = {1558-3791},
  month    = {3},
  number   = {3},
  pages    = {391--395},
  volume   = {65},
  abstract = {In this brief, we obtain the exact solution of the absolute value equation (AVE). To the best of our knowledge, there is no attempt to obtain the exact solution to this problem. However, there exist many numerical methods to get the approximation solution of the AVE. Here, we try to present a neural network model in order to find the solution of the AVE, analytically. Furthermore, the Lyapunov stability and the global convergence of the model are proved. Finally, the simulation results show the performance, the effectiveness, and the accuracy of the method.},
  doi      = {10.1109/TCSII.2017.2750065},
  file     = {:FILES/2017 - Mansoori2018 - An Efficient Neural Network Model for Solving the Absolute Value Equations.pdf:PDF},
  groups   = {structure},
  keywords = {convergence of numerical methods;Lyapunov methods;neural nets;stability;absolute value equation;AVE;numerical methods;neural network model;Lyapunov stability;global convergence;Mathematical model;Neural networks;Numerical models;Newton method;Integrated circuit modeling;Analytical models;Absolute value equations;linear complementarity problem;neural network;globally stable in the sense of Lyapunov},
}

@InProceedings{Daxberger2020,
  author    = {Daxberger, Erik and Makarova, Anastasia and Turchetta, Matteo and Krause, Andreas},
  booktitle = {Proceedings of the 29th International Joint Conference on Artificial Intelligence},
  title     = {Mixed-variable {Bayesian} optimization},
  year      = {2020},
  editor    = {Bessiere, Christian},
  month     = jul,
  pages     = {2633--2639},
  abstract  = {The optimization of expensive to evaluate, black-box, mixed-variable functions, i.e. functions that have continuous and discrete inputs, is a difficult and yet pervasive problem in science and engineering. In Bayesian optimization (BO), special cases of this problem that consider fully continuous or fully discrete domains have been widely studied. However, few methods exist for mixed-variable domains and none of them can handle discrete constraints that arise in many real-world applications. In this paper, we introduce MiVaBo, a novel BO algorithm for the efficient optimization of mixed-variable functions combining a linear surrogate model based on expressive feature representations with Thompson sampling. We propose an effective method to optimize its acquisition function, a challenging problem for mixed-variable domains, making MiVaBo the first BO method that can handle complex constraints over the discrete variables. Moreover, we provide the first convergence analysis of a mixed-variable BO algorithm. Finally, we show that MiVaBo is significantly more sample efficient than state-of-the-art mixed-variable BO algorithms on several hyperparameter tuning tasks, including the tuning of deep generative models.},
  doi       = {10.24963/ijcai.2020/365},
  file      = {:FILES/2020 - Daxberger2020 - Mixed-variable {Bayesian} optimization.pdf:PDF},
  groups    = {MIP},
  keywords  = {Machine Learning: Bayesian OptimizationMachine Learning: Active LearningMachine Learning: Probabilistic Machine Learning},
  url       = {https://doi.org/10.24963/ijcai.2020/365},
}

@Article{Oliveira2016,
  author   = {de Oliveira, Welington},
  journal  = {TOP},
  title    = {Regularized optimization methods for convex {MINLP} problems},
  year     = {2016},
  issn     = {1863-8279},
  number   = {3},
  pages    = {665--692},
  volume   = {24},
  abstract = {We propose regularized cutting-plane methods for solving mixed-integer nonlinear programming problems with nonsmooth convex objective and constraint functions. The given methods iteratively search for trial points in certain localizer sets, constructed by employing linearizations of the involved functions. New trial points can be chosen in several ways; for instance, by minimizing a regularized cutting-plane model if functions are costly. When dealing with hard-to-evaluate functions, the goal is to solve the optimization problem by performing as few function evaluations as possible. Numerical experiments comparing the proposed algorithms with classical methods in this area show the effectiveness of our approach.},
  doi      = {10.1007/s11750-016-0413-4},
  file     = {:FILES/2016 - Oliveira2016 - Regularized optimization methods for convex MINLP problems.pdf:PDF},
  groups   = {MINLP},
  refid    = {de Oliveira2016},
  url      = {https://doi.org/10.1007/s11750-016-0413-4},
}

@Article{Wang2020b,
  author    = {Wang, Haoran and Zhou, Xun Yu},
  journal   = {Mathematical Finance},
  title     = {Continuous-time mean–variance portfolio selection: {A} reinforcement learning framework},
  year      = {2020},
  month     = may,
  pages     = {1--36},
  abstract  = {Abstract We approach the continuous-time mean–variance portfolio selection with reinforcement learning (RL). The problem is to achieve the best trade-off between exploration and exploitation, and is formulated as an entropy-regularized, relaxed stochastic control problem. We prove that the optimal feedback policy for this problem must be Gaussian, with time-decaying variance. We then prove a policy improvement theorem, based on which we devise an implementable RL algorithm. We find that our algorithm and its variant outperform both traditional and deep neural network based algorithms in our simulation and empirical studies.},
  doi       = {10.1111/mafi.12281},
  eprint    = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/mafi.12281},
  file      = {:FILES/2020 - Wang2020b - Continuous‐time mean–variance portfolio selection- A reinforcement learning framework.pdf:PDF},
  groups    = {mean variance},
  keywords  = {empirical study, entropy regularization, Gaussian distribution, mean–variance portfolio selection, policy improvement, reinforcement learning, simulation, stochastic control, theorem, value function},
  timestamp = {2020-09-04},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1111/mafi.12281},
}

@InProceedings{Lin2020a,
  author    = {Lin, Jeng-Wei and Liao, Shih-wei and Leu, Fang-Yie},
  booktitle = {Advances in Intelligent Networking and Collaborative Systems},
  title     = {A novel bounded-error piecewise linear approximation algorithm for streaming sensor data in edge computing},
  year      = {2020},
  address   = {Cham},
  editor    = {Barolli, Leonard and Nishino, Hiroaki and Miwa, Hiroyoshi},
  pages     = {123--132},
  publisher = {Springer International Publishing},
  abstract  = {Many studies show that many Data compression schemes, like Bounded-Error Piecewise Linear Approximation (BEPLA) methods, have been proposed to lower the length sensor data, aiming to mitigating data transmission energies. When an error bound is given, these data compression schemes consider how to represent original sensor data by using fewer line segments. In this paper, besides BEPLA, we further deal with resolution reduction, which called Swing-RR (Resolution Reduction) sets a new restriction on the position of line segment endpoints. Our simulating results on existing datasets indicate that the length of compressed data is actually lowered.},
  file      = {:FILES/2020 - Lin2020a - A Novel Bounded-Error Piecewise Linear Approximation Algorithm for Streaming Sensor Data in Edge Computing.pdf:PDF},
  groups    = {Approximation},
  isbn      = {978-3-030-29035-1},
}

@TechReport{Kosaki2010,
  author      = {Kosaki, Toshihiro},
  institution = {Tokyo Institute of Technology},
  title       = {An interior-point method for minimizing the sum of piecewise-linear convex functions},
  year        = {2010},
  address     = {2-12-1 Oh-Okayama, Meguro-ku, Tokyo, Japan},
  month       = feb,
  type        = {techreport},
  abstract    = {We consider the problem to minimize the sum of piecewise-linear convex functions under both linear and nonnegative constraints. We convert the piecewise-linear convex problem into a standard form linear programming problem (LP) and apply a primal-dual interior-point method for the LP. From the solution of the converted problem, we can obtain the solution of the original problem. We establish polynomial convergence of the interior-point method for the converted problem and devise the computaion of the Newton direction.},
  file        = {:FILES/2010 - Kosaki2010 - An interior-point method for minimizing the sum of piecewise-linear convex functions.pdf:PDF},
  groups      = {optimization},
}

@Article{Bao2019,
  author   = {Bao, Y. and Wu, M. and Zhou, X. and Tang, X.},
  journal  = {IEEE Access},
  title    = {Piecewise linear approximation of gas flow function for the optimization of integrated electricity and natural gas system},
  year     = {2019},
  issn     = {2169-3536},
  pages    = {91819--91826},
  volume   = {7},
  abstract = {The development of integrated electricity and natural-gas energy system (IEGS) aims at improving the energy efficiency and realizing complementarity between different energy sources. However, co-optimization of the IEGS suffers from non-convex and nonlinear Weymouth equation. Focusing on the piecewise linear approximation methods of the IEGS, this paper compares with the formation, the computational speed, and accuracy of the existing piecewise linear approximation methods, and proposes a modification method that achieves both fast-processing and high-accuracy. The numeral testing results verify the effectiveness of the proposed method.},
  doi      = {10.1109/ACCESS.2019.2927103},
  file     = {:FILES/2019 - Bao2019 - Piecewise Linear Approximation of Gas Flow Function for the Optimization of Integrated Electricity and Natural Gas System.pdf:PDF},
  groups   = {Approximation},
  keywords = {approximation theory;gas industry;mathematical analysis;natural gas technology;piecewise linear techniques;modification method;gas flow function;integrated electricity;natural-gas energy system;IEGS;energy efficiency;complementarity;energy sources;piecewise linear approximation;computational speed;nonconvex nonlinear Weymouth equation;Manganese;Piecewise linear approximation;Optimization;Mathematical model;Fluid flow;Natural gas;Power systems;Integrated electricity and natural-gas energy system;piecewise linear approximation;co-optimization},
}

@Article{Wang2019,
  author   = {Wang, Weina and Wu, Chunlin and Deng, Jiansong},
  journal  = {Inverse Problems \& Imaging},
  title    = {Piecewise constant signal and image denoising using a selective averaging method with multiple neighbors},
  year     = {2019},
  issn     = {1930-8337},
  month    = oct,
  number   = {15},
  pages    = {903--930},
  volume   = {13},
  abstract = {Piecewise constant signals and images are an important kind of data. Typical examples include bar code signals, logos, cartoons, QR codes (Quick Response codes), and text images, which are widely used in both general commercial and automotive industry use. One previous work called a general selective averaging method (GSAM) was introduced to remove noise from them. It chooses homogeneous neighbors from the two closest pixels (one pixel at each side) to update the current pixel. One limitation is that it suffered from appearing sparse noisy pixels in the denoised result when the noise level is high. In this paper, we try to solve this problem by proposing a selective averaging method with multiple neighbors. To update the intensity value at each pixel, the proposed algorithm averages more homogeneous neighbors selected from a large domain, which is based on the property of the local geometry of signals and images. This greatly reduces sparse noisy pixels left in the final result by GSAM. Similarly, our method adopts the Neumann boundary condition at edges, and thus preserves edges well. In 1D case, some theoretical results are given to guarantee the convergence of our algorithm. In 2D case, except eliminating additive Gaussian noise, this algorithm can be used for restoring noisy images corrupted by speckle noise. Intensive experiments on both gray and color image denoising demonstrate that the proposed method is quite effective for piecewise constant image denoising and achieves superior performance visually and quantitatively.},
  doi      = {10.3934/ipi.2019041},
  file     = {:FILES/2019 - Wang2019 - Piecewise constant signal and image denoising using a selective averaging method with multiple neighbors.pdf:PDF},
  groups   = {interesting articles},
  keywords = {"Selective averaging","multiple neighbors","piecewise constant","additive Gaussian noise","speckle noise"},
  url      = {http://aimsciences.org//article/id/bf4e7fbf-1ce6-47d6-8e3f-9f3236cdfaf4},
}

@InProceedings{Sharma2020,
  author    = {Sharma, Dravyansh and Balcan, Maria-Florina and Dick, Travis},
  booktitle = {Proceedings of Machine Learning Research},
  title     = {Learning piecewise {Lipschitz} functions in changing environments},
  year      = {2020},
  address   = {Online},
  editor    = {Chiappa, Silvia and Calandra, Roberto},
  month     = {8},
  pages     = {3567--3577},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {108},
  abstract  = {Optimization in the presence of sharp (non-Lipschitz), unpredictable (w.r.t. time and amount) changes is a challenging and largely unexplored problem of great significance. We consider the class of piecewise Lipschitz functions, which is the most general online setting considered in the literature for the problem, and arises naturally in various combinatorial algorithm selection problems where utility functions can have sharp discontinuities. The usual performance metric of ‘static’ regret minimizes the gap between the payoff accumulated and that of the best fixed point for the entire duration, and thus fails to capture changing environments. Shifting regret is a useful alternative, which allows for up to $s$ environment {\it shifts}. In this work we provide an $O(\sqrt{sdT\log T}+sT^{1-\beta})$ regret bound for $\beta$-dispersed functions, where $\beta$ roughly quantifies the rate at which discontinuities appear in the utility functions in expectation (typically $\beta\ge1/2$ in problems of practical interest \cite{2019arXiv190409014B,balcan2018dispersion}). We also present a lower bound tight up to sub-logarithmic factors. We further obtain improved bounds when selecting from a small pool of experts. We empirically demonstrate a key application of our algorithms to online clustering problems on popular benchmarks.},
  file      = {:FILES/2020 - Sharma2020 - Learning piecewise Lipschitz functions in changing environments.pdf:PDF},
  groups    = {interesting articles},
  pdf       = {http://proceedings.mlr.press/v108/sharma20a/sharma20a.pdf},
  url       = {http://proceedings.mlr.press/v108/sharma20a.html},
}

@Misc{Laurent2019,
  author        = {Laurent, Michel and Nogueira, Arnaldo},
  title         = {Dynamics of 2-interval piecewise affine maps and hecke-mahler series},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1907.08655},
  file          = {:FILES/2019 - Laurent2019 - Dynamics of 2-interval piecewise affine maps and Hecke-Mahler series.pdf:PDF},
  groups        = {interesting articles},
  primaryclass  = {math.DS},
}

@Article{Chen2020,
  author   = {Chen, Hebai and Tang, Yilei},
  journal  = {Physica D: Nonlinear Phenomena},
  title    = {A proof of {Euz\'{e}bio–Pazim–Ponce’s} conjectures for a degenerate planar piecewise linear differential system with three zones},
  year     = {2020},
  issn     = {0167-2789},
  pages    = {132150},
  volume   = {401},
  abstract = {In this paper we study bifurcations and dynamics in a planar piecewise linear differential system with three zones ẋ=F(x)−y,ẏ=g(x)−α. When the system is degenerate in the central zone, i.e., g′(x)=0 in the central zone, and F(x) is a flute linear function, Euzébio, Pazim and Ponce in Euzébio et al. (2016) proposed three conjectures on limit cycles. The aim of this paper is to prove Euzébio–Pazim–Ponce’s conjectures so that the number and the bifurcation of limit cycles of the degenerate planar piecewise linear differential system with three zones, i.e., under the same assumptions as in Euzébio et al. (2016), are studied completely. Finally, the bifurcation diagrams and the phase portraits of this planar piecewise linear differential system are given completely, including scabbard bifurcation, grazing bifurcation and double limit cycle bifurcation.},
  doi      = {https://doi.org/10.1016/j.physd.2019.132150},
  file     = {:FILES/2020 - Chen2020 - A proof of Euzébio–Pazim–Ponce’s conjectures for a degenerate planar piecewise linear differential system with three zones.pdf:PDF},
  groups   = {application},
  keywords = {Liénard system, Piecewise linear system, Limit cycle, Bifurcation, Rotation},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167278918306237},
}

@Article{Wei2019,
  author   = {Wei, Yanling and Qiu, Jianbin and Karimi, Hamid Reza},
  journal  = {Automatica},
  title    = {A novel approach to sampled-data filter design for piecewise-affine systems},
  year     = {2019},
  issn     = {0005-1098},
  pages    = {108481},
  volume   = {109},
  abstract = {This paper is concerned with the problem of sampled-data piecewise-affine (PWA) filter design of PWA systems via continuous piecewise Lyapunov functionals. Especially, an input delay scheme is initially introduced to characterize the sample-and-hold behavior with a time-varying delayed measurement output. Then, an improved ℋ∞ performance analysis criterion is presented for the filtering error systems, which is achieved by constructing a novel continuous piecewise Lyapunov–Krasovskii functional and an extended integral inequality. Furthermore, with a linearization procedure, the full-order and reduced-order PWA filter synthesis is developed in a unified framework. Simulation studies are conducted to demonstrate the efficacy and less conservativeness of the proposed approach.},
  doi      = {https://doi.org/10.1016/j.automatica.2019.06.033},
  file     = {:FILES/2019 - Wei2019 - A novel approach to sampled-data filter design for piecewise-affine systems.pdf:PDF},
  groups   = {application},
  keywords = {Piecewise-affine systems, Sampled-data filter, Time-varying delay, Extended integral inequality},
  url      = {http://www.sciencedirect.com/science/article/pii/S0005109819303292},
}

@Article{Denis2020,
  author    = {Denis, C. and Lebarbier, E. and L\'{e}vy‐Leduc, C. and Martin, O. and Sansonnet, L.},
  journal   = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  title     = {A novel regularized approach for functional data clustering: {An} application to milking kinetics in dairy goats},
  year      = {2020},
  issn      = {1467-9876},
  month     = {3},
  number    = {3},
  pages     = {623--640},
  volume    = {69},
  doi       = {10.1111/rssc.12404},
  file      = {:FILES/2020 - Denis2020 - A novel regularized approach for functional data clustering An application to milking kinetics in dairy goats.pdf:PDF},
  groups    = {Approximation},
  publisher = {Wiley},
  url       = {http://dx.doi.org/10.1111/rssc.12404},
}

@Misc{Luo2019,
  author        = {Luo, Fengqiao and Mehrotra, Sanjay},
  title         = {A geometric branch and bound method for a class of robust maximization problems of convex functions},
  year          = {2019},
  abstract      = {We investigate robust optimization problems defined for maximizing convex functions. For finite uncertainty set, we develop a geometric branch-and-bound algorithmic approach to solve this problem. The geometric branch-and-bound algorithm performs sequential piecewise-linear approximations of the convex objective, and solves linear programs to determine lower and upper bounds of nodes specified by the active linear pieces. Finite convergence of the algorithm to an ϵ−optimal solution is proved. Numerical results are used to discuss the performance of the developed algorithm. The algorithm developed in this paper can be used as an oracle in the cutting surface method for solving robust optimization problems with compact ambiguity sets.},
  archiveprefix = {arXiv},
  eprint        = {1911.08719},
  file          = {:FILES/2019 - Luo2019 - A Geometric Branch and Bound Method for a Class of Robust Maximization Problems of Convex Functions.pdf:PDF},
  groups        = {concave},
  primaryclass  = {math.OC},
}

@Article{Dolgopolik2019,
  author    = {Dolgopolik, M. V.},
  journal   = {Optimization Methods and Software},
  title     = {The method of codifferential descent for convex and global piecewise affine optimization},
  year      = {2019},
  number    = {0},
  pages     = {1--32},
  volume    = {0},
  abstract  = {The class of nonsmooth codifferentiable functions was introduced by professor V.F. Demyanov in the late 1980s. He also proposed a method for minimizing these functions called the method of codifferential descent (MCD). However, until now almost no theoretical results on the performance of this method on particular classes of nonsmooth optimization problems were known. In the first part of the paper, we study the performance of the method of codifferential descent on a class of nonsmooth convex functions satisfying some regularity assumptions, which in the smooth case are reduced to the Lipschitz continuity of the gradient. We prove that in this case the MCD has the iteration complexity bound O(1/ε). In the second part of the paper we obtain new global optimality conditions for piecewise affine functions in terms of codifferentials. With the use of these conditions we propose a modification of the MCD for minimizing piecewise affine functions (called the method of global codifferential descent) that does not use line search, and discards those ‘pieces’ of the objective functions that are no longer useful for the optimization process. Then we prove that the MCD as well as its modification proposed in the article find a point of global minimum of a nonconvex piecewise affine function in a finite number of steps.},
  doi       = {10.1080/10556788.2019.1571590},
  eprint    = {https://doi.org/10.1080/10556788.2019.1571590},
  file      = {:FILES/2019 - Dolgopolik2019 - The method of codifferential descent for convex and global piecewise affine optimization.pdf:PDF},
  groups    = {optimization},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/10556788.2019.1571590},
}

@InBook{Capodaglio2020,
  author    = {Capodaglio, Giacomo and Gunzburger, Max},
  editor    = {D\'Elia, Marta and Gunzburger, Max and Rozza, Gianluigi},
  pages     = {101--127},
  publisher = {Springer International Publishing},
  title     = {Piecewise polynomial approximation of probability density functions with application to uncertainty quantification for stochastic {PDEs}},
  year      = {2020},
  address   = {Cham},
  isbn      = {978-3-030-48721-8},
  abstract  = {The probability density function (PDF) associated with a given set of samples is approximated by a piecewise-linear polynomial constructed with respect to a binning of the sample space. The kernel functions are a compactly supported basis for the space of such polynomials, i.e. finite element hat functions, that are centered at the bin nodes rather than at the samples, as is the case for the standard kernel density estimation approach. This feature naturally provides an approximation that is scalable with respect to the sample size. On the other hand, unlike other strategies that use a finite element approach, the proposed approximation does not require the solution of a linear system. In addition, a simple rule that relates the bin size to the sample size eliminates the need for bandwidth selection procedures. The proposed density estimator has unitary integral, does not require a constraint to enforce positivity, and is consistent. The proposed approach is validated through numerical examples in which samples are drawn from known PDFs. The approach is also used to determine approximations of (unknown) PDFs associated with outputs of interest that depend on the solution of a stochastic partial differential equation.},
  booktitle = {Quantification of Uncertainty: Improving Efficiency and Technology: QUIET selected contributions},
  doi       = {10.1007/978-3-030-48721-8_5},
  file      = {:FILES/2020 - Capodaglio2020 - Piecewise polynomial approximation of probability density functions with application to uncertainty quantification for stochastic pdes.pdf:PDF},
  groups    = {Approximation},
  url       = {https://doi.org/10.1007/978-3-030-48721-8_5},
}

@Article{Miao2019,
  author   = {Miao, Qing and Ling, Bingo Wing-Kuen and Wang, Xiaoling},
  journal  = {Digital Signal Processing},
  title    = {Piecewise linear relationship between {$L_1$} norm objective functional values and {$L_\infty$} norm constraint specifications},
  year     = {2019},
  issn     = {1051-2004},
  pages    = {234--240},
  volume   = {92},
  abstract = {For a sparse optimization problem with an L1 norm objective function subject to an L∞ norm inequality constraint, this paper finds that there is a piecewise linear relationship between the L1 norm objective functional values and the L∞ norm constraint specifications. This piecewise linear relationship is proved mathematically. Also, computer numerical simulations on a set of signal vectors verify the validity of this result. This result can provide a guidance for system analysts to define the specification on the L∞ norm specification.},
  doi      = {https://doi.org/10.1016/j.dsp.2019.06.012},
  file     = {:FILES/2019 - Miao2019 - Piecewise linear relationship between L1 norm objective functional values and L∞ norm constraint specifications.pdf:PDF},
  groups   = {optimization},
  keywords = {-minimization, -norm constraint, Piecewise linear function, Sparse optimization},
  url      = {http://www.sciencedirect.com/science/article/pii/S105120041930082X},
}

@Article{Martinez2015,
  author   = {Martinez, Diana L. and Shih, Dachuan T. and Chen, Victoria C. P. and Kim, Seoung Bum},
  journal  = {Computational Statistics \& Data Analysis},
  title    = {A convex version of multivariate adaptive regression splines},
  year     = {2015},
  issn     = {0167-9473},
  pages    = {89--106},
  volume   = {81},
  abstract = {Multivariate adaptive regression splines (MARS) provide a flexible statistical modeling method that employs forward and backward search algorithms to identify the combination of basis functions that best fits the data and simultaneously conduct variable selection. In optimization, MARS has been used successfully to estimate the unknown functions in stochastic dynamic programming (SDP), stochastic programming, and a Markov decision process, and MARS could be potentially useful in many real world optimization problems where objective (or other) functions need to be estimated from data, such as in surrogate optimization. Many optimization methods depend on convexity, but a non-convex MARS approximation is inherently possible because interaction terms are products of univariate terms. In this paper a convex MARS modeling algorithm is described. In order to ensure MARS convexity, two major modifications are made: (1) coefficients are constrained, such that pairs of basis functions are guaranteed to jointly form convex functions and (2) the form of interaction terms is altered to eliminate the inherent non-convexity. Finally, MARS convexity can be achieved by the fact that the sum of convex functions is convex. Convex-MARS is applied to inventory forecasting SDP problems with four and nine dimensions and to an air quality ground-level ozone problem.},
  doi      = {https://doi.org/10.1016/j.csda.2014.07.015},
  file     = {:FILES/2015 - Martinez2015 - A convex version of multivariate adaptive regression.pdf:PDF},
  groups   = {identification},
  keywords = {Regression splines, Convexity},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167947314002291},
}

@Article{Stevek2012,
  author  = {Stevek, Juraj and Szucs, Alexander and Kvasnica, Michal and Fikar, Miroslav and Koz\'{a}k, Stefan},
  journal = {Archives of Control Sciences},
  title   = {Two steps piecewise affine identification of nonlinear systems},
  year    = {2012},
  issn    = {1230-2384},
  number  = {4},
  pages   = {371--388},
  volume  = {22},
  doi     = {https://doi.org/10.2478/v10170-011-0029-8},
  file    = {:FILES/2012 - Stevek2012 - Two steps piecewise affine identification of nonlinear systems.pdf:PDF},
  groups  = {identification},
}

@Article{Sridhar2013,
  author   = {Sridhar, Srikrishna and Linderoth, Jeff and Luedtke, James},
  journal  = {Operations Research Letters},
  title    = {Locally ideal formulations for piecewise linear functions with indicator variables},
  year     = {2013},
  issn     = {0167-6377},
  number   = {6},
  pages    = {627--632},
  volume   = {41},
  abstract = {In this paper, we consider mixed integer linear programming (MIP) formulations for piecewise linear functions (PLFs) that are evaluated when an indicator variable is turned on. We describe modifications to standard MIP formulations for PLFs with desirable theoretical properties and superior computational performance in this context.},
  doi      = {https://doi.org/10.1016/j.orl.2013.08.010},
  file     = {:FILES/2013 - Sridhar2013 - Locally ideal formulations for piecewise linear functions with indicator variables.pdf:PDF},
  groups   = {identification},
  keywords = {Piecewise linear function, Mixed-integer programming, Indicator variables},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167637713001211},
}

@Article{Belotti2009,
  author    = {Belotti, Pietro and Lee, Jon and Liberti, Leo and Margot, Fran\c{c}ois and W\"{a}chter, Andreas},
  journal   = {Optimization Methods and Software},
  title     = {Branching and bounds tighteningtechniques for non-convex {MINLP}},
  year      = {2009},
  number    = {4-5},
  pages     = {597--634},
  volume    = {24},
  abstract  = {Many industrial problems can be naturally formulated using mixed integer non-linear programming (MINLP) models and can be solved by spatial Branch\&Bound (sBB) techniques. We study the impact of two important parts of sBB methods: bounds tightening (BT) and branching strategies. We extend a branching technique originally developed for MILP, reliability branching, to the MINLP case. Motivated by the demand for open-source solvers for real-world MINLP problems, we have developed an sBB software package named couenne (Convex Over- and Under-ENvelopes for Non-linear Estimation) and used it for extensive tests on several combinations of BT and branching techniques on a set of publicly available and real-world MINLP instances. We also compare the performance of couenne with a state-of-the-art MINLP solver.},
  doi       = {10.1080/10556780903087124},
  eprint    = {https://doi.org/10.1080/10556780903087124},
  file      = {:FILES/2009 - Belotti2009 - Branching and bounds tightening techniques for non-convex MINLP.pdf:PDF},
  groups    = {MINLP},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/10556780903087124},
}

@Article{Wen2008,
  author   = {Wen, Chengtao and Ma, Xiaoyan},
  journal  = {IEEE Transactions on Circuits and Systems I: Regular Papers},
  title    = {A basis-function canonical piecewise-linear approximation},
  year     = {2008},
  issn     = {1558-0806},
  month    = {6},
  number   = {5},
  pages    = {1328--1334},
  volume   = {55},
  abstract = {This paper proposes a basis-function canonical piecewise-linear (BF-CPWL) function, which can approximate any continuous function using a weighted sum of PWL BFs. The BF-CPWL approximation integrates Breiman's hinging hyperplane model and Julian's high-level canonical PWL approximation into a common theoretical framework. Moreover, an approximation algorithm is developed, which fits and adds the PWL BFs iteratively using a modified Gauss-Newton method. This algorithm guarantees a local convergence, while achieving a good tradeoff between computational simplicity and approximation accuracy. The BF-CPWL approximation can find applications in nonlinear circuit synthesis, dynamic system identification and control.},
  doi      = {10.1109/TCSI.2008.916552},
  file     = {:FILES/2008 - Wen2008 - A Basis-Function Canonical Piecewise-Linear Approximation.pdf:PDF},
  groups   = {Approximation},
  keywords = {convergence of numerical methods;function approximation;piecewise linear techniques;basis-function canonical piecewise-linear approximation;continuous function approximation;hyperplane model;high-level canonical PWL approximation;modified Gauss-Newton method;local convergence;computational simplicity;Piecewise linear techniques;Approximation algorithms;Iterative algorithms;Control system synthesis;Newton method;Least squares methods;Recursive estimation;Convergence;Nonlinear circuits;Circuit synthesis;Canonical piecewise-linear representation (CPWL);nonlinear approximation;nonlinear circuit synthesis;PWL basis function (BF);Nonlinear approximation;Canonical Piecewise-linear representation;PWL basis function;nonlinear circuit synthesis},
}

@Article{Daubechies2004,
  author   = {Daubechies, I. and Defrise, M. and De Mol, C.},
  journal  = {Communications on Pure and Applied Mathematics},
  title    = {An iterative thresholding algorithm for linear inverse problems with a sparsity constraint},
  year     = {2004},
  number   = {11},
  pages    = {1413--1457},
  volume   = {57},
  abstract = {Abstract We consider linear inverse problems where the solution is assumed to have a sparse expansion on an arbitrary preassigned orthonormal basis. We prove that replacing the usual quadratic regularizing penalties by weighted 𝓁p-penalties on the coefficients of such expansions, with 1 ≤ p ≤ 2, still regularizes the problem. Use of such 𝓁p-penalized problems with p < 2 is often advocated when one expects the underlying ideal noiseless solution to have a sparse expansion with respect to the basis under consideration. To compute the corresponding regularized solutions, we analyze an iterative algorithm that amounts to a Landweber iteration with thresholding (or nonlinear shrinkage) applied at each iteration step. We prove that this algorithm converges in norm. © 2004 Wiley Periodicals, Inc.},
  doi      = {10.1002/cpa.20042},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpa.20042},
  file     = {:FILES/2004 - Daubechies2004 - An iterative thresholding algorithm for linear inverse problems with a sparsity constraint.pdf:PDF},
  groups   = {interesting articles},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.20042},
}

@Article{Allgower2000,
  author   = {Allgower, Eugene L. and Georg, Kurt},
  journal  = {Journal of Computational and Applied Mathematics},
  title    = {Piecewise linear methods for nonlinear equations and optimization},
  year     = {2000},
  issn     = {0377-0427},
  note     = {Numerical Analysis 2000. Vol. IV: Optimization and Nonlinear Equations},
  number   = {1},
  pages    = {245--261},
  volume   = {124},
  abstract = {Piecewise linear methods had their beginning in the mid-1960s with Lemke's algorithm for calculating solutions to linear complementarity problems. In the 1970s and 1980s activity moved on to computing fixed points of rather general maps and economic equilibria. More recently, they have been used to approximate implicitly defined manifolds, with applications being made to computer graphics and approximations of integral over implicitly defined manifolds. In this paper we present the basic ideas of piecewise linear algorithms and a selection of applications. Further references to the literature on piecewise linear algorithms are indicated.},
  doi      = {https://doi.org/10.1016/S0377-0427(00)00427-1},
  file     = {:FILES/2000 - Allgower2000 - Piecewise linear methods for nonlinear equations and optimization.pdf:PDF},
  url      = {http://www.sciencedirect.com/science/article/pii/S0377042700004271},
}

@Article{Chambolle1998,
  author   = {Chambolle, A. and De Vore, R. A. and Lee, Nam-Yong and Lucier, B. J.},
  journal  = {IEEE Transactions on Image Processing},
  title    = {Nonlinear wavelet image processing: {Variational} problems, compression, and noise removal through wavelet shrinkage},
  year     = {1998},
  issn     = {1941-0042},
  month    = {3},
  number   = {3},
  pages    = {319--335},
  volume   = {7},
  abstract = {This paper examines the relationship between wavelet-based image processing algorithms and variational problems. Algorithms are derived as exact or approximate minimizers of variational problems; in particular, we show that wavelet shrinkage can be considered the exact minimizer of the following problem. Given an image F defined on a square I, minimize over all g in the Besov space B11(L1(I)) the functional |F-g|L2(I)2+λ|g|(B11(L1(I))). We use the theory of nonlinear wavelet image compression in L2(I) to derive accurate error bounds for noise removal through wavelet shrinkage applied to images corrupted with i.i.d., mean zero, Gaussian noise. A new signal-to-noise ratio (SNR), which we claim more accurately reflects the visual perception of noise in images, arises in this derivation. We present extensive computations that support the hypothesis that near-optimal shrinkage parameters can be derived if one knows (or can estimate) only two parameters about an image F: the largest α for which F∈Bqα(Lq(I)),1/q=α/2+1/2, and the norm |F|Bqα(Lq(I)). Both theoretical and experimental results indicate that our choice of shrinkage parameters yields uniformly better results than Donoho and Johnstone's VisuShrink procedure; an example suggests, however, that Donoho and Johnstone's (1994, 1995, 1996) SureShrink method, which uses a different shrinkage parameter for each dyadic level, achieves a lower error than our procedure.},
  doi      = {10.1109/83.661182},
  file     = {:FILES/1998 - Chambolle1998 - Nonlinear wavelet image processing - variational problems, compression, and noise removal through wavelet shrinkage.pdf:PDF},
  groups   = {interesting articles},
  keywords = {data compression;Gaussian noise;image coding;image representation;minimisation;parameter estimation;transform coding;wavelet transforms;nonlinear wavelet image processing;variational problems;image compression;noise removal;wavelet shrinkage;wavelet based image processing algorithms;approximate minimizers;exact minimizers;accurate error bounds;Gaussian noise;mean zero noise;i.i.d. noise;signal-to-noise ratio;SNR;visual perception;near-optimal shrinkage parameters;parameter estimation;experimental results;shrinkage parameters;SureShrink method;dyadic level;coding error;wavelet representation;Image processing;Image coding;Image segmentation;Signal to noise ratio;Gaussian noise;Mathematics;Visual perception;Parameter estimation;Yield estimation;Contracts},
}

@Article{Tarela1990,
  author   = {Tarela, J. M. and Alonso, E. and Mart\'{i}nez, M. V.},
  journal  = {Mathematical and Computer Modelling},
  title    = {A representation method for {PWL} functions oriented to parallel processing},
  year     = {1990},
  issn     = {0895-7177},
  number   = {10},
  pages    = {75--83},
  volume   = {13},
  abstract = {PWL functions are represented by an algebra that facilitates their treatment in many practical problems. One of the characteristics of the resulting analytical model is that the representation of the data flow proves particularly suitable for parallel processing. The present work shows that the number of computation cells is lower than the number of hyperplanes of the function. Also the analytical expression does not require any information about the regions into which the function domain is divided. These two facts confer the offered method great usefulness within the context of neural computation.},
  doi      = {https://doi.org/10.1016/0895-7177(90)90090-A},
  file     = {:FILES/1990 - Tarela1990 - A representation method for PWL functions oriented to parallel processing.pdf:PDF},
  groups   = {identification},
  url      = {http://www.sciencedirect.com/science/article/pii/089571779090090A},
}

@InBook{Planiden2019,
  author    = {Planiden, C. and Wang, X.},
  editor    = {Hosseini, Seyedehsomayeh and Mordukhovich, Boris S. and Uschmajew, Andr\'{e}},
  pages     = {89--130},
  publisher = {Springer International Publishing},
  title     = {Proximal mappings and moreau envelopes of single-variable convex piecewise cubic functions and multivariable gauge functions},
  year      = {2019},
  address   = {Cham},
  isbn      = {978-3-030-11370-4},
  abstract  = {This work presents a collection of useful properties of the Moreau envelope for finite-dimensional, proper, lower semicontinuous, convex functions. In particular, gauge functions and piecewise cubic functions are investigated and their Moreau envelopes categorized. Characterizations of convex Moreau envelopes are established; topics include strict convexity, strong convexity, and Lipschitz continuity.},
  booktitle = {Nonsmooth Optimization and Its Applications},
  doi       = {10.1007/978-3-030-11370-4_5},
  file      = {:FILES/2019 - Planiden2019 - Proximal Mappings and Moreau Envelopes of Single-Variable Convex Piecewise Cubic Functions and Multivariable Gauge Functions.pdf:PDF},
  groups    = {optimization},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1007/978-3-030-11370-4_5},
}

@Article{Toriello2010,
  author   = {Toriello, Alejandro and Nemhauser, George and Savelsbergh, Martin},
  journal  = {Naval Research Logistics (NRL)},
  title    = {Decomposing inventory routing problems with approximate value functions},
  year     = {2010},
  number   = {8},
  pages    = {718--727},
  volume   = {57},
  abstract = {Abstract We present a time decomposition for inventory routing problems. The methodology is based on valuing inventory with a concave piecewise linear function and then combining solutions to single-period subproblems using dynamic programming techniques. Computational experiments show that the resulting value function accurately captures the inventory's value, and solving the multiperiod problem as a sequence of single-period subproblems drastically decreases computational time without sacrificing solution quality. © 2010 Wiley Periodicals, Inc. Naval Research Logistics, 2010},
  doi      = {10.1002/nav.20433},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/nav.20433},
  file     = {:FILES/2010 - Toriello2010 - Decomposing inventory routing problems with approximate value functions.pdf:PDF},
  groups   = {application},
  keywords = {inventory routing, mixed-integer program, approximate dynamic program},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nav.20433},
}

@Misc{Kaveh2019,
  author        = {Kaveh, Kiumars and Manon, Christopher},
  title         = {Toric bundles, valuations, and tropical geometry over semifield of piecewise linear functions},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1907.00543},
  file          = {:FILES/2019 - Kaveh2019 - Toric bundles, valuations, and tropical geometry over semifield of piecewise linear functions.pdf:PDF},
  groups        = {identification},
  primaryclass  = {math.AG},
}

@Article{Manwani2015,
  author   = {Manwani, Naresh and Sastry, P. S.},
  journal  = {Information Sciences},
  title    = {K-plane regression},
  year     = {2015},
  issn     = {0020-0255},
  pages    = {39--56},
  volume   = {292},
  abstract = {In this paper, we present a novel algorithm for piecewise linear regression which can learn continuous as well as discontinuous piecewise linear functions. The main idea is to repeatedly partition the data and learn a linear model in each partition. The proposed algorithm is similar in spirit to k-means clustering algorithm. We show that our algorithm can also be viewed as a special case of an EM algorithm for maximum likelihood estimation under a reasonable probability model. We empirically demonstrate the effectiveness of our approach by comparing its performance with that of the state of art algorithms on various datasets.},
  doi      = {https://doi.org/10.1016/j.ins.2014.08.058},
  file     = {:FILES/2015 - Manwani2015 - K-plane regression.pdf:PDF},
  groups   = {machine learning},
  keywords = {Piecewise linear regression, Cluster-wise linear regression, Expectation maximization, Mixture of experts},
  url      = {http://www.sciencedirect.com/science/article/pii/S0020025514008639},
}

@Article{Ovchinnikov2010,
  author   = {Ovchinnikov, Sergei},
  journal  = {European Journal of Combinatorics},
  title    = {Discrete piecewise linear functions},
  year     = {2010},
  issn     = {0195-6698},
  number   = {5},
  pages    = {1283--1294},
  volume   = {31},
  abstract = {The concept of permutograph is introduced and properties of integral functions on permutographs are investigated. The central result characterizes the class of integral functions that are representable as lattice polynomials. This result is used to establish lattice polynomial representations of piecewise linear functions on Rd and continuous selectors on linear orders.},
  doi      = {https://doi.org/10.1016/j.ejc.2009.11.005},
  file     = {:FILES/2010 - Ovchinnikov2010 - Discrete piecewise linear functions.pdf:PDF},
  groups   = {identification},
  url      = {http://www.sciencedirect.com/science/article/pii/S0195669809002261},
}

@InProceedings{Zhu2010,
  author    = {Zhu, Y. and Lu, W. and Gao, X. and Jiang, Y. and Huang, D.},
  booktitle = {IEEE ICCA 2010},
  title     = {Optimization on distillation via piecewise linear approximation},
  year      = {2010},
  month     = {6},
  pages     = {2234--2239},
  abstract  = {Distillation is very important in process industry, and the optimization aiming to energy saving and yield improvement is still important and difficult. Piecewise linear approximation is firstly introduced into traditional Chemical Engineering field. And therefore, a novel surrogate optimization strategy based on piecewise linear approximation for distillation, is developed in this paper. The nonlinear character has been approximated by a surrogate model based on continuous piecewise linear function. Then the original nonlinear optimization has been transformed into piecewise linear programming (PLP). The PLP problem is solved to get the new operating point for the control scheme. Some properties of PLP are discussed and a condition of local optimum is given. An algorithm for PLP is also proposed, with a distillation process model based on adaptive hinging hyperplane. The statistics show that the new strategy is feasible and effective.},
  doi       = {10.1109/ICCA.2010.5524318},
  file      = {:FILES/2010 - Zhu2010 - Optimization on distillation via piecewise linear approximation.pdf:PDF},
  groups    = {application},
  issn      = {1948-3457},
  keywords  = {distillation;linear programming;piecewise linear techniques;piecewise linear approximation;process industry;nonlinear optimization;piecewise linear programming;distillation process;Piecewise linear approximation;Piecewise linear techniques;Automation;Linear programming;Feeds;Automatic control;Energy consumption;Lighting control;Thermal variables control;Power generation economics},
}

@Article{Wei2013,
  author    = {Wei, Yujie and Jiang, Yongheng and Yang, Fan and Huang, Dexian},
  journal   = {Industrial \& Engineering Chemistry Research},
  title     = {Three-stage decomposition modeling for quality of gas-phase polyethylene process based on adaptive hinging hyperplanes and impulse response template},
  year      = {2013},
  issn      = {0888-5885},
  month     = {4},
  number    = {16},
  pages     = {5747--5756},
  volume    = {52},
  abstract  = {It is difficult to establish a dynamic model of quality variables in polymerization, because of the high complexity of the nonlinear process behavior and time-consuming laboratory quality measurements. A decomposition scheme is presented in this paper to model the dynamic nonlinear behaviors of the gas-phase polyethylene process, by decomposing the overall process based on its structure into three relatively simpler problems. However, difficulties still come from nonlinearity and nonuniform sampling. Especially, the samples of the product quality in the transitional process are too deficient for traditional data-driven methods. In order to further overcome the difficulties incurred by nonlinearity, the adaptive hinging hyperplanes (AHH) model is adopted. Meanwhile, an impulse response template (IRT) is introduced to model the accumulation process dynamics to deal with the scarcity of sampled data. The proposed model is validated to be effective in comparison with black-box models on the melt index data of 10 transitional processes.},
  comment   = {doi: 10.1021/ie303370x},
  doi       = {10.1021/ie303370x},
  file      = {:FILES/2013 - Wei2013 - Three-Stage Decomposition Modeling for Quality of Gas-Phase Polyethylene Process Based on Adaptive Hinging Hyperplanes and Impulse Response Template.pdf:PDF},
  groups    = {application},
  publisher = {American Chemical Society},
  url       = {https://doi.org/10.1021/ie303370x},
}

@Misc{Klimek2018,
  author        = {Klimek, Matthew D. and Perelstein, Maxim},
  title         = {Neural network-based approach to phase space integration},
  year          = {2018},
  archiveprefix = {arXiv},
  eprint        = {1810.11509},
  file          = {:FILES/2018 - Klimek2018 - Neural Network-Based Approach to Phase Space integration.pdf:PDF},
  groups        = {Neural Network},
  primaryclass  = {hep-ph},
}

@Article{Hu2019a,
  author   = {Hu, Y. and Wu, X. and Geng, P. and Li, Z.},
  journal  = {IEEE Transactions on Industrial Electronics},
  title    = {Evolution strategies learning with variable impedance control for grasping under uncertainty},
  year     = {2019},
  issn     = {1557-9948},
  month    = {10},
  number   = {10},
  pages    = {7788--7799},
  volume   = {66},
  abstract = {During a robot's interaction with the environment, it is necessary to ensure the safety and robustness of the robot's movements. To improve the safety and adaptiveness of robots in performing complex movement tasks, a novel method called covariance matrix adaptation-evolution strategies (CMA-ES) for learning complex and high-dimensional motor skills is presented. Considering the complex motion model of trajectories, dynamic movement primitives (DMPs), which is a generic method for trajectories modeling in attractor landscape based on differential dynamic systems, is used to represent the robot's trajectories. CMA-ES offers a theoretical rule for updating the parameters of DMPs and a variable impedance controller, which can reduce the impact of noisy environment on the robot's movement. In this paper, we propose two hierarchies for controlling the robot: the high-level neural-dynamic network optimization for redundancy resolution in task space and the low-level CMA-ES fusing with DMPs for learning trajectories in joint space. In this paper, CMA-ES method is explored to learn variable impedance control and the performance of the proposed method in learning the robot's movements is also tested.},
  doi      = {10.1109/TIE.2018.2884240},
  file     = {:FILES/2019 - Hu2019a - Evolution Strategies Learning with Variable Impedance Control for Grasping under Uncertainty.pdf:PDF},
  groups   = {Evolution Strategy},
  keywords = {covariance matrices;evolutionary computation;grippers;learning systems;neurocontrollers;optimisation;variable impedance control;safety;robustness;complex movement tasks;covariance matrix adaptation-evolution strategies;high-dimensional motor skills;complex motion model;trajectories;dynamic movement primitives;generic method;differential dynamic systems;variable impedance controller;noisy environment;high-level neural-dynamic network optimization;low-level CMA-ES;CMA-ES method;DMP;Impedance;Trajectory;Robot kinematics;Adaptation models;Manipulators;Linear programming;Covariance matrix adaptation-evolution strategies;dynamic movement primitives;redundancy resolution;variable impedance control},
}

@Article{Gao2018,
  author    = {Gao, Xiaoyong and Feng, Zhenhui and Wang, Yuhong and Huang, Xiaolin and Huang, Dexian and Chen, Tao and Lian, Xue},
  journal   = {Industrial \& Engineering Chemistry Research},
  title     = {Piecewise linear approximation based {MILP} method for pvc plant planning optimization},
  year      = {2018},
  issn      = {0888-5885},
  month     = {1},
  number    = {4},
  pages     = {1233--1244},
  volume    = {57},
  abstract  = {This paper presents a new piecewise linear modeling method for the planning of polyvinyl chloride (PVC) plants. In our previous study (Ind. Eng. Chem. Res., 2016, 55, 12430−12443, DOI: 10.1021/acs.iecr.6b02825), a multiperiod mixed-integer nonlinear programming (MINLP) model was developed to demonstrate the importance of integrating both the material processing and the utility systems. However, the optimization problem is really difficult to solve due to the process intrinsic nonlinearities, i.e., the operating cost or energy-consuming characteristics of calcium carbide furnaces, electrolytic cells, and CHP units. The present paper intends to address this challenge by using the piecewise linear modeling approach that provides good approximation of the global nonlinearity with locally linear models. Specifically, a hinging hyperplanes (HH) model is introduced to approximate the nonlinear items in the original MINLP model. HH model is a kind of continuous piecewise linear (CPWL) model, which is proven to be effective for any continuous linear functions with arbitrary dimensions on compact sets in any given precision, and is the basis for the linearization MINLP model. As a result, with the help of auxiliary variables, the original MINLP can be transformed into a mixed-integer linear program (MILP) model, which then can be solved by many established efficient and mature algorithms. Computational results show that the proposed model can reduce the solving time by up to 97\% or more and the planning results are close to or even better than those obtained by the MINLP approach.},
  comment   = {doi: 10.1021/acs.iecr.7b02130},
  doi       = {10.1021/acs.iecr.7b02130},
  file      = {:FILES/2018 - Gao2018 - Piecewise Linear Approximation Based MILP Method for PVC Plant Planning Optimization.pdf:PDF},
  groups    = {application},
  publisher = {American Chemical Society},
  url       = {https://doi.org/10.1021/acs.iecr.7b02130},
}

@Article{Hiroyuki2018,
  author  = {Kano, Hiroyuki and Fujioka, Hiroyuki},
  journal = {SICE Journal of Control, Measurement, and System Integration},
  title   = {Spline trajectory planning for road-like path with piecewise linear boundaries allowing double corner points},
  year    = {2018},
  number  = {6},
  pages   = {429--437},
  volume  = {11},
  doi     = {10.9746/jcmsi.11.429},
  file    = {:FILES/2018 - Hiroyuki2018 - Spline Trajectory Planning for Road-Like Path with Piecewise Linear Boundaries Allowing Double Corner Points.pdf:PDF},
  groups  = {application},
}

@Misc{Lefakis2019,
  author        = {Lefakis, Leonidas and Zadorozhnyi, Oleksandr and Blanchard, Gilles},
  title         = {Efficient regularized piecewise-linear regression trees},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1907.00275},
  file          = {:FILES/2019 - Lefakis2019 - Efficient Regularized Piecewise-Linear Regression Trees.pdf:PDF},
  groups        = {identification, machine learning},
  primaryclass  = {cs.LG},
}

@InProceedings{Shi2019,
  author    = {Shi, Yu and Li, Jian and Li, Zhize},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, {IJCAI-19}},
  title     = {Gradient boosting with piece-wise linear regression trees},
  year      = {2019},
  month     = {7},
  pages     = {3432--3438},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  doi       = {10.24963/ijcai.2019/476},
  file      = {:FILES/2019 - Shi2019 - Gradient boosting with piece-wise linear regression trees.pdf:PDF},
  groups    = {identification},
  url       = {https://doi.org/10.24963/ijcai.2019/476},
}

@Article{Goncalves2019,
  author   = {Gon\c{c}alves, T. R. and Gabriel, G. W. and Geromel, J. C.},
  journal  = {IEEE Control Systems Letters},
  title    = {Differential linear matrix inequalities optimization},
  year     = {2019},
  issn     = {2475-1456},
  month    = {4},
  number   = {2},
  pages    = {380--385},
  volume   = {3},
  abstract = {This letter proposes a new method to solve convex programming problems with constraints expressed by differential linear matrix inequalities (DLMIs). Initially, feasible solutions of interest are characterized and a general numerical method, based on the well known outer linearization technique, is proposed and discussed from theoretical and numerical viewpoints. Feasible solutions are written as a truncated series of a given set of time valued continuous functions with symmetric matrix coefficients to be determined. The numerical method encompasses the piecewise linear solution usually adopted in the literature with lower computational burden. In the sequel, several sampled-data control design problems whose optimality conditions can be expressed in this mathematical framework are provided. They are solved in order to put in evidence the most important aspects of the proposed method as well as to evaluate and compare numerical efficiency and limitations. Moreover, it is shown that DLMIs are particularly well adapted to cope with this class of optimal control design problems.},
  comment  = {outer linearization},
  doi      = {10.1109/LCSYS.2018.2884016},
  file     = {:FILES/2018 - Goncalves2019 - Differential Linear Matrix Inequalities Optimization.pdf:PDF},
  groups   = {global optimization},
  keywords = {Symmetric matrices;Linear matrix inequalities;Optimal control;Boundary conditions;Fourier series;Optimization;Differential linear matrix inequalities (DLMI);optimal control;sampled-data control},
}

@Article{Lin2019,
  author   = {Lin, Aijin and Zhang, Xiaoxiao},
  journal  = {Advances in Mathematics},
  title    = {Combinatorial $p$-th {Calabi} flows on surfaces},
  year     = {2019},
  issn     = {0001-8708},
  pages    = {1067--1090},
  volume   = {346},
  abstract = {For triangulated surfaces and any p>1, we introduce the combinatorial p-th Calabi flows which precisely equal the combinatorial Calabi flows first introduced in H. Ge's thesis [9] (or see H. Ge [13]) when p=2. The difficulties for the generalizations come from the nonlinearity of the p-th flow equation when p≠2. Adopting different approaches, we show that the solution to the combinatorial p-th Calabi flow exists for all time and converges if and only if there exists a circle packing metric of constant (zero resp.) curvature in Euclidean (hyperbolic resp.) background geometry. Our results generalize the work of H. Ge [13], Ge–Xu [19] and Ge–Hua [14] on the combinatorial Calabi flow from p=2 to any p>1.},
  doi      = {https://doi.org/10.1016/j.aim.2019.02.011},
  file     = {:FILES/2019 - Lin2019 - Combinatorial p-th Calabi flows on surfaces.pdf:PDF},
  groups   = {interesting articles},
  keywords = {Circle packing, Combinatorial -th Calabi flow, Combinatorial Ricci potential},
  url      = {http://www.sciencedirect.com/science/article/pii/S0001870819301021},
}

@Article{Li2019,
  author   = {Li, P. and Lam, J. and Lu, R. and Kwok, K.},
  journal  = {IEEE Transactions on Automatic Control},
  title    = {Stability and $l_2$ synthesis of a class of periodic piecewise time-varying systems},
  year     = {2019},
  issn     = {1558-2523},
  month    = {8},
  number   = {8},
  pages    = {3378--3384},
  volume   = {64},
  abstract = {In this paper, the stability, stabilization, and L2-gain problems are investigated for periodic piecewise systems with time-varying subsystems. Continuous Lyapunov function with time-varying Lyapunov matrix is adopted. A condition guaranteeing the negative definiteness of a matrix polynomial, deriving from the Lyapunov derivative, is first obtained. Based on such a condition, an exponential stability condition is provided. Moreover, a state-feedback controller with time-varying gain is developed to stabilize the unstable periodic piecewise time-varying system. The L2-gain criterion for periodic piecewise time-varying system is also studied. Numerical examples are given to show the validity of the proposed techniques.},
  doi      = {10.1109/TAC.2018.2880678},
  file     = {:FILES/2019 - Li2019 - Stability and L2 Synthesis of A Class of Periodic Piecewise Time-varying Systems.pdf:PDF},
  groups   = {interesting articles},
  keywords = {asymptotic stability;continuous time systems;control system synthesis;linear systems;Lyapunov methods;state feedback;time-varying systems;stabilization;periodic piecewise systems;time-varying subsystems;time-varying Lyapunov matrix;Lyapunov derivative;exponential stability condition;time-varying gain;unstable periodic piecewise time-varying system;continuous Lyapunov function;L2 synthesis;L2-gain criterion;state-feedback controller;Time-varying systems;Symmetric matrices;Lyapunov methods;Numerical stability;Stability criteria;Control theory;Controller synthesis; $L_2$ performance;periodic systems;stability;time-varying systems},
}

@InBook{Shirley2019,
  author    = {Shirley, Peter and Laine, Samuli and Hart, David and Pharr, Matt and Clarberg, Petrik and Haines, Eric and Raab, Matthias and Cline, David},
  editor    = {Haines, Eric and Akenine-M\"{o}ller, Tomas},
  pages     = {223--246},
  publisher = {Apress},
  title     = {Sampling transformations zoo},
  year      = {2019},
  address   = {Berkeley, CA},
  isbn      = {978-1-4842-4427-2},
  abstract  = {We present several formulas and methods for generating samples distributed according to a desired probability density function on a specific domain. Sampling is a fundamental operation in modern rendering, both at runtime and in preprocessing. It is becoming ever more prevalent with the introduction of ray tracing in standard APIs, as many ray tracing algorithms are based on sampling by nature. This chapter provides a concise list of some useful tricks and methods.},
  booktitle = {Ray Tracing Gems: High-Quality and Real-Time Rendering with DXR and Other APIs},
  doi       = {10.1007/978-1-4842-4427-2_16},
  file      = {:FILES/2019 - Shirley2019 - Sampling Transformations Zoo.pdf:PDF},
  groups    = {sampling by distribution},
  url       = {https://doi.org/10.1007/978-1-4842-4427-2_16},
}

@Article{AlHadithi2019,
  author    = {Al-Hadithi, Basil M. and Zhou, Bin and Xie, Shousheng and Ren, Litong and Wang, Lei and Zhang, Yu and Zhang, Ledi and Wang, Hao},
  journal   = {Complexity},
  title     = {Piecewise Adaptive Sliding Mode Control for Aeroengine Networked Control Systems with Resource Constraints},
  year      = {2019},
  issn      = {1076-2787},
  pages     = {8693780},
  volume    = {2019},
  abstract  = {Within the future application of wireless network for the aeroengine control problem, resource constraints (caused by the limitation of hardware) and network traffic restriction must be considered as one of the difficulties to be solved; thus, the network connection and transmission efficiency can be ensured. With focus on the problem of active packed dropout, a MEF-TOD (Maximum Error First-Try Once Discard) scheduling based network parameter and sliding mode joint design method has been proposed. First, a scheduling protocol strained control system and network parameter joint model have been established based on MEF-TOD scheduling strategy, taking sampling period and data packet capacity as unknown network parameters. Subsequently, considering the influence of scheduling strategy, a sliding surface containing a compensation term has been designed, and then a sliding mode parameter and unknown network parameter heuristic joint design method has been developed. Finally, an attenuation factor based piecewise adaptive sliding mode strategy has been designed considering the influence of sampling period on system performance. Simulation results indicate that the joint design method can obtain the network parameter group which has the minimum performance function upper bound, thus achieving relatively high network utilization. The proposed piecewise adaptive sliding mode controller has good dynamic performance and is robust to the packet dropout problem caused by network scheduling and can effectively suppress chattering.},
  doi       = {10.1155/2019/8693780},
  file      = {:FILES/2019 - AlHadithi2019 - Piecewise Adaptive Sliding Mode Control for Aeroengine Networked Control Systems with Resource Constraints.pdf:PDF},
  groups    = {interesting articles},
  publisher = {Hindawi},
  url       = {https://doi.org/10.1155/2019/8693780},
}

@Article{Du2019,
  author   = {Du, Qiang and Yin, Xiaobo},
  journal  = {Journal of Scientific Computing},
  title    = {A Conforming {DG} Method for Linear Nonlocal Models with Integrable Kernels},
  year     = {2019},
  issn     = {1573-7691},
  number   = {3},
  pages    = {1913--1935},
  volume   = {80},
  abstract = {The numerical solution of nonlocal constrained value problems with integrable kernels is considered. These nonlocal problems arise in nonlocal mechanics and nonlocal diffusion. The structure of the true solution to the problem is analyzed first. The analysis leads naturally to a new kind of discontinuous Galerkin method that can more efficiently solve the problem numerically. The new method is shown to be asymptotically compatible. Moreover, it has optimal convergence rate for any dimensional case under mild assumptions.},
  doi      = {10.1007/s10915-019-01006-0},
  file     = {:FILES/2019 - Du2019 - A Conforming {DG} Method for Linear Nonlocal Models with Integrable Kernels.pdf:PDF},
  groups   = {interesting articles},
  refid    = {Du2019},
  url      = {https://doi.org/10.1007/s10915-019-01006-0},
}

@Article{DAmbrosio2019,
  author   = {{D’Ambrosio}, Claudia and Frangioni, Antonio and Gentile, Claudio},
  journal  = {Optimization Letters},
  title    = {Strengthening the sequential convex {MINLP} technique by perspective reformulations},
  year     = {2019},
  issn     = {1862-4480},
  number   = {4},
  pages    = {673--684},
  volume   = {13},
  abstract = {The sequential convex MINLP (SC-MINLP) technique is a solution method for nonconvex mixed-integer nonlinear problems (MINLPs) where the nonconvexities are separable. It is based on solving a sequence of convex MINLPs which trade a better and better relaxation of the nonconvex part of the problem with the introduction of more and more piecewise-linear nonconvex terms, and therefore binary variables. The convex MINLPs are obtained by partitioning the domain of each separable nonconvex term in the intervals in which it is convex and those in which it is concave. In the former, the term is left in its original form, while in the latter it is piecewise-linearized. Since each interval corresponds to a semi-continuous variable, we propose to modify the convex terms using the Perspective Reformulation technique to strengthen the bounds. We show by means of experimental results on different classes of instances that doing so significantly decreases the solution time of the convex MINLPs, which is the most time consuming part of the approach, and has therefore the potential to improving the overall effectiveness of SC-MINLP.},
  doi      = {10.1007/s11590-018-1360-9},
  file     = {:FILES/2018 - DAmbrosio2019 - Strengthening the sequential convex MINLP technique by perspective reformulations.pdf:PDF},
  groups   = {optimization},
  refid    = {D’Ambrosio2019},
  url      = {https://doi.org/10.1007/s11590-018-1360-9},
}

@Article{Bandi2019,
  author   = {Bandi, Hari and Bertsimas, Dimitris and Mazumder, Rahul},
  journal  = {INFORMS Journal on Optimization},
  title    = {Learning a mixture of {Gaussians} via mixed-integer optimization},
  year     = {2019},
  number   = {3},
  pages    = {221--240},
  volume   = {1},
  abstract = {We consider the problem of estimating the parameters of a multivariate Gaussian mixture model (GMM) given access to n samples that are believed to have come from a mixture of multiple subpopulations. State-of-the-art algorithms used to recover these parameters use heuristics to either maximize the log-likelihood of the sample or try to fit first few moments of the GMM to the sample moments. In contrast, we present here a novel mixed-integer optimization (MIO) formulation that optimally recovers the parameters of the GMM by minimizing a discrepancy measure (either the Kolmogorov–Smirnov or the total variation distance) between the empirical distribution function and the distribution function of the GMM whenever the mixture component weights are known. We also present an algorithm for multidimensional data that optimally recovers corresponding means and covariance matrices. We show that the MIO approaches are practically solvable for data sets with n in the tens of thousands in minutes and achieve an average improvement of 60\%–70\% and 50\%–60\% on mean absolute percentage error in estimating the means and the covariance matrices, respectively, over the expectation–maximization (EM) algorithm independent of the sample size n. As the separation of the Gaussians decreases and, correspondingly, the problem becomes more difficult, the edge in performance in favor of the MIO methods widens. Finally, we also show that the MIO methods outperform the EM algorithm with an average improvement of 4\%–5\% on the out-of-sample accuracy for real-world data sets.},
  doi      = {10.1287/ijoo.2018.0009},
  eprint   = {https://doi.org/10.1287/ijoo.2018.0009},
  file     = {:FILES/2018 - Bandi2019 - Learning a Mixture of Gaussians via Mixed Integer Optimization.pdf:PDF},
  groups   = {interesting articles},
  url      = {https://doi.org/10.1287/ijoo.2018.0009},
}

@Article{Lopez2006,
  author   = {L\'{o}pez, M. and Castillo, E. and Garc\'{i}a, G. and Bashir, A.},
  journal  = {Proceedings of the Institution of Mechanical Engineers, Part C: Journal of Mechanical Engineering Science},
  title    = {Delta robot: {Inverse,} direct, and intermediate jacobians},
  year     = {2006},
  number   = {1},
  pages    = {103--109},
  volume   = {220},
  abstract = {AbstractIn the context of a parallel manipulator, inverse and direct Jacobian matrices are known to contain information which helps us identify some of the singular configurations. In this article, we employ kinematic analysis for the Delta robot to derive the velocity of the end-effector in terms of the angular joint velocities, thus yielding the Jacobian matrices. Setting their determinants to zero, several undesirable postures of the manipulator have been extracted. The analysis of the inverse Jacobian matrix reveals that singularities are encountered when the limbs belonging to the same kinematic chain lie in a plane. Two of the possible configurations which correspond to this condition are when the robot is completely extended or contracted, indicating the boundaries of the workspace. Singularities associated with the direct Jacobian matrix, which correspond to relatively more complicated configurations of the manipulator, have also been derived and commented on. Moreover, the idea of intermediate Jacobian matrices have been introduced that are simpler to evaluate but still contain the information of the singularities mentioned earlier in addition to architectural singularities not contemplated in conventional Jacobians.},
  doi      = {10.1243/095440606X78263},
  eprint   = {https://doi.org/10.1243/095440606X78263},
  file     = {:FILES/2006 - Lopez2006 - Delta robot - inverse, direct, and intermediate Jacobians.pdf:PDF},
  groups   = {robots},
  url      = {https://doi.org/10.1243/095440606X78263},
}

@PhdThesis{Vineyard2015,
  author  = {Craig M. Vineyard},
  school  = {The University of New Mexico},
  title   = {A game-theoretic support vector machine classifier},
  year    = {2015},
  address = {Albuquerque, New Mexico},
  month   = may,
  type    = {phdthesis},
  file    = {:FILES/2015 - Vineyard2015 - A game-theoretic support vector machine classifier.pdf:PDF},
  groups  = {SVM},
}

@Article{Zhou2015,
  author   = {Zhou, Jian and Kang, Hee-Jun},
  journal  = {Advances in Mechanical Engineering},
  title    = {A hybrid least-squares genetic algorithm–based algorithm for simultaneous identification of geometric and compliance errors in industrial robots},
  year     = {2015},
  number   = {6},
  pages    = {1--12},
  volume   = {7},
  abstract = {Due to the flexibility of robot joints and links, industrial robots can hardly achieve the accuracy required to perform tasks when a payload is attached at their end-effectors. This article presents a new technique for identifying and compensating compliance errors in industrial robots. Within this technique, a comprehensive error model consisting of both geometric and compliance errors is established, where joint compliance is modeled as a piecewise linear function of joint torque to approximate the nonlinear relation between joint torque and torsional angle. A hybrid least-squares genetic algorithm–based algorithm is then developed to simultaneously identify the geometric parameters, joint compliance values, and the transition joint torques. These identified geometric and non-geometric parameters are then used to compensate geometric and joint compliance errors. Finally, the developed technique is applied to a 6 degree-of-freedom industrial serial robot (Hyundai HA006). Experimental results are presented that demonstrate the effectiveness of the identification and compensation techniques.},
  doi      = {10.1177/1687814015590289},
  eprint   = {https://doi.org/10.1177/1687814015590289},
  file     = {:FILES/2015 - Zhou2015 - A hybrid least-squares genetic algorithm–based algorithm for simultaneous identification of geometric and compliance errors in industrial robots.pdf:PDF},
  groups   = {robots, genetic algorithms},
  url      = {https://doi.org/10.1177/1687814015590289},
}

@Article{Trang2016,
  author    = {Trang, L. H. and Kozma, A. and An, P. T. and Diehl, M.},
  journal   = {Optimization Methods and Software},
  title     = {A sequential convex programming algorithm for minimizing a sum of euclidean norms with non-convex constraints},
  year      = {2016},
  number    = {1},
  pages     = {187--203},
  volume    = {31},
  abstract  = {Given and a finite set of convex polygons in , we consider the problem of finding the Euclidean shortest path starting at p then visiting the relative boundaries of the convex polygons in a given order, and ending at q. An approximate algorithm is proposed. The problem can be rewritten under a variant of minimizing a sum of Euclidean norms: , where and , subject to is on the relative boundary of , for . The objective function of the problem is convex but not everywhere differentiable and the constraints are non-convex. By using a smooth inner approximation of with parameter t, a relaxed form of the problem is constructed such that its solution, denoted by , is inside but outside the inner approximation. The relaxed problem is then solved iteratively using a sequential convex programming. The obtained solution , however, is actually not on the relative boundary of . Then a so-called refinement of is finally required to determine a solution passing through the relative boundary of , for . It is shown that the solution of the relaxed problem tends to its refined one as . The algorithm is implemented in Matlab using the CVX package. Numerical tests indicate that the solution obtained by the algorithm is close to the global one.},
  doi       = {10.1080/10556788.2015.1055561},
  eprint    = {https://doi.org/10.1080/10556788.2015.1055561},
  file      = {:FILES/2016 - Trang2016 - A sequential convex programming algorithm for minimizing a sum of Euclidean norms with non-convex constraints.pdf:PDF},
  groups    = {global optimization},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/10556788.2015.1055561},
}

@Article{Arena2006,
  author    = {Arena, Paolo and Buscarino, Arturo and Fortuna, Luigi and Frasca, Mattia},
  journal   = {Phys. Rev. E},
  title     = {Separation and synchronization of piecewise linear chaotic systems},
  year      = {2006},
  month     = {8},
  pages     = {026212},
  volume    = {74},
  doi       = {10.1103/PhysRevE.74.026212},
  file      = {:FILES/2016 - Arena2006 - Separation and synchronization of piecewise linear chaotic systems.pdf:PDF},
  groups    = {application},
  issue     = {2},
  numpages  = {11},
  publisher = {American Physical Society},
  url       = {https://link.aps.org/doi/10.1103/PhysRevE.74.026212},
}

@Article{Li2008,
  author  = {W. T. Li and L. Xu and X. W. Shi},
  journal = {PIERS ONLINE},
  title   = {A hybrid of genetic algorithm and particle swarm optimization for antenna design},
  year    = {2008},
  number  = {1},
  pages   = {56--60},
  volume  = {4},
  file    = {:FILES/2008 - Li2008 - A hybrid of genetic algorithm and particle swarm optimization for antenna design.pdf:PDF},
  groups  = {genetic algorithms},
}

@Article{Yu2014,
  author    = {Yu, Gaohang and Shen, Jie and Li, Dan and Pang, Li-Ping},
  journal   = {Abstract and Applied Analysis},
  title     = {A cutting plane and level stabilization bundle method with inexact data for minimizing nonsmooth nonconvex functions},
  year      = {2014},
  issn      = {1085-3375},
  pages     = {192893},
  volume    = {2014},
  abstract  = {Under the condition that the values of the objective function and its subgradient are computed approximately, we introduce a cutting plane and level bundle method for minimizing nonsmooth nonconvex functions by combining cutting plane method with the ideas of proximity control and level constraint. The proposed algorithm is based on the construction of both a lower and an upper polyhedral approximation model to the objective function and calculates new iteration points by solving a subproblem in which the model is employed not only in the objective function but also in the constraints. Compared with other proximal bundle methods, the new variant updates the lower bound of the optimal value, providing an additional useful stopping test based on the optimality gap. Another merit is that our algorithm makes a distinction between affine pieces that exhibit a convex or a concave behavior relative to the current iterate. Convergence to some kind of stationarity point is proved under some looser conditions.},
  doi       = {10.1155/2014/192893},
  file      = {:FILES/2014 - Yu2014 - A Cutting Plane and Level Stabilization Bundle Method with Inexact Data for Minimizing Nonsmooth Nonconvex Functions.pdf:PDF},
  groups    = {nonsmooth optimization, proximal bundle method},
  publisher = {Hindawi Publishing Corporation},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1155/2014/192893},
}

@Article{Misener2015,
  author    = {Misener, Ruth and Smadbeck, James B. and Floudas, Christodoulos A.},
  journal   = {Optimization Methods and Software},
  title     = {Dynamically generated cutting planes for mixed-integer quadratically constrained quadratic programs and their incorporation into glomiqo 2},
  year      = {2015},
  number    = {1},
  pages     = {215--249},
  volume    = {30},
  abstract  = {The global mixed-integer quadratic optimizer, GloMIQO, addresses mixed-integer quadratically constrained quadratic programs (MIQCQP) to ε-global optimality. This paper documents the branch-and-cut framework integrated into GloMIQO 2. Cutting planes are derived from reformulation–linearization technique equations, convex multivariable terms, αBB convexifications, and low- and high-dimensional edge-concave aggregations. Cuts are based on both individual equations and collections of nonlinear terms in MIQCQP. Novel contributions of this paper include: development of a corollary to Crama's [Concave extensions for nonlinear 0-1 maximization problems, Math. Program. 61 (1993), pp. 53–60] necessary and sufficient condition for the existence of a cut dominating the termwise relaxation of a bilinear expression; algorithmic descriptions for deriving each class of cut; presentation of a branch-and-cut framework integrating the cuts. Computational results are presented along with comparison of the GloMIQO 2 performance to several state-of-the-art solvers.},
  doi       = {10.1080/10556788.2014.916287},
  eprint    = {https://doi.org/10.1080/10556788.2014.916287},
  file      = {:FILES/2015 - Misener2015 - Dynamically generated cutting planes for mixed-integer quadratically constrained quadratic programs and their incorporation into GloMIQO 2.pdf:PDF},
  groups    = {MINLP},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/10556788.2014.916287},
}

@Article{Pardalos1986,
  author   = {Pardalos, P. M. and Rosen, J. B.},
  journal  = {SIAM Review},
  title    = {Methods for global concave minimization: {A} bibliographic survey},
  year     = {1986},
  number   = {3},
  pages    = {367--379},
  volume   = {28},
  abstract = {The global concave minimization problem is to find the constrained global minimum of a concave function. Since such a function may have many local minima, finding the global minimum is a computationally difficult problem. In this bibliographic survey, which includes most of the recent papers on constrained global concave minimization, we have attempted to briefly summarize the main ideas in each paper. These recent papers include those concerned with large scale global concave minimization and bilinear programming.},
  doi      = {10.1137/1028106},
  eprint   = {https://doi.org/10.1137/1028106},
  file     = {:FILES/1986 - Pardalos1986 - Methods for global concave minimization {A} bibliographic survey .pdf:PDF},
  groups   = {concave},
  url      = {https://doi.org/10.1137/1028106},
}

@PhdThesis{Feng2019,
  author   = {Feng, Siwei},
  school   = {University of Massachusetts Amherst},
  title    = {Sparsity in machine learning: {An} information selecting perspective},
  year     = {2019},
  abstract = {Today we are living in a world awash with data. Large volumes of data are acquired, analyzed and applied to tasks through machine learning algorithms in nearly every area of science, business, and industry. For example, medical scientists analyze the gene expression data from a single specimen to learn the underlying causes of disease (e.g. cancer) and choose the best treatment; retailers can know more about customers' shopping habits from retail data to adjust their business strategies to better appeal to customers; suppliers can enhance supply chain success through supply chain systems built on knowledge sharing. However, it is also reasonable to doubt whether all the genes make contributions to a disease; whether all the data obtained from existing customers can be applied to a new customer; whether all shared knowledge in the supply network is useful to a specific supply scenario. Therefore, it is crucial to sort through the massive information provided by data and keep what we really need. This process is referred to as information selection, which keeps the information that helps improve the performance of corresponding machine learning tasks and discards information that is useless or even harmful to task performance. Sparse learning is a powerful tool to achieve information selection. In this thesis, we apply sparse learning to two major areas in machine learning -- feature selection and transfer learning.

Feature selection is a dimensionality reduction technique that selects a subset of representative features. Recently, feature selection combined with sparse learning has attracted significant attention due to its outstanding performance compared with traditional feature selection methods that ignore correlation between features. However, they are restricted by design to linear data transformations, a potential drawback given that the underlying correlation structures of data are often non-linear. To leverage more sophisticated embedding than the linear model assumed by sparse learning, we propose an autoencoder-based unsupervised feature selection approach that leverages a single-layer autoencoder for a joint framework of feature selection and manifold learning. Additionally, we include spectral graph analysis on the projected data into the learning process to achieve local data geometry preservation from the original data space to the low-dimensional feature space.

Transfer learning describes a set of methods that aim at transferring knowledge from related domains to alleviate the problems caused by limited/no labeled training data in machine learnig tasks. Many transfer learning techniques have been proposed to deal with different application scenarios. However, due to the differences in data distribution, feature space, label space, etc., between source domain and target domain, it is necessary to select and only transfer relevant information from source domain to improve the performance of target learner. Otherwise, the target learner can be negatively impacted by the weak-related knowledge from source domain, which is referred to as negative transfer. In this thesis, we focus on two transfer learning scenarios for which limited labeled training data are available in target domain. In the first scenario, no label information is avaible in source data. In the second scenario, large amounts of labeled source data are available, but there is no overlap between the source and target label spaces. The corresponding transfer learning technique to the former case is called \emph{self-taught learning}, while that for the latter case is called \emph{few-shot learning}. We apply self-taught learning to visual, textal, and audio data. We also apply few-shot learning to wearable sensor based human activity data. For both cases, we propose a metric for the relevance between a target sample/class and a source sample/class, and then extract information from the related samples/classes for knowledge transfer to perform information selection so that negative transfer caused by weakly related source information can be alleviated. Experimental results show that transfer learning can provide better performance with information selection.},
  file     = {:FILES/2019 - Feng2019 - Sparsity in Machine Learning- An Information Selecting Perspective.pdf:PDF},
  groups   = {sparsity},
  url      = {https://scholarworks.umass.edu/dissertations_2/1550},
}

@Article{Cheng2006,
  author    = {Cheng, Chih-Huai and Chen, Kuan-Yu and Tien, Wen-Chin and Chao, Kun-Mao},
  journal   = {Theoretical Computer Science},
  title     = {Improved algorithms for the k maximum-sums problems},
  year      = {2006},
  issn      = {0304-3975},
  number    = {1},
  pages     = {162 -- 170},
  volume    = {362},
  abstract  = {Given a sequence of n real numbers and an integer k, 1<=k<=12n(n-1), the k maximum-sum segments problem is to locate the k segments whose sums are the k largest among all possible segment sums. Recently, Bengtsson and Chen gave an O(min{k+nlog2n,nk})-time algorithm for this problem. Bae and Takaoka later proposed a more efficient algorithm for small k. In this paper, we propose an O(n+klog(min{n,k}))-time algorithm for the same problem, which is superior to both of them when k is o(nlogn). We also give the first optimal algorithm for delivering the k maximum-sum segments in non-decreasing order if k⩽n. Then we develop an O(n2d-1+klogmin{n,k})-time algorithm for the d-dimensional version of the problem, where d>1 and each dimension, without loss of generality, is of the same size n. This improves the best previously known O(n2d-1C)-time algorithm, also by Bengtsson and Chen, where C=min{k+nlog2n,nk}. It should be pointed out that, given a two-dimensional array of size m×n, our algorithm for finding the k maximum-sum subarrays is the first one achieving cubic time provided that k is O(m2n/logn).},
  doi       = {https://doi.org/10.1016/j.tcs.2006.06.007},
  file      = {:FILES/2005 - Cheng2005 - Improved algorithms for the k maximum-sums problems.pdf:PDF},
  groups    = {mathematical basis},
  keywords  = {Maximum-sum subsequence, Maximum-sum subarray, Sequence analysis},
  timestamp = {2020-09-04},
  url       = {http://www.sciencedirect.com/science/article/pii/S0304397506003501},
}

@Article{Ji2008,
  author    = {Ji, S. and Xue, Y. and Carin, L.},
  journal   = {IEEE Transactions on Signal Processing},
  title     = {Bayesian compressive sensing},
  year      = {2008},
  issn      = {1941-0476},
  month     = {6},
  number    = {6},
  pages     = {2346--2356},
  volume    = {56},
  abstract  = {The data of interest are assumed to be represented as N-dimensional real vectors, and these vectors are compressible in some linear basis B, implying that the signal can be reconstructed accurately using only a small number M Lt N of basis-function coefficients associated with B. Compressive sensing is a framework whereby one does not measure one of the aforementioned N-dimensional signals directly, but rather a set of related measurements, with the new measurements a linear combination of the original underlying N-dimensional signal. The number of required compressive-sensing measurements is typically much smaller than N, offering the potential to simplify the sensing system. Let f denote the unknown underlying N-dimensional signal, and g a vector of compressive-sensing measurements, then one may approximate f accurately by utilizing knowledge of the (under-determined) linear relationship between f and g, in addition to knowledge of the fact that f is compressible in B. In this paper we employ a Bayesian formalism for estimating the underlying signal f based on compressive-sensing measurements g. The proposed framework has the following properties: i) in addition to estimating the underlying signal f, "error bars" are also estimated, these giving a measure of confidence in the inverted signal; ii) using knowledge of the error bars, a principled means is provided for determining when a sufficient number of compressive-sensing measurements have been performed; iii) this setting lends itself naturally to a framework whereby the compressive sensing measurements are optimized adaptively and hence not determined randomly; and iv) the framework accounts for additive noise in the compressive-sensing measurements and provides an estimate of the noise variance. In this paper we present the underlying theory, an associated algorithm, example results, and provide comparisons to other compressive-sensing inversion algorithms in the literature.},
  doi       = {10.1109/TSP.2007.914345},
  file      = {:FILES/2008 - Ji2008 - Bayesian compressive sensing.pdf:PDF},
  groups    = {Compressive sensing},
  keywords  = {Bayes methods;estimation theory;noise;signal reconstruction;signal representation;Bayesian compressive sensing framework;N-dimensional signal representation;signal reconstruction;signal estimation;noise variance;Bayesian methods;Noise measurement;Vectors;Performance evaluation;Additive noise;Transform coding;Bars;Design for experiments;Machine learning;Discrete wavelet transforms;Adaptive compressive sensing;Bayesian model selection;compressive sensing (CS);experimental design;relevance vector machine (RVM);sparse Bayesian learning},
  timestamp = {2020-09-04},
}

@InProceedings{Seeger2008,
  author    = {Seeger, Matthias W. and Nickisch, Hannes},
  booktitle = {Proceedings of the 25th International Conference on Machine Learning},
  title     = {Compressed sensing and {Bayesian} experimental design},
  year      = {2008},
  address   = {New York, NY, USA},
  pages     = {912–919},
  publisher = {Association for Computing Machinery},
  series    = {ICML '08},
  abstract  = {We relate compressed sensing (CS) with Bayesian experimental design and provide a novel efficient approximate method for the latter, based on expectation propagation. In a large comparative study about linearly measuring natural images, we show that the simple standard heuristic of measuring wavelet coefficients top-down systematically outperforms CS methods using random measurements; the sequential projection optimisation approach of (Ji  Carin, 2007) performs even worse. We also show that our own approximate Bayesian method is able to learn measurement filters on full images efficiently which outperform the wavelet heuristic. To our knowledge, ours is the first successful attempt at "learning compressed sensing" for images of realistic size. In contrast to common CS methods, our framework is not restricted to sparse signals, but can readily be applied to other notions of signal complexity or noise models. We give concrete ideas how our method can be scaled up to large signal representations.},
  doi       = {10.1145/1390156.1390271},
  file      = {:FILES/2008 - Seeger2008 - Compressed sensing and {Bayesian} experimental design.pdf:PDF},
  groups    = {Compressive sensing},
  isbn      = {9781605582054},
  location  = {Helsinki, Finland},
  numpages  = {8},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1145/1390156.1390271},
}

@Article{Astorino2011,
  author    = {Astorino, A. and Frangioni, A. and Gaudioso, M. and Gorgone, E.},
  journal   = {SIAM Journal on Optimization},
  title     = {Piecewise-quadratic approximations in convex numerical optimization},
  year      = {2011},
  number    = {4},
  pages     = {1418--1438},
  volume    = {21},
  abstract  = {We present a bundle method for convex nondifferentiable minimization where the model is a piecewise-quadratic convex approximation of the objective function. Unlike standard bundle approaches, the model only needs to support the objective function from below at a properly chosen (small) subset of points, as opposed to everywhere. We provide the convergence analysis for the algorithm, with a general form of master problem which combines features of trust region stabilization and proximal stabilization, taking care of all the important practical aspects such as proper handling of the proximity parameters and the bundle of information. Numerical results are also reported.


Read More: https://epubs.siam.org/doi/abs/10.1137/100817930},
  doi       = {10.1137/100817930},
  eprint    = {https://doi.org/10.1137/100817930},
  file      = {:FILES/2011 - Astorino2011 - Piecewise-quadratic Approximations in Convex Numerical Optimization.pdf:PDF},
  groups    = {Approximation},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1137/100817930},
}

@Article{Hare2010,
  author    = {Hare, Warren and Sagastiz\'{a}bal, Claudia},
  journal   = {SIAM Journal on Optimization},
  title     = {A redistributed proximal bundle method for nonconvex optimization},
  year      = {2010},
  number    = {5},
  pages     = {2442--2473},
  volume    = {20},
  abstract  = {Proximal bundle methods have been shown to be highly successful optimization methods for unconstrained convex problems with discontinuous first derivatives. This naturally leads to the question of whether proximal variants of bundle methods can be extended to a nonconvex setting. This work proposes an approach based on generating cutting-planes models, not of the objective function as most bundle methods do but of a local convexification of the objective function. The corresponding convexification parameter is calculated “on the fly” in such a way that the algorithm can inform the user as to what proximal parameters are sufficiently large that the objective function is likely to have well-defined proximal points. This novel approach, shown to be sound from both the objective function and subdifferential modelling perspectives, opens the way to create workable nonconvex algorithms based on nonconvex $\mathcal{VU}$ theory. Both theoretical convergence analysis and some encouraging preliminary numerical experience are provided. Read More: https://epubs.siam.org/doi/abs/10.1137/090754595},
  doi       = {10.1137/090754595},
  eprint    = {https://doi.org/10.1137/090754595},
  file      = {:FILES/2010 - Hare2010 - A Redistributed Proximal Bundle Method for Nonconvex Optimization.pdf:PDF},
  groups    = {proximal bundle method},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1137/090754595},
}

@Article{Karmitsa2018,
  author    = {Karmitsa, Napsu and Bagirov, Adil M. and Taheri, Sona},
  journal   = {Pattern Recognition},
  title     = {Clustering in large data sets with the limited memory bundle method},
  year      = {2018},
  issn      = {0031-3203},
  pages     = {245--259},
  volume    = {83},
  abstract  = {The aim of this paper is to design an algorithm based on nonsmooth optimization techniques to solve the minimum sum-of-squares clustering problems in very large data sets. First, the clustering problem is formulated as a nonsmooth optimization problem. Then the limited memory bundle method [Haarala et al., 2007] is modified and combined with an incremental approach to design a new clustering algorithm. The algorithm is evaluated using real world data sets with both the large number of attributes and the large number of data points. It is also compared with some other optimization based clustering algorithms. The numerical results demonstrate the efficiency of the proposed algorithm for clustering in very large data sets.},
  doi       = {https://doi.org/10.1016/j.patcog.2018.05.028},
  file      = {:FILES/2018 - Karmitsa2018 - Clustering in large data sets with the limited memory bundle method.pdf:PDF},
  groups    = {proximal bundle method},
  keywords  = {Cluster analysis, Nonsmooth optimization, Nonconvex optimization, Bundle methods, Limited memory methods},
  publisher = {Elsevier},
  timestamp = {2020-09-04},
  url       = {http://www.sciencedirect.com/science/article/pii/S0031320318302085},
}

@Article{HoseiniMonjezi2019,
  author    = {Hoseini Monjezi, Najmeh and Nobakhtian, S.},
  journal   = {Computational Optimization and Applications},
  title     = {A new infeasible proximal bundle algorithm for nonsmooth nonconvex constrained optimization},
  year      = {2019},
  issn      = {1573-2894},
  number    = {2},
  pages     = {443--480},
  volume    = {74},
  abstract  = {Proximal bundle method has usually been presented for unconstrained convex optimization problems. In this paper, we develop an infeasible proximal bundle method for nonsmooth nonconvex constrained optimization problems. Using the improvement function we transform the problem into an unconstrained one and then we build a cutting plane model. The resulting algorithm allows effective control of the size of quadratic programming subproblems via the aggregation techniques. The novelty in our approach is that the objective and constraint functions can be any arbitrary (regular) locally Lipschitz functions. In addition the global convergence, starting from any point, is proved in the sense that every accumulation point of the iterative sequence is stationary for the improvement function. At the end, some encouraging numerical results with a MATLAB implementation are also reported.},
  doi       = {10.1007/s10589-019-00115-8},
  file      = {:FILES/2019 - HoseiniMonjezi2019 - A new infeasible proximal bundle algorithm for nonsmooth nonconvex constrained optimization.pdf:PDF},
  groups    = {proximal bundle method},
  refid     = {Hoseini Monjezi2019},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1007/s10589-019-00115-8},
}

@Article{Joki2017,
  author    = {Joki, Kaisa and Bagirov, Adil M. and Karmitsa, Napsu and Mäkelä, Marko M.},
  journal   = {Journal of Global Optimization},
  title     = {A proximal bundle method for nonsmooth {DC} optimization utilizing nonconvex cutting planes},
  year      = {2017},
  issn      = {1573-2916},
  number    = {3},
  pages     = {501--535},
  volume    = {68},
  abstract  = {In this paper, we develop a version of the bundle method to solve unconstrained difference of convex (DC) programming problems. It is assumed that a DC representation of the objective function is available. Our main idea is to utilize subgradients of both the first and second components in the DC representation. This subgradient information is gathered from some neighborhood of the current iteration point and it is used to build separately an approximation for each component in the DC representation. By combining these approximations we obtain a new nonconvex cutting plane model of the original objective function, which takes into account explicitly both the convex and the concave behavior of the objective function. We design the proximal bundle method for DC programming based on this new approach and prove the convergence of the method to an $$\varepsilon $$ε-critical point. The algorithm is tested using some academic test problems and the preliminary numerical results have shown the good performance of the new bundle method. An interesting fact is that the new algorithm finds nearly always the global solution in our test problems.},
  doi       = {10.1007/s10898-016-0488-3},
  file      = {:FILES/2017 - Joki2017 - A proximal bundle method for nonsmooth DC optimization utilizing nonconvex cutting planes.pdf:PDF},
  groups    = {proximal bundle method},
  refid     = {Joki2017},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1007/s10898-016-0488-3},
}

@Article{Hintermueller2001,
  author    = {Hintermüller, Michael},
  journal   = {Computational Optimization and Applications},
  title     = {A Proximal Bundle Method Based on Approximate Subgradients},
  year      = {2001},
  issn      = {1573-2894},
  number    = {3},
  pages     = {245--266},
  volume    = {20},
  abstract  = {In this paper a proximal bundle method is introduced that is capable to deal with approximate subgradients. No further knowledge of the approximation quality (like explicit knowledge or controllability of error bounds) is required for proving convergence. It is shown that every accumulation point of the sequence of iterates generated by the proposed algorithm is a well-defined approximate solution of the exact minimization problem. In the case of exact subgradients the algorithm behaves like well-established proximal bundle methods. Numerical tests emphasize the theoretical findings.},
  doi       = {10.1023/A:1011259017643},
  file      = {:FILES/2001 - Hintermueller2001 - A Proximal Bundle Method Based on Approximate Subgradients.pdf:PDF},
  groups    = {proximal bundle method},
  refid     = {Hintermüller2001},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1023/A:1011259017643},
}

@Article{Fuduli2015,
  author    = {Fuduli, A. and Gaudioso, M. and Nurminski, E. A.},
  journal   = {Optimization},
  title     = {A splitting bundle approach for non-smooth non-convex minimization},
  year      = {2015},
  number    = {5},
  pages     = {1131--1151},
  volume    = {64},
  abstract  = {We present a bundle-type method for minimizing non-convex non-smooth functions. Our approach is based on the partition of the bundle into two sets, taking into account the local convex or concave behaviour of the objective function. Termination at a point satisfying an approximate stationarity condition is proved and numerical results are provided.},
  doi       = {10.1080/02331934.2013.840625},
  eprint    = {https://doi.org/10.1080/02331934.2013.840625},
  file      = {:FILES/2015 - Fuduli2015 - A splitting bundle approach for non-smooth non-convex minimization.pdf:PDF},
  groups    = {nonsmooth optimization, proximal bundle method},
  publisher = {Taylor \& Francis},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1080/02331934.2013.840625},
}

@Article{Haarala2007,
  author    = {Haarala, Napsu and Miettinen, Kaisa and M\"{a}kel\"{a}, Marko M.},
  journal   = {Mathematical Programming},
  title     = {Globally convergent limited memory bundle method for large-scale nonsmooth optimization},
  year      = {2007},
  issn      = {1436-4646},
  number    = {1},
  pages     = {181--205},
  volume    = {109},
  abstract  = {Many practical optimization problems involve nonsmooth (that is, not necessarily differentiable) functions of thousands of variables. In the paper [Haarala, Miettinen, Mäkelä, Optimization Methods and Software, 19, (2004), pp. 673-692] we have described an efficient method for large-scale nonsmooth optimization. In this paper, we introduce a new variant of this method and prove its global convergence for locally Lipschitz continuous objective functions, which are not necessarily differentiable or convex. In addition, we give some encouraging results from numerical experiments.},
  doi       = {10.1007/s10107-006-0728-2},
  file      = {:FILES/2007 - Haarala2007 - Globally convergent limited memory bundle method for large-scale nonsmooth optimization.pdf:PDF},
  groups    = {proximal bundle method},
  timestamp = {2020-09-04},
  url       = {https://link.springer.com/article/10.1007/s10107-006-0728-2},
}

@Article{Maekelae2002,
  author    = {M\"{a}kel\"{a}, Marko},
  journal   = {Optimization Methods and Software},
  title     = {Survey of bundle methods for nonsmooth optimization},
  year      = {2002},
  number    = {1},
  pages     = {1--29},
  volume    = {17},
  abstract  = {Bundle methods are at the moment the most efficient and promising methods for nonsmooth optimization. They have been successfully used in many practical applications, for example, in economics, mechanics, engineering and optimal control. The aim of this paper is to give an overview of the development and history of the bundle methods from the seventies to the present. For simplicity, we first concentrate on the convex unconstrained case with a single objective function. The methods are later extended to nonconvex, constrained and multicriteria cases.},
  doi       = {10.1080/10556780290027828},
  eprint    = {https://doi.org/10.1080/10556780290027828},
  file      = {:FILES/2002 - Maekelae2002 - Survey of bundle methods for nonsmooth optimization.pdf:PDF},
  groups    = {proximal bundle method},
  publisher = {Taylor \& Francis},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1080/10556780290027828},
}

@Article{bacaud2001bundle,
  author    = {Bacaud, L\'{e}onard and Lemar\'{e}chal, Claude and Renaud, Arnaud and Sagastiz\'{a}bal, Claudia},
  journal   = {Computational Optimization and Applications},
  title     = {Bundle methods in stochastic optimal power management: {A} disaggregated approach using preconditioners},
  year      = {2001},
  issn      = {1573-2894},
  number    = {3},
  pages     = {227--244},
  volume    = {20},
  abstract  = {A specialized variant of bundle methods suitable for large-scale problems with separable objective is presented. The method is applied to the resolution of a stochastic unit-commitment problem solved by Lagrangian relaxation. The model includes hydro- as well as thermal-powered plants. Uncertainties lie in the demand, which evolves in time according to a tree of scenarios. Dual variables are preconditioned by using probabilities associated to nodes in the tree The approach is illustrated by numerical results, obtained on a model of the French production mix over a time horizon of 10 days and 1 month.},
  doi       = {10.1023/A:1011202900805},
  file      = {:FILES/2001 - bacaud2001bundle - Bundle Methods in Stochastic Optimal Power Management- A Disaggregated Approach Using Preconditioners.pdf:PDF},
  groups    = {proximal bundle method},
  publisher = {Springer},
  timestamp = {2020-09-04},
  url       = {https://doi.org/10.1023/A:1011202900805},
}

@Article{Zhou2020,
  author    = {Zhou, Y. and Hao, J. and Fu, Z. and Wang, Z. and Lai, X.},
  journal   = {IEEE Transactions on Evolutionary Computation},
  title     = {Variable population memetic search: {A} case study on the critical node problem},
  year      = {2020},
  issn      = {1941-0026},
  pages     = {1--1},
  abstract  = {Population-based memetic algorithms have been successfully applied to solve many difficult combinatorial problems. Often, a population of fixed size is used in such algorithms to record some best solutions sampled during the search. However, given the particular features of the problem instance under consideration, a population of variable size would be more suitable to ensure the best search performance possible. In this work, we propose variable population memetic search (VPMS), where a strategic population sizing mechanism is used to dynamically adjust the population size during the search process. Our VPMS approach starts its search from a small population of only two solutions to focus on exploitation, and then adapts the population size according to the search status to continuously influence the balancing between exploitation and exploration. We illustrate an application of the VPMS approach to solve the challenging critical node problem (CNP). We show that the VPMS algorithm integrating a variable population, an effective local optimization procedure and a backbone-based crossover operator performs very well compared to state-of-the-art CNP algorithms. The algorithm is able to discover new upper bounds for 12 instances out of the 42 popular benchmark instances, while matching 23 previous best-known upper bounds.},
  doi       = {10.1109/TEVC.2020.3011959},
  file      = {:FILES/2020 - Zhou2020 - Variable population memetic search- {A} case study on the critical node problem.pdf:PDF},
  groups    = {Evolutionary Algorithms},
  keywords  = {Sociology;Statistics;Memetics;Optimization;Genetic algorithms;Search problems;Heuristic algorithms;Memetic search;Population sizing;local search;critical node problem.},
  timestamp = {2020-09-05},
}

@Article{Qian2018,
  author    = {Qian, C. and Shi, J. and Tang, K. and Zhou, Z.},
  journal   = {IEEE Transactions on Evolutionary Computation},
  title     = {Constrained monotone $k$ -submodular function maximization using multiobjective evolutionary algorithms with theoretical guarantee},
  year      = {2018},
  issn      = {1941-0026},
  month     = {8},
  number    = {4},
  pages     = {595--608},
  volume    = {22},
  abstract  = {The problem of maximizing monotone k-submodular functions under a size constraint arises in many applications, and it is NP-hard. In this paper, we propose a new approach which employs a multiobjective evolutionary algorithm to maximize the given objective and minimize the size simultaneously. For general cases, we prove that the proposed method can obtain the asymptotically tight approximation guarantee, which was also achieved by the greedy algorithm. Moreover, we further give instances where the proposed approach performs better than the greedy algorithm on applications of influence maximization, information coverage maximization, and sensor placement. Experimental results on real-world data sets exhibit the superior performance of the proposed approach.},
  doi       = {10.1109/TEVC.2017.2749263},
  file      = {:FILES/2018 - Qian2018 - Constrained monotone $k$ -submodular function maximization using multiobjective evolutionary algorithms with theoretical guarantee.pdf:PDF},
  groups    = {Evolutionary Algorithms, multi-objective},
  keywords  = {approximation theory;evolutionary computation;greedy algorithms;minimisation;sensor placement;constrained monotone;submodular function maximization;multiobjective evolutionary algorithm;submodular functions;size constraint;asymptotically tight approximation guarantee;greedy algorithm;influence maximization;information coverage maximization;monotone k-submodular functions;sensor placement;Greedy algorithms;Method of moments;Optimization;Evolutionary computation;Electronic mail;Integrated circuit modeling;Constrained optimization;experimental studies;multiobjective evolutionary algorithms (MOEAs);submodular optimization;theoretical analysis},
  timestamp = {2020-09-05},
}

@Article{Jin2019,
  author    = {Jin, Y. and Wang, H. and Chugh, T. and Guo, D. and Miettinen, K.},
  journal   = {IEEE Transactions on Evolutionary Computation},
  title     = {Data-driven evolutionary optimization: {An} overview and case studies},
  year      = {2019},
  issn      = {1941-0026},
  month     = {6},
  number    = {3},
  pages     = {442--458},
  volume    = {23},
  abstract  = {Most evolutionary optimization algorithms assume that the evaluation of the objective and constraint functions is straightforward. In solving many real-world optimization problems, however, such objective functions may not exist. Instead, computationally expensive numerical simulations or costly physical experiments must be performed for fitness evaluations. In more extreme cases, only historical data are available for performing optimization and no new data can be generated during optimization. Solving evolutionary optimization problems driven by data collected in simulations, physical experiments, production processes, or daily life are termed data-driven evolutionary optimization. In this paper, we provide a taxonomy of different data driven evolutionary optimization problems, discuss main challenges in data-driven evolutionary optimization with respect to the nature and amount of data, and the availability of new data during optimization. Real-world application examples are given to illustrate different model management strategies for different categories of data-driven optimization problems.},
  doi       = {10.1109/TEVC.2018.2869001},
  file      = {:FILES/2019 - Jin2019 - Data-driven evolutionary optimization- {An} overview and case studies.pdf:PDF},
  groups    = {Evolutionary Algorithms},
  keywords  = {evolutionary computation;optimisation;data-driven evolutionary optimization;evolutionary optimization algorithms;real-world optimization problems;physical experiments;production processes;objective functions;constraint functions;Optimization;Data models;Computational modeling;Data mining;Sociology;Statistics;Machine learning;Data science;data-driven optimization;evolutionary algorithms (EAs);machine learning;model management;surrogate},
  timestamp = {2020-09-05},
}

@Article{Cao2020,
  author    = {Cao, L. and Xu, L. and Goodman, E. D. and Bao, C. and Zhu, S.},
  journal   = {IEEE Transactions on Evolutionary Computation},
  title     = {Evolutionary dynamic multiobjective optimization assisted by a support vector regression predictor},
  year      = {2020},
  issn      = {1941-0026},
  month     = {4},
  number    = {2},
  pages     = {305--319},
  volume    = {24},
  abstract  = {Dynamic multiobjective optimization problems (DMOPs) challenge multiobjective evolutionary algorithms (MOEAs) because those problems change rapidly over time. The class of DMOPs whose objective functions change over time steps, in ways that exhibit some hidden patterns has gained much attention. Their predictability indicates that the problem exhibits some correlations between solutions obtained in sequential time periods. Most of the current approaches use linear models or similar strategies to describe the correlations between historical solutions obtained, and predict the new solutions in the following time period as an initial population from which the MOEA can begin searching in order to improve its efficiency. However, nonlinear correlations between historical solutions and current solutions are more common in practice, and a linear model may not be suitable for the nonlinear case. In this paper, we present a support vector regression (SVR)-based predictor to generate the initial population for the MOEA in the new environment. The basic idea of this predictor is to map the historical solutions into a high-dimensional feature space via a nonlinear mapping, and to do linear regression in this space. SVR is used to implement this process. We incorporate this predictor into the MOEA based on decomposition (MOEA/D) to construct a novel algorithm for solving the aforementioned class of DMOPs. Comprehensive experiments have shown the effectiveness and competitiveness of our proposed predictor, comparing with the state-of-the-art methods.},
  doi       = {10.1109/TEVC.2019.2925722},
  file      = {:FILES/2020 - Cao2020 - Evolutionary dynamic multiobjective optimization assisted by a support vector regression predictor.pdf:PDF},
  groups    = {Evolutionary Algorithms, multi-objective},
  keywords  = {evolutionary computation;Pareto optimisation;regression analysis;support vector machines;linear regression;nonlinear mapping;support vector regression-based predictor;nonlinear correlations;time period;linear model;sequential time periods;hidden patterns;objective functions;multiobjective evolutionary algorithms;DMOP;support vector regression predictor;evolutionary dynamic multiobjective optimization;Correlation;Optimization;Sociology;Support vector machines;Predictive models;Linear programming;Decomposition;dynamic multiobjective optimization;multiobjective evolutionary algorithm (MOEA);nonlinear mapping;predictor;support vector regression (SVR)},
  timestamp = {2020-09-05},
}

@Article{Li2019a,
  author    = {Li, K. and Chen, R. and Fu, G. and Yao, X.},
  journal   = {IEEE Transactions on Evolutionary Computation},
  title     = {Two-archive evolutionary algorithm for constrained multiobjective optimization},
  year      = {2019},
  issn      = {1941-0026},
  month     = {4},
  number    = {2},
  pages     = {303--315},
  volume    = {23},
  abstract  = {When solving constrained multiobjective optimization problems, an important issue is how to balance convergence, diversity, and feasibility simultaneously. To address this issue, this paper proposes a parameter-free constraint handling technique, a two-archive evolutionary algorithm, for constrained multiobjective optimization. It maintains two collaborative archives simultaneously: one, denoted as the convergence-oriented archive (CA), is the driving force to push the population toward the Pareto front; the other one, denoted as the diversity-oriented archive (DA), mainly tends to maintain the population diversity. In particular, to complement the behavior of the CA and provide as much diversified information as possible, the DA aims at exploring areas under-exploited by the CA including the infeasible regions. To leverage the complementary effects of both archives, we develop a restricted mating selection mechanism that adaptively chooses appropriate mating parents from them according to their evolution status. Comprehensive experiments on a series of benchmark problems and a real-world case study fully demonstrate the competitiveness of our proposed algorithm, in comparison to five state-of-the-art constrained evolutionary multiobjective optimizers.},
  doi       = {10.1109/TEVC.2018.2855411},
  file      = {:FILES/2019 - Li2019a - Two-archive evolutionary algorithm for constrained multiobjective optimization.pdf:PDF},
  groups    = {Evolutionary Algorithms, multi-objective},
  keywords  = {convergence;evolutionary computation;Pareto optimisation;restricted mating selection mechanism;infeasible regions;Pareto front;constrained evolutionary multiobjective optimizers;parameter-free constraint handling technique;multiobjective optimization problems;two-archive evolutionary algorithm;population diversity;diversity-oriented archive;convergence-oriented archive;Sociology;Statistics;Convergence;Optimization;Linear programming;Evolutionary computation;Sorting;Constraint handling;evolutionary algorithm (EA);decomposition-based technique;multiobjective optimization;two-archive strategy},
  timestamp = {2020-09-05},
}

@Article{Wolpert2005,
  author    = {Wolpert, David H. and Macready, W. G.},
  journal   = {IEEE Transactions on Evolutionary Computation},
  title     = {Coevolutionary free lunches},
  year      = {2005},
  issn      = {1941-0026},
  month     = {12},
  number    = {6},
  pages     = {721--735},
  volume    = {9},
  abstract  = {Recent work on the foundational underpinnings of black-box optimization has begun to uncover a rich mathematical structure. In particular, it is now known that an inner product between the optimization algorithm and the distribution of optimization problems likely to be encountered fixes the distribution over likely performances in running that algorithm. One ramification of this is the "No Free Lunch" (NFL) theorems, which state that any two algorithms are equivalent when their performance is averaged across all possible problems. This highlights the need for exploiting problem-specific knowledge to achieve better than random performance. In this paper, we present a general framework covering most optimization scenarios. In addition to the optimization scenarios addressed in the NFL results, this framework covers multiarmed bandit problems and evolution of multiple coevolving players. As a particular instance of the latter, it covers "self-play" problems. In these problems, the set of players work together to produce a champion, who then engages one or more antagonists in a subsequent multiplayer game. In contrast to the traditional optimization case where the NFL results hold, we show that in self-play there are free lunches: in coevolution some algorithms have better performance than other algorithms, averaged across all possible problems. However, in the typical coevolutionary scenarios encountered in biology, where there is no champion, the NFL theorems still hold.},
  doi       = {10.1109/TEVC.2005.856205},
  file      = {:FILES/2005 - Wolpert2005 - Coevolutionary free lunches.pdf:PDF},
  groups    = {global optimization, TEC},
  keywords  = {evolutionary computation;game theory;decision making;coevolutionary free lunches;black box optimization;no free lunch theorem;multiarmed bandit problems;self-play problem;subsequent multiplayer game;Evolution (biology);Evolutionary computation;NASA;Sorting;Coevolution;multiarmed bandits;no free lunch;optimizations;self-play},
  timestamp = {2020-09-05},
}

@Article{Wolpert1997,
  author    = {Wolpert, D. H. and Macready, W. G.},
  journal   = {IEEE Transactions on Evolutionary Computation},
  title     = {No free lunch theorems for optimization},
  year      = {1997},
  issn      = {1941-0026},
  month     = {4},
  number    = {1},
  pages     = {67--82},
  volume    = {1},
  abstract  = {A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving. A number of "no free lunch" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. These theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization problem. Applications of the NFL theorems to information-theoretic aspects of optimization and benchmark measures of performance are also presented. Other issues addressed include time-varying optimization problems and a priori "head-to-head" minimax distinctions between optimization algorithms, distinctions that result despite the NFL theorems' enforcing of a type of uniformity over all algorithms.},
  doi       = {10.1109/4235.585893},
  file      = {:FILES/1997 - Wolpert1997 - No free lunch theorems for optimization.pdf:PDF},
  groups    = {global optimization, TEC},
  keywords  = {genetic algorithms;information theory;search problems;combinatorial mathematics;no free lunch theorems;optimization;elevated performance;geometric interpretation;information-theoretic aspects;time-varying optimization;a priori head-to-head minimax distinctions;Iron;Evolutionary computation;Information theory;Minimax techniques;Simulated annealing;Algorithm design and analysis;Performance analysis;Probability distribution;Bayesian methods},
  timestamp = {2020-09-05},
}

@Article{Consigli2002,
  author    = {Consigli, Giorgio},
  journal   = {Journal of Banking \& Finance},
  title     = {Tail estimation and mean-{CVaR} portfolio selection in markets subject to financial instability},
  year      = {2002},
  number    = {7},
  pages     = {1355--1382},
  volume    = {26},
  comment   = {\cite{BENATI2007milp} heuristics for VaR},
  file      = {:FILES/2002 - Consigli2002 - Tail estimation and mean–VaR portfolio selection in markets subject to financial instability.pdf:PDF},
  groups    = {cvar, TEC},
  timestamp = {2020-09-05},
}

@Misc{cplex,
  author       = {IBM},
  howpublished = {Online},
  title        = {{IBM ILOG CPLEX} {Optimization Studio} {V12.10.0} documentation},
  year         = {2020},
  groups       = {softwares, TEC},
  timestamp    = {2020-09-05},
  url          = {https://www.ibm.com/support/knowledgecenter/SSSA5P_12.10.0/COS_KC_home.html},
}

@Article{Lawrynczuk2019,
  author    = {Lawrynczuk, Maciej and Hou, Shiwang and Wen, Haijun and Feng, Shunxiao and Wang, Hui and Li, Zhibin},
  journal   = {Computational Intelligence and Neuroscience},
  title     = {Application of layered coding genetic algorithm in optimization of unequal area production facilities layout},
  year      = {2019},
  issn      = {1687-5265},
  pages     = {3650923},
  volume    = {2019},
  abstract  = {Unequal area facilities layout problem (UA-FLP) is an inevitable problem in the process of new construction, reconstruction, and expansion of enterprises. The rationality of the facilities layout has a great influence on the operation performance of the production system. Finding the optimal solution of UA-FLP according to the requirement of production process is the main content of the plant design. The facilities were constrained by given areas and aspect ratio, respectively. By adopting the method of slicing tree, the layout space was divided into multiple regions for each facility. The genetic algorithm was developed by using layered coding to show the slicing process. Considering the production logistics cost as well as the adjacency relations between the facilities, the goal function was established and the optimal solution was obtained by running the proposed algorithm. Finally, the feasibility of the proposed approach was validated by a set of known problems. The comparison results show that it can provide decision support for rapid optimal layout of multifacilities.},
  doi       = {10.1155/2019/3650923},
  file      = {:FILES/2019 - Lawrynczuk2019 - Application of layered coding genetic algorithm in optimization of unequal area production facilities layout.pdf:PDF},
  groups    = {genetic algorithms},
  publisher = {Hindawi},
  timestamp = {2020-09-05},
  url       = {https://doi.org/10.1155/2019/3650923},
}

@Article{Zhou2018,
  author    = {Zhou, Lin and Yu, Qianxiang and Liu, Daozhi and Li, Ming and Chi, Shukai and Liu, Lanjun},
  journal   = {Advances in Mechanical Engineering},
  title     = {Compressive sensing-based vibration signal reconstruction using sparsity adaptive subspace pursuit},
  year      = {2018},
  number    = {8},
  pages     = {1--12},
  volume    = {10},
  abstract  = {Wireless sensors produce large amounts of data in long-term online monitoring following the Shannon–Nyquist theorem, leading to a heavy burden on wireless communications and data storage. To address this problem, compressive sensing which allows wireless sensors to sample at a much lower rate than the Nyquist frequency has been considered. However, the lower rate sacrifices the integrity of the signal. Therefore, reconstruction from low-dimension measurement samples is necessary. Generally, the reconstruction needs the information of signal sparsity in advance, whereas it is usually unknown in practical applications. To address this issue, a sparsity adaptive subspace pursuit compressive sensing algorithm is deployed in this article. In order to balance the computational speed and estimation accuracy, a half-fold sparsity estimation method is proposed. To verify the effectiveness of this algorithm, several simulation tests were performed. First, the feasibility of subspace pursuit algorithm is verified using random sparse signals with five different sparsities. Second, the synthesized vibration signals for four different compression rates are reconstructed. The corresponding reconstruction correlation coefficient and root mean square error are demonstrated. The high correlation and low error result mean that the proposed algorithm can be applied in the vibration signal process. Third, implementation of the proposed approach for a practical vibration signal from an offshore structure is carried out. To reduce the effect of signal noise, the wavelet de-noising technique is used. Considering the randomness of the sampling, many reconstruction tests were carried out. Finally, to validate the reliability of the reconstructed signal, the structure modal parameters are calculated by the Eigensystem realization algorithm, and the result is only slightly different between original and reconstructed signal, which means that the proposed method can successfully save the modal information of vibration signals.},
  doi       = {10.1177/1687814018790877},
  eprint    = {https://doi.org/10.1177/1687814018790877},
  groups    = {Compressive sensing},
  timestamp = {2020-09-05},
  url       = {https://doi.org/10.1177/1687814018790877},
}

@Article{Michalewicz1996,
  author    = {Michalewicz, Z. and Schoenauer, M.},
  journal   = {Evolutionary Computation},
  title     = {Evolutionary algorithms for constrained parameter optimization problems},
  year      = {1996},
  issn      = {1063-6560},
  month     = {3},
  number    = {1},
  pages     = {1--32},
  volume    = {4},
  abstract  = {Evolutionary computation techniques have received a great deal of attention regarding their potential as optimization techniques for complex numerical functions. However, they have not produced a significant breakthrough in the area of nonlinear programming due to the fact that they have not addressed the issue of constraints in a systematic way. Only recently have several methods been proposed for handling nonlinear constraints by evolutionary algorithms for numerical optimization problems; however, these methods have several drawbacks, and the experimental results on many test cases have been disappointing. In this paper we (1) discuss difficulties connected with solving the general nonlinear programming problem; (2) survey several approaches that have emerged in the evolutionary computation community; and (3) provide a set of 11 interesting test cases that may serve as a handy reference for future methods.},
  doi       = {10.1162/evco.1996.4.1.1},
  file      = {:FILES/1996 - Michalewicz1996 - Evolutionary algorithms for constrained parameter optimization problems.pdf:PDF},
  groups    = {genetic algorithms},
  keywords  = {Parametric optimization;constraint handling;test functions},
  timestamp = {2020-09-05},
}

@Article{Venkatraman2005,
  author    = {Venkatraman, S. and Yen, G. G.},
  journal   = {IEEE Transactions on Evolutionary Computation},
  title     = {A generic framework for constrained optimization using genetic algorithms},
  year      = {2005},
  issn      = {1941-0026},
  month     = {8},
  number    = {4},
  pages     = {424--435},
  volume    = {9},
  abstract  = {In this paper, we propose a generic, two-phase framework for solving constrained optimization problems using genetic algorithms. In the first phase of the algorithm, the objective function is completely disregarded and the constrained optimization problem is treated as a constraint satisfaction problem. The genetic search is directed toward minimizing the constraint violation of the solutions and eventually finding a feasible solution. A linear rank-based approach is used to assign fitness values to the individuals. The solution with the least constraint violation is archived as the elite solution in the population. In the second phase, the simultaneous optimization of the objective function and the satisfaction of the constraints are treated as a biobjective optimization problem. We elaborate on how the constrained optimization problem requires a balance of exploration and exploitation under different problem scenarios and come to the conclusion that a nondominated ranking between the individuals will help the algorithm explore further, while the elitist scheme will facilitate in exploitation. We analyze the proposed algorithm under different problem scenarios using Test Case Generator-2 and demonstrate the proposed algorithm's capability to perform well independent of various problem characteristics. In addition, the proposed algorithm performs competitively with the state-of-the-art constraint optimization algorithms on 11 test cases which were widely studied benchmark functions in literature.},
  doi       = {10.1109/TEVC.2005.846817},
  file      = {:FILES/2005 - Venkatraman2005 -  A generic framework for constrained optimization using genetic algorithms.pdf:PDF},
  groups    = {genetic algorithms},
  keywords  = {constraint handling;genetic algorithms;operations research;constrained optimization problem;genetic algorithms;two-phase framework;constrained satisfaction;constraint satisfaction problem;genetic search;linear rank-based approach;least constraint violation;biobjective optimization problem;Constraint optimization;Genetic algorithms;Interference constraints;Performance evaluation;Performance analysis;Algorithm design and analysis;Character generation;Benchmark testing;Production;Cost function;Constrained optimization;constraint handling;genetic algorithm (GA);hyperheuristic},
  timestamp = {2020-09-05},
}

@Article{Chang2000,
  author     = {Chang, T.-J. and Meade, N. and Beasley, J. E. and Sharaiha, Y. M.},
  journal    = {Computers \& Operations Research},
  title      = {Heuristics for cardinality constrained portfolio optimisation},
  year       = {2000},
  issn       = {0305-0548},
  number     = {13},
  pages      = {1271--1302},
  volume     = {27},
  abstract   = {In this paper we consider the problem of finding the efficient frontier associated with the standard mean–variance portfolio optimisation model. We extend the standard model to include cardinality constraints that limit a portfolio to have a specified number of assets, and to impose limits on the proportion of the portfolio held in a given asset (if any of the asset is held). We illustrate the differences that arise in the shape of this efficient frontier when such constraints are present. We present three heuristic algorithms based upon genetic algorithms, tabu search and simulated annealing for finding the cardinality constrained efficient frontier. Computational results are presented for five data sets involving up to 225 assets. Scope and purpose The standard Markowitz mean–variance approach to portfolio selection involves tracing out an efficient frontier, a continuous curve illustrating the tradeoff between return and risk (variance). This frontier can be easily found via quadratic programming. This approach is well-known and widely applied. However, for practical purposes, it may be desirable to limit the number of assets in a portfolio, as well as imposing limits on the proportion of the portfolio devoted to any particular asset. If such constraints exist, the problem of finding the efficient frontier becomes much harder. This paper illustrates how, in the presence of such constraints, the efficient frontier becomes discontinuous. Three heuristic techniques are applied to the problem of finding this efficient frontier and computational results presented for a number of data sets which are made publicly available.},
  doi        = {https://doi.org/10.1016/S0305-0548(99)00074-X},
  file       = {:FILES/2000 - Chang2000 - Heuristics for cardinality constrained portfolio optimisation.pdf:PDF},
  groups     = {VaR, TEC},
  keywords   = {Portfolio optimisation, Efficient frontier, read},
  readstatus = {read},
  timestamp  = {2020-09-06},
  url        = {http://www.sciencedirect.com/science/article/pii/S030505489900074X},
}

@Article{Anagnostopoulos2011,
  author    = {Anagnostopoulos, Konstantinos P. and Mamanis, Georgios},
  journal   = {Computational Management Science},
  title     = {Multiobjective evolutionary algorithms for complex portfolio optimization problems},
  year      = {2011},
  issn      = {1619-6988},
  number    = {3},
  pages     = {259--279},
  volume    = {8},
  abstract  = {This paper investigates the ability of Multiobjective Evolutionary Algorithms (MOEAs), namely the Non-dominated Sorting Genetic Algorithm II (NSGA-II), Pareto Envelope-based Selection Algorithm (PESA) and Strength Pareto Evolutionary Algorithm 2 (SPEA2), for solving complex portfolio optimization problems. The portfolio optimization problem is a typical bi-objective optimization problem with objectives the reward that should be maximized and the risk that should be minimized. While reward is commonly measured by the portfolio’s expected return, various risk measures have been proposed that try to better reflect a portfolio’s riskiness or to simplify the problem to be solved with exact optimization techniques efficiently. However, some risk measures generate additional complexities, since they are non-convex, non-differentiable functions. In addition, constraints imposed by the practitioners introduce further difficulties since they transform the search space into a non-convex region. The results show that MOEAs, in general, are efficient and reliable strategies for this kind of problems, and their performance is independent of the risk function used.},
  doi       = {10.1007/s10287-009-0113-8},
  file      = {:FILES/2011 - Anagnostopoulos2011 - Multiobjective evolutionary algorithms for complex portfolio optimization problems.pdf:PDF},
  groups    = {VaR, TEC},
  timestamp = {2020-09-12},
  url       = {https://doi.org/10.1007/s10287-009-0113-8},
}

@Article{Nemirovski2007,
  author    = {Nemirovski, Arkadi and Shapiro, Alexander},
  journal   = {SIAM Journal on Optimization},
  title     = {Convex approximations of chance constrained programs},
  year      = {2007},
  number    = {4},
  pages     = {969--996},
  volume    = {17},
  abstract  = {We consider a chance constrained problem, where one seeks to minimize a convex objective over solutions satisfying, with a given close to one probability, a system of randomly perturbed convex constraints. This problem may happen to be computationally intractable; our goal is to build its computationally tractable approximation, i.e., an efficiently solvable deterministic optimization program with the feasible set contained in the chance constrained problem. We construct a general class of such convex conservative approximations of the corresponding chance constrained problem. Moreover, under the assumptions that the constraints are affine in the perturbations and the entries in the perturbation vector are independent‐of‐each‐other random variables, we build a large deviation‐type approximation, referred to as “Bernstein approximation,” of the chance constrained problem. This approximation is convex and efficiently solvable. We propose a simulation‐based scheme for bounding the optimal value in the chance constrained problem and report numerical experiments aimed at comparing the Bernstein and well‐known scenario approximation approaches. Finally, we extend our construction to the case of ambiguous chance constrained problems, where the random perturbations are independent with the collection of distributions known to belong to a given convex compact set rather than to be known exactly, while the chance constraint should be satisfied for every distribution given by this set. Read More: https://epubs.siam.org/doi/abs/10.1137/050622328},
  comment   = {VaR in the constraint.},
  doi       = {10.1137/050622328},
  eprint    = {https://doi.org/10.1137/050622328},
  file      = {:FILES/2007 - Nemirovski2007 - Convex approximations of chance constrained programs.pdf:PDF},
  groups    = {VaR},
  timestamp = {2020-09-06},
  url       = {https://doi.org/10.1137/050622328},
}

@Article{Tsyurmasto2014,
  author    = {Tsyurmasto, Peter and Zabarankin, Michael and Uryasev, Stan},
  journal   = {Journal of Combinatorial Optimization},
  title     = {Value-at-risk support vector machine: stability to outliers},
  year      = {2014},
  issn      = {1573-2886},
  number    = {1},
  pages     = {218--232},
  volume    = {28},
  abstract  = {A support vector machine (SVM) stable to data outliers is proposed in three closely related formulations, and relationships between those formulations are established. The SVM is based on the value-at-risk (VaR) measure, which discards a specified percentage of data viewed as outliers (extreme samples), and is referred to as $$\mathrm{VaR}$$VaR-SVM. Computational experiments show that compared to the $$\nu $$ν-SVM, the VaR-SVM has a superior out-of-sample performance on datasets with outliers.},
  doi       = {10.1007/s10878-013-9678-9},
  file      = {:FILES/2014 - Tsyurmasto2014 - Value-at-risk support vector machine- stability to outliers.pdf:PDF},
  groups    = {VaR, SVM},
  refid     = {Tsyurmasto2014},
  timestamp = {2020-09-06},
  url       = {https://doi.org/10.1007/s10878-013-9678-9},
}

@InBook{Gilli2008,
  author    = {Gilli, Manfred and Maringer, Dietmar and Winker, Peter},
  chapter   = {Applications of heuristics in finance},
  editor    = {Seese, Detlef and Weinhardt, Christof and Schlottmann, Frank},
  pages     = {635--653},
  publisher = {Springer Berlin Heidelberg},
  year      = {2008},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-49487-4},
  abstract  = {Having the optimal solution for a given problem is crucial in the competitive world of finance; finding this optimal solution, however, is often an utter challenge. Even if the problem is well defined and all necessary data are available, it is not always well behaved: rather simple constraints are often enough to prohibit closed form solutions or evade the reliable application of standard numerical solutions. A common way to avoid this difficulty is to restate the problem: restricting and cumbersome constraints are relaxed and simplifying assumptions are introduced until the revised problem is approachable with the available methods, and are afterwards superimposed onto the solution for the simplified problem. Unfortunately, subtleties as well as central properties of the initial problem can be lost in this process, and results assumed to be ideal can actually be far away from the true optimum.},
  booktitle = {Handbook on Information Technology in Finance},
  doi       = {10.1007/978-3-540-49487-4_26},
  file      = {:FILES/2008 - Gilli2008 - Applications of Heuristics in Finance.pdf:PDF},
  groups    = {VaR},
  url       = {https://doi.org/10.1007/978-3-540-49487-4_26},
}

@TechReport{Gilli2008a,
  author      = {Gilli, Manfred and Winker, Peter},
  institution = {COMISEF},
  title       = {Review of heuristic optimization methods in econometrics},
  year        = {2008},
  month       = {9},
  number      = {001},
  type        = {Working Papers},
  abstract    = {Estimation and modelling problems as they arise in many fields often turn out to be intractable by standard numerical methods. One way to deal with such a situation consists in simplifying models and procedures. However, the solutions to these simplified problems might not be satisfying. A different approach consists in applying optimization heuristics such as evolutionary algorithms (Simulated Annealing, Threshold Accepting), Neural Networks, Genetic Algorithms, Tabu Search, hybrid methods and many others, which have been developed over the last two decades. Although the use of these methods became more standard in several fields of sciences, their use in estimation and modelling in econometrics appears to be still limited. We present an introduction to heuristic optimization methods and provide some examples for which these methods are found to work efficiently.<br><small>(This abstract was borrowed from another version of this item.)</small>},
  file        = {:FILES/2008 - Gilli2008a - Review of Heuristic Optimization Methods in Econometrics.pdf:PDF},
  groups      = {VaR},
  url         = {https://ideas.repec.org/p/com/wpaper/001.html},
}

@Article{Sharma2015,
  author     = {Bhanu Sharma and Ruppa K. Thulasiram and Parimala Thulasiraman},
  journal    = {Journal of Risk Finance},
  title      = {Computing value-at-risk using genetic algorithm},
  year       = {2015},
  issn       = {1526-5943},
  pages      = {170--189},
  volume     = {16},
  abstract   = {urpose
Value-at-risk (VaR) is a risk measure of potential loss on a specific portfolio. The main uses of VaR are in risk management and financial reporting. Researchers are continuously looking for new and efficient ways to evaluate VaR, and the 2008 financial crisis has given further impetus to finding new and reliable ways of evaluating and using VaR. In this study, the authors use genetic algorithm (GA) to evaluate VaR and compare the results with conventional VaR techniques.

Design/methodology/approach
In essence, the authors propose two modifications to the standard GA: normalized population selection and strict population selection. For a typical set of simulation, eight chromosomes were used each with eight stored values, and the authors get eight values for VaR.

Findings
The experiments using data from four different market indices show that by adjusting the volatility, the VaR computed using GA is more conservative as compared to those computed using Monte Carlo simulation.

Research limitations/implications
The proposed methodology is designed for VaR computation only. This could be generalized for other applications.

Practical implications
This is achieved with much less cost of computation, and hence, the proposed methodology could be a viable practical approach for computing VaR.

Originality/value
The proposed methodology is simple and, at the same time, novel that could have far-reaching impact on practitioners.},
  comment    = {The main is to evaluate VaR, not optimize it. 


GA is real-coded, with roulette wheel selection, mutation with randonly selected bit and random value. recombination of parents as crossover(single point).

they propose a normalized population selection. (which normalizes the fitness of all individuals, so that the range for roulette is [0,1]).

They propose the strict population selection, i.e, replace the individuals whose fitness values are lower than threshold with the best individual.},
  doi        = {10.1108/jrf-09-2014-0132},
  file       = {:FILES/2015 - Sharma2015 - Computing value-at-risk using genetic algorithm.pdf:PDF},
  groups     = {VaR},
  issue      = {2},
  keywords   = {read},
  readstatus = {read},
}

@Article{Sukono2018,
  author     = {Sukono and Supian, S. and Napitupulu, H. and Hidayat, Yuyun and Putra, Adam Sukma},
  journal    = {Journal of Physics: Conference Series},
  title      = {The application of genetic algorithm optimization on quadratic investment portfolio without a risk-free asset under value-at-risk},
  year       = {2018},
  month      = {9},
  pages      = {012026},
  volume     = {1090},
  abstract   = {In this paper, we performed the Genetic Algorithm within problems of quadratic investment portfolio without a risk-free asset under Value-at-Risk. The limitation of this study is that the risk of an investment portfolio measured by Value-at-Risk, and each investor has the nature of risk aversion. To solve these problems: First, we established the mean vector and covariance matrix. The second step was to define the vector mean and covariance matrices for the formulation of Value-at-Risk of the investment portfolio. Third, using the mean vector and Value-at-Risk established the model. To complete the optimization problem, we performed the Genetic Algorithm. The results show that the trade-off between risk and expected return does not only depend on the type of investor but also on the size of the investment. The Genetic Algorithm certifies us the robust solution in the optimization problem because of its natural ability to locate the global minimal. Moreover, genetic algorithm can be used as an effective way in numerical completion of the optimization of quadratic investment portfolio. In a realistic investment situation, it has likely more constraints. For example, the restriction on short-selling, is need to be considered.},
  comment    = {This paper is not well written. 

It formualtes the portfolio as a quadratic programming problem, where the objective is the composition of the mean and VaR (VaR is expressed using the covariance matrix), and the constraint is only the inequality budget constraint. 

The GA is real-coded, with random crossover and mutation, Roulette wheel selection, (e^f), and no special treatment.},
  doi        = {10.1088/1742-6596/1090/1/012026},
  file       = {:FILES/2018 - Sukono2018 - The application of genetic algorithm optimization on quadratic investment portfolio without a risk-free asset under value-at-risk.pdf:PDF},
  groups     = {VaR},
  keywords   = {read},
  publisher  = {{IOP} Publishing},
  readstatus = {read},
  url        = {https://doi.org/10.1088%2F1742-6596%2F1090%2F1%2F012026},
}

@Article{Vladimir2014,
  author   = {Rankovi\'{c} Vladimir and Drenovak Mikica and Stojanovi\'{c} Boban and Kalini\'{c} Zoran and Arsovski Zora},
  journal  = {Computer Science and Information Systems},
  title    = {The mean-value at risk static portfolio optimization using genetic algorithm},
  year     = {2014},
  number   = {1},
  pages    = {89--109},
  volume   = {11},
  abstract = {In this paper we solve the problem of static portfolio allocation based on historical Value at Risk (VaR) by using genetic algorithm (GA). VaR is a predominantly used measure of risk of extreme quantiles in modern finance. For estimation of historical static portfolio VaR, calculation of time series of portfolio returns is required. To avoid daily recalculations of proportion of capital invested in portfolio assets, we introduce a novel set of weight parameters based on proportion of shares. Optimal portfolio allocation in the VaR context is computationally very complex since VaR is not a coherent risk metric while number of local optima increases exponentially with the number of securities. We presented two different single-objective and a multiobjective technique for generating mean-VaR efficient frontiers. Results document good risk/reward characteristics of solution portfolios while there is a trade-off between the ability to control diversity of solutions and computation time.},
  doi      = {https://doi.org/10.2298/CSIS121024017R},
  file     = {:FILES/2014 - Vladimir2014 - The mean-value at risk static portfolio optimization using genetic algorithm.pdf:PDF},
  groups   = {VaR},
  keywords = {genetic algorithm, static portfolio optimization, value at risk, mean-VaR efficient frontier},
  url      = {http://www.doiserbia.nb.rs/Article.aspx?ID=1820-02141400017R#.X1nRaigzaUk},
}

@Article{Jin2019ga,
  author         = {Jin, Zhuo and Yang, Zhixin and Yuan, Quan},
  journal        = {Risks},
  title          = {A genetic algorithm for investment–consumption optimization with value-at-risk constraint and information-processing cost},
  year           = {2019},
  issn           = {2227-9091},
  number         = {1},
  volume         = {7},
  abstract       = {This paper studies the optimal investment and consumption strategies in a two-asset model. A dynamic Value-at-Risk constraint is imposed to manage the wealth process. By using Value at Risk as the risk measure during the investment horizon, the decision maker can dynamically monitor the exposed risk and quantify the maximum expected loss over a finite horizon period at a given confidence level. In addition, the decision maker has to filter the key economic factors to make decisions. Considering the cost of filtering the factors, the decision maker aims to maximize the utility of consumption in a finite horizon. By using the Kalman filter, a partially observed system is converted to a completely observed one. However, due to the cost of information processing, the decision maker fails to process the information in an arbitrarily rational manner and can only make decisions on the basis of the limited observed signals. A genetic algorithm was developed to find the optimal investment, consumption strategies, and observation strength. Numerical simulation results are provided to illustrate the performance of the algorithm.},
  article-number = {32},
  doi            = {10.3390/risks7010032},
  file           = {:FILES/2019 - Jin2019ga - A Genetic Algorithm for Investment–Consumption Optimization with Value-at-Risk Constraint and Information-Processing Cost.pdf:PDF},
  groups         = {VaR},
  keywords       = {genetic algorithm; investment; Value-at-Risk; rational inattention},
  url            = {https://www.mdpi.com/2227-9091/7/1/32},
}

@MastersThesis{Movahed2019,
  author   = {Saber Bayat Movahed and Sina Fanian},
  school   = {Simon Fraser University},
  title    = {Optimum portfolio construction considering value at risk using genetic algorithms and {Monte} {Carlo} simulation},
  year     = {2019},
  month    = dec,
  type     = {mathesis},
  abstract = {Determining the best portfolio out of set of alternative investment opportunities to optimize risk-adjusted return and value-at-risk simultaneously is a challenging issue for many practitioners. In recent years, the application of non-conventional methods for portfolio optimization problems has grown in importance in the investment industry. As an effective alternative to traditional optimization techniques for handling the computationally complicated portfolio optimization problems, many nature-inspired optimization methods have emerged and have been developed by researchers. In this thesis, a novel algorithm is suggested to construct a promising portfolio in terms of Mean return- VaR and Sharpe ratio-VaR from a limited number of securities from a set of available equities. The algorithm consist of three stages of refining. The first stage is to select 60 stocks out of all the securities in S\&P500 index based on fundamental factors using factor analysis. In the second stage, the proposed algorithm employs a Markowitz' mean-variance optimization model to refine the quality of initial population of portfolios of 30 stocks and improve the convergence behaviour of the algorithm. And in the third stage, a state-of-the-art genetic algorithm is applied to determine an optimized portfolio of assets in terms of risk-adjusted return and value at risk. The novel genetic algorithm developed in this research benefits from an innovative solution representation which make GA searches over both discrete and continuous variables in the problem of optimizing stock and industry selection and weight allocation. In this study, the outperformance and effectiveness of the proposed algorithm are demonstrated by comparing annual return, annual volatility, Sharpe ratio, Jensen's alpha and beta of a constructed portfolio with the S\&P 500 index and Mean-Variance constructed portfolio. The robustness of our evolutionary algorithm is verified by evaluation of the results in both in-sample and out-sample data.},
  comment  = {objective: mean-variance
constraints: budget, quantity, expected return.},
  file     = {:FILES/2019 - Movahed2019 - Optimum portfolio construction considering value at risk using genetic algorithms and {Monte} {Carlo} simulation.pdf:PDF},
  groups   = {VaR},
  url      = {http://summit.sfu.ca/item/19580},
}

@Article{Samuel2012GA,
  author   = {Samuel Baixauli-Soler, J. and Alfaro-Cid, Eva and Fernandez-Blanco, Matilde O.},
  journal  = {Investigaciones Europeas de Dirección y Economía de la Empresa},
  title    = {A na\"{i}ve approach to speed up portfolio optimization problem using a multiobjective genetic algorithm},
  year     = {2012},
  issn     = {1135-2523},
  number   = {2},
  pages    = {126--131},
  volume   = {18},
  abstract = {Genetic algorithms (GAs) are appropriate when investors have the objective of obtaining mean-variance (VaR) efficient frontier as minimising VaR leads to non-convex and non-differential risk-return optimisation problems. However GAs are a time-consuming optimisation technique. In this paper, we propose to use a naïve approach consisting of using samples split by quartile of risk to obtain complete efficient frontiers in a reasonable computation time. Our results show that using reduced problems which only consider a quartile of the assets allow us to explore the efficient frontier for a large range of risk values. In particular, the third quartile allows us to obtain efficient frontiers from the 1.8\% to 2.5\% level of VaR quickly, while that of the first quartile of assets is from 1\% to 1.3\% level of VaR. Resumen Los algoritmos genéticos son apropiados cuando los inversores tienen el propósito de obtener la frontera eficiente media-VaR, ya que minimizar el VaR ocasiona que el problema de optimización rentabilidad-riesgo no sea ni convexo ni diferencial. Sin embargo, los algoritmos genéticos son una técnica de optimización que exige mucho tiempo de computación. En este artículo proponemos usar una aproximación naïve, consistente en dividir la muestra por cuartiles de riesgo para obtener la frontera eficiente en un tiempo razonable. Nuestros resultados muestran que usando problemas reducidos que sólo consideran un cuartil de los activos podemos explorar la frontera eficiente para un mayor número de niveles de riesgo. Concretamente, la muestra del tercer cuartil permite obtener rápidamente fronteras eficientes con un VaR entre el 1,8 y el 2,5\%, mientras que el primer cuartil permite obtener las carteras eficientes con niveles de VaR entre el 1 y el 1,3\%.},
  doi      = {https://doi.org/10.1016/S1135-2523(12)70002-3},
  file     = {:FILES/2012 - Samuel2012GA - A naïve approach to speed up portfolio optimization problem using a multiobjective genetic algorithm.pdf:PDF},
  groups   = {VaR},
  keywords = {Efficient portfolio, Genetic algorithm, Value-at-Risk, Cartera eficiente, Algoritmo genético, Valor en riesgo},
  url      = {http://www.sciencedirect.com/science/article/pii/S1135252312700023},
}

@Article{Wang2015,
  author     = {Wang, Yuping and Wang, Weijia and Hu, Jie and Dong, Ning},
  journal    = {Mathematical Problems in Engineering},
  title      = {A convex-risk-measure based model and genetic algorithm for portfolio selection},
  year       = {2015},
  issn       = {1024-123X},
  pages      = {451627},
  volume     = {2015},
  abstract   = {A convex risk measure called weighted expected shortfall (briefly denoted as WES (Chen and Yang, 2011)) is adopted as the risk measure. This measure can reflect the reasonable risk in the stock markets. Then a portfolio optimization model based on this risk measure is set up. Furthermore, a genetic algorithm is proposed for this portfolio optimization model. At last, simulations are made on randomly chosen ten stocks for 60 days (during January 2, 2014 to April 2, 2014) from Wind database (CFD) in Shenzhen Stock Exchange, and the results indicate that the proposed model is reasonable and the proposed algorithm is effective.},
  comment    = {they propose weighted expected short fall as the risk measure, which is convex. The constraints are budget, quantity, no short fall, and expected return. 

the proposed crossover might be a random linear combination of each bits, the combination factor might be different for differnt bits.

Mutation is specially design. not looked into.

No constraint handling is given.},
  doi        = {10.1155/2015/451627},
  file       = {:FILES/2015 - Wang2015 - A convex-risk-measure based model and genetic algorithm for portfolio selection.pdf:PDF},
  groups     = {expected shortfall},
  keywords   = {read},
  publisher  = {Hindawi Publishing Corporation},
  readstatus = {read},
  url        = {https://doi.org/10.1155/2015/451627},
}

@Article{Mostafa2016,
  author     = {El Hachloufi Mostafa and El Haddad Mohammed and El Attar Abderrahim3},
  journal    = {Journal of Applied Finance \& Banking},
  title      = {Minimization of Value at Risk of Financial Assets Portfolio using Genetic Algorithms and Neural Networks},
  year       = {2016},
  issn       = {1792-6580},
  number     = {2},
  pages      = {39--52},
  volume     = {6},
  abstract   = {In this paper we have proposed an approach for minimization of a shares portfolio invested in a market which the fluctuations follow a normal distribution based in amathematical explicit formulae for calculating Value at Risk (VaR) for portfolios of linear financial assets invested using the Black-Scholes stochastic process and assuming that the portfolio structure remains constant over the considered time horizon. We minimize this Value at Risk using neural networks and genetic algorithms.
… Read more},
  comment    = {It uses the Black-Scholes stochastic differential equation to describe the dynamics of portfolio decision. And the problem is solved via GA and NN.

The VaR is expressed as a quadratic problem using the mean and covariance of returns. It considers dividend. with expected return, no short sell, budget, and risk constraints. The risk constraint is the VaR with a bounded value obtained using NN.

GA and NN takes turns to function where the output of one is the initialization of the other. 

NN accepts the input of portfolios, and the output is VaR. It finds the dynamics of the portfolio decision.

GA is real-coded for the portfolios. roulette wheel selection. single point crossover. Mutation: randomly choose a gene and replace it with a random number.

It doesnot consider the handling of constraints.},
  file       = {:FILES/2016 - Mostafa2016 - Minimization of Value at Risk of Financial Assets Portfolio using Genetic Algorithms and Neural Networks.pdf:PDF},
  groups     = {VaR, time series},
  keywords   = {read},
  readstatus = {read},
  url        = {http://www.scienpress.com/Upload/JAFB/Vol 6_2_3.pdf},
}

@Article{Ghoreishi2018,
  author     = {Ghoreishi, S. Amir and khaloozadeh, hamid},
  journal    = {International Journal of Business and Development Studies},
  title      = {Optimal portfolio allocation based on two novel risk measures and genetic algorithm},
  year       = {2018},
  issn       = {2008-448X},
  number     = {1},
  pages      = {95--113},
  volume     = {10},
  abstract   = {The problem of optimal portfolio selection has attracted a great attention in the finance and optimization field. The future stock price should be predicted in an acceptable precision, and a suitable model and criterion for risk and the expected return of the stock portfolio should be proposed in order to solve the optimization problem. In this paper, two new criterions for the risk of stock price prediction has been presented, of which the first one is based on the interval predictions which vary with time and proportional to the uncertainty of stock price data, while the second one is a constant risk term that is proportional to the prediction error variances of the neural networks. A novel cost function has been presented to simultaneously consider the expected returns and risks. Genetic algorithm has been used to solve this optimization problem. Finally, 18 shares of the Tehran Stock Exchange have been considered to evaluate the performance of the proposed risk criterions. Two proposed risk criteria, by the conditional value at risk (CVaR) associated with the same stock. The problem of stock portfolio optimization has been solved for all three situations, and the PI-based risk criteria yielded a better return},
  comment    = {This uses NN to predict future returns of length $n$.},
  doi        = {10.22111/ijbds.2018.4056},
  eprint     = {https://ijbds.usb.ac.ir/article_4056_6a61144ea519ec3a0274c2b5ce8addc6.pdf},
  file       = {:FILES/2018 - Ghoreishi2018 - Optimal portfolio allocation based on two novel risk measures and genetic algorithm.pdf:PDF},
  groups     = {time series},
  keywords   = {Stock Portfolio Optimization, Interval Prediction Neural Networks, Conditional Value at Risk, Risk measure, skimmed},
  publisher  = {University of Sistan and Balouchestan},
  readstatus = {skimmed},
  url        = {https://ijbds.usb.ac.ir/article_4056.html},
}

@Article{Lin2012,
  author   = {Lin, Ping-Chen},
  journal  = {Journal of Industrial \& Management Optimization},
  title    = {Portfolio optimization and risk measurement based on non-dominated sorting genetic algorithm},
  year     = {2012},
  issn     = {1547-5816},
  number   = {1547-5816_2012_3_549},
  pages    = {549},
  volume   = {8},
  abstract = {This paper introduces a multi-objective genetic algorithm (MOGA) in regard to the portfolio optimization issue in different risk measures, such as mean-variance, semi-variance, mean-variance-skewness, mean-absolute-deviation and lower-partial-moment to optimize risk of portfolio. This study introduces a PONSGA model by appling the non-dominated sorting genetic algorithm (NSGA-II) to maximize both the expected return and the skewness of portfolio as well as to simultaneously minimize different portfolio risks. The experimental results demonstrated that the PONSGA approach is significantly superior to the GA in all performances, examined such as the coefficient of variation, Sharpe index, Sortino index and portfolio performance index. The statistical significance tests also showed that the NSGA-II models outperformed the GA models in different risk measures.},
  doi      = {10.3934/jimo.2012.8.549},
  file     = {:FILES/2012 - Lin2012 - Portfolio optimization and risk measurement based on non-dominated sorting genetic algorithm.pdf:PDF},
  groups   = {VaR},
  keywords = {49 and 90.},
  url      = {http://aimsciences.org//article/id/2769ef10-ad7a-4376-832e-a9343bdbd10b},
}

@Article{Lin2008,
  author    = {Lin, Chang-Chun and Liu, Yi-Ting},
  journal   = {European Journal of Operational Research},
  title     = {Genetic algorithms for portfolio selection problems with minimum transaction lots},
  year      = {2008},
  issn      = {0377-2217},
  number    = {1},
  pages     = {393--404},
  volume    = {185},
  abstract  = {Conventionally, portfolio selection problems are solved with quadratic or linear programming models. However, the solutions obtained by these methods are in real numbers and difficult to implement because each asset usually has its minimum transaction lot. Methods considering minimum transaction lots were developed based on some linear portfolio optimization models. However, no study has ever investigated the minimum transaction lot problem in portfolio optimization based on Markowitz’ model, which is probably the most well-known and widely used. Based on Markowitz’ model, this study presents three possible models for portfolio selection problems with minimum transaction lots, and devises corresponding genetic algorithms to obtain the solutions. The results of the empirical study show that the portfolios obtained using the proposed algorithms are very close to the efficient frontier, indicating that the proposed method can obtain near optimal and also practically feasible solutions to the portfolio selection problem in an acceptable short time. One model that is based on a fuzzy multi-objective decision-making approach is highly recommended because of its adaptability and simplicity.},
  comment   = {GA to optimize with transaction cost},
  doi       = {https://doi.org/10.1016/j.ejor.2006.12.024},
  file      = {:FILES/2008 - Lin2008 - Genetic algorithms for portfolio selection problems with minimum transaction lots.pdf:PDF},
  groups    = {algorithms},
  keywords  = {Portfolio selection, Markowitz model, Minimum transaction lots, Genetic algorithm, Fuzzy multi-objective decision making, prio2},
  priority  = {prio2},
  timestamp = {2020-09-12},
  url       = {http://www.sciencedirect.com/science/article/pii/S0377221707000057},
}

@Article{Anagnostopoulos2010,
  author    = {Anagnostopoulos, K. P. and Chatzoglou, P. D. and Katsavounis, S.},
  journal   = {Managerial Finance},
  title     = {A reactive greedy randomized adaptive search procedure for a mixed integer portfolio optimization problem},
  year      = {2010},
  month     = {10},
  number    = {12},
  pages     = {1057--1065},
  volume    = {36},
  abstract  = {Purpose - The purpose of this paper is to present a procedure for finding the efficient frontier, i.e. a non-decreasing curve representing the set of Pareto-optimal or non-dominated portfolios, when the standard Markowitz' classical mean-variance model is enriched with additional constraints. Design/methodology/approach - The mean-variance portfolio optimization model is extended to include integer constraints that limit a portfolio to have a specified number of assets, and to impose limits on the proportion of the portfolio held in a given asset. Optimization-based procedures run into difficulties in this framework and this motivates the investigation of heuristic algorithms to find acceptable solutions. Findings - The problem is solved by a greedy randomized adaptive search procedure (GRASP), enhanced by a learning mechanism and a bias function for determining the next element to be introduced in the solution. Originality/value - This is believed to be the first time, a GRASP for finding the efficient frontier for this class of portfolio selection problems is used.},
  comment   = {heuristic for portfolio selection, using GRASP with learning mechanism and a bias function},
  file      = {:FILES/2010 - Anagnostopoulos2010 - A reactive greedy randomized adaptive search procedure for a mixed integer portfolio optimization problem.pdf:PDF},
  groups    = {algorithms},
  keywords  = {Portfolio investment; Optimization techniques; Modelling, prio2},
  priority  = {prio2},
  timestamp = {2020-09-12},
  url       = {https://ideas.repec.org/a/eme/mfipps/v36y2010i12p1057-1065.html},
}

@Article{Maringer2003,
  author    = {Maringer, Dietmar and Kellerer, Hans},
  journal   = {OR Spectrum},
  title     = {Optimization of cardinality constrained portfolios with a hybrid local search algorithm},
  year      = {2003},
  issn      = {1436-6304},
  number    = {4},
  pages     = {481--495},
  volume    = {25},
  abstract  = {One of the main advantages of portfolios over single assets is that risk can be diversified without necessarily reducing the expected return - provided "proper" assets are selected and they are assigned the "proper" weights. Since in practice investors tend to restrict themselves to a rather small number of different assets, the decision which securities to include is a crucial one that turns out to be NP-hard.},
  comment   = {using SA and evolutionary strategies},
  doi       = {10.1007/s00291-003-0139-1},
  file      = {:FILES/2003 - Maringer2003 - Optimization of cardinality constrained portfolios with a hybrid local search algorithm.pdf:PDF},
  groups    = {algorithms},
  keywords  = {prio2},
  priority  = {prio2},
  refid     = {Maringer2003},
  timestamp = {2020-09-12},
  url       = {https://doi.org/10.1007/s00291-003-0139-1},
}

@Article{Crama2003,
  author    = {Crama, Y. and Schyns, M.},
  journal   = {European Journal of Operational Research},
  title     = {Simulated annealing for complex portfolio selection problems},
  year      = {2003},
  issn      = {0377-2217},
  note      = {Financial Modelling},
  number    = {3},
  pages     = {546--571},
  volume    = {150},
  abstract  = {This paper describes the application of a simulated annealing approach to the solution of a complex portfolio selection model. The model is a mixed integer quadratic programming problem which arises when Markowitz’ classical mean–variance model is enriched with additional realistic constraints. Exact optimization algorithms run into difficulties in this framework and this motivates the investigation of heuristic techniques. Computational experiments indicate that the approach is promising for this class of problems.},
  comment   = {SA with trading and turnover constraints},
  doi       = {https://doi.org/10.1016/S0377-2217(02)00784-1},
  file      = {:FILES/2003 - Crama2003 - Simulated annealing for complex portfolio selection problems.pdf:PDF},
  groups    = {algorithms},
  keywords  = {Finance, Simulated annealing, Metaheuristics, Portfolio selection, Quadratic programming, prio1},
  priority  = {prio1},
  timestamp = {2020-09-12},
  url       = {http://www.sciencedirect.com/science/article/pii/S0377221702007841},
}

@Article{Schaerf2002,
  author    = {Schaerf, Andrea},
  journal   = {Computational Economics},
  title     = {Local Search Techniques for Constrained Portfolio Selection Problems},
  year      = {2002},
  issn      = {1572-9974},
  number    = {3},
  pages     = {177--190},
  volume    = {20},
  abstract  = {We consider the problem of selecting a portfolio of assets that provides theinvestor a suitable balance of expected return and risk. With respect to theseminal mean-variance model of Markowitz, we consider additionalconstraints on the cardinality of the portfolio and on the quantity ofindividual shares. Such constraints better capture the real-world tradingsystem, but make the problem more difficult to be solved with exact methods.We explore the use of local search techniques, mainly tabu search, for theportfolio selection problem. We compare the combine previous work on portfolioselection that makes use of the local search approach and we propose newalgorithms that combine different neighborhood relations. In addition, we showhow the use of randomization and of a simple form of adaptiveness simplifiesthe setting of a large number of critical parameters. Finally, we show how ourtechniques perform on public benchmarks.},
  comment   = {SA, tabu search and hill climbing},
  doi       = {10.1023/A:1020920706534},
  file      = {:FILES/2002 - Schaerf2002 - Local Search Techniques for Constrained Portfolio Selection Problems.pdf:PDF},
  groups    = {algorithms},
  keywords  = {prio2},
  priority  = {prio2},
  refid     = {Schaerf2002},
  timestamp = {2020-09-12},
  url       = {https://doi.org/10.1023/A:1020920706534},
}

@Article{Jobst2001,
  author    = {Jobst, N. J. and Horniman, M. D. and Lucas, C. A. and Mitra, G.},
  journal   = {null},
  title     = {Computational aspects of alternative portfolio selection models in the presence of discrete asset choice constraints},
  year      = {2001},
  issn      = {1469-7688},
  month     = may,
  number    = {5},
  pages     = {489--501},
  volume    = {1},
  abstract  = {We consider the mean-variance (M-V) model of Markowitz and the construction of the risk-return efficient frontier. We examine the effects of applying buy-in thresholds, cardinality constraints and transaction roundlot restrictions to the portfolio selection problem. Such discrete constraints are of practical importance but make the efficient frontier discontinuous. The resulting quadratic mixed-integer (QMIP) problems are NP-hard and therefore computing the entire efficient frontier is computationally challenging. We propose alternative approaches for computing this frontier and provide insight into its discontinuous structure. Computational results are reported for a set of benchmark test problems.},
  comment   = {B\&B with heuristics},
  doi       = {10.1088/1469-7688/1/5/301},
  file      = {:FILES/2001 - Jobst2001 - Computational aspects of alternative portfolio selection models in the presence of discrete asset choice constraints.pdf:PDF},
  groups    = {algorithms},
  keywords  = {prio2},
  priority  = {prio2},
  publisher = {Routledge},
  timestamp = {2020-09-12},
  url       = {https://doi.org/10.1088/1469-7688/1/5/301},
}

@TechReport{MGI2011,
  author      = {James Manyika and Michael Chui and Brad Brown and Jacques Bughin and Richard Dobbs and Charles Roxburgh and Angela Hung Byers},
  institution = {McKinsey Global Institute},
  title       = {Big data: {The} next frontier for innovation, competition, and productivity},
  year        = {2011},
  month       = may,
  groups      = {industry report},
  url         = {https://www.mckinsey.com/~/media/McKinsey/Business Functions/McKinsey Digital/Our Insights/Big data The next frontier for innovation/MGI_big_data_full_report.pdf},
}

@Article{Edgeworth1887,
  author    = {Edgeworth, F. Y.},
  journal   = {Hermathena},
  title     = {On observations relating to several quantities},
  year      = {1887},
  issn      = {00180750},
  number    = {13},
  pages     = {279--285},
  volume    = {6},
  groups    = {regression},
  publisher = {Trinity College Dublin},
  url       = {http://www.jstor.org/stable/23036355},
}

@Article{Bertsimas2014,
  author    = {Bertsimas, Dimitris and Mazumder, Rahul},
  journal   = {Annals of Statistics},
  title     = {Least quantile regression via modern optimization},
  year      = {2014},
  month     = {12},
  number    = {6},
  pages     = {2494--2525},
  volume    = {42},
  doi       = {10.1214/14-AOS1223},
  file      = {:FILES/2014 - Bertsimas2014 - Least quantile regression via modern optimization.pdf:PDF},
  groups    = {LMS},
  keywords  = {prio1},
  priority  = {prio1},
  publisher = {The Institute of Mathematical Statistics},
  url       = {https://doi.org/10.1214/14-AOS1223},
}

@Article{Giloni2002,
  author   = {Giloni, A. and Padberg, M.},
  journal  = {Mathematical and Computer Modelling},
  title    = {Least trimmed squares regression, least median squares regression, and mathematical programming},
  year     = {2002},
  issn     = {0895-7177},
  number   = {9},
  pages    = {1043--1060},
  volume   = {35},
  abstract = {In this paper, we study LTS and LMS regression, two high breakdown regression estimators, from an optimization point of view. We show that LTS regression is a nonlinear optimization problem that can be treated as a concave minimization problem over a polytope. We derive several important properties of the corresponding objective function that can be used to obtain algorithms for the exact solution of LTS regression problems, i.e., to find a global optimum to the problem. Because of today's limited problem-solving capabilities in exact concave minimization, we give an easy-to-implement pivoting algorithm to determine regression parameters corresponding to local optima of the LTS regression problem. For the LMS regression problem, we briefly survey the existing solution methods which are all based on enumeration. We formulate the LMS regression problem as a mixed zero-one linear programming problem which we analyze in depth to obtain theoretical insights required for future algorithmic and computational work.},
  doi      = {https://doi.org/10.1016/S0895-7177(02)00069-9},
  file     = {:FILES/2002 - Giloni2002 - Least trimmed squares regression, least median squares regression, and mathematical programming.pdf:PDF},
  groups   = {LMS},
  keywords = {LTS and LMS regression, Robust regression, Breakdown point, Global optimization, Mixed integer programming},
  url      = {http://www.sciencedirect.com/science/article/pii/S0895717702000699},
}

@TechReport{Bernholt2006,
  author      = {Bernholt, Thorsten and Informatik, Lehrstuhl},
  institution = {Universit\"{a}t Dortmund, Germany},
  title       = {Robust estimators are hard to compute},
  year        = {2006},
  file        = {:FILES/2006 - Bernholt2006 - Robust estimators are hard to compute.pdf:PDF},
  groups      = {LMS},
}

@Article{Erickson2006,
  author   = {Erickson, Jeff and Har-Peled, Sariel and Mount, David M.},
  journal  = {Discrete \& Computational Geometry},
  title    = {On the least median square problem},
  year     = {2006},
  issn     = {1432-0444},
  number   = {4},
  pages    = {593--607},
  volume   = {36},
  abstract = {We consider the exact and approximate computational complexity of the multivariate least median-of-squares (LMS) linear regression estimator. The LMS estimator is among the most widely used robust linear statistical estimators. Given a set of n points in ${\Bbb R}^d$and a parameter k, the problem is equivalent to computing the narrowest slab bounded by two parallel hyperplanes that contains k of the points.  We present algorithms for the exact and approximate versions of the multivariate LMS problem.  We also provide nearly matching lower bounds for these problems. These lower bounds hold under the assumptions that k is Ω(n) and that deciding whether n given points in ${\Bbb R}^d$are affinely non-degenerate requires Ω(nd) time.},
  doi      = {10.1007/s00454-006-1267-6},
  file     = {:FILES/2006 - Erickson2006 - On the least median square problem.pdf:PDF},
  groups   = {LMS},
  url      = {https://doi.org/10.1007/s00454-006-1267-6},
}

@Article{Mount2007,
  author   = {Mount, David M. and Netanyahu, Nathan S. and Romanik, Kathleen and Silverman, Ruth and Wu, Angela Y.},
  journal  = {Computational Statistics \& Data Analysis},
  title    = {A practical approximation algorithm for the {LMS} line estimator},
  year     = {2007},
  issn     = {0167-9473},
  number   = {5},
  pages    = {2461--2486},
  volume   = {51},
  abstract = {The problem of fitting a straight line to a finite collection of points in the plane is an important problem in statistical estimation. Robust estimators are widely used because of their lack of sensitivity to outlying data points. The least median-of-squares (LMS) regression line estimator is among the best known robust estimators. Given a set of n points in the plane, it is defined to be the line that minimizes the median squared residual or, more generally, the line that minimizes the residual of any given quantile q, where 0<q⩽1. This problem is equivalent to finding the strip defined by two parallel lines of minimum vertical separation that encloses at least half of the points. The best known exact algorithm for this problem runs in O(n2) time. We consider two types of approximations, a residual approximation, which approximates the vertical height of the strip to within a given error bound εr⩾0, and a quantile approximation, which approximates the fraction of points that lie within the strip to within a given error bound εq⩾0. We present two randomized approximation algorithms for the LMS line estimator. The first is a conceptually simple quantile approximation algorithm, which given fixed q and εq>0 runs in O(nlogn) time. The second is a practical algorithm, which can solve both types of approximation problems or be used as an exact algorithm. We prove that when used as a quantile approximation, this algorithm's expected running time is O(nlog2n). We present empirical evidence that the latter algorithm is quite efficient for a wide variety of input distributions, even when used as an exact algorithm.},
  doi      = {https://doi.org/10.1016/j.csda.2006.08.033},
  file     = {:FILES/2007 - Mount2007 - A practical approximation algorithm for the {LMS} line estimator.pdf:PDF},
  groups   = {LMS},
  keywords = {Least median-of-squares regression, Robust estimation, Line fitting, Approximation algorithms, Randomized algorithms, Line arrangements},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167947306002921},
}

@Article{Mount2000,
  author   = {Mount, David M. and Nethanyahu, Nathan S. and Piatko, Christine D. and Silverman, Ruth and Wu, Angela Y.},
  journal  = {International Journal of Computational Geometry \& Applications},
  title    = {Quantile approximation for robust statistical estimation and $k$-enclosing problems},
  year     = {2000},
  number   = {06},
  pages    = {593--608},
  volume   = {10},
  abstract = {Given a set P of n points in Rd, a fundamental problem in computational geometry is concerned with finding the smallest shape of some type that encloses all the points of P. Well-known instances of this problem include finding the smallest enclosing box, minimum volume ball, and minimum volume annulus. In this paper we consider the following variant: Given a set of n points in Rd, find the smallest shape in question that contains at least k points or a certain quantile of the data. This type of problem is known as a k-enclosing problem. We present a simple algorithmic framework for computing quantile approximations for the minimum strip, ellipsoid, and annulus containing a given quantile of the points. The algorithms run in O(n log n) time.},
  doi      = {10.1142/S0218195900000334},
  eprint   = {https://doi.org/10.1142/S0218195900000334},
  file     = {:FILES/2000 - Mount2000 - Quantile approximation for robust statistical estimation and k-enclosing problems.pdf:PDF},
  groups   = {LMS},
  url      = {https://doi.org/10.1142/S0218195900000334},
}

@Article{Nunkesser2010,
  author   = {Nunkesser, Robin and Morell, Oliver},
  journal  = {Computational Statistics \& Data Analysis},
  title    = {An evolutionary algorithm for robust regression},
  year     = {2010},
  issn     = {0167-9473},
  number   = {12},
  pages    = {3242--3248},
  volume   = {54},
  abstract = {A drawback of robust statistical techniques is the increased computational effort often needed as compared to non-robust methods. Particularly, robust estimators possessing the exact fit property are NP-hard to compute. This means that—under the widely believed assumption that the computational complexity classes NP and P are not equal—there is no hope to compute exact solutions for large high dimensional data sets. To tackle this problem, search heuristics are used to compute NP-hard estimators in high dimensions. A new evolutionary algorithm that is applicable to different robust estimators is presented. Further, variants of this evolutionary algorithm for selected estimators—most prominently least trimmed squares and least median of squares—are introduced and shown to outperform existing popular search heuristics in difficult data situations. The results increase the applicability of robust methods and underline the usefulness of evolutionary algorithms for computational statistics.},
  doi      = {https://doi.org/10.1016/j.csda.2010.04.017},
  file     = {:FILES/2010 - Nunkesser2010 - An evolutionary algorithm for robust regression.pdf:PDF},
  groups   = {LMS},
  keywords = {Random search heuristics, Robust regression, Least trimmed squares (LTS), Least median of squares (LMS), Least quantile of squares (LQS), Least quartile difference (LQD)},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167947310001623},
}

@InProceedings{Bernholt2005,
  author    = {Bernholt, Thorsten},
  booktitle = {Computational Science and Its Applications -- ICCSA 2005},
  title     = {Computing the least median of squares estimator in time $o(n^d)$},
  year      = {2005},
  address   = {Berlin, Heidelberg},
  editor    = {Gervasi, Osvaldo and Gavrilova, Marina L. and Kumar, Vipin and Lagan\`{a}, Antonio and Lee, Heow Pueh and Mun, Youngsong and Taniar, David and Tan, Chih Jeng Kenneth},
  pages     = {697--706},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {In modern statistics, the robust estimation of parameters of a regression hyperplane is a central problem, i. e., an estimation that is not or only slightly affected by outliers in the data. In this paper we will consider the least median of squares (LMS) estimator. For n points in d dimensions we describe a randomized algorithm for LMS running in O(nd) time and O(n) space, for d fixed, and in time O(d3(2n)d) and O(dn) space, for arbitrary d.},
  doi       = {https://doi.org/10.1007/11424758_72},
  file      = {:FILES/2005 - Bernholt2005 - Computing the least median of squares estimator in time $o(n^d)$.pdf:PDF},
  groups    = {LMS},
  isbn      = {978-3-540-32043-2},
  keywords  = {Intersection Point, Computational Geometry, Breakdown Point, Extended Space. Quantile Approximation},
  url       = {https://link.springer.com/chapter/10.1007/11424758_72},
}

@Article{Zioutas2005,
  author   = {Zioutas, Georgios and Avramidis, Antonios},
  journal  = {Acta Mathematicae Applicatae Sinica},
  title    = {Deleting outliers in robust regression with mixed integer programming},
  year     = {2005},
  issn     = {1618-3932},
  number   = {2},
  pages    = {323--334},
  volume   = {21},
  abstract = {In robust regression we often have to decide how many are the unusual observations, which should be removed from the sample in order to obtain better fitting for the rest of the observations. Generally, we use the basic principle of LTS, which is to fit the majority of the data, identifying as outliers those points that cause the biggest damage to the robust fit. However, in the LTS regression method the choice of default values for high break down-point affects seriously the efficiency of the estimator. In the proposed approach we introduce penalty cost for discarding an outlier, consequently, the best fit for the majority of the data is obtained by discarding only catastrophic observations. This penalty cost is based on robust design weights and high break down-point residual scale taken from the LTS estimator. The robust estimation is obtained by solving a convex quadratic mixed integer programming problem, where in the objective function the sum of the squared residuals and penalties for discarding observations is minimized. The proposed mathematical programming formula is suitable for small-sample data. Moreover, we conduct a simulation study to compare other robust estimators with our approach in terms of their efficiency and robustness.},
  doi      = {10.1007/s10255-005-0240-0},
  file     = {:FILES/2005 - Zioutas2005 - Deleting Outliers in Robust Regression with Mixed Integer Programming.pdf:PDF},
  groups   = {LMS},
  refid    = {Zioutas2005},
  url      = {https://doi.org/10.1007/s10255-005-0240-0},
}

@Article{Huang2014a,
  author    = {Huang, Xiaolinand Shi, L. and Suykens, JohanA. K.},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title     = {Support vector machine classifier with pinball loss},
  year      = {2014},
  issn      = {1939-3539},
  month     = {5},
  number    = {5},
  pages     = {984--997},
  volume    = {36},
  abstract  = {Traditionally, the hinge loss is used to construct support vector machine (SVM) classifiers. The hinge loss is related to the shortest distance between sets and the corresponding classifier is hence sensitive to noise and unstable for re-sampling. In contrast, the pinball loss is related to the quantile distance and the result is less sensitive. The pinball loss has been deeply studied and widely applied in regression but it has not been used for classification. In this paper, we propose a SVM classifier with the pinball loss, called pin-SVM, and investigate its properties, including noise insensitivity, robustness, and misclassification error. Besides, insensitive zone is applied to the pin-SVM for a sparse model. Compared to the SVM with the hinge loss, the proposed pin-SVM has the same computational complexity and enjoys noise insensitivity and re-sampling stability.},
  doi       = {10.1109/TPAMI.2013.178},
  file      = {:FILES/2014 - Huang2014a - Support vector machine classifier with pinball loss.pdf:PDF},
  groups    = {SVM},
  keywords  = {computational complexity;pattern classification;regression analysis;support vector machines;support vector machine classifier;pinball loss;hinge loss;quantile distance;regression;pin-SVM;misclassification error;insensitive zone;computational complexity;noise insensitivity;resampling stability;Support vector machines;Fasteners;Noise;Loss measurement;Robustness;Kernel;Optimization;Classifier design and evaluation;Models;Classification;support vector machine;pinball loss},
  timestamp = {2020-09-17},
}

@Article{Shen2017,
  author    = {Shen, Xin and Niu, Lingfeng and Qi, Zhiquan and Tian, Yingjie},
  journal   = {Pattern Recognition},
  title     = {Support vector machine classifier with truncated pinball loss},
  year      = {2017},
  issn      = {0031-3203},
  pages     = {199--210},
  volume    = {68},
  abstract  = {Feature noise, namely noise on inputs is a long-standing plague to support vector machine(SVM). Conventional SVM with the hinge loss(C-SVM) is sparse but sensitive to feature noise. Instead, the pinball loss SVM(pin-SVM) enjoys noise robustness but loses the sparsity completely. To bridge the gap between C-SVM and pin-SVM, we propose the truncated pinball loss SVM(pin¯-SVM) in this paper. It provides a flexible framework of trade-off between sparsity and feature noise insensitivity. Theoretical properties including Bayes rule, misclassification error bound, sparsity, and noise insensitivity are discussed in depth. To train pin¯-SVM, the concave-convex procedure(CCCP) is used to handle non-convexity and the decomposition method is used to deal with the subproblem of each CCCP iteration. Accordingly, we modify the popular solver LIBSVM to conduct experiments and numerical results validate the properties of pin¯-SVM on the synthetic and real-world data sets.},
  doi       = {https://doi.org/10.1016/j.patcog.2017.03.011},
  file      = {:FILES/2017 - Shen2017 - Support vector machine classifier with truncated pinball loss.pdf:PDF},
  groups    = {SVM},
  keywords  = {Pinball loss, Feature noise, Sparsity, Support vector machine},
  timestamp = {2020-09-17},
  url       = {http://www.sciencedirect.com/science/article/pii/S0031320317301103},
}

@Article{Tanveer2019,
  author    = {Tanveer, M. and Sharma, A. and Suganthan, P. N.},
  journal   = {Information Sciences},
  title     = {General twin support vector machine with pinball loss function},
  year      = {2019},
  issn      = {0020-0255},
  pages     = {311--327},
  volume    = {494},
  abstract  = {The standard twin support vector machine (TSVM) uses the hinge loss function which leads to noise sensitivity and instability. In this paper, we propose a novel general twin support vector machine with pinball loss (Pin-GTSVM) for solving classification problems. We show that the proposed Pin-GTSVM is noise insensitive and more stable for re-sampling. Further, the computational complexity of the proposed Pin-GTSVM is similar to that of the TSVM. Thus, the pinball loss function does not increase the computation time of the proposed Pin-GTSVM. Numerical experiments with different noise are performed on 17 UCI and KEEL benchmark real-world datasets and the results are compared with other baseline methods. The comparisons clearly show that the proposed Pin-GTSVM has better generalization performance for noise corrupted datasets.},
  doi       = {https://doi.org/10.1016/j.ins.2019.04.032},
  file      = {:FILES/2019 - Tanveer2019 - General twin support vector machine with pinball loss function.pdf:PDF},
  groups    = {SVM},
  keywords  = {Hinge loss, Pinball loss, Quantile distance, Pin-SVM, Noise insensitivity, TSVM},
  timestamp = {2020-09-17},
  url       = {http://www.sciencedirect.com/science/article/pii/S0020025519303469},
}

@Article{Huber1964,
  author    = {Huber, Peter J.},
  journal   = {The Annals of Mathematical Statistics},
  title     = {Robust estimation of a location parameter},
  year      = {1964},
  issn      = {00034851},
  number    = {1},
  pages     = {73--101},
  volume    = {35},
  abstract  = {This paper contains a new approach toward a theory of robust estimation; it treats in detail the asymptotic theory of estimating a location parameter for contaminated normal distributions, and exhibits estimators--intermediaries between sample mean and sample median--that are asymptotically most robust (in a sense to be specified) among all translation invariant estimators. For the general background, see Tukey (1960) (p. 448 ff.) Let x1, ⋯, xn be independent random variables with common distribution function F(t - ξ). The problem is to estimate the location parameter ξ, but with the complication that the prototype distribution F(t) is only approximately known. I shall primarily be concerned with the model of indeterminacy F = (1 - ε)Φ + ε H, where $0 \leqq \epsilon < 1$ is a known number, Φ(t) = (2π)-1/2 ∫t -∞ exp(-1/2s2) ds is the standard normal cumulative and H is an unknown contaminating distribution. This model arises for instance if the observations are assumed to be normal with variance 1, but a fraction ε of them is affected by gross errors. Later on, I shall also consider other models of indeterminacy, e.g., $\sup_t |F(t) - \Phi(t)| \leqq \epsilon$. Some inconvenience is caused by the fact that location and scale parameters are not uniquely determined: in general, for fixed ε, there will be several values of ξ and σ such that $\sup_t|F(t) - \Phi((t - \xi)/\sigma)| \leqq \epsilon$, and similarly for the contaminated case. Although this inherent and unavoidable indeterminacy is small if ε is small and is rather irrelevant for practical purposes, it poses awkward problems for the theory, especially for optimality questions. To remove this difficulty, one may either (i) restrict attention to symmetric distributions, and estimate the location of the center of symmetry (this works for ξ but not for σ); or (ii) one may define the parameter to be estimated in terms of the estimator itself, namely by its asymptotic value for sample size n → ∞; or (iii) one may define the parameters by arbitrarily chosen functionals of the distribution (e.g., by the expectation, or the median of F). All three possibilities have unsatisfactory aspects, and I shall usually choose the variant which is mathematically most convenient. It is interesting to look back to the very origin of the theory of estimation, namely to Gauss and his theory of least squares. Gauss was fully aware that his main reason for assuming an underlying normal distribution and a quadratic loss function was mathematical, i.e., computational, convenience. In later times, this was often forgotten, partly because of the central limit theorem. However, if one wants to be honest, the central limit theorem can at most explain why many distributions occurring in practice are approximately normal. The stress is on the word "approximately." This raises a question which could have been asked already by Gauss, but which was, as far as I know, only raised a few years ago (notably by Tukey): What happens if the true distribution deviates slightly from the assumed normal one? As is now well known, the sample mean then may have a catastrophically bad performance: seemingly quite mild deviations may already explode its variance. Tukey and others proposed several more robust substitutes--trimmed means, Winsorized means, etc.--and explored their performance for a few typical violations of normality. A general theory of robust estimation is still lacking; it is hoped that the present paper will furnish the first few steps toward such a theory. At the core of the method of least squares lies the idea to minimize the sum of the squared "errors," that is, to adjust the unknown parameters such that the sum of the squares of the differences between observed and computed values is minimized. In the simplest case, with which we are concerned here, namely the estimation of a location parameter, one has to minimize the expression ∑i (xi - T)2; this is of course achieved by the sample mean T = ∑i xi/n. I should like to emphasize that no loss function is involved here; I am only describing how the least squares estimator is defined, and neither the underlying family of distributions nor the true value of the parameter to be estimated enters so far. It is quite natural to ask whether one can obtain more robustness by minimizing another function of the errors than the sum of their squares. We shall therefore concentrate our attention to estimators that can be defined by a minimum principle of the form (for a location parameter): T = Tn(x1, ⋯, xn) minimizes ∑i ρ(xi - T), \begin{equation*} \tag{M} where \rho is a non-constant function. \end{equation*} Of course, this definition generalizes at once to more general least squares type problems, where several parameters have to be determined. This class of estimators contains in particular (i) the sample mean (ρ(t) = t2), (ii) the sample median (ρ(t) = |t|), and more generally, (iii) all maximum likelihood estimators (ρ(t) = -log f(t), where f is the assumed density of the untranslated distribution). These (M)-estimators, as I shall call them for short, have rather pleasant asymptotic properties; sufficient conditions for asymptotic normality and an explicit expression for their asymptotic variance will be given. How should one judge the robustness of an estimator Tn(x) = Tn(x1, ⋯, xn)? Since ill effects from contamination are mainly felt for large sample sizes, it seems that one should primarily optimize large sample robustness properties. Therefore, a convenient measure of robustness for asymptotically normal estimators seems to be the supremum of the asymptotic variance (n → ∞) when F ranges over some suitable set of underlying distributions, in particular over the set of all F = (1 - ε)Φ + ε H for fixed ε and symmetric H. On second thought, it turns out that the asymptotic variance is not only easier to handle, but that even for moderate values of n it is a better measure of performance than the actual variance, because (i) the actual variance of an estimator depends very much on the behavior of the tails of H, and the supremum of the actual variance is infinite for any estimator whose value is always contained in the convex hull of the observations. (ii) If an estimator is asymptotically normal, then the important central part of its distribution and confidence intervals for moderate confidence levels can better be approximated in terms of the asymptotic variance than in terms of the actual variance. If we adopt this measure of robustness, and if we restrict attention to (M)-estimators, then it will be shown that the most robust estimator is uniquely determined and corresponds to the following ρ:ρ(t) = 1/2t2 for $|t| < k, \rho(t) = k|t| - \frac{1}{2}k^2$ for |t| ≥ k, with k depending on ε. This estimator is most robust even among all translation invariant estimators. Sample mean (k = ∞) and sample median (k = 0) are limiting cases corresponding to ε = 0 and ε = 1, respectively, and the estimator is closely related and asymptotically equivalent to Winsorizing. I recall the definition of Winsorizing: assume that the observations have been ordered, x1 ≤ x2 ≤ ⋯ ≤ xn, then the statistic T = n-1(gxg + 1 + xg + 1 + xg + 2 + ⋯ + xn - h + hxn - h) is called the Winsorized mean, obtained by Winsorizing the g leftmost and the h rightmost observations. The above most robust (M)-estimators can be described by the same formula, except that in the first and in the last summand, the factors xg + 1 and xn - h have to be replaced by some numbers u, v satisfying xg ≤ u ≤ xg + 1 and xn - h ≤ v ≤ xn - h + 1, respectively; g, h, u and v depend on the sample. In fact, this (M)-estimator is the maximum likelihood estimator corresponding to a unique least favorable distribution F0 with density f0(t) = (1 - ε)(2π)-1/2e-ρ(t). This f0 behaves like a normal density for small t, like an exponential density for large t. At least for me, this was rather surprising--I would have expected an f0 with much heavier tails. This result is a particular case of a more general one that can be stated roughly as follows: Assume that F belongs to some convex set C of distribution functions. Then the most robust (M)-estimator for the set C coincides with the maximum likelihood estimator for the unique F0 ε C which has the smallest Fisher information number I(F) = ∫ (f'/f)2f dt among all F ε C. Miscellaneous related problems will also be treated: the case of non-symmetric contaminating distributions; the most robust estimator for the model of indeterminacy $\sup_t|F(t) - \Phi(t)| \leqq \epsilon$; robust estimation of a scale parameter; how to estimate location, if scale and ε are unknown; numerical computation of the estimators; more general estimators, e.g., minimizing $\sum_{i < j} \rho(x_i - T, x_j - T)$, where ρ is a function of two arguments. Questions of small sample size theory will not be touched in this paper.},
  comment   = {huber loss
proposed M estimator},
  file      = {:FILES/1964 - Huber1964 - Robust estimation of a location parameter.pdf:PDF},
  groups    = {SVM, LMS},
  publisher = {Institute of Mathematical Statistics},
  timestamp = {2020-09-17},
  url       = {http://www.jstor.org/stable/2238020},
}

@Article{Chen2017,
  author    = {Chen, Chuanfa and Yan, Changqing and Zhao, Na and Guo, Bin and Liu, Guolin},
  journal   = {Soft Computing},
  title     = {A robust algorithm of support vector regression with a trimmed {Huber} loss function in the primal},
  year      = {2017},
  issn      = {1433-7479},
  number    = {18},
  pages     = {5235--5243},
  volume    = {21},
  abstract  = {Support vector machine for regression (SVR) is an efficient tool for solving function estimation problem. However, it is sensitive to outliers due to its unbounded loss function. In order to reduce the effect of outliers, we propose a robust SVR with a trimmed Huber loss function (SVRT) in this paper. Synthetic and benchmark datasets were, respectively, employed to comparatively assess the performance of SVRT, and its results were compared with those of SVR, least squares SVR (LS-SVR) and a weighted LS-SVR. The numerical test shows that when training samples are subject to errors with a normal distribution, SVRT is slightly less accurate than SVR and LS-SVR, yet more accurate than the weighted LS-SVR. However, when training samples are contaminated by outliers, SVRT has a better performance than the other methods. Furthermore, SVRT is faster than the weighted LS-SVR. Simulating eight benchmark datasets shows that SVRT is averagely more accurate than the other methods when sample points are contaminated by outliers. In conclusion, SVRT can be considered as an alternative robust method for simulating contaminated sample points.},
  doi       = {10.1007/s00500-016-2229-4},
  file      = {:FILES/2017 - Chen2017 - A robust algorithm of support vector regression with a trimmed {Huber} loss function in the primal.pdf:PDF},
  groups    = {SVM},
  refid     = {Chen2017},
  timestamp = {2020-09-17},
  url       = {https://doi.org/10.1007/s00500-016-2229-4},
}

@Article{Martins2016,
  author        = {Martins, Andr\'{e} F. T. and Astudillo, Ram\'{o}n Fern\'{a}ndez},
  journal       = {CoRR},
  title         = {From softmax to sparsemax: {A} sparse model of attention and multi-label classification},
  year          = {2016},
  volume        = {abs/1602.02068},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/MartinsA16.bib},
  eprint        = {1602.02068},
  groups        = {Neural Network, interesting articles},
  keywords      = {prio1},
  priority      = {prio1},
  timestamp     = {2020-09-17},
  url           = {http://arxiv.org/abs/1602.02068},
}

@Article{Kibzun1991,
  author    = {Kibzun, A. I. and Kurbakovskiy, V. Yu.},
  journal   = {Annals of Operations Research},
  title     = {Guaranteeing approach to solving quantile optimization problems},
  year      = {1991},
  issn      = {1572-9338},
  number    = {1},
  pages     = {81--93},
  volume    = {30},
  abstract  = {This paper presents a numerical method for solving quantile optimization problems, i.e. stochastic programming problems in which the quantile of the distribution of an objective function is the criterion to be optimized.},
  doi       = {10.1007/BF02204810},
  file      = {:FILES/1991 - Kibzun1991 - Guaranteeing approach to solving quantile optimization problems.pdf:PDF},
  groups    = {quantile optimization},
  refid     = {Kibzun1991},
  timestamp = {2020-09-17},
  url       = {https://doi.org/10.1007/BF02204810},
}

@Article{Ivanov2019,
  author    = {Ivanov, S. V. and Kibzun, A. I. and Stepanova, A. S.},
  journal   = {Applied Stochastic Models in Business and Industry},
  title     = {An algorithm to solve a quantile optimization problem with loss function having a separable structure, and its application to an aerospace problem},
  year      = {2019},
  number    = {5},
  pages     = {1269--1281},
  volume    = {35},
  abstract  = {Abstract A quantile minimization problem with loss function having separable structure is considered. The distribution of the random parameters is assumed to be normal. To solve the problem, the confidence method and the sample average approximation method are used. Thus, the problem is reduced to a combinatorial one, which is solved by using the variable neighborhood search. The suggested algorithm is applied to optimization of runway area. Parameters of the runway are selected to minimize the area taking into account random wind speed.},
  doi       = {10.1002/asmb.2475},
  eprint    = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/asmb.2475},
  file      = {:FILES/2019 - Ivanov2019 - An algorithm to solve a quantile optimization problem with loss function having a separable structure, and its application to an aerospace problem.pdf:PDF},
  groups    = {quantile optimization},
  keywords  = {quantile objective, runway, sample average approximation, variable neighborhood search},
  timestamp = {2020-09-17},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asmb.2475},
}

@Article{Hrley2009,
  author    = {Hurley, N. and Rickard, S.},
  journal   = {IEEE Transactions on Information Theory},
  title     = {Comparing measures of sparsity},
  year      = {2009},
  issn      = {1557-9654},
  month     = {10},
  number    = {10},
  pages     = {4723--4741},
  volume    = {55},
  abstract  = {Sparsity of representations of signals has been shown to be a key concept of fundamental importance in fields such as blind source separation, compression, sampling and signal analysis. The aim of this paper is to compare several commonly-used sparsity measures based on intuitive attributes. Intuitively, a sparse representation is one in which a small number of coefficients contain a large proportion of the energy. In this paper, six properties are discussed: (Robin Hood, Scaling, Rising Tide, Cloning, Bill Gates, and Babies), each of which a sparsity measure should have. The main contributions of this paper are the proofs and the associated summary table which classify commonly-used sparsity measures based on whether or not they satisfy these six propositions. Only two of these measures satisfy all six: the pq-mean with p les 1, q > 1 and the Gini index.},
  doi       = {10.1109/TIT.2009.2027527},
  file      = {:FILES/2009 - Hrley2009 - Comparing measures of sparsity.pdf:PDF},
  groups    = {sparsity},
  keywords  = {information theory;sparsity measures;blind source separation;signal analysis;sampling analysis;compression analysis;Gini index;Sea measurements;Machine learning;Source separation;Adaptive signal processing;Blind source separation;Image coding;Sampling methods;Signal analysis;Tides;Cloning;Measures of sparsity;measuring sparsity;sparse distribution;sparse representation;sparsity},
  timestamp = {2020-09-17},
}

@Article{Arvaneh2011,
  author    = {Arvaneh, M. and Guan, C. and Ang, K. K. and Quek, C.},
  journal   = {IEEE Transactions on Biomedical Engineering},
  title     = {Optimizing the channel selection and classification accuracy in {EEG-based} {BCI}},
  year      = {2011},
  issn      = {1558-2531},
  month     = {6},
  number    = {6},
  pages     = {1865--1873},
  volume    = {58},
  abstract  = {Multichannel EEG is generally used in brain-computer interfaces (BCIs), whereby performing EEG channel selection 1) improves BCI performance by removing irrelevant or noisy channels and 2) enhances user convenience from the use of lesser channels. This paper proposes a novel sparse common spatial pattern (SCSP) algorithm for EEG channel selection. The proposed SCSP algorithm is formulated as an optimization problem to select the least number of channels within a constraint of classification accuracy. As such, the proposed approach can be customized to yield the best classification accuracy by removing the noisy and irrelevant channels, or retain the least number of channels without compromising the classification accuracy obtained by using all the channels. The proposed SCSP algorithm is evaluated using two motor imagery datasets, one with a moderate number of channels and another with a large number of channels. In both datasets, the proposed SCSP channel selection significantly reduced the number of channels, and outperformed existing channel selection methods based on Fisher criterion, mutual information, support vector machine, common spatial pattern, and regularized common spatial pattern in classification accuracy. The proposed SCSP algorithm also yielded an average improvement of 10\% in classification accuracy compared to the use of three channels (C3, C4, and Cz).},
  doi       = {10.1109/TBME.2011.2131142},
  groups    = {interesting articles},
  keywords  = {brain-computer interfaces;data analysis;electroencephalography;medical disorders;medical signal processing;neurophysiology;signal classification;support vector machines;optimization;brain-computer interfaces;multichannel EEG;signal classification;sparse common spatial pattern algorithm;motor imagery datasets;Fisher criterion;support vector machine;severe motor disabilities;Accuracy;Electroencephalography;Covariance matrix;Optimization;Eigenvalues and eigenfunctions;Support vector machines;Testing;Brain–computer interface (BCI);EEG channel selection;motor imagery;sparse common spatial pattern (SCSP);Algorithms;Artificial Intelligence;Databases, Factual;Electrocardiography;Humans;Imagination;Motor Activity;Neural Prostheses;Signal Processing, Computer-Assisted, prio1},
  priority  = {prio1},
  timestamp = {2020-09-17},
}

@PhdThesis{Tan2019,
  author    = {Tan, Benying},
  school    = {University of Aizu},
  title     = {Sparse Representation with Nonconvex Regularization and Its Efficient Methods},
  year      = {2019},
  file      = {:FILES/2019 - Tan2019 - Sparse Representation with Nonconvex Regularization and Its Efficient Methods.pdf:PDF},
  groups    = {interesting articles},
  timestamp = {2020-09-17},
  url       = {https://u-aizu.repo.nii.ac.jp/?action=pages_view_main&active_action=repository_view_main_item_detail&item_id=183&item_no=1&page_id=3&block_id=69},
}

@PhdThesis{Zhao2019,
  author    = {Zhao, Haoli},
  school    = {University of Aizu},
  title     = {Trainable Sparse Coding with $\ell_p$ norm-Based regularization},
  year      = {2019},
  file      = {:FILES/2019 - Zhao2019 - Space Representation, Lp norm, Dictionary Learning, Deep Neural Network Structured Sparse Coding, Independently Interpretable Sparse Coding, Real-time Graphic Denoising, Gene Expression Data.pdf:PDF},
  groups    = {interesting articles},
  timestamp = {2020-09-17},
  url       = {https://u-aizu.repo.nii.ac.jp/?action=pages_view_main&active_action=repository_view_main_item_detail&item_id=169&item_no=1&page_id=3&block_id=69},
}

@Misc{dhanaa2017,
  author    = {dhanaa},
  title     = {Generalized geometric programming solver for {MATLBA} users},
  year      = {2017},
  date      = {2017-05-23},
  groups    = {softwares},
  timestamp = {2020-09-20},
  url       = {https://ww2.mathworks.cn/matlabcentral/fileexchange/63067-generalized-geometric-programming},
}

@Article{Pirvu2007,
  author    = {Pirvu, Traian A.},
  journal   = {Quantitative Finance},
  title     = {Portfolio optimization under the value-at-risk constraint},
  year      = {2007},
  number    = {2},
  pages     = {125--136},
  volume    = {7},
  abstract  = {In this paper we analyse the effects arising from imposing a Value-at-Risk constraint in an agent's portfolio selection problem. The financial market is incomplete and consists of multiple risky assets (stocks) plus a risk-free asset. The stocks are modelled as exponential Brownian motions with random drift and volatility. The risk of the trading portfolio is re-evaluated dynamically, hence the agent must satisfy the Value-at-Risk constraint continuously. We derive the optimal consumption and portfolio allocation policy in closed form for the case of logarithmic utility. The non-logarithmic CRRA utilities are considered as well, when the randomness of market coefficients is independent of the Brownian motion driving the stocks. The portfolio selection, a stochastic control problem, is reduced, in this context, to a deterministic control one, which is analysed, and a numerical treatment is proposed.},
  doi       = {10.1080/14697680701213868},
  eprint    = {https://doi.org/10.1080/14697680701213868},
  file      = {:/Users/X/Library/Mobile Documents/com~apple~CloudDocs/Research/references/FILES/2007 - Pirvu2007 - Portfolio optimization under the value-at-risk constraint.pdf:PDF},
  groups    = {VaR},
  publisher = {Routledge},
  timestamp = {2020-09-20},
  url       = {https://doi.org/10.1080/14697680701213868},
}

@Book{Dempster2009,
  editor    = {M. A. H. Dempster and Georg Pflug and Gautam Mitra},
  publisher = {CRC Press},
  title     = {Quantitative fund management},
  year      = {2009},
  isbn      = {978-1-4200-8191-6},
  file      = {:/Users/X/Library/Mobile Documents/com~apple~CloudDocs/Research/references/FILES/2009 - Dempster2009 - Quantitative Fund Management.pdf:PDF},
  groups    = {Portfolio Selection},
  timestamp = {2020-09-20},
}

@Article{Xu2017,
  author    = {Xu, Guibiao and Cao, Zheng and Hu, Bao-Gang and Principe, Jose C.},
  journal   = {Pattern Recognition},
  title     = {Robust support vector machines based on the rescaled hinge loss function},
  year      = {2017},
  issn      = {0031-3203},
  pages     = {139--148},
  volume    = {63},
  abstract  = {The support vector machine (SVM) is a popular classifier in machine learning, but it is not robust to outliers. In this paper, based on the Correntropy induced loss function, we propose the rescaled hinge loss function which is a monotonic, bounded and nonconvex loss that is robust to outliers. We further show that the hinge loss is a special case of the proposed rescaled hinge loss. Then, we develop a new robust SVM based on the rescaled hinge loss. After using the half-quadratic optimization method, we find that the new robust SVM is equivalent to an iterative weighted SVM, which can help explain the robustness of iterative weighted SVM from a loss function perspective. Experimental results confirm that the new robust SVM not only performs better than SVM and the existing robust SVMs on the datasets that have outliers, but also presents better sparseness than SVM.},
  doi       = {https://doi.org/10.1016/j.patcog.2016.09.045},
  file      = {:FILES/2017 - Xu2017 - Robust support vector machines based on the rescaled hinge loss function.pdf:PDF},
  groups    = {SVM},
  keywords  = {Support vector machine, Robustness, Rescaled hinge loss, Half-quadratic optimization},
  timestamp = {2020-09-21},
  url       = {http://www.sciencedirect.com/science/article/pii/S0031320316303065},
}

@InProceedings{Xi2020a,
  author    = {Xi, Xiangming and Lou, Yunjiang},
  booktitle = {The China Automation congress (CAC2000)},
  title     = {Compact estimation and optimization of signomial geometric programming},
  year      = {2020},
  address   = {Shanghai, China},
  month     = nov,
  pages     = {6759--6764},
  publisher = {IEEE},
  abstract  = {Among the broad class of non-linear programming, signomial geometric programming (SGP) still remains challenging in global optimization due to its non-convexity. The general framework of handling SGP problems is to approximate the SPG problems and solve a series of surrogate problems to approach its global optima. However, most of the methods in the literature requires integer variables and/or additional constraints, which burdens the solving procedures and leads to less efficiency. In this paper, we propose two compact surrogate models which underestimate and overestimate SGP problems, respectively. Moreover, the novel surrogate models consist of only continuous variables, requires no additional constraints, and have been proved to provide tight upper and lower bounds for the SGP problem with proper parameter configuration. In order to solve the proposed surrogate problems, we propose a global search algorithm which an enhanced local search procedures. In order to confirm the validity of the proposed model and the efficiency of the corresponding algorithm, we perform numerical experiments on both benchmark problems and the real-world application on designing sparse finite impulse filter (FIR) filters with comparison to some state-of-the-art algorithms.},
  comment   = {2020.11.08},
  doi       = {10.1109/CAC51589.2020.9327080},
  groups    = {my paper},
  timestamp = {2020-09-21},
  url       = {https://ieeexplore.ieee.org/document/9327080},
}

@Article{Beale1975,
  author    = {Beale, E. M. L.},
  journal   = {Journal of the Operational Research Society},
  title     = {Some uses of mathematical programming systems to solve problems that are not linear},
  year      = {1975},
  number    = {3},
  pages     = {609--618},
  volume    = {26},
  abstract  = {AbstractThere are three main reasons why a purely linear programming model may not represent a constrained optimization problem adequately: economies of scale, other non-linearities that do not invalidate a local optimum, random data. These reasons lead respectively to integer programming, non-linear programming and stochastic programming.Examples of each type of model are discussed. These have all been solved using a standard mathematical programming system to exploit sparseness efficiently.Economies of scale arise when selecting a set of new pipelines to expand the capacity of a given network. This problem involves non-linear functions, but is essentially an integer programming problem because we must use branch and bound methods to find the best combinations of pipelines, and pipeline diameters. An unsuccessful and a subsequent successful formulation for this problem are discussed.A non-linear programming model for allocating resources in health care is outlined.A model for multi-time-period production scheduling with stochastic demands is also outlined. The model requires data defining the uncertainties in demand forecasts, and the extent to which these are correlated with each other and with past sales. The existence of software for this model may encourage more people to quantify these data.},
  comment   = {SOS-2},
  doi       = {10.1057/jors.1975.131},
  eprint    = {https://doi.org/10.1057/jors.1975.131},
  file      = {:FILES/1975 - Beale1975 - Some uses of mathematical programming systems to solve problems that are not linear.pdf:PDF},
  groups    = {optimization},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1057/jors.1975.131},
}

@Article{Adams2008,
  author   = {Adams, R. J. and Xu, Y. and Canning, F. X.},
  journal  = {IEEE Transactions on Antennas and Propagation},
  title    = {Sparse pseudo inverse of the discrete plane wave transform},
  year     = {2008},
  issn     = {1558-2221},
  month    = {2},
  number   = {2},
  pages    = {475--484},
  volume   = {56},
  abstract = {An algorithm is presented for the sparse pseudo inversion of discrete forms of the plane wave transform. The starting point for the sparse pseudo inverse is a new sparse representation of the discrete plane wave transform (DPWT). While other sparse representations of the DPWT exist, the sparse representation developed here is shown to be amenable to sparse factorization. This feature is used to develop an efficient, error-controlled pseudo-inverse of the DPWT. Representative numerical examples are provided to illustrate the general properties of the proposed algorithms. Areas for additional work are identified, and potential applications of the results are discussed.},
  comment  = {application on antenna and propogation},
  doi      = {10.1109/TAP.2007.915420},
  file     = {:FILES/2008 - Adams2008 - Sparse pseudo inverse of the discrete plane wave transform.pdf:PDF},
  groups   = {sparsity},
  keywords = {discrete transforms;electromagnetic fields;matrix decomposition;sparse pseudo inverse;discrete plane wave transform;sparse factorization;electromagnetic fields;Discrete transforms;Conductors;Canning;Scattering;Sparse matrices;Vectors;Numerical analysis;Computational complexity;Integral equations;Electromagnetic fields;Electromagnetic fields;linear algegra;numerical analysis},
}

@Article{Leung2008,
  author   = {Leung, K. Y. E. and van Stralen, M. and Nemes, A. and Voormolen, M. M. and van Burken, G. and Geleijnse, M. L. and ten Cate, F. J. and Reiber, J. H. C. and de Jong, N. and van der Steen, A. F. W. and Bosch, J. G.},
  journal  = {IEEE Transactions on Medical Imaging},
  title    = {Sparse registration for three-dimensional stress echocardiography},
  year     = {2008},
  issn     = {1558-254X},
  month    = {11},
  number   = {11},
  pages    = {1568--1579},
  volume   = {27},
  abstract = {Three-dimensional (3-D) stress echocardiography is a novel technique for diagnosing cardiac dysfunction. It involves evaluating wall motion of the left ventricle, by visually analyzing ultrasound images obtained in rest and in different stages of stress. Since the acquisitions are performed minutes apart, variabilities may exist in the visualized cross-sections. To improve anatomical correspondence between rest and stress, aligning the images is essential. We developed a new intensity-based, sparse registration method to retrieve standard anatomical views from 3-D stress images that were equivalent to the manually selected views in the rest images. Using sparse image planes, the influence of common image artifacts could be reduced. We investigated different similarity measures and different levels of sparsity. The registration was tested using data of 20 patients and quantitatively evaluated based on manually defined anatomical landmarks. Alignment was best using sparse registration with two long-axis and two short-axis views; registration errors were reduced significantly, to the range of interobserver variabilities. In 91\% of the cases, the registration result was qualitatively assessed as better than or equal to the manual alignment. In conclusion, sparse registration improves the alignment of rest and stress images, with a performance similar to manual alignment. This is an important step towards objective quantification in 3-D stress echocardiography.},
  doi      = {10.1109/TMI.2008.922685},
  file     = {:FILES/2008 - Leung2008 - Sparse registration for three-dimensional stress echocardiography.pdf:PDF},
  groups   = {sparsity},
  keywords = {echocardiography;image registration;medical image processing;patient diagnosis;3D stress echocardiography;cardiac dysfunction diagnosis;left ventricle wall motion evaluation;ultrasound images;visualized cross section variabilities;image alignment;intensity based sparse registration method;sparse image planes;similarity measures;sparsity levels;Stress;Echocardiography;Motion analysis;Image analysis;Image motion analysis;Ultrasonic imaging;Visualization;Image retrieval;Standards development;Testing;Image registration;stress echocardiography;three-dimensional ultrasound imaging;image registration;stress echocardiography;three-dimensional ultrasound imaging;Artifacts;Echocardiography, Stress;Echocardiography, Three-Dimensional;Heart;Heart;Humans;Motion;Myocardial Contraction;Pattern Recognition, Automated;Subtraction Technique},
}

@Article{Li2007,
  author   = {Li, W. and Preisig, J. C.},
  journal  = {IEEE Journal of Oceanic Engineering},
  title    = {Estimation of rapidly time-varying sparse channels},
  year     = {2007},
  issn     = {1558-1691},
  month    = {10},
  number   = {4},
  pages    = {927--939},
  volume   = {32},
  abstract = {The estimation of sparse shallow-water acoustic communication channels and the impact of estimation performance on the equalization of phase coherent communication signals are investigated. Given sufficiently wide transmission bandwidth, the impulse response of the shallow-water acoustic channel is often sparse as the multipath arrivals become resolvable. In the presence of significant surface waves, the multipath arrivals associated with surface scattering fluctuate rapidly over time, in the sense that the complex gain, the arrival time, and the Dopplers of each arrival all change dynamically. A sparse channel estimation technique is developed based on the delay-Doppler-spread function representation of the channel. The delay-Doppler-spread function may be considered as a first-order approximation to the rapidly time-varying channel in which each channel component is associated with Doppler shifts that are assumed constant over an averaging interval. The sparse structure of the delay-Doppler-spread function is then exploited by sequentially choosing the dominant components that minimize a least squares error. The advantage of this approach is that it captures both the channel structure as well as its dynamics without the need of explicit dynamic channel modeling. As the symbols are populated with the sample Dopplers, the increase in complexity depends on the channel Doppler spread and can be significant for a severely Doppler-spread channel. Comparison is made between nonsparse recursive least squares (RLS) channel estimation, sparse channel impulse response estimation, and estimation using the proposed approach. The results are demonstrated using experimental data. In training mode, the proposed approach shows a 3-dB reduction in signal prediction error. In decision-directed mode, it improves significantly the robustness of the performance of the channel-estimate-based equalizer against rapid channel fluctuations.},
  doi      = {10.1109/JOE.2007.906409},
  file     = {:FILES/2007 - Li2007 - Estimation of rapidly time-varying sparse channels.pdf:PDF},
  groups   = {sparsity},
  keywords = {approximation theory;channel estimation;Doppler shift;equalisers;least squares approximations;surface scattering;time-varying channels;transient response;underwater acoustic communication;time-varying sparse channel estimation;shallow-water acoustic communication;phase coherent communication signal equalization;impulse response;surface scattering;delay-Doppler-spread function representation;first-order approximation;Doppler shift;least squares error minimization;signal prediction error;equalizer;Phase estimation;Surface acoustic waves;Channel estimation;Delay;Least squares approximation;Recursive estimation;Communication channels;Bandwidth;Signal resolution;Acoustic scattering;Channel-estimate-based equalization;delay-Doppler-spread function;matching pursuit;sparse estimation;time-varying channels},
}

@Article{Mishali2008,
  author   = {Mishali, M. and Eldar, Y. C.},
  journal  = {IEEE Transactions on Signal Processing},
  title    = {Reduce and boost: {Recovering} arbitrary sets of jointly sparse vectors},
  year     = {2008},
  issn     = {1941-0476},
  month    = {10},
  number   = {10},
  pages    = {4692--4702},
  volume   = {56},
  abstract = {The rapid developing area of compressed sensing suggests that a sparse vector lying in a high dimensional space can be accurately and efficiently recovered from only a small set of nonadaptive linear measurements, under appropriate conditions on the measurement matrix. The vector model has been extended both theoretically and practically to a finite set of sparse vectors sharing a common sparsity pattern. In this paper, we treat a broader framework in which the goal is to recover a possibly infinite set of jointly sparse vectors. Extending existing algorithms to this model is difficult due to the infinite structure of the sparse vector set. Instead, we prove that the entire infinite set of sparse vectors can be recovered by solving a single, reduced-size finite-dimensional problem, corresponding to recovery of a finite set of sparse vectors. We then show that the problem can be further reduced to the basic model of a single sparse vector by randomly combining the measurements. Our approach is exact for both countable and uncountable sets, as it does not rely on discretization or heuristic techniques. To efficiently find the single sparse vector produced by the last reduction step, we suggest an empirical boosting strategy that improves the recovery ability of any given suboptimal method for recovering a sparse vector. Numerical experiments on random data demonstrate that, when applied to infinite sets, our strategy outperforms discretization techniques in terms of both run time and empirical recovery rate. In the finite model, our boosting algorithm has fast run time and much higher recovery rate than known popular methods.},
  doi      = {10.1109/TSP.2008.927802},
  file     = {:FILES/2008 - Mishali2008 - Reduce and boost- {Recovering} arbitrary sets of jointly sparse vectors.pdf:PDF},
  groups   = {sparsity},
  keywords = {signal representation;arbitrary sets;jointly sparse vectors;finite-dimensional problem;single sparse vector;empirical boosting strategy;suboptimal method;boosting algorithm;Vectors;Compressed sensing;Area measurement;Boosting;Extraterrestrial measurements;Sparse matrices;Image coding;Digital audio players;Transform coding;Wireless communication;Basis pursuit;compressed sensing;multiple measurement vectors (MMVs);sparse representation;Basis pursuit;compressed sensing;multiple measurement vectors (MMV);sparse representation},
}

@Article{Zhou2020a,
  author   = {Zhou, Deqing},
  journal  = {Finance Research Letters},
  title    = {Strategic trading with transaction cost in the long run},
  year     = {2020},
  issn     = {1544-6123},
  pages    = {101087},
  volume   = {32},
  abstract = {Based on Holden and Subrahmanyam (1994), this work examines how the transaction cost imposed on insiders affects the strategic trading and the consequences. We find that with transaction cost, insiders refrain their trading and prices are less efficient in reflecting the private information. Interestingly, the noise traders’ losses increase with the insiders’ transaction cost when insiders are either competitive or risk averse, since the transaction cost can soften the competition among insiders and can change insiders’ risk-sharing allocation across periods.},
  comment  = {this used the quadratic form of transaction cost, as well as in some references herein.},
  doi      = {https://doi.org/10.1016/j.frl.2018.12.035},
  file     = {:FILES/2020 - Zhou2020a - Strategic trading with transaction cost in the long run.pdf:PDF},
  groups   = {concepts},
  url      = {http://www.sciencedirect.com/science/article/pii/S1544612318306202},
}

@Article{DeMiguel2015,
  author    = {DeMiguel, Victor and Mart\'{i}n-Utrera, Alberto and Nogales, Francisco J.},
  journal   = {Journal of Financial and Quantitative Analysis},
  title     = {Parameter uncertainty in multiperiod portfolio optimization with transaction costs},
  year      = {2015},
  number    = {6},
  pages     = {1443--1471},
  volume    = {50},
  comment   = {transaction cost},
  doi       = {10.1017/S002210901500054X},
  file      = {:FILES/2015 - DeMiguel2015 - Parameter uncertainty in multiperiod portfolio optimization with transaction costs.pdf:PDF},
  groups    = {concepts},
  publisher = {Cambridge University Press},
}

@Article{Beraldi2019,
  author   = {Beraldi, Patrizia and Violi, Antonio and Ferrara, Massimiliano and Ciancio, Claudio and Pansera, Bruno Antonio},
  journal  = {Annals of Operations Research},
  title    = {Dealing with complex transaction costs in portfolio management},
  year     = {2019},
  issn     = {1572-9338},
  abstract = {This paper deals with the problem of modelling complex transaction cost structures within portfolio management models in an efficient and effective way. We consider a general structure of transaction costs, where the applied commissions depend on the range of traded monetary amount and we use this general structure within a portfolio optimization problem with rebalancing decisions in response to new market conditions. The presence of transaction costs reduces the fund’s capital and should be properly accounted for to avoid substantial costs that impact on portfolio performance. In this paper we present a mixed integer model equipped with a specialized Branch and Bound method that exploits the specific formulation of the trading operations. Computational experiments, carried out on transaction cost structures offered by real-life traders, have shown the effectiveness of the proposed model and the computational efficiency of the solution approach.},
  doi      = {10.1007/s10479-019-03210-5},
  file     = {:FILES/2019 - Beraldi2019 - Dealing with complex transaction costs in portfolio management.pdf:PDF},
  groups   = {concepts},
  refid    = {Beraldi2019},
  url      = {https://doi.org/10.1007/s10479-019-03210-5},
}

@Article{Gupta2014,
  author   = {Gupta, Pankaj and Mittal, Garima and Mehlawat, Mukesh Kumar},
  journal  = {Memetic Computing},
  title    = {A multicriteria optimization model of portfolio rebalancing with transaction costs in fuzzy environment},
  year     = {2014},
  issn     = {1865-9292},
  number   = {1},
  pages    = {61--74},
  volume   = {6},
  abstract = {In this paper we propose multicriteria credibilistic framework for portfolio rebalancing (adjusting) problem with fuzzy parameters considering return, risk and liquidity as key financial criteria. The portfolio risk is characterized by a risk curve that represents each likely loss of the portfolio return and the corresponding chance of its occurrence rather than a single pre-set level of the loss. Furthermore, we consider an investment market scenario where, at the end of a typical time period, the investor would like to modify his existing portfolio by buying and/or selling assets in response to changing market conditions. We assume that the investor pays transaction costs based on incremental discount schemes associated with the buying and/or selling of assets, which are adjusted in the net return of the portfolio. A hybrid intelligent algorithm that integrates fuzzy simulation with a real-coded genetic algorithm is developed to solve the portfolio rebalancing (adjusting) problem. The proposed solution approach is useful particularly for the cases where fuzzy parameters of the problem are characterized by general functional forms.},
  doi      = {10.1007/s12293-012-0102-2},
  file     = {:FILES/2014 - Gupta2014 - A multicriteria optimization model of portfolio rebalancing with transaction costs in fuzzy environment.pdf:PDF},
  groups   = {concepts},
  refid    = {Gupta2014},
  url      = {https://doi.org/10.1007/s12293-012-0102-2},
}

@Article{Lobo2007,
  author   = {Lobo, Miguel Sousa and Fazel, Maryam and Boyd, Stephen},
  journal  = {Annals of Operations Research},
  title    = {Portfolio optimization with linear and fixed transaction costs},
  year     = {2007},
  issn     = {1572-9338},
  number   = {1},
  pages    = {341--365},
  volume   = {152},
  abstract = {We consider the problem of portfolio selection, with transaction costs and constraints on exposure to risk. Linear transaction costs, bounds on the variance of the return, and bounds on different shortfall probabilities are efficiently handled by convex optimization methods. For such problems, the globally optimal portfolio can be computed very rapidly. Portfolio optimization problems with transaction costs that include a fixed fee, or discount breakpoints, cannot be directly solved by convex optimization. We describe a relaxation method which yields an easily computable upper bound via convex optimization. We also describe a heuristic method for finding a suboptimal portfolio, which is based on solving a small number of convex optimization problems (and hence can be done efficiently). Thus, we produce a suboptimal solution, and also an upper bound on the optimal solution. Numerical experiments suggest that for practical problems the gap between the two is small, even for large problems involving hundreds of assets. The same approach can be used for related problems, such as that of tracking an index with a portfolio consisting of a small number of assets.},
  comment  = {linear transaction model},
  doi      = {10.1007/s10479-006-0145-1},
  file     = {:FILES/2007 - Lobo2007 - Portfolio optimization with linear and fixed transaction costs.pdf:PDF},
  groups   = {concepts},
  refid    = {Lobo2007},
  url      = {https://doi.org/10.1007/s10479-006-0145-1},
}

@Article{Konno2005,
  author   = {Konno, Hiroshi and Yamamoto, Rei},
  journal  = {Journal of Global Optimization},
  title    = {Global optimization versus integer programming in portfolio optimization under nonconvex transaction costs},
  year     = {2005},
  issn     = {1573-2916},
  number   = {2},
  pages    = {207--219},
  volume   = {32},
  abstract = {This paper is concerned with a portfolio optimization problem under concave and piecewise constant transaction cost. We formulate the problem as nonconcave maximization problem under linear constraints using absolute deviation as a measure of risk and solve it by a branch and bound algorithm developed in the field of global optimization. Also, we compare it with a more standard 0-1 integer programming approach. We will show that a branch and bound method elaborating the special structure of the problem can solve the problem much faster than the state-of-the integer programming code.},
  comment  = {PWL concave transaction cost},
  doi      = {10.1007/s10898-004-2703-x},
  file     = {:FILES/2005 - Konno2005 - Global optimization versus integer programming in portfolio optimization under nonconvex transaction costs.pdf:PDF},
  groups   = {concepts},
  refid    = {Konno2005},
  url      = {https://doi.org/10.1007/s10898-004-2703-x},
}

@Article{Baumann2013,
  author   = {Baumann, Philipp and Trautmann, Norbert},
  journal  = {Mathematical Methods of Operations Research},
  title    = {Portfolio-optimization models for small investors},
  year     = {2013},
  issn     = {1432-5217},
  number   = {3},
  pages    = {345--356},
  volume   = {77},
  abstract = {Since 2010, the client base of online-trading service providers has grown significantly. Such companies enable small investors to access the stock market at advantageous rates. Because small investors buy and sell stocks in moderate amounts, they should consider fixed transaction costs, integral transaction units, and dividends when selecting their portfolio. In this paper, we consider the small investor’s problem of investing capital in stocks in a way that maximizes the expected portfolio return and guarantees that the portfolio risk does not exceed a prescribed risk level. Portfolio-optimization models known from the literature are in general designed for institutional investors and do not consider the specific constraints of small investors. We therefore extend four well-known portfolio-optimization models to make them applicable for small investors. We consider one nonlinear model that uses variance as a risk measure and three linear models that use the mean absolute deviation from the portfolio return, the maximum loss, and the conditional value-at-risk as risk measures. We extend all models to consider piecewise-constant transaction costs, integral transaction units, and dividends. In an out-of-sample experiment based on Swiss stock-market data and the cost structure of the online-trading service provider Swissquote, we apply both the basic models and the extended models; the former represent the perspective of an institutional investor, and the latter the perspective of a small investor. The basic models compute portfolios that yield on average a slightly higher return than the portfolios computed with the extended models. However, all generated portfolios yield on average a higher return than the Swiss performance index. There are considerable differences between the four risk measures with respect to the mean realized portfolio return and the standard deviation of the realized portfolio return.},
  doi      = {10.1007/s00186-012-0408-3},
  file     = {:FILES/2013 - Baumann2013 - Portfolio-optimization models for small investors.pdf:PDF},
  groups   = {concepts},
  refid    = {Baumann2013},
  url      = {https://doi.org/10.1007/s00186-012-0408-3},
}

@Article{Thi2009,
  author    = {Thi, Hoai An Le and Moeini, Mahdi and Dinh, Tao Pham},
  journal   = {Optimization},
  title     = {{DC} programming approach for portfolio optimization under step increasing transaction costs},
  year      = {2009},
  number    = {3},
  pages     = {267--289},
  volume    = {58},
  abstract  = {We address a class of particularly hard-to-solve portfolio optimization problems, namely the portfolio optimization under step increasing transaction costs. The step increasing functions are approximated, as closely as desired by a difference of polyhedral convex functions. Then we apply the difference of convex functions algorithm (DCA) to the resulting polyhedral DC program. For testing the efficiency of the DCA we compare it with CPLEX and the branch and bound algorithm proposed by Konno et al.},
  doi       = {10.1080/02331930902741721},
  eprint    = {https://doi.org/10.1080/02331930902741721},
  file      = {:FILES/2009 - Thi2009 - Dc programming approach for portfolio optimization under step increasing transaction costs.pdf:PDF},
  groups    = {concepts},
  publisher = {Taylor \& Francis},
  url       = {https://doi.org/10.1080/02331930902741721},
}

@Article{Bouten2007,
  author   = {Bouten, Luc and Van Handel, Ramon and James, Matthew R.},
  journal  = {SIAM Journal on Control and Optimization},
  title    = {An introduction to quantum filtering},
  year     = {2007},
  number   = {6},
  pages    = {2199--2241},
  volume   = {46},
  abstract = {This paper provides an introduction to quantum filtering theory. An introduction to quantum probability theory is given, focusing on the spectral theorem and the conditional expectation as a least squares estimate, and culminating in the construction of Wiener and Poisson processes on the Fock space. We describe the quantum Itô calculus and its use in the modeling of physical systems. We use both reference probability and innovations methods to obtain quantum filtering equations for system-probe models from quantum optics.},
  doi      = {10.1137/060651239},
  eprint   = {https://doi.org/10.1137/060651239},
  file     = {:FILES/2007 - Bouten2007 - An introduction to quantum filtering.pdf:PDF},
  groups   = {quantum filtering},
  url      = {https://doi.org/10.1137/060651239},
}

@Misc{Gough2018,
  author        = {Gough, John E.},
  title         = {An introduction to quantum filtering},
  year          = {2018},
  abstract      = {The following notes are based on lectures delivered at the research school Modeling and Control of Open Quantum Systems (Modélisation et contrôle des systèmes quantiques ouverts) at CIRM, Marseille, 16-20 April, 2018, as part of the Trimester \textit{Measurement and Control of Quantum Systems: Theory and Experiments} organized at Institut Henri Poincaré, Paris, France. The aim is to introduce quantum filtering to an audience with a background in either quantum theory or classical filtering.},
  archiveprefix = {arXiv},
  eprint        = {1804.09086},
  file          = {:FILES/2018 - Gough2018 - An introduction to quantum filtering.pdf:PDF},
  groups        = {quantum filtering},
  url           = {https://arxiv.org/abs/1804.09086},
}

@Article{Gao2020,
  author   = {Gao, Q. and Dong, D. and Petersen, I. R. and Ding, S. X.},
  journal  = {IEEE Transactions on Automatic Control},
  title    = {Design of a quantum projection filter},
  year     = {2020},
  issn     = {1558-2523},
  month    = {8},
  number   = {8},
  pages    = {3693--3700},
  volume   = {65},
  abstract = {This article develops a quantum projection filtering approach to approximating the quantum filter equation based on It$\hat{\rm o}$ stochastic Taylor expansions and quantum information geometric techniques. The proposed approximation scheme is designed so that the truncated Taylor expansion of the difference between the true quantum trajectory, and its approximation on a lower dimensional differential submanifold is minimized, through an orthogonal projection operation in the quantum Fisher metric. In addition, a convenient design for a special class of open quantum systems is formulated. Simulation results from a numerical example demonstrate the approximation capability of the proposed quantum projection filter.},
  doi      = {10.1109/TAC.2019.2953457},
  file     = {:FILES/2020 - Gao2020 - Design of a quantum projection filter.pdf:PDF},
  groups   = {quantum filtering},
  keywords = {Mathematical model;Stochastic processes;Taylor series;Measurement;Quantum computing;Elementary particle vacuum;Trajectory;It $\hat{\rm o}$ stochastic Taylor expansions;quantum filter;quantum information geometry;quantum projection filter},
  url      = {https://ieeexplore.ieee.org/document/8901195},
}

@InBook{James2020,
  author    = {James, Matthew R.},
  editor    = {Baillieul, John and Samad, Tariq},
  pages     = {1--8},
  publisher = {Springer London},
  title     = {Quantum networks},
  year      = {2020},
  address   = {London},
  isbn      = {978-1-4471-5102-9},
  abstract  = {In this entry we discuss a symbolic tool for describing the interconnection of open quantum systems using boson fields. The tool called the series product is expressed in terms of physical parameters. Boson fields, such as free quantum optical fields, serve as ``wires'' connecting components. The framework is general and allows for the description of networks consisting of quantum and classical components in a consistent and unified manner.},
  booktitle = {Encyclopedia of Systems and Control},
  doi       = {10.1007/978-1-4471-5102-9_100162-1},
  groups    = {quantum network},
  url       = {https://doi.org/10.1007/978-1-4471-5102-9_100162-1},
}

@Article{Gao2020a,
  author   = {Gao, Qing and Zhang, Guofeng and Petersen, Ian R.},
  journal  = {Automatica},
  title    = {An improved quantum projection filter},
  year     = {2020},
  issn     = {0005-1098},
  pages    = {108716},
  volume   = {112},
  abstract = {This work extends the previous quantum projection filtering scheme in Gao et al. (2019), by adding an optimality analysis result. A reformulation of the quantum projection filter is derived by minimizing the truncated Stratonovich stochastic Taylor expansion of the difference between the true quantum trajectory and its approximation on a lower-dimensional submanifold through quantum information geometric techniques. Simulation results for a qubit example demonstrate better approximation performance for the new quantum projection filter.},
  doi      = {https://doi.org/10.1016/j.automatica.2019.108716},
  file     = {:FILES/2020 - Gao2020a - An improved quantum projection filter.pdf:PDF},
  groups   = {quantum filtering},
  keywords = {Quantum filters, Quantum projection filters, Stratonovich stochastic Taylor expansions, Quantum information geometry},
  url      = {http://www.sciencedirect.com/science/article/pii/S0005109819305795},
}

@Book{Bagirov2020,
  author    = {Adil M. Bagirov and Manlio Gaudioso and Napsu Karmitsa and Marko M. M\"{a}kel\"{a} and Sona Taheri},
  publisher = {Springer},
  title     = {Numerical nonsmooth optimization: {State} of {the} art algorithms},
  year      = {2020},
  isbn      = {9783030349097},
  file      = {:FILES/2020 - Bagirov2020 - Numerical nonsmooth optimization- {State} of {the} art algorithms.pdf:PDF},
  groups    = {nonsmooth optimization, to_read},
  keywords  = {prio1},
  priority  = {prio1},
}

@Book{Powell1981,
  author    = {Michael James David Powell},
  publisher = {Cambridge University Press},
  title     = {Approximation theory and methods},
  year      = {1981},
  isbn      = {0521295149},
  file      = {:FILES/1981 - Powell1981 - Approximation Theory and Methods.pdf:PDF},
  groups    = {approximation},
}

@Article{Belz2017,
  author   = {Julian Belz and Tobias Münker and Tim O. Heinz and Geritt Kampmann and Oliver Nelles},
  journal  = {IFAC-PapersOnLine},
  title    = {Automatic modeling with local model networks for benchmark processes},
  year     = {2017},
  issn     = {2405-8963},
  note     = {20th IFAC World Congress},
  number   = {1},
  pages    = {470 - 475},
  volume   = {50},
  abstract = {In this paper an automated model generation framework is used to identify three nonlinear dynamic benchmark processes. The nonlinearity is approximated using tree-based local model networks (LMN) with external dynamics, which are represented by three different approaches: NARX, NFIR and NOBF. The automated method assumes no prior knowledge about the process, and aims to be a ready-to-use tool for system identification. Results are given for the different approaches and benchmark processes. The importance of the choice of training data for a good generalizing model performance is discussed.},
  doi      = {https://doi.org/10.1016/j.ifacol.2017.08.089},
  groups   = {interesting articles},
  keywords = {Local Model Network, LMN, HILOMOT, LOLIMOT, System Identification, Benchmark Process, Bouc-Wen, Wiener-Hammerstein, Cascaded Tanks, Nonlinear Dynamic Systems, NARX, NFIR, NOBF},
  url      = {http://www.sciencedirect.com/science/article/pii/S2405896317301210},
}

@Article{Westwick2018,
  author   = {David T. Westwick and Gabriel Hollander and Kiana Karami and Johan Schoukens},
  journal  = {IFAC-PapersOnLine},
  title    = {Using decoupling methods to reduce polynomial {NARX} models},
  year     = {2018},
  issn     = {2405-8963},
  number   = {15},
  pages    = {796--801},
  volume   = {51},
  abstract = {The polynomial NARX model, where the output is a polynomial function of past inputs and outputs, is a commonly used equation error model for nonlinear systems. While it is linear in the variables, which simplifies its identification, it suffers from two major drawbacks: the number of parameters grows combinatorially with the degree of the nonlinearity, and it is a black box model, which makes it difficult to draw any insights from the identified model. Polynomial decoupling techniques are used to replace the multiple-input single-output polynomial with a decoupled polynomial structure comprising a transformation matrix followed by bank of SISO polynomials, whose outputs are then summed. This approach is demonstrated on two benchmark systems: The Bouc-Wen friction model and the data from the Silverbox model. In both cases, the decoupling results in a substantial reduction in the number of parameters, and allows some insight into the nature of the nonlinearities in the system.},
  doi      = {https://doi.org/10.1016/j.ifacol.2018.09.133},
  groups   = {interesting articles},
  keywords = {Nonlinear System Identification, NARX Models, Polynomial Decoupling},
  url      = {http://www.sciencedirect.com/science/article/pii/S2405896318317944},
}

@Article{Avery1944gene,
  author   = {Avery, Oswald T. and MacLeod, Colin M. and McCarty, Maclyn},
  journal  = {Journal of Experimental Medicine},
  title    = {Studies on the chemical nature of the substance inducing transformation of pneumococcal types: {Induction} of transformation by a desoxyribonucleic acid fraction isolated from pneumococcus type {III}},
  year     = {1944},
  issn     = {0022-1007},
  month    = {02},
  number   = {2},
  pages    = {137--158},
  volume   = {79},
  abstract = {{1. From Type III pneumococci a biologically active fraction has been isolated in highly purified form which in exceedingly minute amounts is capable under appropriate cultural conditions of inducing the transformation of unencapsulated R variants of Pneumococcus Type II into fully encapsulated cells of the same specific type as that of the heat-killed microorganisms from which the inducing material was recovered. 2. Methods for the isolation and purification of the active transforming material are described. 3. The data obtained by chemical, enzymatic, and serological analyses together with the results of preliminary studies by electrophoresis, ultracentrifugation, and ultraviolet spectroscopy indicate that, within the limits of the methods, the active fraction contains no demonstrable protein, unbound lipid, or serologically reactive polysaccharide and consists principally, if not solely, of a highly polymerized, viscous form of desoxyribonucleic acid. 4. Evidence is presented that the chemically induced alterations in cellular structure and function are predictable, type-specific, and transmissible in series. The various hypotheses that have been advanced concerning the nature of these changes are reviewed. }},
  doi      = {10.1084/jem.79.2.137},
  eprint   = {https://rupress.org/jem/article-pdf/79/2/137/1182848/137.pdf},
  groups   = {Biological Basis},
  url      = {https://doi.org/10.1084/jem.79.2.137},
}

@Article{Cui2020,
  author   = {Cui, Xiangyu and Li, Xun and Yang, Lanzhi},
  journal  = {Operations Research Letters},
  title    = {Better than optimal mean–variance portfolio policy in multi-period asset–liability management problem},
  year     = {2020},
  issn     = {0167-6377},
  number   = {6},
  pages    = {693--696},
  volume   = {48},
  abstract = {When the wealth is larger than some threshold in multi-period mean–variance asset–liability management, the pre-committed policy is no longer mean–variance efficient policy for the remaining investment horizon. To revise the policy, by relaxing self-financing constraint and allowing to withdraw some wealth, we derive a new dominating policy, which is better than the pre-committed policy. The revised policy can achieve the same mean–variance pairs attained by the pre-committed policy, and yields a nonnegative free cash flow stream over the investment horizon.},
  doi      = {https://doi.org/10.1016/j.orl.2020.08.010},
  file     = {:FILES/2020 - Cui2020 - Better than optimal mean–variance portfolio policy in multi-period asset–liability management problem.pdf:PDF},
  groups   = {portfolio},
  keywords = {Mean–variance model, Free cash flow stream, Wealth threshold, Asset–liability management},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167637720301243},
}

@Article{Yu2020,
  author   = {Yu, Xingying and Shen, Yang and Li, Xiang and Fan, Kun},
  journal  = {Operations Research Letters},
  title    = {Portfolio selection with parameter uncertainty under $\alpha$ maxmin mean-variance criterion},
  year     = {2020},
  issn     = {0167-6377},
  number   = {6},
  pages    = {720--724},
  volume   = {48},
  abstract = {We consider a mean–variance portfolio selection problem with uncertain model parameters. We formulate the mean–variance problem under the α maxmin criterion, in which the investor has mixed ambiguity aversion and ambiguity seeking attitudes and solves a convex combination of max–min and max–max optimization problems. By the Lagrangian method, we obtain the efficient portfolio and quasi-efficient frontier in closed form. We provide comparative statics of the quasi-efficient frontier to various parameters.},
  doi      = {https://doi.org/10.1016/j.orl.2020.08.008},
  file     = {:FILES/2020 - Yu2020 - Portfolio selection with parameter uncertainty under alpha maxmin mean-variance criterion.pdf:PDF},
  groups   = {portfolio},
  keywords = {Portfolio selection, Uncertainty, Ambiguity seeking, Ambiguity aversion, Quasi-efficient frontier},
  url      = {http://www.sciencedirect.com/science/article/pii/S016763772030122X},
}

@Article{Chan2020,
  author   = {Chan, Timothy C. Y. and Diamant, Adam and Mahmood, Rafid},
  journal  = {Operations Research Letters},
  title    = {Sampling from the complement of a polyhedron: {An} {MCMC} algorithm for data augmentation},
  year     = {2020},
  issn     = {0167-6377},
  number   = {6},
  pages    = {744--751},
  volume   = {48},
  abstract = {We present an MCMC algorithm for sampling from the complement of a polyhedron. Our approach is based on the Shake-and-bake algorithm for sampling from the boundary of a set and provably covers the complement. We use this algorithm for data augmentation in a machine learning task of classifying a hidden feasible set in a data-driven optimization pipeline. Numerical results on simulated and MIPLIB instances demonstrate that our algorithm, along with a supervised learning technique, outperforms conventional unsupervised baselines.},
  doi      = {10.1016/j.orl.2020.08.014},
  file     = {:FILES/2020 - Chan2020 - Sampling from the complement of a polyhedron- {An} {MCMC} algorithm for data augmentation.pdf:PDF},
  groups   = {nonconvex},
  keywords = {MCMC, Optimization, Machine learning},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167637720301280},
}

@Article{Ouorou2020,
  author   = {Ouorou, Adam},
  journal  = {Operations Research Letters},
  title    = {Fast proximal algorithms for nonsmooth convex optimization},
  year     = {2020},
  issn     = {0167-6377},
  number   = {6},
  pages    = {777--783},
  volume   = {48},
  abstract = {In the lines of our previous approach to devise proximal algorithms for nonsmooth convex optimization by applying Nesterov fast gradient concept to the Moreau–Yosida regularization of a convex function, we develop three new proximal algorithms for nonsmooth convex optimization. In these algorithms, the errors in computing approximate solutions for the Moreau–Yosida regularization are not fixed beforehand, while preserving the complexity estimates already established. We report some preliminary computational results to give a first estimate of their performance.},
  doi      = {https://doi.org/10.1016/j.orl.2020.09.008},
  file     = {:FILES/2020 - Ouorou2020 - Fast proximal algorithms for nonsmooth convex optimization.pdf:PDF},
  groups   = {nonconvex},
  keywords = {Nesterov accelerated gradient method, Proximal methods, Nonsmooth optimization, Convex programming},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167637720301462},
}

@Article{Fischer2020,
  author   = {Fischer, Dennis and Woeginger, Gerhard J.},
  journal  = {Operations Research Letters},
  title    = {A faster algorithm for the continuous bilevel knapsack problem},
  year     = {2020},
  issn     = {0167-6377},
  number   = {6},
  pages    = {784--786},
  volume   = {48},
  abstract = {We construct a fast algorithm with time complexity O(nlogn) for a continuous bilevel knapsack problem with interdiction constraints for n items. This improves on a recent algorithm from the literature with quadratic time complexity O(n2).},
  doi      = {https://doi.org/10.1016/j.orl.2020.09.007},
  file     = {:FILES/2020 - Fischer2020 - A faster algorithm for the continuous bilevel knapsack problem.pdf:PDF},
  groups   = {discrete},
  keywords = {Bilevel programming, Fast algorithm, Knapsack problem},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167637720301450},
}

@Article{Onn2020,
  author   = {Onn, Shmuel},
  journal  = {Operations Research Letters},
  title    = {On degree sequence optimization},
  year     = {2020},
  issn     = {0167-6377},
  number   = {6},
  pages    = {840--843},
  volume   = {48},
  abstract = {We consider the problem of finding a subgraph of a given graph maximizing a given function evaluated at its degree sequence. While it is intractable already for convex functions, we show it is polynomial time solvable for convex multi-criteria objectives. We also consider a colored extension of the problem with separable objectives, which includes the notorious exact matching problem as a special case, and show that it is polynomial time solvable on graphs of bounded tree-depth for any vertex functions.},
  doi      = {https://doi.org/10.1016/j.orl.2020.10.010},
  file     = {:FILES/2020 - Onn2020 - On degree sequence optimization.pdf:PDF},
  groups   = {to_read},
  keywords = {Graph, Combinatorial optimization, Degree sequence, Factor, Matching, Integer programming},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167637720301589},
}

@Book{Fuller2000,
  author    = {Robert Full\'{e}r},
  publisher = {Springer-Verlag Berlin Heidelberg GmbH},
  title     = {Introduction to neuro-fuzzy systems},
  year      = {2000},
  isbn      = {978-3-7908-1256-5},
  file      = {:FILES/2000 - Fuller2000 - Introduction to Neuro-Fuzzy Systems.pdf:PDF},
  groups    = {intelligent},
}

@Article{Ma2020,
  author   = {Ma, Jun and Yang, Liming and Sun, Qun},
  journal  = {Neurocomputing},
  title    = {Capped $L_1$-norm distance metric-based fast robust twin bounded support vector machine},
  year     = {2020},
  issn     = {0925-2312},
  pages    = {295--311},
  volume   = {412},
  abstract = {In this paper, to improve the performance of capped L1-norm twin support vector machine (CTSVM), we first propose a new robust twin bounded support vector machine (RTBSVM) by introducing the regularization term. The significant advantage of our RTBSVM over CTSVM is that the structural risk minimization principle is implemented. This embodies the marrow of statistical learning theory, so this modification can improve the performance of classification. Furthermore, to accelerate the computation of RTBSVM and simultaneously inherit the merit of robustness, we construct a least squares version of RTBSVM (called RTBSVM). This formulation leads to a simple and fast algorithm for binary classifiers by solving just two systems of linear equations. Finally, we derive two simple and effective iterative optimization algorithms for solving RTBSVM and FRTBSVM, respectively. Simultaneously, we theoretically rigorously analyze and prove the computational complexity, local optimality and convergence of the algorithms. Experimental results on one synthetic dataset and nine UCI datasets demonstrate that our methods are competitive with other methods. Additionally, the FRTBSVM is directly applied to recognize the purity of hybrid maize seeds using near-infrared spectral data. Experiments show that our method achieves better performance than the traditional methods in most spectral regions.},
  doi      = {https://doi.org/10.1016/j.neucom.2020.06.053},
  file     = {:FILES/2020 - Ma2020 - Capped l1-norm distance metric-based fast robust twin bounded support vector machine.pdf:PDF},
  groups   = {svm},
  keywords = {Twin bounded support vector machine, Least squares twin bounded support vector machine, Capped -norm, Robustness, Outliers},
  url      = {http://www.sciencedirect.com/science/article/pii/S0925231220310249},
}

@Article{Dun2020,
  author    = {Dun, Xiong and Ikoma, Hayato and Wetzstein, Gordon and Wang, Zhanshan and Cheng, Xinbin and Peng, Yifan},
  journal   = {Optica},
  title     = {Learned rotationally symmetric diffractive achromat for full-spectrum computational imaging},
  year      = {2020},
  month     = {8},
  number    = {8},
  pages     = {913--922},
  volume    = {7},
  abstract  = {Diffractive achromats (DAs) promise ultra-thin and light-weight form factors for full-color computational imaging systems. However, designing DAs with the optimal optical transfer function (OTF) distribution suitable for image reconstruction algorithms has been a difficult challenge. Emerging end-to-end optimization paradigms of diffractive optics and processing algorithms have achieved impressive results, but these approaches require immense computational resources and solve non-convex inverse problems with millions of parameters. Here, we propose a learned rotational symmetric DA design using a concentric ring decomposition that reduces the computational complexity and memory requirements by one order of magnitude compared with conventional end-to-end optimization procedures, which simplifies the optimization significantly. With this approach, we realize the joint learning of a DA with an aperture size of 8 mm and an image recovery neural network, i.e., Res-Unet, in an end-to-end manner across the full visible spectrum (429--699 nm). The peak signal-to-noise ratio of the recovered images of our learned DA is 1.3 dB higher than that of DAs designed by conventional sequential approaches. This is because the learned DA exhibits higher amplitudes of the OTF at high frequencies over the full spectrum. We fabricate the learned DA using imprinting lithography. Experiments show that it resolves both fine details and color fidelity of diverse real-world scenes under natural illumination. The proposed design paradigm paves the way for incorporating DAs for thinner, lighter, and more compact full-spectrum imaging systems.},
  doi       = {10.1364/OPTICA.394413},
  file      = {:FILES/2020 - Dun2020 - Learned rotationally symmetric diffractive achromat for full-spectrum computational imaging.pdf:PDF},
  groups    = {intelligent},
  keywords  = {Image processing; Image quality; Image reconstruction; Imaging systems; Inverse problems; Reconstruction algorithms},
  publisher = {OSA},
  url       = {http://www.osapublishing.org/optica/abstract.cfm?URI=optica-7-8-913},
}

@Misc{Yan2020,
  author        = {Yan, Xiaojuan and An, Kang and Wang, Cheng-Xiang and Zhu, Wei-Ping and Li, Yusheng and Feng, Zhiqiang},
  title         = {Genetic algorithm optimized support vector machine in noma-based satellite networks with imperfect csi},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2002.00529},
  file          = {:FILES/2020 - Yan2020 - Genetic Algorithm Optimized Support Vector Machine in NOMA-Based Satellite Networks with Imperfect CSI.pdf:PDF},
  groups        = {svm},
  primaryclass  = {eess.SP},
  url           = {https://arxiv.org/abs/2002.00529},
}

@Article{XuHaitong2020,
  author   = {Xu, Haitong and Hassani, Vahid and Guedes Soares, C.},
  journal  = {Applied Ocean Research},
  title    = {Truncated least square support vector machine for parameter estimation of a nonlinear manoeuvring model based on pmm tests},
  year     = {2020},
  issn     = {0141-1187},
  pages    = {102076},
  volume   = {97},
  abstract = {A new version of least square support vector machine (LS-SVM), the truncated LS-SVM, is proposed to estimate the nondimensionalized hydrodynamic coefficients. Truncated LS-SVM is shown to be an efficient and robust method that avoids the costly matrix inversion operation in classical LS-SVM using the singular values decomposition. Meanwhile, the smaller singular values are neglected considering their negligible contribution to the solutions. In order to get a robust parameter estimation, the model simplification of the nonlinear manoeuvring model is carried out using a leave-one-out method, considering the trade-off between the parameter uncertainty and accuracy of the numerical model. The simplified manoeuvring model and the values of nondimensionalized hydrodynamic coefficients are presented. The coefficients are estimated using Planar motion mechanism (PMM) tests, which were carried out in a towing tank. The validation process is carried to validate the generalization performance of the obtained numerical model using the PMM test data.},
  doi      = {https://doi.org/10.1016/j.apor.2020.102076},
  file     = {:FILES/2020 - XuHaitong2020 - Truncated least square support vector machine for parameter estimation of a nonlinear manoeuvring model based on PMM tests.pdf:PDF},
  groups   = {svm},
  keywords = {Truncated support vector machine, Parameter estimation, Model reduction, Nonlinear manoeuvring model, Planar motion mechanism test},
  url      = {http://www.sciencedirect.com/science/article/pii/S0141118719300112},
}

@Article{Yuan2021,
  author   = {Yuan, Chao and Yang, Liming and Sun, Ping},
  journal  = {Information Sciences},
  title    = {Correntropy-based metric for robust twin support vector machine},
  year     = {2021},
  issn     = {0020-0255},
  pages    = {82--101},
  volume   = {545},
  abstract = {This work proposes a robust distance metric that is induced by correntropy based on Laplacian kernel. The proposed metric satisfies the properties that distance metric must have. Moreover, we demonstrate important properties of the proposed metric such as robustness, boundedness, non-convexity and approximation behaviors. The proposed metric includes and extends the traditional metrics such as L0-norm and L1-norm metrics. Following that we apply the proposed metric to twin support vector machine classification (TSVM), and then a new robust TSVM algorithm (called RCTSVM) is built to reduce the influence of noise and outliers. The proposed RCTSVM inherits the advantages of TSVM and improves the robustness. However, the non-convexity of the proposed model makes it difficult to optimize. A continuous optimization method is developed to solve the RCTSVM. The problem is converted into difference of convex (DC) programming, and the corresponding DC algorithm (DCA) converges linearly. Compared with the traditional algorithms, numerical experiments under different noise setting and evaluation criteria show that the proposed RCTSVM has robustness to noise and outliers in most cases, which demonstrates the feasibility and effectiveness of the proposed method.},
  doi      = {10.1016/j.ins.2020.07.068},
  file     = {:FILES/2021 - Yuan2021 - Correntropy-based metric for robust twin support vector machine.pdf:PDF},
  groups   = {svm},
  keywords = {Robustness, Correntropy, Metric learning, Twin support vector machine, DC programming},
  url      = {http://www.sciencedirect.com/science/article/pii/S0020025520307477},
}

@Article{Chen2020a,
  author   = {Chen, Wei-Jie and Shao, Yuan-Hai and Li, Chun-Na and Wang, Yu-Qing and Liu, Ming-Zeng and Wang, Zhen},
  journal  = {Applied Soft Computing},
  title    = {{NPrSVM}: {Nonparallel} sparse projection support vector machine with efficient algorithm},
  year     = {2020},
  issn     = {1568-4946},
  pages    = {106142},
  volume   = {90},
  abstract = {The recently proposed projection twin support vector machine (PTSVM) is an excellent nonparallel classifier. However, PTSVM employs the least-squares loss function to measure its within-class empirical risk, resulting in several drawbacks, such as non-sparseness for decision, sensitivity to outliers, expensive matrix inversion, and inconsistency in the linear and nonlinear models. To alleviate these issues, in this paper, we propose a novel nonparallel sparse projection support vector machine (NPrSVM). Different from the original PTSVM that squeezes the projected values of within-class instances to its own class center, NPrSVM aims to cluster them as much as possible within an insensitive tube. Specifically, our NPrSVM owns the following attractive merits: (i) Benefiting from the L1-norm symmetric Hinge loss function, NPrSVM not only enjoys sparseness for decision but also improves robustness to outliers. (ii) The elegant formulation of dual problems in NPrSVM no longer involves the matrix inversion during the training procedure. This greatly saves the computing time compared to PTSVM. (iii) While the nonlinear formulation of PTSVM is not the direct extension of linear PTSVM, the linear and nonlinear versions of our NPrSVM are consistent. (iv) An efficient dual coordinate descent algorithm is further designed for NPrSVM to handle large-scale classification. Finally, the feasibility and effectiveness of NPrSVM are validated by extensive experiments on both synthetic and real-world datasets.},
  doi      = {https://doi.org/10.1016/j.asoc.2020.106142},
  file     = {:FILES/2020 - Chen2020a - NPrSVM- Nonparallel sparse projection support vector machine with efficient algorithm.pdf:PDF},
  groups   = {svm},
  keywords = {Support vector machine, Projection twin support vector machine, Nonparallel projections, Sparseness, Classification},
  url      = {http://www.sciencedirect.com/science/article/pii/S156849462030082X},
}

@Article{Liu2020,
  author   = {Liu, Liming and Chu, Maoxiang and Gong, Rongfen and Peng, Yongcheng},
  journal  = {Pattern Recognition},
  title    = {Nonparallel support vector machine with large margin distribution for pattern classification},
  year     = {2020},
  issn     = {0031-3203},
  pages    = {107374},
  volume   = {106},
  abstract = {The large margin distribution machine (LDM) combines the working principle of support vector machine (SVM) and the margin distribution to directly improve the algorithm's generalization. The margin distribution can be expressed with the margin mean and margin variance. It has been proved to be an efficient algorithm for binary classification. Inspired by the LDM, a novel classifier termed as LMD-NPSVM is proposed to improve the generalization performance of the nonparallel support vector machine (NPSVM) in this paper. Firstly, to meet the structure of NPSVM, the large margin distribution is reconstructed. Then, the linear LMD-NPSVM is built by introducing the reconstructed margin distribution into NPSVM. In addition, the linear case is extended to the nonlinear case with a kernel trick. All experiments show that our LMD-NPSVM is superior to the state-of-the-art algorithms in generalization performance.},
  doi      = {https://doi.org/10.1016/j.patcog.2020.107374},
  file     = {:FILES/2020 - Liu2020 - Nonparallel support vector machine with large margin distribution for pattern classification.pdf:PDF},
  groups   = {svm},
  keywords = {Pattern classification, Nonparallel support vector machine, Margin distribution, Generalization performance},
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320320301771},
}

@Article{Razzak2020,
  author   = {Razzak, Imran and Zafar, Khurram and Imran, Muhammad and Xu, Guandong},
  journal  = {Future Generation Computer Systems},
  title    = {Randomized nonlinear one-class support vector machines with bounded loss function to detect of outliers for large scale iot data},
  year     = {2020},
  issn     = {0167-739X},
  pages    = {715--723},
  volume   = {112},
  abstract = {Exponential growth of large scale data industrial internet of things is evident due to the enormous deployment of IoT data acquisition devices. Detection of unusual patterns from large scale IoT data is important though challenging task. Recently, one-class support vector machines is extensively being used for anomaly detection. It tries to find an optimal hyperplane in high dimensional data that best separates the data from anomalies with maximum margin. However, the hinge loss of traditional one-class support vector machines is unbounded, which results in larger loss caused by outliers affecting its performance for anomaly detection. Furthermore, existing methods are computationally complex for larger data. In this paper, we present novel anomaly detection for large scale data by using randomized nonlinear features in support vector machines with bounded loss function rather than finding optimized support vectors with unbounded loss function. Extensive experimental evaluation on ten benchmark datasets shows the robustness of the proposed approach against outliers such as 0.8239, 0.7921 , 0.7501, 0.6711 , 0.6692, 0.4789 , 0.6462 , 0.6812 , 0.7271 and 0.7873 accuracy for Gas Sensor Array, Human Activity Recognition, Parkinson’s, Hepatitis, Breast Cancer, Blood Transfusion , Heart, ILPD and Wholesale Customers datasets respectively. In addition to this, introduction of randomized nonlinear feature helps to considerably decrease the computational complexity and space complexity from O(N3) to O(Bkn) and O(N2) to O(Bkn). Thus, very attractive for larger datasets.},
  doi      = {https://doi.org/10.1016/j.future.2020.05.045},
  file     = {:FILES/2020 - Razzak2020 - Randomized nonlinear one-class support vector machines with bounded loss function to detect of outliers for large scale IoT data.pdf:PDF},
  groups   = {svm},
  keywords = {Anomaly detection, Hinge loss, Support Vector Machines, Randomized, SVM, One-class classification},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167739X19313913},
}

@Article{Ye2020,
  author   = {Ye, Yafen and Gao, Junbin and Shao, Yuanhai and Li, Chunna and Jin, Yan and Hua, Xiangyu},
  journal  = {Applied Mathematical Modelling},
  title    = {Robust support vector regression with generic quadratic nonconvex $\varepsilon$-insensitive loss},
  year     = {2020},
  issn     = {0307-904X},
  pages    = {235--251},
  volume   = {82},
  abstract = {In this paper, we propose a robust support vector regression with a novel generic nonconvex quadratic ε-insensitive loss function. The proposed method is robust to outliers or noise since it can adaptively control the loss value and decrease the negative influence of outliers or noise on the decision function by adjusting the elastic interval parameter and adaptive robustification parameter. Given the nature of the nonconvexity of the optimization problem, a concave-convex programming procedure is employed to solve the proposed problem. Experimental results on two artificial data sets and three real-world data sets indicate that the proposed method outperforms support vector regression, L1-norm support vector regression, least squares support vector regression, robust least squares support vector regression, and support vector regression with the Huber loss function on both robustness and generalization ability.},
  doi      = {https://doi.org/10.1016/j.apm.2020.01.053},
  file     = {:FILES/2020 - Ye2020 - Robust support vector regression with generic quadratic nonconvex ε-insensitive loss.pdf:PDF},
  groups   = {svm},
  keywords = {Support vector regression, Nonconvex loss, Robust regression, Concave-convex programming},
  url      = {http://www.sciencedirect.com/science/article/pii/S0307904X20300536},
}

@Article{Zhu2020,
  author   = {Zhu, Wenxin and Song, Yunyan and Xiao, Yingyuan},
  journal  = {Engineering Applications of Artificial Intelligence},
  title    = {Support vector machine classifier with huberized pinball loss},
  year     = {2020},
  issn     = {0952-1976},
  pages    = {103635},
  volume   = {91},
  abstract = {The original support vector machine (SVM) uses the hinge loss function, which is non-differentiable and makes the problem difficult to solve in particular for regularized SVM, such as with ℓ1-regularized. On the other hand, the hinge loss is sensitive to noise. To circumvent these drawbacks, a huberized pinball loss function is proposed. It is less sensitive to noise, similar to the pinball loss which is related to the quantile distance. The proposed loss function is differentiable everywhere and this differentiability can significantly reduce the computational cost for the SVM algorithm. The elastic net penalty is applied to the SVM and the support vector machine classifier with huberized pinball loss (HPSVM) is proposed. Due to the continuous differentiability of the huberized pinball loss function, the Proximal Gradient method is used to solve the proposed model. The numerical experiments on synthetic data, real world datasets confirm the robustness and effectiveness of the proposed method. Statistical comparison is performed to show the significant difference between the proposed method and other compered ones.},
  doi      = {https://doi.org/10.1016/j.engappai.2020.103635},
  file     = {:FILES/2020 - Zhu2020 - Support vector machine classifier with huberized pinball loss.pdf:PDF},
  groups   = {svm},
  keywords = {Support vector machine, Huberized pinball loss, Proximal gradient, Wilcoxon signed rank test, Friedman test, ROC curve, AUC},
  url      = {http://www.sciencedirect.com/science/article/pii/S0952197620300920},
}

@Article{Chen2018b,
  author   = {Chen, Wei-Jie and Li, Chun-Na and Shao, Yuan-Hai and Zhang, Ju and Deng, Nai-Yang},
  journal  = {Neurocomputing},
  title    = {Robust $L_1$-norm multi-weight vector projection support vector machine with efficient algorithm},
  year     = {2018},
  issn     = {0925-2312},
  pages    = {345--361},
  volume   = {315},
  abstract = {The recently proposed multi-weight vector projection support vector machine (EMVSVM) is an excellent multi-projections classifier. However, the formulation of MVSVM is based on the L2-norm criterion, which makes it prone to be affected by outliers. To alleviate this issue, in this paper, we propose a robust L1-norm MVSVM method, termed as MVSVML1. Specifically, our MVSVML1 aims to seek a pair of multiple projections such that, for each class, it maximizes the ratio of the L1-norm between-class dispersion and the L1-norm within-class dispersion. To optimize such L1-norm ratio problem, a simple but efficient iterative algorithm is further presented. The convergence of the algorithm is also analyzed theoretically. Extensive experimental results on both synthetic and real-world datasets confirm the feasibility and effectiveness of the proposed MVSVML1.},
  doi      = {https://doi.org/10.1016/j.neucom.2018.04.083},
  file     = {:FILES/2018 - Chen2018b - robust l1 norm multi-weight vector projection support vector machine with efficient algorithms.pdf:PDF},
  groups   = {svm},
  keywords = {Support vector machine, Multi-weight vector projections, -norm ratio optimization, Outliers, Multiple projections},
  url      = {http://www.sciencedirect.com/science/article/pii/S0925231218308622},
}

@Article{Golbayani2020,
  author   = {Golbayani, Parisa and Florescu, Ionuţ and Chatterjee, Rupak},
  journal  = {The North American Journal of Economics and Finance},
  title    = {A comparative study of forecasting corporate credit ratings using neural networks, support vector machines, and decision trees},
  year     = {2020},
  issn     = {1062-9408},
  pages    = {101251},
  volume   = {54},
  abstract = {Credit ratings are one of the primary keys that reflect the level of riskiness and reliability of corporations to meet their financial obligations. Rating agencies tend to take extended periods of time to provide new ratings and update older ones. Therefore, credit scoring assessments using artificial intelligence has gained a lot of interest in recent years. Successful machine learning methods can provide rapid analysis of credit scores while updating older ones on a daily time scale. Related studies have shown that neural networks and support vector machines outperform other techniques by providing better prediction accuracy. The purpose of this paper is two fold. First, we provide a survey and a comparative analysis of results from literature applying machine learning techniques to predict credit rating. Second, we apply ourselves four machine learning techniques deemed useful from previous studies (Bagged Decision Trees, Random Forest, support vector machine and Multilayer Perceptron) to the same datasets. We evaluate the results using a 10-fold cross validation technique. The results of the experiment for the datasets chosen show superior performance for decision tree based models. In addition to the conventional accuracy measure of classifiers, we introduce a measure of accuracy based on notches called ”Notch Distance” to analyze the performance of the above classifiers in the specific context of credit rating. This measure tells us how far the predictions are from the true ratings. We further compare the performance of three major rating agencies, Standard \& Poors, Moody’s and Fitch where we show that the difference in their ratings is comparable with the decision tree prediction versus the actual rating on the test dataset.},
  doi      = {https://doi.org/10.1016/j.najef.2020.101251},
  file     = {:FILES/2020 - Golbayani2020 - A comparative study of forecasting corporate credit ratings using neural networks, support vector machines, and decision trees.pdf:PDF},
  groups   = {svm},
  keywords = {Machine learning models, Support vector machine, Credit rating, Neural networks, Classification trees},
  url      = {http://www.sciencedirect.com/science/article/pii/S1062940820301480},
}

@Article{Lee2020,
  author   = {Lee, In Gyu and Zhang, Qianqian and Yoon, Sang Won and Won, Daehan},
  journal  = {Knowledge-Based Systems},
  title    = {A mixed integer linear programming support vector machine for cost-effective feature selection},
  year     = {2020},
  issn     = {0950-7051},
  pages    = {106145},
  volume   = {203},
  abstract = {In the era of big data, feature selection is indispensable as a dimensional reduction technique to lower data complexity and enhance machine learning performances. However, traditional feature selection methods mainly focus on classification performances, while they exclude the impact of associated feature costs; e.g., price, risk, and computational complexity for feature acquisition. In this research, we extend the ℓ1 norm support vector machine (ℓ1-SVM) to address the feature costs, by incorporating a budget constraint to preserve classification accuracy with the least expensive features. Furthermore, we formulate its robust counterpart to address the uncertainty of the feature costs. To enhance computational efficiency, we also develop an algorithm to tighten the bound of the weight vector in the budget constraint. Through the experimental study on a variety of benchmark and synthetic datasets, our proposed mixed integer linear programming (MILP) models show that they can achieve competitive outcomes in terms of predictive and economic performances. Also, the algorithm that tightens the budget constraint helps to curtail computational complexity.},
  doi      = {https://doi.org/10.1016/j.knosys.2020.106145},
  file     = {:FILES/2020 - Lee2020 - A mixed integer linear programming support vector machine for cost-effective feature selection.pdf:PDF},
  groups   = {svm},
  keywords = {Feature selection, Support vector machine, Mixed integer linear programming, Robust optimization, Feature cost, Cost uncertainty},
  url      = {http://www.sciencedirect.com/science/article/pii/S0950705120303944},
}

@Article{Li2021,
  author   = {Li, Guoquan and Yang, Linxi and Wu, Zhiyou and Wu, Changzhi},
  journal  = {Information Sciences},
  title    = {{D.C.} programming for sparse proximal support vector machines},
  year     = {2021},
  issn     = {0020-0255},
  pages    = {187--201},
  volume   = {547},
  abstract = {Proximal support vector machine (PSVM), as a variant of support vector machine (SVM), is to generate a pair of non-parallel hyperplanes for classification. Although PSVM is one of the powerful classification tools, its ability on feature selection is still weak. To overcome this defect, we introduce ℓ0-norm regularization in PSVM which enables PSVM to select important features and remove redundant features simultaneously for classification. This PSVM is called as a sparse proximal support vector machine (SPSVM). Due to the presence of ℓ0-norm, the resulting optimization problem of SPSVM is neither convex nor smooth and thus, is difficult to solve. In this paper, we introduce a continuous nonconvex function to approximate ℓ0-norm, and propose a novel difference of convex functions algorithms (DCA) to solve SPSVM. The main merit of the proposed method is that all subproblems are smooth and admit closed form solutions. The effectiveness of the proposed method is illustrated by theoretical analysis as well as some numerical experiments on both simulation datasets and real world datasets.},
  doi      = {10.1016/j.ins.2020.08.038},
  file     = {:FILES/2021 - Li2021 - D.C. programming for sparse proximal support vector machines.pdf:PDF},
  groups   = {svm},
  keywords = {Support vector machine, Sparse proximal support vector machine, DC programming, DC Algorithm},
  url      = {http://www.sciencedirect.com/science/article/pii/S0020025520308057},
}

@Article{Liu2019a,
  author   = {Liu, Xinggao and Gu, Youzhi and He, Shuting and Xu, Zhipeng and Zhang, Zeyin},
  journal  = {Applied Soft Computing},
  title    = {A robust reliability prediction method using weighted least square support vector machine equipped with chaos modified particle swarm optimization and online correcting strategy},
  year     = {2019},
  issn     = {1568-4946},
  pages    = {105873},
  volume   = {85},
  abstract = {Accurate reliability prediction in engineering systems has drawn more and more attention over the past decades due to its important role in accessing the security condition of the system and providing safety operation basis, however, which still remains challenging caused by the mismatch of reliability prediction model especially for dynamic uncertainty of future sampled data. Therefore, a novel approach for reliability prediction with an optimal Online Correcting Strategy (OCS) combined with Weighted Least Square Support Vector Machine (WLSSVM) and Chaos Modified Particle Swarm Optimization (CMPSO) algorithm, named OCS–CMPSO–WLSSVM, are proposed, where WLSSVM models the functional relationship between input and output of the system, CMPSO optimizes the parameters of WLSSVM, and OCS modifies the model to reduce its mismatch as the system runs, respectively. The performance of the proposed model is demonstrated with five classic practical engineering examples and compared with the existing methods reported in literature in detail. The experimental results show that the proposed method not only has higher reliability prediction accuracy and robustness, but also has its superiority and applicability in other fields including time-ordered, feature-based regression problem and classification problem.},
  doi      = {https://doi.org/10.1016/j.asoc.2019.105873},
  file     = {:FILES/2019 - Liu2019a - A robust reliability prediction method using Weighted Least Square Support Vector Machine equipped with Chaos Modified Particle Swarm Optimization and Online Correcting Strategy.pdf:PDF},
  groups   = {svm},
  keywords = {Reliability prediction, Model mismatch, Online correcting strategy (OCS), Weighted least square support vector machine (WLSSVM), Chaos modified particle swarm optimization algorithm (CMPSO)},
  url      = {http://www.sciencedirect.com/science/article/pii/S1568494619306544},
}

@Article{Liu2020a,
  author   = {Liu, Xinggao and He, Shuting and Gu, Youzhi and Xu, Zhipeng and Zhang, Zeyin and Wang, Wenhai and Liu, Ping},
  journal  = {ISA Transactions},
  title    = {A robust cutting pattern recognition method for shearer based on least square support vector machine equipped with chaos modified particle swarm optimization and online correcting strategy},
  year     = {2020},
  issn     = {0019-0578},
  pages    = {199--209},
  volume   = {99},
  abstract = {Accurate cutting pattern recognition method for shearer in coal mining process has drawn more and more attention over the past decades due to its important role in guaranteeing the steady operation of the equipment, which, however, remains challenging caused by the mismatch of cutting pattern recognition especially for dynamic uncertainty of future sampled data. Therefore, a novel approach for cutting pattern recognition with an optimal Online Correcting Strategy (OCS) combined with Least Square Support Vector Machine (LSSVM) and Chaos Modified Particle Swarm Optimization (CMPSO) algorithm, named OCS-CMPSO-LSSVM, is proposed, where LSSVM models the functional relationship between input and output of the system, CMPSO optimizes the parameters of LSSVM, and OCS modifies the model to reduce its mismatch as the system runs, respectively. The performance of the proposed model is demonstrated with a simulation experiment and compared with the existing methods reported in the literature in detail. The experimental results reveal that the proposed models can achieve better cutting pattern recognition performance and higher robustness.},
  doi      = {https://doi.org/10.1016/j.isatra.2019.08.069},
  file     = {:FILES/2020 - Liu2020a - A robust cutting pattern recognition method for shearer based on Least Square Support Vector Machine equipped with Chaos Modified Particle Swarm Optimization and Online Correcting Strategy.pdf:PDF},
  groups   = {svm},
  keywords = {Cutting pattern recognition, Model mismatch, Online Correcting Strategy (OCS), Least Square Support Vector Machine (LSSVM), Chaos Modified Particle Swarm Optimization algorithm (CMPSO)},
  url      = {http://www.sciencedirect.com/science/article/pii/S001905781930415X},
}

@Article{Lopez2019,
  author   = {L\'{o}pez, Julio and Maldonado, Sebasti\'{a}n and Carrasco, Miguel},
  journal  = {Neurocomputing},
  title    = {Robust nonparallel support vector machines via second-order cone programming},
  year     = {2019},
  issn     = {0925-2312},
  pages    = {227--238},
  volume   = {364},
  abstract = {A novel binary classification approach is proposed in this paper, extending the ideas behind nonparallel support vector machine (NPSVM) to robust machine learning. NPSVM constructs two twin hyperplanes by solving two independent quadratic programming problems and generalizes the well-known twin support vector machine (TWSVM) method. Robustness is conferred on the NPSVM approach by using a probabilistic framework for maximizing model fit, which is cast into two second-order cone programming (SOCP) problems by assuming a worst-case setting for the data distribution of the training patterns. Experiments on benchmark datasets confirmed the theoretical virtues of our approach, showing superior average performance compared with various SVM formulations.},
  doi      = {https://doi.org/10.1016/j.neucom.2019.07.072},
  file     = {:FILES/2019 - Lopez2019 - Robust nonparallel support vector machines via second-order cone programming.pdf:PDF},
  groups   = {svm},
  keywords = {Support vector machines, Twin support vector machines, Nonparallel support vector machines, Second-order cone programming, Robustness},
  url      = {http://www.sciencedirect.com/science/article/pii/S0925231219310793},
}

@Article{Ma2018,
  author   = {Ma, Yue and He, Yiwei and Tian, Yingjie},
  journal  = {Procedia Computer Science},
  title    = {Online robust {Lagrangian} support vector machine against adversarial attack},
  year     = {2018},
  issn     = {1877-0509},
  note     = {6th International Conference on Information Technology and Quantitative Management},
  pages    = {173--181},
  volume   = {139},
  abstract = {In adversarial environment such as intrusion detection and spam filtering, the adversary-intruder or spam advertiser may attempt to produce contaminate training instance and manipulate the learning of classifier. In order to keep good classification performance, many robuster learning methods have been proposed to deal with the adversarial attack. Support Vector Machines(SVMs) is a kind of successful approach in the adversarial classification tasks and the investigation of robust SVMs is very popular. However, in many real application, the data including stain instance is coming dynamically. Batch learning which needs retraining when encountering new samples, will consume more computing resources. In this paper, we propose a robust Lagrangian support vector machine (RLSVM) with modified kernel matrix and explore the online learning algorithm on it. The experimental results show the robustness of RLSVM against label noise produced by adversaries under the online adversarial environment.},
  doi      = {https://doi.org/10.1016/j.procs.2018.10.239},
  file     = {:FILES/2018 - Ma2018 - Online Robust Lagrangian Support Vector Machine against Adversarial Attack.pdf:PDF},
  groups   = {svm},
  keywords = {adversarial attack, poison attack, label noise, online learning, Lagrangian SVM},
  url      = {http://www.sciencedirect.com/science/article/pii/S1877050918319082},
}

@Article{Okwuashi2020,
  author   = {Okwuashi, Onuwa and Ndehedehe, Christopher E.},
  journal  = {Pattern Recognition},
  title    = {Deep support vector machine for hyperspectral image classification},
  year     = {2020},
  issn     = {0031-3203},
  pages    = {107298},
  volume   = {103},
  abstract = {To improve on the robustness of traditional machine learning approaches, emphasis has recently shifted to the integration of such methods with Deep Learning techniques. However, the classification problems, complexity and inconsistency in several spectral classifiers developed for hyperspectral images are some reasons warranting further research. This study investigates the application of Deep Support Vector Machine (DSVM) for hyperspectral image classification. Two hyperspectral images, Indian Pines and University of Pavia are used as tentative test beds for the experiment. The DSVM is implemented with four kernel functions: Exponential Radial Basis Function (ERBF), Gaussian Radial Basis Function (GRBF), neural and polynomial. Stand-alone Support Vector Machines form the interconnecting weights of the entire network. The network is trained with one hundred input datasets, and the interconnecting weights of the network are initialised using the regularisation parameter of the model. Numerical results show that the classification accuracies of the DSVM for Indian Pines and University of Pavia based on each DSVM kernel functions are: ERBF (98.87\%, 98.16\%), GRBF (98.90\%, 98.47\%), neural (98.41\%, 97.27\%), and polynomial (99.24\%, 98.79\%). By comparing the DSVM algorithm against well-known classifiers, Support Vector Machine (SVM), Deep Neural Network (DNN), Gaussian Mixture Model (GMM), K Nearest Neighbour (KNN), and K Means (KM) classifiers, the mean classification accuracies for Indian Pines and University of Pavia are: DSVM (98.86\%, 98.17\%), SVM (76.03\%, 73.52\%), DNN (94.45\%, 93.79\%), GMM (76.82\%, 78.35\%), KNN (76.87\%, 78.80\%), and KM (21.65\%, 18.18\%). These results indicate that the DSVM outperformed the other classification algorithms. The high accuracy obtained with the DSVM validates its efficacy as state-of-the-art algorithm for hyperspectral image classification.},
  doi      = {https://doi.org/10.1016/j.patcog.2020.107298},
  file     = {:FILES/2020 - Okwuashi2020 - Deep support vector machine for hyperspectral image classification.pdf:PDF},
  groups   = {svm},
  keywords = {Remote sensing, Hyperspectral image, Deep support vector machine, Image classification},
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320320301023},
}

@Article{Qi2019,
  author   = {Qi, Kai and Yang, Hu and Hu, Qingyu and Yang, Dongjun},
  journal  = {Knowledge-Based Systems},
  title    = {A new adaptive weighted imbalanced data classifier via improved support vector machines with high-dimension nature},
  year     = {2019},
  issn     = {0950-7051},
  pages    = {104933},
  volume   = {185},
  abstract = {The standard support vector machine (SVM) models are widely used in various fields, but we show that they are not rationally defined from the perspective of geometric point, which is likely to degrade the models’ performances theoretically, especially under the high-dimensional cases. In this paper, we consider a composite penalty and propose an elastic net support vector machine (ENSVM). Unlike the doubly regularized support vector machine (DrSVM, Wang et al. (2006)), we impose the penalty to the slack variables rather than the normal vectors of the hyperplane. Then, we prove that ENSVM is more rationally defined than standard SVM and DrSVM (in section 3.2.1). Moreover, the ENSVM demonstrates a more stable and high-dimension nature inherently, while the simulation results cogently support these merits. Besides, we also combine fused weights with ENSVM and propose an adaptive weighted elastic net support vector machine (AWENSVM), to make the primal model more adaptive and robust to the imbalanced data. Compared with the other popular SVMs, the AWENSVM model proposed in this paper performs better obviously.},
  doi      = {https://doi.org/10.1016/j.knosys.2019.104933},
  file     = {:FILES/2019 - Qi2019 - A new adaptive weighted imbalanced data classifier via improved support vector machines with high-dimension nature.pdf:PDF},
  groups   = {svm},
  keywords = {Imbalanced data, Support vector machine, High dimension, Adaptive weights},
  url      = {http://www.sciencedirect.com/science/article/pii/S0950705119303764},
}

@Article{Tian2018,
  author   = {Tian, Yingjie and Mirzabagheri, Mahboubeh and Bamakan, Seyed Mojtaba Hosseini and Wang, Huadong and Qu, Qiang},
  journal  = {Neurocomputing},
  title    = {Ramp loss one-class support vector machine; a robust and effective approach to anomaly detection problems},
  year     = {2018},
  issn     = {0925-2312},
  pages    = {223--235},
  volume   = {310},
  abstract = {Anomaly detection defines as a problem of finding those data samples, which do not follow the patterns of the majority of data points. Among the variety of methods and algorithms proposed to deal with this problem, boundary based methods include One-class support vector machine (OC-SVM) is considered as an effective and outstanding one. Nevertheless, extremely sensitivity to the presence of outliers and noises in the training set is considered as an important drawback of this group of classifiers. In this paper, we address this problem by developing a robust and sparse methodology for anomaly detection by introducing Ramp loss function to the original One-class SVM, called “Ramp-OCSVM”. The main objective of this research is to taking the advantages of non-convexity properties of the Ramp loss function to make robust and sparse semi-supervised algorithm. Furthermore, the Concave–Convex Procedure (CCCP) is utilized to solve the obtained model that is a non-differentiable non-convex optimization problem. We do comprehensive experiments and parameters sensitivity analysis on two artificial data sets and some chosen data sets from UCI repository, to show the superiority of our model in terms of detection power and sparsity. Moreover, some evaluations are done with NSL-KDD and UNSW-NB15 data sets as well-known and recently published intrusion detection data sets, respectively. The obtained results reveal the outperforming of our model in terms of robustness to outliers and superiority in the detection of anomalies.},
  doi      = {https://doi.org/10.1016/j.neucom.2018.05.027},
  file     = {:FILES/2018 - Tian2018 - Ramp loss one-class support vector machine\; A robust and effective approach to anomaly detection problems.pdf:PDF},
  groups   = {svm},
  keywords = {Anomaly detection, One-class SVM, Ramp loss function, Non-convex problem},
  url      = {http://www.sciencedirect.com/science/article/pii/S0925231218305666},
}

@Article{Wang2019a,
  author   = {Wang, Chunyan and Ye, Qiaolin and Luo, Peng and Ye, Ning and Fu, Liyong},
  journal  = {Neural Networks},
  title    = {Robust capped {L1}-norm twin support vector machine},
  year     = {2019},
  issn     = {0893-6080},
  pages    = {47--59},
  volume   = {114},
  abstract = {Twin support vector machine (TWSVM) is a classical and effective classifier for binary classification. However, its robustness cannot be guaranteed due to the utilization of squared L2-norm distance that can usually exaggerate the influence of outliers. In this paper, we propose a new robust capped L1-norm twin support vector machine (CTWSVM), which sustains the advantages of TWSVM and promotes the robustness in solving a binary classification problem with outliers. The solution of the proposed method can be achieved by optimizing a pair of capped L1-norm related problems using a newly-designed effective iterative algorithm. Also, we present some theoretical analysis on existence of local optimum and convergence of the algorithm. Extensive experiments on an artificial dataset and several UCI datasets demonstrate the robustness and feasibility of our proposed CTWSVM.},
  doi      = {https://doi.org/10.1016/j.neunet.2019.01.016},
  file     = {:FILES/2019 - Wang2019a - Robust capped L1-norm twin support vector machine.pdf:PDF},
  groups   = {svm},
  keywords = {Machine learning, TWSVM, Capped L1-norm, Robustness},
  url      = {http://www.sciencedirect.com/science/article/pii/S0893608019300309},
}

@Article{Wang2018,
  author    = {Wang, Di and Xie, Lin and Yang, Simon and Tian, Fengchun},
  journal   = {Sensors},
  title     = {Support vector machine optimized by genetic algorithm for data analysis of near-infrared spectroscopy sensors},
  year      = {2018},
  issn      = {1424-8220},
  month     = {9},
  number    = {10},
  pages     = {3222},
  volume    = {18},
  doi       = {10.3390/s18103222},
  file      = {:FILES/2018 - Wang2018 - Support Vector Machine Optimized by Genetic Algorithm for Data Analysis of Near-Infrared Spectroscopy Sensors.pdf:PDF},
  groups    = {svm},
  publisher = {MDPI AG},
  url       = {http://dx.doi.org/10.3390/s18103222},
}

@Article{Xing2018,
  author   = {Xing, Hong-Jie and Ji, Man},
  journal  = {Pattern Recognition},
  title    = {Robust one-class support vector machine with rescaled hinge loss function},
  year     = {2018},
  issn     = {0031-3203},
  pages    = {152--164},
  volume   = {84},
  abstract = {In this paper, a novel robust one-class support vector machine (OCSVM) based on the rescaled hinge loss function is proposed to enhance the robustness of the conventional OCSVM against outliers. The optimization problem of the proposed robust OCSVM can be iteratively solved by the half-quadratic optimization technique. Compared to OCSVM, robust OCSVM may achieve higher generalization performance from the theoretical analysis. Moreover, the robustness of robust OCSVM against outliers is explained from the weighted viewpoint. Experimental results on the synthetic and benchmark data sets demonstrate that the proposed robust OCSVM is superior to the conventional OCSVM and the other two related approaches.},
  doi      = {https://doi.org/10.1016/j.patcog.2018.07.015},
  file     = {:FILES/2018 - Xing2018 - Robust one-class support vector machine with rescaled hinge loss function.pdf:PDF},
  groups   = {svm},
  keywords = {One-class classification, One-class support vector machine, Hinge loss function, Half-quadratic optimization},
  url      = {http://www.sciencedirect.com/science/article/pii/S0031320318302498},
}

@Article{Zhang2020,
  author   = {Zhang, Qianqian and Wang, Haifeng and Yoon, Sang Won},
  journal  = {Neurocomputing},
  title    = {A 1-norm regularized linear programming nonparallel hyperplane support vector machine for binary classification problems},
  year     = {2020},
  issn     = {0925-2312},
  pages    = {141--152},
  volume   = {376},
  abstract = {This research proposes a 1-norm regularized linear programming nonparallel hyperplane support vector machine (LNSVM) model to solve binary classification problems and enhance the robustness performance. Numerous nonparallel support vector machine (SVM) models have been studied with outstanding performance on classification tasks. However, most nonparallel SVM models require two independent models to determine hyperplanes. In addition, due to the involvement of the 2-norm terms, traditional SVM models may suffer from the lack of robustness to outliers and irrelevant features. Therefore, the LNSVM model is proposed by reformulating a typical nonparallel SVM model through the 1-norm regularization. By applying the exterior penalty theory, the proposed LNSVM model is converted to the dual exterior penalty problem, which is solved by the Newton–Armijo algorithm. The essential differences that distinguish the LNSVM model from other nonparallel SVM models are: (1) Different from typical nonparallel SVM models, which solve two quadratic programming (QP) problems, the proposed LNSVM model determines two nonparallel hyperplanes simultaneously by solving a single linear programming (LP) model; (2) The robustness performance of the proposed LNSVM model has been enhanced to tolerate noisy data through the involvement of 1-norm loss function, which can also eliminate redundant features by generating sparse solution during the training procedure. The performance of the proposed LNSVM model is tested through a comparison with state-of-art SVM-based classifiers using a synthetic dataset and 11 practical benchmark datasets. The experimental results show the superiority of the proposed LNSVM model, by achieving better classification performance regarding accuracy, sensitivity, specificity, and removing redundant features synchronously.},
  doi      = {https://doi.org/10.1016/j.neucom.2019.09.068},
  file     = {:FILES/2020 - Zhang2020 - A 1-norm regularized linear programming nonparallel hyperplane support vector machine for binary classification problems.pdf:PDF},
  groups   = {svm},
  keywords = {1-Norm regularization, Nonparallel hyperplane support vector machine, Feature selection, Newton–Armijo algorithm, Pattern classification},
  url      = {http://www.sciencedirect.com/science/article/pii/S0925231219313360},
}

@Article{Sousa2015,
  author    = {Sousa, Sílvia A. and Zhang, Daqing and Xiao, Jianfeng and Zhou, Nannan and Zheng, Mingyue and Luo, Xiaomin and Jiang, Hualiang and Chen, Kaixian},
  journal   = {BioMed Research International},
  title     = {A Genetic Algorithm Based Support Vector Machine Model for Blood-Brain Barrier Penetration Prediction},
  year      = {2015},
  issn      = {2314-6133},
  pages     = {292683},
  volume    = {2015},
  abstract  = {Blood-brain barrier (BBB) is a highly complex physical barrier determining what substances are allowed to enter the brain. Support vector machine (SVM) is a kernel-based machine learning method that is widely used in QSAR study. For a successful SVM model, the kernel parameters for SVM and feature subset selection are the most important factors affecting prediction accuracy. In most studies, they are treated as two independent problems, but it has been proven that they could affect each other. We designed and implemented genetic algorithm (GA) to optimize kernel parameters and feature subset selection for SVM regression and applied it to the BBB penetration prediction. The results show that our GA/SVM model is more accurate than other currently available log <italic>BB</italic> models. Therefore, to optimize both SVM parameters and feature subset simultaneously with genetic algorithm is a better approach than other methods that treat the two problems separately. Analysis of our log <italic>BB</italic> model suggests that carboxylic acid group, polar surface area (PSA)/hydrogen-bonding ability, lipophilicity, and molecular charge play important role in BBB penetration. Among those properties relevant to BBB penetration, lipophilicity could enhance the BBB penetration while all the others are negatively correlated with BBB penetration.},
  doi       = {10.1155/2015/292683},
  file      = {:FILES/2015 - Sousa2015 - A Genetic Algorithm Based Support Vector Machine Model for Blood-Brain Barrier Penetration Prediction.pdf:PDF},
  groups    = {svm},
  publisher = {Hindawi Publishing Corporation},
  url       = {https://doi.org/10.1155/2015/292683},
}

@Article{Chuang2011,
  author   = {Chuang, Chen-Chia and Lee, Zne-Jung},
  journal  = {Applied Soft Computing},
  title    = {Hybrid robust support vector machines for regression with outliers},
  year     = {2011},
  issn     = {1568-4946},
  number   = {1},
  pages    = {64--72},
  volume   = {11},
  abstract = {In this study, a hybrid robust support vector machine for regression is proposed to deal with training data sets with outliers. The proposed approach consists of two stages of strategies. The first stage is for data preprocessing and a support vector machine for regression is used to filter out outliers in the training data set. Since the outliers in the training data set are removed, the concept of robust statistic is not needed for reducing the outliers’ effects in the later stage. Then, the training data set except for outliers, called as the reduced training data set, is directly used in training the non-robust least squares support vector machines for regression (LS-SVMR) or the non-robust support vector regression networks (SVRNs) in the second stage. Consequently, the learning mechanism of the proposed approach is much easier than that of the robust support vector regression networks (RSVRNs) approach and of the weighted LS-SVMR approach. Based on the simulation results, the performance of the proposed approach with non-robust LS-SVMR is superior to the weighted LS-SVMR approach when the outliers exist. Moreover, the performance of the proposed approach with non-robust SVRNs is also superior to the RSVRNs approach.},
  doi      = {https://doi.org/10.1016/j.asoc.2009.10.017},
  file     = {:FILES/2011 - Chuang2011 - Hybrid robust support vector machines for regression with outliers.pdf:PDF},
  groups   = {svm},
  keywords = {Outliers, Support vector machines for regression, Least squares support vector machines for regression (LS-SVMR), Weighted LS-SVMR, Robust support vector regression networks},
  url      = {http://www.sciencedirect.com/science/article/pii/S1568494609002075},
}

@Article{Ilhan2013,
  author   = {İlhan, İlhan and Tezel, G\"{u}lay},
  journal  = {Journal of Biomedical Informatics},
  title    = {A genetic algorithm–support vector machine method with parameter optimization for selecting the tag {SNPs}},
  year     = {2013},
  issn     = {1532-0464},
  number   = {2},
  pages    = {328--340},
  volume   = {46},
  abstract = {SNPs (Single Nucleotide Polymorphisms) include millions of changes in human genome, and therefore, are promising tools for disease-gene association studies. However, this kind of studies is constrained by the high expense of genotyping millions of SNPs. For this reason, it is required to obtain a suitable subset of SNPs to accurately represent the rest of SNPs. For this purpose, many methods have been developed to select a convenient subset of tag SNPs, but all of them only provide low prediction accuracy. In the present study, a brand new method is developed and introduced as GA–SVM with parameter optimization. This method benefits from support vector machine (SVM) and genetic algorithm (GA) to predict SNPs and to select tag SNPs, respectively. Furthermore, it also uses particle swarm optimization (PSO) algorithm to optimize C and γ parameters of support vector machine. It is experimentally tested on a wide range of datasets, and the obtained results demonstrate that this method can provide better prediction accuracy in identifying tag SNPs compared to other methods at present.},
  doi      = {https://doi.org/10.1016/j.jbi.2012.12.002},
  file     = {:FILES/2013 - Ilhan2013 - A genetic algorithm–support vector machine method with parameter optimization for selecting the tag SNPs.pdf:PDF},
  groups   = {svm},
  keywords = {Single Nucleotide Polymorphisms (SNPs), Tag SNPs, Genetic algorithm (GA), Support vector machine (SVM), Particle swarm optimization (PSO)},
  url      = {http://www.sciencedirect.com/science/article/pii/S1532046412001852},
}

@Article{JubertdeAlmeida2018,
  author   = {Jubert de Almeida, Bernardo and Ferreira Neves, Rui and Horta, Nuno},
  journal  = {Applied Soft Computing},
  title    = {Combining support vector machine with genetic algorithms to optimize investments in forex markets with high leverage},
  year     = {2018},
  issn     = {1568-4946},
  pages    = {596--613},
  volume   = {64},
  abstract = {This work proposes a new approach, based on Genetic Algorithms and Support Vector Machine to trade in the forex market. In this work, a new algorithm capable of generating technical rules to make investments with a given amount of leverage depending on the certainty of the prediction is presented. To forecast those predictions, a combination of a Support Vector Machine (SVM) algorithm – to identify and classify the market in three different stages –, and a Dynamic Genetic Algorithm – to optimize trading rules in each type of market, is used. The optimization of the trading rules is based on several technical indicators. Forex data for the EUR/USD currency pair, in a timeframe between the years of 2003 and 2016, is used as training and test data. The proposed architecture for the machine learning system, as well as the implementation and study of the proposed system is described in detail. The use of an hybrid system, combining a SVM and a GA with dynamic approaches such as hyper-mutation and adaptability approaches by training three different GA’s for each type of market, provide a new approach for FOREX trading, where it is possible to classify trends using price sequences and therefore using the same classification for optimizing investment strategies with the most appropriate GA. Finally, the work shows promising results during the test period between the 2nd of January of 2015 until the 2nd of March of 2016, where the Return on Investment obtained is 83\%.},
  doi      = {https://doi.org/10.1016/j.asoc.2017.12.047},
  file     = {:FILES/2018 - JubertdeAlmeida2018 - Combining Support Vector Machine with Genetic Algorithms to optimize investments in Forex markets with high leverage.pdf:PDF},
  groups   = {svm},
  keywords = {Genetic Algorithms, Support Vector Machine, Leverage, Forex},
  url      = {http://www.sciencedirect.com/science/article/pii/S1568494618300036},
}

@Article{Rebentrost2014,
  author    = {Rebentrost, Patrick and Mohseni, Masoud and Lloyd, Seth},
  journal   = {Physical Review Letters},
  title     = {Quantum support vector machine for big data classification},
  year      = {2014},
  issn      = {1079-7114},
  month     = {9},
  number    = {13},
  volume    = {113},
  doi       = {10.1103/physrevlett.113.130503},
  file      = {:FILES/2014 - Rebentrost2014 - Quantum Support Vector Machine for Big Data Classification.pdf:PDF},
  groups    = {svm},
  publisher = {American Physical Society (APS)},
  url       = {http://dx.doi.org/10.1103/PhysRevLett.113.130503},
}

@Article{Richhariya2018,
  author   = {Richhariya, B. and Tanveer, M.},
  journal  = {Applied Soft Computing},
  title    = {A robust fuzzy least squares twin support vector machine for class imbalance learning},
  year     = {2018},
  issn     = {1568-4946},
  pages    = {418--432},
  volume   = {71},
  abstract = {Twin support vector machine is one of the most prominent techniques for classification problems. It has been applied in various real world applications due to its less computational complexity. In most of the applications on classification, there is imbalance in the number of samples of the classes which leads to incorrect classification of the data points of the minority class. Further, while dealing with imbalanced data, noise poses a major challenge in various applications. To resolve these problems, in this paper we propose a robust fuzzy least squares twin support vector machine for class imbalance learning termed as RFLSTSVM-CIL using 2-norm of the slack variables which makes the optimization problem strongly convex. In order to reduce the effect of outliers, we propose a novel fuzzy membership function specifically for class imbalance problems. Our proposed function gives the appropriate weights to the datasets and also incorporates the knowledge about the imbalance ratio of the data. In our proposed model, a pair of system of linear equations is solved instead of solving a quadratic programming problem (QPP) which makes our model efficient in terms of computation complexity. To check the performance of our proposed approach, several numerical experiments are performed on synthetic and real world benchmark datasets. Our proposed model RFLSTSVM-CIL has shown better generalization performance in comparison to the existing methods in terms of AUC and training time.},
  doi      = {https://doi.org/10.1016/j.asoc.2018.07.003},
  file     = {:FILES/2018 - Richhariya2018 - A robust fuzzy least squares twin support vector machine for class imbalance learning.pdf:PDF},
  groups   = {svm},
  keywords = {Fuzzy membership, Least squares twin support vector machine, Class imbalance, Imbalance ratio, Outliers},
  url      = {http://www.sciencedirect.com/science/article/pii/S1568494618303879},
}

@PhdThesis{Huang2016,
  author   = {Huang, Jian},
  school   = {University of Iowa},
  title    = {Penalized methods and algorithms for high-dimensional regression in the presence of heterogeneity},
  year     = {2016},
  abstract = {In fields such as statistics, economics and biology, heterogeneity is an important topic concerning validity of data inference and discovery of hidden patterns. This thesis focuses on penalized methods for regression analysis with the presence of heterogeneity in a potentially high-dimensional setting. Two possible strategies to deal with heterogeneity are: robust regression methods that provide heterogeneity-resistant coefficient estimation, and direct detection of heterogeneity while estimating coefficients accurately in the meantime.

We consider the first strategy for two robust regression methods, Huber loss regression and quantile regression with Lasso or Elastic-Net penalties, which have been studied theoretically but lack efficient algorithms. We propose a new algorithm Semismooth Newton Coordinate Descent to solve them. The algorithm is a novel combination of Semismooth Newton Algorithm and Coordinate Descent that applies to penalized optimization problems with both nonsmooth loss and nonsmooth penalty. We prove its convergence properties, and show its computational efficiency through numerical studies.

We also propose a nonconvex penalized regression method, Heterogeneity Discovery Regression (HDR) , as a realization of the second idea. We establish theoretical results that guarantees statistical precision for any local optimum of the objective function with high probability. We also compare the numerical performances of HDR with competitors including Huber loss regression, quantile regression and least squares through simulation studies and a real data example. In these experiments, HDR methods are able to detect heterogeneity accurately, and also largely outperform the competitors in terms of coefficient estimation and variable selection.},
  doi      = {https://doi.org/10.17077/etd.lremrcvo},
  file     = {:FILES/2016 - Huang2016 - Penalized methods and algorithms for high-dimensional regression in the presence of heterogeneity.pdf:PDF},
  groups   = {intelligent},
  keywords = {heterogeneity detection, high-dimensional, nonconvex regularization, optimization, robust regression, variable selection},
}

@Article{Burke2004,
  author   = {Burke, E. K. and Gustafson, S. and Kendall, G.},
  journal  = {IEEE Transactions on Evolutionary Computation},
  title    = {Diversity in genetic programming: {An} analysis of measures and correlation with fitness},
  year     = {2004},
  issn     = {1941-0026},
  month    = {2},
  number   = {1},
  pages    = {47--62},
  volume   = {8},
  abstract = {Examines measures of diversity in genetic programming. The goal is to understand the importance of such measures and their relationship with fitness. Diversity methods and measures from the literature are surveyed and a selected set of measures are applied to common standard problem instances in an experimental study. Results show the varying definitions and behaviors of diversity and the varying correlation between diversity and fitness during different stages of the evolutionary process. Populations in the genetic programming algorithm are shown to become structurally similar while maintaining a high amount of behavioral differences. Conclusions describe what measures are likely to be important for understanding and improving the search process and why diversity might have different meaning for different problem domains.},
  doi      = {10.1109/TEVC.2003.819263},
  file     = {:FILES/2004 - Burke2004 - Diversity in Genetic Programming An Analysis of Measures and Correlation With Fitness.pdf:PDF},
  groups   = {intelligent},
  keywords = {genetic algorithms;genetic programming;fitness;diversity methods;evolutionary process;diversity measures;Genetic programming;Diversity methods;Algorithm design and analysis;Measurement standards;Dynamic programming;Computer science;Information technology;Stochastic processes;Convergence},
}

@Article{Geng2014,
  author   = {Geng, F. Z. and Qian, S. P.},
  journal  = {Applied Mathematics Letters},
  title    = {Piecewise reproducing kernel method for singularly perturbed delay initial value problems},
  year     = {2014},
  issn     = {0893-9659},
  pages    = {67--71},
  volume   = {37},
  abstract = {A direct application of the reproducing kernel method presented in the previous works cannot yield accurate approximate solutions for singularly perturbed delay differential equations. In this letter, we construct a new numerical method called piecewise reproducing kernel method for singularly perturbed delay initial value problems. Numerical results show that the present method does not share the drawback of standard reproducing kernel method and is an effective method for the considered singularly perturbed delay initial value problems.},
  doi      = {https://doi.org/10.1016/j.aml.2014.05.014},
  file     = {:FILES/2014 - Geng2014 - Piecewise reproducing kernel method for singularly perturbed delay initial value problems.pdf:PDF},
  groups   = {intelligent},
  keywords = {Reproducing kernel method, Piecewise, Singularly perturbed problems, Delay initial value problems},
  url      = {http://www.sciencedirect.com/science/article/pii/S0893965914001864},
}

@Misc{Kidzinski2020,
  author        = {Kidzi\'{n}ski, Łukasz and Hui, Francis K. C. and Warton, David I. and Hastie, Trevor},
  title         = {Generalized matrix factorization},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2010.02469},
  file          = {:FILES/2020 - Kidzinski2020 - generalized matrix factorization.pdf:PDF},
  groups        = {intelligent},
  primaryclass  = {cs.LG},
}

@Misc{Yi2016,
  author        = {Yi, Congrui and Huang, Jian},
  title         = {Semismooth {Newton} coordinate descent algorithm for elastic-net penalized huber loss regression and quantile regression},
  year          = {2016},
  archiveprefix = {arXiv},
  eprint        = {1509.02957},
  file          = {:FILES/2016 - Yi2016 - Semismooth Newton Coordinate Descent Algorithm for Elastic-Net Penalized Huber Loss Regression and Quantile Regression.pdf:PDF},
  groups        = {intelligent},
  primaryclass  = {stat.CO},
}

@Misc{Zhou2020b,
  author        = {Zhou, Zhiyong and Yu, Jun},
  title         = {Minimization of the $q$-ratio sparsity with $1 < q \leq \infty$ for signal recovery},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2010.03402},
  file          = {:FILES/2020 - Zhou2020b - Minimization of the q-ratio sparsity with 1  q   for signal recovery.pdf:PDF},
  groups        = {intelligent},
  primaryclass  = {cs.IT},
}

@Article{Li2017,
  author    = {Li, Jinying and Zhang, Binghua and Shi, Jianfeng},
  journal   = {Energies},
  title     = {Combining a genetic algorithm and support vector machine to study the factors influencing co2 emissions in {Beijing} with scenario analysis},
  year      = {2017},
  issn      = {1996-1073},
  month     = {10},
  number    = {10},
  pages     = {1520},
  volume    = {10},
  doi       = {10.3390/en10101520},
  file      = {:FILES/2017 - Li2017 - Combining a genetic algorithm and support vector machine to study the factors influencing co2 emissions in {Beijing} with scenario analysis.pdf:PDF},
  groups    = {svm},
  publisher = {MDPI AG},
  url       = {http://dx.doi.org/10.3390/en10101520},
}

@Article{Xu2019a,
  author   = {Xu, J. and van den Boom, T. and De Schutter, B.},
  journal  = {IEEE Transactions on Automatic Control},
  title    = {Model predictive control for stochastic max-plus linear systems with chance constraints},
  year     = {2019},
  issn     = {1558-2523},
  month    = {1},
  number   = {1},
  pages    = {337--342},
  volume   = {64},
  abstract = {The topic of this paper is model predictive control (MPC) for max-plus linear systems with stochastic uncertainties the distribution of which is supposed to be known. We consider linear constraints on the inputs and the outputs. Due to the uncertainties, these linear constraints are formulated as probabilistic or chance constraints, i.e., the constraints are required to be satisfied with a predefined probability level. The proposed chance constraints can be equivalently rewritten into a max-affine (i.e., the maximum of affine terms) form if the linear constraints are monotonically nondecreasing as a function of the outputs. Based on the resulting max-affine form, two methods are developed for solving the chance-constrained MPC problem for stochastic max-plus linear systems. Method 1 uses Boole's inequality to convert the multivariate chance constraint into univariate chance constraints for which the probability can be computed more efficiently. Method 2 employs Chebyshev's inequality and transforms the chance constraint into linear constraints on the inputs. The simulation results for a production system example show that the two proposed methods are faster than the Monte Carlo simulation method and yield lower closed-loop costs than the nominal MPC method.},
  doi      = {10.1109/TAC.2018.2849570},
  file     = {:FILES/2019 - Xu2019a - Model Predictive Control for Stochastic Max-Plus Linear Systems With Chance Constraints.pdf:PDF},
  groups   = {nonconvex},
  keywords = {closed loop systems;linear systems;predictive control;probability;stochastic systems;transforms;stochastic max-plus linear systems;multivariate chance constraint;univariate chance constraints;linear constraints;model predictive control;MPC;max-affine form;Boole's inequality;Chebyshev's inequality;Chebyshev's transforms;Uncertainty;Stochastic processes;Production systems;Random variables;Linear systems;Computational modeling;Probabilistic logic;Constrained control;discrete-event systems;max-plus linear systems;nonlinear predictive control;stochastic optimal control},
}

@Article{Xu2016b,
  author   = {Xu, Jia and van den Boom, Ton and De Schutter, Bart},
  journal  = {Automatica},
  title    = {Optimistic optimization for model predictive control of max-plus linear systems},
  year     = {2016},
  issn     = {0005-1098},
  pages    = {16--22},
  volume   = {74},
  abstract = {Model predictive control for max-plus linear discrete-event systems usually leads to a nonsmooth nonconvex optimization problem with real valued variables, which may be hard to solve efficiently. An alternative approach is to transform the given problem into a mixed integer linear programming problem. However, the computational complexity of current mixed integer linear programming algorithms increases in the worst case exponentially as a function of the prediction horizon. The focus of this paper is on making optimistic optimization suited to solve the given problem. Optimistic optimization is a class of algorithms that can find an approximation of the global optimum for general nonlinear optimization. A key advantage of optimistic optimization is that one can specify the computational budget in advance and guarantee bounds on the suboptimality with respect to the global optimum. We prove that optimistic optimization can be applied for the given problem by developing a dedicated semi-metric and by proving it satisfies the necessary requirements for optimistic optimization. Moreover, we show that the complexity of optimistic optimization is exponential in the control horizon instead of the prediction horizon. Hence, using optimistic optimization is more efficient when the control horizon is small and the prediction horizon is large.},
  doi      = {https://doi.org/10.1016/j.automatica.2016.07.002},
  file     = {:FILES/2016 - Xu2016b - Optimistic optimization for model predictive control of max-plus linear systems.pdf:PDF},
  groups   = {nonconvex},
  keywords = {Max-plus linear systems, Model predictive control, Optimistic optimization},
  url      = {http://www.sciencedirect.com/science/article/pii/S0005109816302709},
}

@Article{Wu2018,
  author   = {Wu, Di and Zhu, Helin and Zhou, Enlu},
  journal  = {SIAM Journal on Optimization},
  title    = {A {Bayesian} risk approach to data-driven stochastic optimization: {Formulations} and asymptotics},
  year     = {2018},
  number   = {2},
  pages    = {1588--1612},
  volume   = {28},
  abstract = {A large class of stochastic programs involve optimizing an expectation taken with respect to an underlying distribution that is unknown in practice. One popular approach to addressing the distributional uncertainty, known as the distributionally robust optimization, is to hedge against the worst case over an uncertainty set of candidate distributions. However, it has been observed that inappropriate construction of the uncertainty set can sometimes result in overconservative solutions. To explore the middle ground between optimistically ignoring the distributional uncertainty and pessimistically fixating on the worst-case scenario, we propose a Bayesian risk optimization (BRO) framework for parametric underlying distributions, which is to optimize a risk functional applied to the posterior distribution of an unknown distribution parameter. Of our particular interest are four risk functionals: mean, mean-variance, value-at-risk, and conditional value-at-risk. To unravel the implication of BRO, we establish the consistency of objective functions and optimal solutions, as well as the asymptotic normality of objective functions and optimal values. More importantly, our analysis reveals a hidden interpretation: the objectives of BRO can be approximately viewed as a weighted sum of posterior mean objective and the (squared) half-width of the true objective's confidence interval. Read More: https://epubs.siam.org/doi/abs/10.1137/16M1101933},
  doi      = {10.1137/16M1101933},
  eprint   = {https://doi.org/10.1137/16M1101933},
  file     = {:FILES/2018 - Wu2018 - A {Bayesian} risk approach to data-driven stochastic optimization- {Formulations} and asymptotics.pdf:PDF},
  groups   = {quantile optimization},
  url      = {https://doi.org/10.1137/16M1101933},
}

@Article{Rockafellar2013,
  author   = {Rockafellar, R. Tyrrell and Uryasev, Stan},
  journal  = {Surveys in Operations Research and Management Science},
  title    = {The fundamental risk quadrangle in risk management, optimization and statistical estimation},
  year     = {2013},
  issn     = {1876-7354},
  number   = {1},
  pages    = {33--53},
  volume   = {18},
  abstract = {Random variables that stand for cost, loss or damage must be confronted in numerous situations. Dealing with them systematically for purposes in risk management, optimization and statistics is the theme of this presentation, which brings together ideas coming from many different areas. Measures of risk can be used to quantify the hazard in a random variable by a single value which can substitute for the otherwise uncertain outcomes in a formulation of constraints and objectives. Such quantifications of risk can be portrayed on a higher level as generated from penalty-type expressions of “regret” about the mix of potential outcomes. A trade-off between an up-front level of hazard and the uncertain residual hazard underlies that derivation. Regret is the mirror image of utility, a familiar concept for dealing with gains instead of losses, but regret concerns hazards relative to a benchmark. It bridges between risk measures and expected utility, thereby reconciling those two approaches to optimization under uncertainty. Statistical estimation is inevitably a partner with risk management in handling hazards, which may be known only partially through a data base. However, a much deeper connection has come to light with statistical theory itself, in particular regression. Very general measures of error can associate with any hazard variable a “statistic” along with a “deviation” which quantifies the variable’s nonconstancy. Measures of deviation, on the other hand, are paired closely with measures of risk exhibiting “aversity”. A direct correspondence can furthermore be identified between measures of error and measures of regret. The fundamental quadrangle of risk developed here puts all of this together in a unified scheme.},
  doi      = {https://doi.org/10.1016/j.sorms.2013.03.001},
  file     = {:FILES/2013 - Rockafellar2013 - The fundamental risk quadrangle in risk management, optimization and statistical estimation.pdf:PDF},
  groups   = {quantile optimization},
  url      = {http://www.sciencedirect.com/science/article/pii/S1876735413000032},
}

@Article{Lam2016,
  author   = {Lam, Henry},
  journal  = {Mathematics of Operations Research},
  title    = {Robust sensitivity analysis for stochastic systems},
  year     = {2016},
  number   = {4},
  pages    = {1248--1275},
  volume   = {41},
  abstract = {We study a worst-case approach to measure the sensitivity to model misspecification in the performance analysis of stochastic systems. The situation of interest is when only minimal parametric information is available on the form of the true model. Under this setting, we post optimization programs that compute the worst-case performance measures, subject to constraints on the amount of model misspecification measured by Kullback-Leibler divergence. Our main contribution is the development of infinitesimal approximations for these programs, resulting in asymptotic expansions of their optimal values as the divergence shrinks to zero. The coefficients of these expansions can be computed via simulation, and are mathematically derived from the representation of the worst-case models as changes of measure that satisfy a well-defined class of functional fixed-point equations.},
  doi      = {10.1287/moor.2015.0776},
  eprint   = {https://doi.org/10.1287/moor.2015.0776},
  file     = {:FILES/2016 - Lam2016 - Robust sensitivity analysis for stochastic systems.pdf:PDF},
  groups   = {quantile optimization},
  url      = {https://doi.org/10.1287/moor.2015.0776},
}

@Article{Zhu2018,
  author   = {Zhu, Helin and Hale, Joshua and Zhou, Enlu},
  journal  = {Journal of Global Optimization},
  title    = {Simulation optimization of risk measures with adaptive risk levels},
  year     = {2018},
  issn     = {1573-2916},
  number   = {4},
  pages    = {783--809},
  volume   = {70},
  abstract = {Optimizing risk measures such as Value-at-Risk (VaR) and Conditional Value-at-Risk (CVaR) of a general loss distribution is usually difficult, because (1) the loss function might lack structural properties such as convexity or differentiability since it is often generated via black-box simulation of a stochastic system; (2) evaluation of risk measures often requires rare-event simulation, which is computationally expensive. In this paper, we study the extension of the recently proposed gradient-based adaptive stochastic search to the optimization of risk measures VaR and CVaR. Instead of optimizing VaR or CVaR at the target risk level directly, we incorporate an adaptive updating scheme on the risk level, by initializing the algorithm at a small risk level and adaptively increasing it until the target risk level is achieved while the algorithm converges at the same time. This enables us to adaptively reduce the number of samples required to estimate the risk measure at each iteration, and thus improving the overall efficiency of the algorithm.},
  doi      = {10.1007/s10898-017-0588-8},
  file     = {:FILES/2018 - Zhu2018 - Simulation optimization of risk measures with adaptive risk levels.pdf:PDF},
  groups   = {quantile optimization},
  refid    = {Zhu2018},
  url      = {https://doi.org/10.1007/s10898-017-0588-8},
}

@Article{Dentcheva2017,
  author   = {Dentcheva, Darinka and Penev, Spiridon and Ruszczyński, Andrzej},
  journal  = {Annals of the Institute of Statistical Mathematics},
  title    = {Statistical estimation of composite risk functionals and risk optimization problems},
  year     = {2017},
  issn     = {1572-9052},
  number   = {4},
  pages    = {737--760},
  volume   = {69},
  abstract = {We address the statistical estimation of composite functionals which may be nonlinear in the probability measure. Our study is motivated by the need to estimate coherent measures of risk, which become increasingly popular in finance, insurance, and other areas associated with optimization under uncertainty and risk. We establish central limit theorems for composite risk functionals. Furthermore, we discuss the asymptotic behavior of optimization problems whose objectives are composite risk functionals and we establish a central limit formula of their optimal values when an estimator of the risk functional is used. While the mathematical structures accommodate commonly used coherent measures of risk, they have more general character, which may be of independent interest.},
  doi      = {10.1007/s10463-016-0559-8},
  file     = {:FILES/2017 - Dentcheva2017 - Statistical estimation of composite risk functionals and risk optimization problems.pdf:PDF},
  groups   = {quantile optimization},
  refid    = {Dentcheva2017},
  url      = {https://doi.org/10.1007/s10463-016-0559-8},
}

@Misc{Gotoh2017,
  author   = {Jun-ya Gotoh and Michael Kim and Andrew Lim},
  month    = nov,
  title    = {Robust Empirical Optimization is Almost the Same As Mean-Variance Optimization},
  year     = {2017},
  abstract = {We formulate a distributionally robust optimization problem where the empirical distribution plays the role of the nominal model, the decision maker optimizes against a worst-case alternative, and the deviation of the alternative distribution from the nominal is controlled by a $\phi$-divergence penalty in the objective, and show that a large class of these problems are essentially equivalent to an in-sample mean-variance problem. Intuitively, controlling the variance reduces the sensitivity of the expected reward to perturbations in the tail of the in-sample reward distribution, which reduces the sensitivity of its out-of-sample performance to errors in the nominal model. We also quantify the relationship between the ``level of robustness" in the robust optimization model and the mean and variance of the objective and we show that while a ``small amount of robustness" reduces the expected reward, the reduction in the variance is an order of magnitude larger. As a practical application of our theory, we introduce the notion of a robust mean-variance frontier and show how it can be used to balance out-of-sample performance and robustness when calibrating the robust model. To illustrate the usefulness of such frontiers we consider a real world portfolio optimization application.},
  file     = {:FILES/2017 - Gotoh2017 - Robust Empirical Optimization is Almost the Same As Mean-Variance Optimization.pdf:PDF},
  groups   = {quantile optimization},
  keywords = {robust empirical optimization, mean-variance optimization, data-driven optimization, relative entropy, $\phi$-divergence, robust cross-validation},
  url      = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2827400},
}

@Article{GuerraVazquez2008,
  author   = {Guerra V\'{a}zquez, F. and R\"{u}ckmann, J.-J. and Stein, O. and Still, G.},
  journal  = {Journal of Computational and Applied Mathematics},
  title    = {Generalized semi-infinite programming: {A} tutorial},
  year     = {2008},
  issn     = {0377-0427},
  note     = {Special Issue: Semi-infinite Programming (SIP)},
  number   = {2},
  pages    = {394--419},
  volume   = {217},
  abstract = {This tutorial presents an introduction to generalized semi-infinite programming (GSIP) which in recent years became a vivid field of active research in mathematical programming. A GSIP problem is characterized by an infinite number of inequality constraints, and the corresponding index set depends additionally on the decision variables. There exist a wide range of applications which give rise to GSIP models; some of them are discussed in the present paper. Furthermore, geometric and topological properties of the feasible set and, in particular, the difference to the standard semi-infinite case are analyzed. By using first-order approximations of the feasible set corresponding constraint qualifications are developed. Then, necessary and sufficient first- and second-order optimality conditions are presented where directional differentiability properties of the optimal value function of the so-called lower level problem are used. Finally, an overview of numerical methods is given.},
  doi      = {https://doi.org/10.1016/j.cam.2007.02.012},
  file     = {:FILES/2008 - GuerraVazquez2008 - Generalized semi-infinite programming- {A} tutorial.pdf:PDF},
  groups   = {semi-infinite programming},
  keywords = {Generalized semi-infinite programming, Structure of the feasible set, First- and second-order optimality conditions, Reduction ansatz, Numerical methods, Design centering, Robust optimization, prio1},
  priority = {prio1},
  url      = {http://www.sciencedirect.com/science/article/pii/S0377042707000982},
}

@Book{Maronna2018,
  author    = {Ricardo A. Maronna and R. Douglas Martin and Victor J. Yohai and Matias Salibian-Barrera},
  publisher = {Wiley-Blackwell},
  title     = {Robust statistics: {Theory} and methods ({With} {R})},
  year      = {2018},
  edition   = {Second Edition},
  isbn      = {9781119214687},
  series    = {Wiley Series in Probability and Statistics},
  abstract  = {A new edition of this popular text on robust statistics, thoroughly updated to include new and improved methods and focus on implementation of methodology using the increasingly popular open-source software R.

Classical statistics fail to cope well with outliers associated with deviations from standard distributions. Robust statistical methods take into account these deviations when estimating the parameters of parametric models, thus increasing the reliability of fitted models and associated inference. This new, second edition of Robust Statistics Theory and Methods (with R) presents a broad coverage of the theory of robust statistics that is integrated with computing methods and applications. Updated to include important new research results of the last decade and focus on the use of the popular software package R, it features in-depth coverage of the key methodology, including regression, multivariate analysis, and time series modeling. The book is illustrated throughout by a range of examples and applications that are supported by a companion website featuring data sets and R code that allow the reader to reproduce the examples given in the book.

Unlike other books on the market, Robust Statistics Theory and Methods (with R) offers the most comprehensive, definitive, and up-to-date treatment of the subject. It features chapters on estimating location and scale; measuring robustness; linear regression with fixed and with random predictors; multivariate analysis; generalized linear models; time series; numerical algorithms; and asymptotic theory of M-estimates.

Explains both the use and theoretical justification of robust methods
Guides readers in selecting and using the most appropriate robust methods for their problems
Features computational algorithms for the core methods
Robust statistics research results of the last decade included in this 2nd edition include: fast deterministic robust regression, finite-sample robustness, robust regularized regression, robust location and scatter estimation with missing data, robust estimation with independent outliers in variables, and robust mixed linear models.

Robust Statistics aims to stimulate the use of robust methods as a powerful tool to increase the reliability and accuracy of statistical modelling and data analysis. It is an ideal resource for researchers, practitioners, and graduate students in statistics, engineering, computer science, and physical and social sciences.},
  file      = {:FILES/2018 - Maronna2018 - Robust Statistics- Theory and Methods (With R).pdf:PDF},
  groups    = {interesting articles},
  keywords  = {prio1},
  priority  = {prio1},
  url       = {https://onlinelibrary.wiley.com/doi/book/10.1002/0470010940},
}

@Article{许赟杰2019,
  author   = {许赟杰 and 徐菲菲},
  journal  = {数据采集与处理},
  title    = {基于{ArcReLU}函数的神经网络激活函数优化研究},
  year     = {2019},
  number   = {03},
  pages    = {517--529},
  volume   = {34},
  abstract = {近年来深度学习发展迅猛。由于深度学习的概念源于神经网络,而激活函数更是神经网络模型在学习理解非线性函数时不可或缺的部分,因此本文对常用的激活函数进行了研究比较。针对常用的激活函数在反向传播神经网络中具有收敛速度较慢、存在局部极小或梯度消失的问题,将Sigmoid系和ReLU系激活函数进行了对比,分别讨论了其性能,详细分析了几类常用激活函数的优点及不足,并通过研究Arctan函数在神经网络中应用的可能性,结合ReLU函数,提出了一种新型的激活函数ArcReLU。实验证明,该函数既能显著加快反向传播神经网络的训练速度,又能有效降低训练误差并避免梯度消失的问题。},
  file     = {:FILES/2019 - 许赟杰2019 - 基于ArcReLU函数的神经网络激活函数优化研究.pdf:PDF},
  groups   = {Neural Network},
  keywords = {神经网络;激活函数;反正切函数;ArcReLU},
}

@Article{Ning2020,
  author    = {Ning, Hong-Bin and Deng, Xiao-Fei and Zhu, Jun-Wei and Zhou, Kai-Qing},
  journal   = {{IOP} Conference Series: Materials Science and Engineering},
  title     = {Critical saturation function based sliding mode control for path tracking of mobile robot},
  year      = {2020},
  month     = {7},
  pages     = {012054},
  volume    = {864},
  abstract  = {This paper proposes a new sliding mode controller, as to enhance the performance of path tracking of three-wheeled mobile robot system. To begin with, backstepping design is used to construct a new sliding mode control law for better dynamic response and robustness. Next, in order to reduce chattering, the symbolic function is replaced with the critical saturation function in the conventional reaching law. At last, the simulation results show that backstepping design combined with saturation function can not only improve the response rate and robustness of the system, but also effectively reduce the chattering.},
  doi       = {10.1088/1757-899x/864/1/012054},
  file      = {:FILES/2020 - Ning2020 - Critical saturation function based sliding mode control for path tracking of mobile robot.pdf:PDF},
  groups    = {application},
  publisher = {{IOP} Publishing},
  url       = {https://doi.org/10.1088%2F1757-899x%2F864%2F1%2F012054},
}

@Article{Kong2011,
  author   = {Xiaowei Kong and Wei Xia and Zishu He and Hongshu Liao},
  journal  = {{IEICE} Electronics Express},
  title    = {A special complex-valued simplicial canonical piecewise linear function for amplifier and predistorter nonlinearity representation},
  year     = {2011},
  issn     = {1349-2543},
  pages    = {1556--1561},
  volume   = {8},
  abstract = {In this paper, a special complex-valued simplicial canonical piecewise linear (CSCPWL) function is presented for power amplifier and digital predistorter nonlinearity representation. The proposed function is derived from the simplicial canonical piecewise linear (SCPWL) function approximates to polynomial basis and can be easily applied for baseband modeling with complex-valued signal. Through the experiment simulation, the modeling capacity, algorithm complexity and numerical stability of the proposed function are discussed. Finally, the conclusion that the special CSCPWL function is a compromise between the system performance and hardware cost is given.},
  doi      = {10.1587/elex.8.1556},
  file     = {:FILES/2011 - Kong2011 - A special complex-valued simplicial canonical piecewise linear function for amplifier and predistorter nonlinearity representation.pdf:PDF},
  groups   = {Approximation},
}

@Article{Chiquet2008,
  author   = {Chiquet, Julien and Limnios, Nikolaos},
  journal  = {Statistics \& Probability Letters},
  title    = {A method to compute the transition function of a piecewise deterministic markov process with application to reliability},
  year     = {2008},
  issn     = {0167-7152},
  number   = {12},
  pages    = {1397--1403},
  volume   = {78},
  abstract = {We study the time evolution of an increasing stochastic process governed by a first-order stochastic differential system. This defines a particular piecewise deterministic Markov process (PDMP). We consider a Markov renewal process (MRP) associated to the PDMP and its Markov renewal equation (MRE) which is solved in order to obtain a closed-form solution of the transition function of the PDMP. It is then applied in the framework of survival analysis to evaluate the reliability function of a given system. We give a numerical illustration and we compare this analytical solution with the Monte Carlo estimator.},
  doi      = {https://doi.org/10.1016/j.spl.2007.12.016},
  file     = {:FILES/2008 - Chiquet2008 - A method to compute the transition function of a piecewise deterministic markov process with application to reliability.pdf:PDF},
  groups   = {application},
  url      = {http://www.sciencedirect.com/science/article/pii/S016771520700421X},
}

@Article{Yohai1987,
  author    = {Yohai, Victor J.},
  journal   = {The Annual of Statistics},
  title     = {High breakdown-point and high efficiency robust estimates for regression},
  year      = {1987},
  month     = {06},
  number    = {2},
  pages     = {642--656},
  volume    = {15},
  comment   = {proposed L estimator},
  doi       = {10.1214/aos/1176350366},
  file      = {:FILES/1987 - Yohai1987 - High breakdown-point and high efficiency robust estimates for regression.pdf:PDF},
  groups    = {LMS},
  publisher = {The Institute of Mathematical Statistics},
  url       = {https://doi.org/10.1214/aos/1176350366},
}

@Article{Davies1987,
  author  = {P. L. Davies},
  journal = {The Annals of Statistics},
  title   = {Asymptotic behaviour of {$S$}-estimates of multivariate location parameters and dispersion matrices},
  year    = {1987},
  issn    = {0090-5364},
  pages   = {1269--1292},
  volume  = {15},
  comment = {introduced S-estimator},
  doi     = {10.1214/aos/1176350505},
  file    = {:FILES/1987 - Davies1987 - Asymptotic Behaviour of S-Estimates of Multivariate Location Parameters and Dispersion Matrices.pdf:PDF},
  groups  = {LMS},
}

@Article{Croux1994,
  author    = {Croux, Christophe and Rousseeuw, Peter J. and Hossjer, Ola},
  journal   = {Journal of the American Statistical Association},
  title     = {Generalized {S}-estimators},
  year      = {1994},
  issn      = {01621459},
  number    = {428},
  pages     = {1271--1281},
  volume    = {89},
  abstract  = {In this article we introduce a new type of positive-breakdown regression method, called a generalized S-estimator (or GS-estimator), based on the minimization of a generalized M-estimator of residual scale. We compare the class of GS-estimators with the usual S-estimators, including least median of squares. It turns out that GS-estimators attain a much higher efficiency than S-estimators, at the cost of a slightly increased worst-case bias. We investigate the breakdown point, the maxbias curve, and the influence function of GS-estimators. We also give an algorithm for computing GS-estimators and apply it to real and simulated data.},
  file      = {:FILES/1994 - Croux1994 - Generalized s-estimators.pdf:PDF},
  groups    = {LMS},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  url       = {http://www.jstor.org/stable/2290990},
}

@InBook{Mendes1996,
  author    = {Mendes, Beatriz and Tyler, David E.},
  editor    = {Rieder, Helmut},
  pages     = {299--320},
  publisher = {Springer New York},
  title     = {Constrained {M}-estimation for regression},
  year      = {1996},
  address   = {New York, NY},
  isbn      = {978-1-4612-2380-1},
  abstract  = {When using redescending M-estimates of regression, one must choose not only an estimate of scale, but since the redescending M-estimating equations may admit multiple solutions, of which all of them may not be a desired solution, one must also have a method for choosing a desirable solution to the estimating equations. We introduce here a new approach for properly scaling redescending M-estimating equations and for obtaining high breakdown point solutions to the equations by the introduction of the constrained M-estimates of regression, or the CM-estimates of regression for short. Unlike the S-estimates of regression, the CM-estimates of regression can be tuned to obtain good local robustness properties while maintaining a breakdown point of 1/2.},
  booktitle = {Robust Statistics, Data Analysis, and Computer Intensive Methods: In Honor of Peter Huber's 60th Birthday},
  doi       = {10.1007/978-1-4612-2380-1_20},
  file      = {:FILES/1996 - Mendes1996 - Constrained m-estimation for regression.pdf:PDF},
  groups    = {LMS},
  url       = {https://doi.org/10.1007/978-1-4612-2380-1_20},
}

@Article{Kudraszow2011,
  author   = {Kudraszow, Nadia L. and Maronna, Ricardo A.},
  journal  = {Journal of Multivariate Analysis},
  title    = {Estimates of {MM} type for the multivariate linear model},
  year     = {2011},
  issn     = {0047-259X},
  number   = {9},
  pages    = {1280--1292},
  volume   = {102},
  abstract = {We propose a class of robust estimates for multivariate linear models. Based on the approach of MM-estimation (Yohai 1987, [24]), we estimate the regression coefficients and the covariance matrix of the errors simultaneously. These estimates have both a high breakdown point and high asymptotic efficiency under Gaussian errors. We prove consistency and asymptotic normality assuming errors with an elliptical distribution. We describe an iterative algorithm for the numerical calculation of these estimates. The advantages of the proposed estimates over their competitors are demonstrated through both simulated and real data.},
  doi      = {https://doi.org/10.1016/j.jmva.2011.04.011},
  file     = {:FILES/2011 - Kudraszow2011 - Estimates of {MM} type for the multivariate linear model.pdf:PDF},
  groups   = {LMS},
  keywords = {Robust methods, MM-estimate, Multivariate linear model},
  url      = {http://www.sciencedirect.com/science/article/pii/S0047259X11000674},
}

@Article{Sjoeberg1995,
  author   = {Sj\"{o}berg, Jonas and Zhang, Qinghua and Ljung, Lennart and Benveniste, Albert and Delyon, Bernard and Glorennec, Pierre-Yves and Hjalmarsson, H\a{a}kan and Juditsky, Anatoli},
  journal  = {Automatica},
  title    = {Nonlinear black-box modeling in system identification: {A} unified overview},
  year     = {1995},
  issn     = {0005-1098},
  note     = {Trends in System Identification},
  number   = {12},
  pages    = {1691--1724},
  volume   = {31},
  abstract = {A nonlinear black-box structure for a dynamical system is a model structure that is prepared to describe virtually any nonlinear dynamics. There has been considerable recent interest in this area, with structures based on neural networks, radial basis networks, wavelet networks and hinging hyperplanes, as well as wavelet-transform-based methods and models based on fuzzy sets and fuzzy rules. This paper describes all these approaches in a common framework, from a user's perspective. It focuses on what are the common features in the different approaches, the choices that have to be made and what considerations are relevant for a successful system-identification application of these techniques. It is pointed out that the nonlinear structures can be seen as a concatenation of a mapping form observed data to a regression vector and a nonlinear mapping from the regressor space to the output space. These mappings are discussed separately. The latter mapping is usually formed as a basis function expansion. The basis functions are typically formed from one simple scalar function, which is modified in terms of scale and location. The expansion from the scalar argument to the regressor space is achieved by a radial- or a ridge-type approach. Basic techniques for estimating the parameters in the structures are criterion minimization, as well as two-step procedures, where first the relevant basis functions are determined, using data, and then a linear least-squares step to determine the coordinates of the function approximation. A particular problem is to deal with the large number of potentially necessary parameters. This is handled by making the number of ‘used’ parameters considerably less than the number of ‘offered’ parameters, by regularization, shrinking, pruning or regressor selection.},
  comment  = {NARX},
  doi      = {https://doi.org/10.1016/0005-1098(95)00120-8},
  file     = {:FILES/1995 - Sjoeberg1995 - Nonlinear black-box modeling in system identification- {A} unified overview.pdf:PDF},
  groups   = {identification},
  keywords = {Nonlinear systems, model structures, parameter estimation, wavelets, neural networks, fuzzy modeling},
  url      = {http://www.sciencedirect.com/science/article/pii/0005109895001208},
}

@Book{Suykens1996,
  author    = {Suykens, Johan A. K. and Vandewalle, Joos P. L. and de Moor, B. L.},
  publisher = {Springer US},
  title     = {Artificial neural networks for modelling and control of non-linear systems},
  year      = {1996},
  isbn      = {978-1-4757-2493-6},
  abstract  = {Artificial neural networks possess several properties that make them particularly attractive for applications to modelling and control of complex non-linear systems. Among these properties are their universal approximation ability, their parallel network structure and the availability of on- and off-line learning methods for the interconnection weights. However, dynamic models that contain neural network architectures might be highly non-linear and difficult to analyse as a result. Artificial Neural Networks for Modelling and Control of Non-Linear Systems investigates the subject from a system theoretical point of view. However the mathematical theory that is required from the reader is limited to matrix calculus, basic analysis, differential equations and basic linear system theory. No preliminary knowledge of neural networks is explicitly required.
The book presents both classical and novel network architectures and learning algorithms for modelling and control. Topics include non-linear system identification, neural optimal control, top-down model based neural control design and stability analysis of neural control systems. A major contribution of this book is to introduce NLq Theory as an extension towards modern control theory, in order to analyze and synthesize non-linear systems that contain linear together with static non-linear operators that satisfy a sector condition: neural state space control systems are an example. Moreover, it turns out that NLq Theory is unifying with respect to many problems arising in neural networks, systems and control. Examples show that complex non-linear systems can be modelled and controlled within NLq theory, including mastering chaos.
The didactic flavor of this book makes it suitable for use as a text for a course on Neural Networks. In addition, researchers and designers will find many important new techniques, in particular NLq Theory, that have applications in control theory, system theory, circuit theory and Time Series Analysis.},
  doi       = {10.1007/978-1-4757-2493-6},
  groups    = {identification},
}

@Article{Ismail2009,
  author   = {Ismail, Mohammed and Ikhouane, Fay\c{c}al and Rodellar, Jos\'{e}},
  journal  = {Archives of Computational Methods in Engineering},
  title    = {The Hysteresis {Bouc-Wen} Model, a Survey},
  year     = {2009},
  issn     = {1886-1784},
  number   = {2},
  pages    = {161--188},
  volume   = {16},
  abstract = {Structural systems often show nonlinear behavior under severe excitations generated by natural hazards. In that condition, the restoring force becomes highly nonlinear showing significant hysteresis. The hereditary nature of this nonlinear restoring force indicates that the force cannot be described as a function of the instantaneous displacement and velocity. Accordingly, many hysteretic restoring force models were developed to include the time dependent nature using a set of differential equations. This survey contains a review of the past, recent developments and implementations of the Bouc-Wen model which is used extensively in modeling the hysteresis phenomenon in the dynamically excited nonlinear structures.},
  doi      = {10.1007/s11831-009-9031-8},
  file     = {:FILES/2009 - Ismail2009 - The Hysteresis {Bouc-Wen} Model, a Survey.pdf:PDF},
  groups   = {interesting articles},
  url      = {https://doi.org/10.1007/s11831-009-9031-8},
}

@Article{Croux1998,
  author   = {Croux, Christophe},
  journal  = {Statistics \& Probability Letters},
  title    = {Limit behavior of the empirical influence function of the median},
  year     = {1998},
  issn     = {0167-7152},
  number   = {4},
  pages    = {331--340},
  volume   = {37},
  abstract = {The empirical influence function EIF(x, Tn; X) measures the influence of an observation x on the estimator Tn at a sample X of size n. In this note we show that the empirical influence function of the median is not a consistent estimator of the corresponding influence function. This observation leads to a reconsideration of the most -robustness property of the median. We will prove and show by simulations that the median is less robust to single outliers than commonly believed.},
  comment  = {proof the sensitive curve converges to the influence function with probability 1},
  doi      = {https://doi.org/10.1016/S0167-7152(97)00135-1},
  file     = {:FILES/1998 - Croux1998 - Limit behavior of the empirical influence function of the median.pdf:PDF},
  groups   = {robust statistics},
  keywords = {Breakdown point, Influence function, Location estimator, Robustness, Sensitivity},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167715297001351},
}

@Article{Hampel1974,
  author    = {Hampel, Frank R.},
  journal   = {Journal of the American Statistical Association},
  title     = {The influence curve and its role in robust estimation},
  year      = {1974},
  issn      = {01621459},
  number    = {346},
  pages     = {383--393},
  volume    = {69},
  abstract  = {This paper treats essentially the first derivative of an estimator viewed as functional and the ways in which it can be used to study local robustness properties. A theory of robust estimation "near" strict parametric models is briefly sketched and applied to some classical situations. Relations between von Mises functionals, the jackknife and U-statistics are indicated. A number of classical and new estimators are discussed, including trimmed and Winsorized means, Huber-estimators, and more generally maximum likelihood and M-estimators. Finally, a table with some numerical robustness properties is given.},
  comment   = {first introduction of influence function},
  doi       = {10.2307/2285666},
  file      = {:FILES/1974 - Hampel1974 - The influence curve and its role in robust estimation.pdf:PDF},
  groups    = {robust statistics},
  publisher = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  url       = {http://www.jstor.org/stable/2285666},
}

@Article{Hampel1971,
  author    = {Hampel, Frank R.},
  journal   = {The Annals of Mathematical Statistics},
  title     = {A general qualitative definition of robustness},
  year      = {1971},
  issn      = {0003-4851},
  number    = {6},
  pages     = {1887--1896},
  volume    = {42},
  abstract  = {Two very closely related definitions of robustness of a sequence of estimators are given which take into account the types of deviations from parametric models that occur in practice. These definitions utilize the properties of the Prokhorov distance between probability distributions. It is proved that weak *-continuous functionals on the space of probability distributions define robust sequences of estimators (in either sense). The concept of the "breakdown point" of a sequence of estimators is defined, and some examples are given.},
  file      = {:FILES/1971 - Hampel1971 - A general qualitative definition of robustness.pdf:PDF},
  groups    = {robust statistics},
  publisher = {Institute of Mathematical Statistics},
  url       = {http://www.jstor.org/stable/2240114},
}

@Article{Davies2007,
  author   = {P. L. Davies and U. Gather},
  journal  = {{REVSTAT} – Statistical Journal},
  title    = {The breakdown point – examples and counterexamples},
  year     = {2007},
  month    = mar,
  number   = {1},
  pages    = {1--17},
  volume   = {5},
  abstract = {The breakdown point plays an important though at times controversial role in statistics. In situations in which it has proved most successful there is a group of transformations which act on the sample space and which give rise to an equivariance
structure. For equivariant functionals, that is those functionals which respect the
group structure, a non-trivial upper bound for the breakdown point was derived in
Davies and Gather (2005). The present paper briefly repeats the main results of
Davies and Gather (2005) but is mainly concerned with giving additional insight into
the concept of breakdown point. In particular, we discuss the attainability of the
bound and the dependence of the breakdown point on the sample or distribution and
on the metrics used in its definition.},
  file     = {:FILES/2007 - Davies2007 - The breakdown point – examples and counterexamples.pdf:PDF},
  groups   = {robust statistics},
  url      = {https://www.ine.pt/revstat/pdf/rs070101.pdf},
}

@Article{Donoho1992,
  author    = {Donoho, David L. and Gasko, Miriam},
  journal   = {Ann. Statist.},
  title     = {Breakdown properties of location estimates based on halfspace depth and projected outlyingness},
  year      = {1992},
  month     = {12},
  number    = {4},
  pages     = {1803--1827},
  volume    = {20},
  doi       = {10.1214/aos/1176348890},
  file      = {:FILES/1992 - Donoho1992 - Breakdown properties of location estimates based on halfspace depth and projected outlyingness.pdf:PDF},
  groups    = {robust statistics},
  publisher = {The Institute of Mathematical Statistics},
  url       = {https://doi.org/10.1214/aos/1176348890},
}

@InProceedings{Hodges1967,
  author    = {Hodges, J. L.},
  booktitle = {Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Statistics},
  title     = {Efficiency in normal samples and tolerance of extreme values for some estimates of location},
  year      = {1967},
  address   = {Berkeley, Calif.},
  pages     = {163--186},
  publisher = {University of California Press},
  file      = {:FILES/1967 - Hodges1967 - Efficiency in normal samples and tolerance of extreme values for some estimates of location.pdf:PDF},
  groups    = {robust statistics},
  url       = {https://projecteuclid.org/euclid.bsmsp/1200512985},
}

@Article{Liu2017a,
  author   = {Liu, Xiaohui and Zuo, Yijun and Wang, Qihua},
  journal  = {Science China Mathematics},
  title    = {Finite sample breakdown point of {Tukey’s} halfspace median},
  year     = {2017},
  issn     = {1869-1862},
  number   = {5},
  pages    = {861--874},
  volume   = {60},
  abstract = {Tukey’s halfspace median (HM), servicing as the multivariate counterpart of the univariate median, has been introduced and extensively studied in the literature. It is supposed and expected to preserve robustness property (the most outstanding property) of the univariate median. One of prevalent quantitative assessments of robustness is finite sample breakdown point (FSBP). Indeed, the FSBP of many multivariate medians have been identified, except for the most prevailing one--the Tukey’s halfspace median. This paper presents a precise result on FSBP for Tukey’s halfspace median. The result here depicts the complete prospect of the global robustness of HM in the finite sample practical scenario, revealing the dimension effect on the breakdown point robustness and complimenting the existing asymptotic breakdown point result.},
  doi      = {10.1007/s11425-016-0285-1},
  file     = {:FILES/2017 - Liu2017a - Finite sample breakdown point of {Tukey’s} halfspace median.pdf:PDF},
  groups   = {robust statistics},
  refid    = {Liu2017},
  url      = {https://doi.org/10.1007/s11425-016-0285-1},
}

@Article{AMC1989,
  author  = {{Analytical Methods Committee}},
  journal = {Analyst},
  title   = {Robust statistics - {How} not to reject outliers},
  year    = {1989},
  month   = dec,
  pages   = {1693--1697},
  volume  = {114},
  file    = {:FILES/1989 - AMC1989 - Robust statistics - {How} not to reject outliers.pdf:PDF},
  groups  = {robust statistics},
}

@InProceedings{Schoukens2016,
  author    = {Maarten Schoukens and Fritjof Griesing Scheiwe},
  booktitle = {Workshop on Nonlinear System Identification Benchmarks},
  title     = {Modeling nonlinear systems using a {Volterra} feedback model},
  year      = {2016},
  address   = {Brussels, Belgium},
  month     = apr,
  file      = {:FILES/2016 - Schoukens2016 - Modeling nonlinear systems using a volterra feedback model.pdf:PDF},
  groups    = {robust statistics},
}

@Article{黄德先2012,
  author   = {黄德先 and 余冰 and 高小永 and 摆亮 and 施磊 and 江永亨},
  journal  = {清华大学学报(自然科学版)},
  title    = {基于分片线性代理模型的成品油调合优化},
  year     = {2012},
  number   = {09},
  pages    = {1230--1235+1243},
  volume   = {52},
  abstract = {成品油调合对提高炼厂经济效益有着重要的作用和意义。成品油调合优化是一个非线性约束优化问题,传统的进化算法由于搜索空间大又没有结构信息,要取得期望的求解效率和解的稳定性都是具有挑战性的任务。针对上述问题,提出了一种基于分片线性代理模型的成品油调合优化方法,它包含分片线性建模和优化2部分内容。首先,利用分片线性函数模型作为成品油调合非线性调合性质指标函数的代理模型,将原非线性约束优化问题转化为一系列线性规划子问题;然后,利用差分进化算法搜索相关线性子区域来获得全局最优值,以达到提高进化算法的求解速度和避免算法陷入局部最优解的目的;最后,通过成品油调合优化案例验证了该方法的有效性。},
  file     = {:FILES/2012 - 黄德先2012 - 基于分片线性代理模型的成品油调合优化.pdf:PDF},
  groups   = {application},
  keywords = {成品油调合;分片线性;自适应超平面链接;差分进化},
  url      = {https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFD2012&filename=QHXB201209013&v=mHFRnExWYa6MYg1TUIrLtyyzqlYNPmhCuboSwOg6oyYsvax6sawh2qvdoYK5w5Xb},
}

@InProceedings{Gao2013,
  author    = {Gao, X. and Jiang, Y. and Huang, D. and Xiong, Z.},
  booktitle = {2013 10th IEEE International Conference on Control and Automation (ICCA)},
  title     = {A novel high level canonical piecewise linear model based on the simplicial partition and its application},
  year      = {2013},
  month     = {6},
  pages     = {1856--1861},
  abstract  = {Piecewise linear model has attracted more and more concerns in recent researches because it can handle the complex nonlinearity and maintain linearity in subregions. The compact representations of piecewise linear (PWL) such as hinging hyperplanes (HH), generalized hinging hyperplanes (GHH) and so on have been introduced. But during parameters training, the partitions are uncontrollable and unpredicted and will result in a large number of crossing subregions, that is so-called the curse of partitions, which makes it hard in the real world application. In this paper, a novel high level canonical piecewise linear model based on simplex partition is addressed to tackle the curse of partitions. Several numerical experiments are done to show the effectiveness of proposed model. And then, Petro-SIM is used to simulate the refinery hydro-upgrading processing units (HUPUs) and scheduling models of HUPUs are obtained with the proposed model. The simulation experiments show that the proposed model formulation can not only maintain a relatively high fitting accuracy but also effectively avoid the curse of partitions.},
  doi       = {10.1109/ICCA.2013.6565070},
  file      = {:FILES/2013 - Gao2013 - A novel high level canonical piecewise linear model based on simplicial partition and its application.pdf:PDF},
  groups    = {identification},
  issn      = {1948-3457},
  keywords  = {oil refining;piecewise linear techniques;scheduling;high level canonical piecewise linear model;simplicial partition;complex nonlinearity;compact representations;PWL;generalized hinging hyperplanes;GHH;parameters training;crossing subregions;simplex partition;Petro-SIM;refinery hydro-upgrading processing units;HUPU;scheduling models;fitting accuracy;Numerical models;Training;Piecewise linear approximation;Approximation methods;Accuracy;Vectors;Fitting},
}

@Article{Gao2004,
  author   = {Gao, David Yang},
  journal  = {Journal of Global Optimization},
  title    = {Canonical duality theory and solutions to constrained nonconvex quadratic programming},
  year     = {2004},
  issn     = {1573-2916},
  number   = {4},
  pages    = {377--399},
  volume   = {29},
  abstract = {This paper presents a perfect duality theory and a complete set of solutions to nonconvex quadratic programming problems subjected to inequality constraints. By use of the canonical dual transformation developed recently, a canonical dual problem is formulated, which is perfectly dual to the primal problem in the sense that they have the same set of KKT points. It is proved that the KKT points depend on the index of the Hessian matrix of the total cost function. The global and local extrema of the nonconvex quadratic function can be identified by the triality theory [11]. Results show that if the global extrema of the nonconvex quadratic function are located on the boundary of the primal feasible space, the dual solutions should be interior points of the dual feasible set, which can be solved by deterministic methods. Certain nonconvex quadratic programming problems in {\open {R}}^{n} can be converted into a dual problem with only one variable. It turns out that a complete set of solutions for quadratic programming over a sphere is obtained as a by-product. Several examples are illustrated.},
  doi      = {10.1023/B:JOGO.0000048034.94449.e3},
  file     = {:FILES/2004 - Gao2004 - Canonical duality theory and solutions to constrained nonconvex quadratic programming.pdf:PDF},
  groups   = {mathematical basis},
  refid    = {Gao2004},
  url      = {https://doi.org/10.1023/B:JOGO.0000048034.94449.e3},
}

@Article{Zhu2009,
  author   = {Zhu, Jinghao and Tao, Shiming and Gao, David},
  journal  = {Journal of Computational and Applied Mathematics},
  title    = {A study on concave optimization via canonical dual function},
  year     = {2009},
  issn     = {0377-0427},
  number   = {2},
  pages    = {459--464},
  volume   = {224},
  abstract = {In this study we find a global minimizer of a concave function over a sphere. By introducing a differential equation, we obtain the invariant characteristics for a given optimization problem by constructing a canonical dual function. We present two theorems concerning the global optimality of an extrema of the optimization problem.},
  doi      = {https://doi.org/10.1016/j.cam.2008.05.011},
  file     = {:FILES/2009 - Zhu2009 - A study on concave optimization via canonical dual function.pdf:PDF},
  groups   = {concave},
  keywords = {Concave optimization, Canonical dual function, Global optimization},
  url      = {http://www.sciencedirect.com/science/article/pii/S0377042708002495},
}

@Article{Ren2018,
  author   = {Ren, Yixuan and Ye, Tao and Huang, Mengxing and Feng, Siling},
  journal  = {Algorithms},
  title    = {Gray wolf optimization algorithm for multi-constraints second-order stochastic dominance portfolio optimization},
  year     = {2018},
  month    = may,
  number   = {5},
  pages    = {72},
  volume   = {11},
  abstract = {In the field of investment, how to construct a suitable portfolio based on historical data is still an important issue. The second-order stochastic dominant constraint is a branch of the stochastic dominant constraint theory. However, only considering the second-order stochastic dominant constraints does not conform to the investment environment under realistic conditions. Therefore, we added a series of constraints into basic portfolio optimization model, which reflect the realistic investment environment, such as skewness and kurtosis. In addition, we consider two kinds of risk measures: conditional value at risk and value at risk. Most important of all, in this paper, we introduce Gray Wolf Optimization (GWO) algorithm into portfolio optimization model, which simulates the gray wolf’s social hierarchy and predatory behavior. In the numerical experiments, we compare the GWO algorithm with Particle Swarm Optimization (PSO) algorithm and Genetic Algorithm (GA). The experimental results show that GWO algorithm not only shows better optimization ability and optimization efficiency, but also the portfolio optimized by GWO algorithm has a better performance than FTSE100 index, which prove that GWO algorithm has a great potential in portfolio optimization.},
  doi      = {https://doi.org/10.3390/a11050072},
  file     = {:FILES/2018 - Ren2018 - Gray Wolf Optimization Algorithm for Multi-Constraints Second-Order Stochastic Dominance Portfolio Optimization.pdf:PDF},
  groups   = {Swarm algorithms, Portfolio Selection},
  keywords = {portfolio optimization; gray wolf optimization; second-order stochastic dominance; risk; constraint},
  url      = {https://www.mdpi.com/1999-4893/11/5/72},
}

@Misc{Chatterjee2017,
  author        = {Chatterjee, Saikat and Javid, Alireza M. and Sadeghi, Mostafa and Mitra, Partha P. and Skoglund, Mikael},
  title         = {Progressive learning for systematic design of large neural networks},
  year          = {2017},
  archiveprefix = {arXiv},
  eprint        = {1710.08177},
  file          = {:FILES/2017 - Chatterjee2017 - Progressive Learning for Systematic Design of Large Neural Networks.pdf:PDF},
  groups        = {Neural Network},
  primaryclass  = {cs.NE},
}

@Article{Shirai2015,
  author   = {Kenji Shirai and Yoshinori Amano},
  journal  = {Asian Journal of Management Science and Applications},
  title    = {Model of production system with time delay using stochastic bilinear equation},
  year     = {2015},
  month    = sep,
  number   = {1},
  pages    = {81--103},
  volume   = {2},
  abstract = {This study proposes a stochastic bilinear differential equation to model the production process by including a time delay. The time delay is caused by factors such as variations in workers' skill levels, the delay in delivering materials, and logistical issues. We verify the existence of a unique solution to the proposed mathematical model. To obtain a unique solution, we introduce a stochastic bilinear partial differential equation. We consider that a manufacturer with external companies produces some of the ordered equipment. For the model evaluation, we compare the model results with actual data, which were obtained from the production of control equipment.},
  doi      = {10.1504/AJMSA.2015.071897},
  file     = {:FILES/2015 - Shirai2015 - Model of production system with time delay using stochastic bilinear equation.pdf:PDF},
  groups   = {bilinear},
  keywords = {stochastic bilinear PDEs; partial differential equations; time delay; distributed parameter systems; average regression models; production system modelling; skills levels; materials delivery; logistics; mathematical modelling; control equipment.},
  url      = {https://www.inderscience.com/info/inarticle.php?artid=71897},
}

@Book{Ruzhansky2016,
  editor    = {Ruzhansky, Michael and Tikhonov, Sergey},
  publisher = {Birkh\"{a}user},
  title     = {Methods of {Fourier} analysis and approximation theory},
  year      = {2016},
  address   = {Switzerland},
  isbn      = {978-3-319-27465-2},
  abstract  = {Different facets of interplay between harmonic analysis and approximation theory are covered in this volume.  The topics included are Fourier analysis, function spaces, optimization theory, partial differential equations, and their links to modern developments in the approximation theory. The articles of this collection were originated from two events. The first event took place during the 9th ISAAC Congress in Krakow, Poland, 5th-9th August 2013, at the section “Approximation Theory and Fourier Analysis”. The second event was the conference on Fourier Analysis and Approximation Theory in the Centre de Recerca  Matemàtica (CRM), Barcelona, during 4th-8th November 2013, organized by the editors of this volume. All articles selected to be part of this collection were carefully reviewed.},
  doi       = {10.1007/978-3-319-27466-9},
  file      = {:FILES/2016 - Ruzhansky2016 - Methods of Fourier Analysis and Approximation Theory.pdf:PDF},
  groups    = {Approximation},
  url       = {https://www.springer.com/gp/book/9783319274652},
}

@Article{叶丹2010,
  author   = {叶丹 and 胡支军},
  journal  = {中国管理科学},
  title    = {基于损失厌恶的非线性投资组合问题},
  year     = {2010},
  number   = {4},
  pages    = {28--33},
  volume   = {18},
  abstract = {借鉴Kahneman\&Tversky(1979)提出的展望理论,本文从期望效用最大化的角度研究不同风险资产的配置问题。通过将投资者的效用函数表示为期末财富变化的函数,建立了基于损失厌恶的最优投资组合模型。针对S-型效用函数在参考点附近的非光滑问题,设计了一个三次样条函数对其进行光滑化处理;同时,还设计了一个随机搜索算法用以处理由于目标函数的非凹性而导致出现多个局部最优解的问题。最后利用中国证券市场的实际数据验证了该模型的合理性和有效性。},
  file     = {:FILES/2010 - 叶丹2010 - 基于损失厌恶的非线性投资组合问题.pdf:PDF},
  groups   = {Portfolio Selection},
  keywords = {展望理论;损失厌恶;投资组合;非光滑问题;局部最优},
}

@Article{Rumelhart1986,
  author   = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
  journal  = {Nature},
  title    = {Learning representations by back-propagating errors},
  year     = {1986},
  issn     = {1476-4687},
  number   = {6088},
  pages    = {533--536},
  volume   = {323},
  abstract = {We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal ‘hidden’ units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
  doi      = {10.1038/323533a0},
  file     = {:FILES/1986 - Rumelhart1986 - learning representations by back-propagation errors.pdf:PDF},
  groups   = {machine learning},
  url      = {https://doi.org/10.1038/323533a0},
}

@Book{Cao2007,
  author    = {Xi-Ren Cao},
  publisher = {Springer},
  title     = {Stochastic learning and optimization: {A} sensitivity-based approach},
  year      = {2007},
  isbn      = {9780387367873},
  series    = {International series on discrete event dynamic systems},
  doi       = {10.1007/978-0-387-69082-7},
  file      = {:FILES/2007 - Cao2007 - Stochastic learning and optimization- {A} sensitivity-based approach.pdf:PDF},
  groups    = {machine learning},
  url       = {https://www.springer.com/gp/book/9780387367873},
}

@Article{Bottou2018,
  author  = {Bottou, L\'{e}on and Curtis, Frank E. and Nocedal, Jorge},
  journal = {SIAM Review},
  title   = {Optimization methods for large-scale machine learning},
  year    = {2018},
  number  = {2},
  pages   = {223--311},
  volume  = {60},
  doi     = {10.1137/16M1080173},
  eprint  = {https://doi.org/10.1137/16M1080173},
  file    = {:FILES/2018 - Bottou2018 - Optimization methods for large-scale machine learning.pdf:PDF},
  groups  = {machine learning},
  url     = {https://doi.org/10.1137/16M1080173},
}

@InProceedings{Rakhlin2012,
  author    = {Rakhlin, Alexander and Shamir, Ohad and Sridharan, Karthik},
  booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
  title     = {Making gradient descent optimal for strongly convex stochastic optimization},
  year      = {2012},
  address   = {Madison, WI, USA},
  pages     = {1571--1578},
  publisher = {Omnipress},
  series    = {ICML'12},
  abstract  = {Stochastic gradient descent (SGD) is a simple and popular method to solve stochastic optimization problems which arise in machine learning. For strongly convex problems, its convergence rate was known to be O(log(T)/T), by running SGD for T iterations and returning the average point. However, recent results showed that using a different algorithm, one can get an optimal O(1/T) rate. This might lead one to believe that standard SGD is suboptimal, and maybe should even be replaced as a method of choice. In this paper, we investigate the optimality of SGD in a stochastic setting. We show that for smooth problems, the algorithm attains the optimal O(1/T) rate. However, for non-smooth problems, the convergence rate with averaging might really be Ω(log(T)/T), and this is not just an artifact of the analysis. On the flip side, we show that a simple modification of the averaging step suffices to recover the O(1/T) rate, and no other change of the algorithm is necessary. We also present experimental results which support our findings, and point out open problems.},
  file      = {:FILES/2012 - Rakhlin2012 - Making gradient descent optimal for strongly convex stochastic optimization.pdf:PDF},
  groups    = {global optimization},
  isbn      = {9781450312851},
  location  = {Edinburgh, Scotland},
  numpages  = {8},
  url       = {https://icml.cc/Conferences/2012/papers/},
}

@Article{Bertsekas2011,
  author   = {Bertsekas, Dimitri P.},
  journal  = {Mathematical Programming},
  title    = {Incremental proximal methods for large scale convex optimization},
  year     = {2011},
  issn     = {1436-4646},
  number   = {2},
  pages    = {163},
  volume   = {129},
  abstract = {We consider the minimization of a sum $${\sum_{i=1}^mf_i(x)}$$consisting of a large number of convex component functions fi. For this problem, incremental methods consisting of gradient or subgradient iterations applied to single components have proved very effective. We propose new incremental methods, consisting of proximal iterations applied to single components, as well as combinations of gradient, subgradient, and proximal iterations. We provide a convergence and rate of convergence analysis of a variety of such methods, including some that involve randomization in the selection of components. We also discuss applications in a few contexts, including signal processing and inference/machine learning.},
  doi      = {10.1007/s10107-011-0472-0},
  file     = {:FILES/2011 - Bertsekas2011 - incremental proximal methods for large scale convex optimization.pdf:PDF},
  groups   = {proximal bundle method},
  url      = {https://doi.org/10.1007/s10107-011-0472-0},
}

@Article{Parikh2014,
  author   = {Parikh, Neal and Boyd, Stephen},
  journal  = {Foundations and Trends\textregistered in Optimization},
  title    = {Proximal algorithms},
  year     = {2014},
  number   = {3},
  pages    = {127--239},
  volume   = {1},
  abstract = {This monograph is about a class of optimization algorithms called proximal algorithms. Much like Newton’s method is a standard tool for solving unconstrained smooth optimization problems of modest size, proximal algorithms can be viewed as an analogous tool for nonsmooth, constrained, large-scale, or distributed versions of these problems. They are very generally applicable, but are especially well-suited to problems of substantial recent interest involving large or high-dimensional datasets. Proximal methods sit at a higher level of abstraction than classical algorithms like Newton’s method: the base operation is evaluating the proximal operator of a function, which itself involves solving a small convex optimization problem. These subproblems, which generalize the problem of projecting a point onto a convex set, often admit closed-form solutions or can be solved very quickly with standard or simple specialized methods. Here, we discuss the many different interpretations of proximal operators and algorithms, describe their connections to many other topics in optimization and applied mathematics, survey some popular algorithms, and provide a large number of examples of proximal operators that commonly arise in practice.},
  doi      = {10.1561/2400000003},
  file     = {:FILES/2014 - Parikh2014 - Proximal Algorithms.pdf:PDF},
  groups   = {proximal bundle method},
  url      = {https://web.stanford.edu/~boyd/papers/prox_algs.html;https://www.nowpublishers.com/article/Details/OPT-003},
}

@InBook{Haupt2003,
  author    = {Randy L. Haupt and Sue Ellen Haupt},
  chapter   = {2},
  pages     = {27--50},
  publisher = {John Wiley \& Sons, Ltd},
  title     = {The binary genetic algorithm},
  year      = {2003},
  isbn      = {9780471671749},
  abstract  = {Summary Examples are used to introduce application of a simple binary genetic algorithm. This chapter discusses variable encoding and decoding, initializing the population, natural selection, mating, mutation, and convergence. A detailed step-by-step example of finding the maximum of a multi-modal function is given.},
  booktitle = {Practical Genetic Algorithms},
  doi       = {https://doi.org/10.1002/0471671746.ch2},
  eprint    = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/0471671746.ch2},
  file      = {:FILES/2003 - Haupt2003 - The binary genetic algorithm.pdf:PDF},
  groups    = {genetic algorithms},
  keywords  = {binary genetic algorithm, natural selection, simple genetic algorithm, mating, mutation, encoding, decoding, gene, chromosome, mutation rate, crossover, offspring, population, tournament selection, roulette wheel selection, rank weighting, cost weighting},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/0471671746.ch2},
}

@Article{Tao2020,
  author   = {Tao, Qinghua and Li, Zhen and Xu, Jun and Xie, Na and Wang, Shuning and Suykens, Johan A. K.},
  journal  = {Expert Systems with Applications},
  title    = {Learning with continuous piecewise linear decision trees},
  year     = {2020},
  issn     = {0957-4174},
  pages    = {114214},
  abstract = {In this paper, we propose a piecewise linear decision tree and its generalized form, namely the (G)PWL-DT, which introduces piecewise linearity and overcomes the discontinuity of the existing piecewise constant decision trees (PWC-DT). The proposed (G)PWL-DT inherits the basic topology and interpretability of decision trees by recursively partitioning the domain into subregions, which are represented by leaf nodes. Rather than the indicator function, the (G)PWL-DT employs rectifier linear units (ReLU) to interpret domain partitions, where the nested ReLUs are combined to formulate the corresponding PWL decision rules. Due to the piecewise linearity of each leaf node, additional boundaries among linear areas are obtained to approach greater flexibility than the existing PWC-DT under the same tree structure, where the continuity can also be guaranteed. Then, an optimization algorithm is constructed analogously based on the second-order approximation. The proposed (G)PWL-DT can be flexibly applied as a novel decision tree in different tree learning methods and it can also be regarded as a simple extension of ReLUs to the framework of tree learning. Numerical experiments verify the effectiveness of the proposed (G)PWL-DT and its potential as an alternative of the existing PWC-DT to approach better performance even with more concise structures.},
  doi      = {https://doi.org/10.1016/j.eswa.2020.114214},
  file     = {:FILES/2020 - Tao2020 - Learning with continuous piecewise linear decision trees.pdf:PDF},
  groups   = {identification},
  keywords = {Decision tree, Continuity, Piecewise linearity, Domain partition},
  url      = {http://www.sciencedirect.com/science/article/pii/S0957417420309404},
}

@Misc{Fang2020,
  author        = {Fang, Kun and Huang, Xiaolin and Liu, Fanghui and Yang, Jie},
  title         = {End-to-end kernel learning via generative random fourier features},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2009.04614},
  file          = {:FILES/2020 - Fang2020 - End-to-end kernel learning via generative random fourier features.pdf:PDF},
  groups        = {machine learning},
  primaryclass  = {cs.LG},
}

@Misc{Bai2020,
  author        = {Bai, Zonglong and Shi, Liming and Sun, Jinwei and Christensen, Mads Græsb\oll},
  title         = {Complex sparse signal recovery with adaptive {Laplace} priors},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2006.16720},
  file          = {:FILES/2020 - Bai2020 - Complex sparse signal recovery with adaptive laplace priors.pdf:PDF},
  groups        = {Compressive sensing},
  primaryclass  = {eess.SP},
}

@Misc{Huang2020,
  author        = {Huang, Jianwen and Liu, Xinling and Hou, Jinyao and Wang, Jianjun},
  title         = {The high-order block rip for non-convex block-sparse compressed sensing},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2006.06344},
  file          = {:FILES/2020 - Huang2020 - The high-order block rip for non-convex block-sparse compressed sensing.pdf:PDF},
  groups        = {Compressive sensing},
  primaryclass  = {cs.IT},
}

@Article{Li2020a,
  author    = {Li, Ruilin and Chang, Christopher and Justesen, Johanne Marie and Tanigawa, Yosuke and Qian, Junyang and Hastie, Trevor and Rivas, Manuel A. and Tibshirani, Robert},
  journal   = {bioRxiv},
  title     = {Fast {LASSO} method for large-scale and ultrahigh-dimensional cox model with applications to {UK} biobank},
  year      = {2020},
  abstract  = {We develop a scalable and highly efficient algorithm to fit a Cox proportional hazard model by maximizing the L1-regularized (Lasso) partial likelihood function, based on the Batch Screening Iterative Lasso (BASIL) method developed in (Qian et al. 2019). The output of our algorithm is the full Lasso path, the parameter estimates at all predefined regularization parameters, as well as their validation accuracy measured using the concordance index (C-index) or the validation deviance. To demonstrate the effectiveness of our algorithm, we analyze a large genotype-survival time dataset across 306 disease outcomes from the UK Biobank (Sudlow et al. 2015). Our approach, which we refer to as snpnet-Cox, is implemented in a publicly available package.},
  doi       = {10.1101/2020.01.20.913194},
  eprint    = {https://www.biorxiv.org/content/early/2020/01/21/2020.01.20.913194.full.pdf},
  file      = {:FILES/2020 - Li2020a - Fast lasso method for large-scale and ultrahigh-dimensional cox model with applications to uk biobank.pdf:PDF},
  groups    = {optimization},
  publisher = {Cold Spring Harbor Laboratory},
  url       = {https://www.biorxiv.org/content/early/2020/01/21/2020.01.20.913194},
}

@Article{Maleki2010,
  author   = {Maleki, A. and Donoho, D. L.},
  journal  = {IEEE Journal of Selected Topics in Signal Processing},
  title    = {Optimally tuned iterative reconstruction algorithms for compressed sensing},
  year     = {2010},
  issn     = {1941-0484},
  month    = {4},
  number   = {2},
  pages    = {330--341},
  volume   = {4},
  abstract = {We conducted an extensive computational experiment, lasting multiple CPU-years, to optimally select parameters for two important classes of algorithms for finding sparse solutions of underdetermined systems of linear equations. We make the optimally tuned implementations available at sparselab.stanford.edu; they run ¿out of the box¿ with no user tuning: it is not necessary to select thresholds or know the likely degree of sparsity. Our class of algorithms includes iterative hard and soft thresholding with or without relaxation, as well as CoSaMP, subspace pursuit and some natural extensions. As a result, our optimally tuned algorithms dominate such proposals. Our notion of optimality is defined in terms of phase transitions, i.e., we maximize the number of nonzeros at which the algorithm can successfully operate. We show that the phase transition is a well-defined quantity with our suite of random underdetermined linear systems. Our tuning gives the highest transition possible within each class of algorithms. We verify by extensive computation the robustness of our recommendations to the amplitude distribution of the nonzero coefficients as well as the matrix ensemble defining the underdetermined system. Our findings include the following. 1) For all algorithms, the worst amplitude distribution for nonzeros is generally the constant-amplitude random-sign distribution, where all nonzeros are the same amplitude. 2) Various random matrix ensembles give the same phase transitions; random partial isometries may give different transitions and require different tuning. 3) Optimally tuned subspace pursuit dominates optimally tuned CoSaMP, particularly so when the system is almost square.},
  doi      = {10.1109/JSTSP.2009.2039176},
  file     = {:FILES/2010 - Maleki2010 - Optimally tuned iterative reconstruction algorithms for compressed sensing.pdf:PDF},
  groups   = {Compressive sensing},
  keywords = {iterative methods;signal reconstruction;sparse matrices;tuning;iterative reconstruction algorithms;compressed sensing;sparse solutions;underdetermined linear systems;matrix ensembles;random partial isometries;optimal tuning;linear equations;thresholding;degree of sparsity;Reconstruction algorithms;Compressed sensing;Iterative algorithms;Signal processing algorithms;Proposals;Equations;Pursuit algorithms;Sparse matrices;Linear systems;Distributed computing;Compressed sensing;iterative algorithms;phase transition;random matrices;thresholding},
}

@Article{Qaisar2013,
  author   = {Qaisar, Saad and Bilal, Rana Muhammad and Iqbal, Wafa and Naureen, Muqaddas and Lee, Sungyoung},
  journal  = {Journal of Communications and Networks},
  title    = {Compressive sensing: {From} theory to applications, a survey},
  year     = {2013},
  issn     = {1976-5541},
  month    = {10},
  number   = {5},
  pages    = {443--456},
  volume   = {15},
  abstract = {Compressive sensing (CS) is a novel sampling paradigm that samples signals in a much more efficient way than the established Nyquist sampling theorem. CS has recently gained a lot of attention due to its exploitation of signal sparsity. Sparsity, an inherent characteristic of many natural signals, enables the signal to be stored in few samples and subsequently be recovered accurately, courtesy of CS. This article gives a brief background on the origins of this idea, reviews the basic mathematical foundation of the theory and then goes on to highlight different areas of its application with a major emphasis on communications and network domain. Finally, the survey concludes by identifying new areas of research where CS could be beneficial.},
  doi      = {10.1109/JCN.2013.000083},
  file     = {:FILES/2013 - Qaisar2013 - Compressive sensing- {From} theory to applications, a survey.pdf:PDF},
  groups   = {Compressive sensing},
  keywords = {compressed sensing;mathematical analysis;signal sampling;compressive sensing;CS;signals sampling paradigm;Nyquist sampling theorem;signal sparsity exploitation;mathematical foundation;Minimization;Matching pursuit algorithms;Sparse matrices;Sensors;Reconstruction algorithms;Compressed sensing;Image reconstruction;Compressive imaging;compressive sensing (CS);incoherence;sparsity;wireless sensor networks (WSNs)},
}

@Article{Kumar2020,
  author   = {Kumar, Sandeep and Ying, Jiaxi and M. Cardoso, Jos茅 Vin铆cius and Palomar, Daniel P.},
  journal  = {Journal of Machine Learning Research},
  title    = {A unified framework for structured graph learning via spectral constraints},
  year     = {2020},
  number   = {22},
  pages    = {1--60},
  volume   = {21},
  abstract = {Graph learning from data is a canonical problem that has received substantial attention in the literature. Learning a structured graph is essential for interpretability and identification of the relationships among data. In general, learning a graph with a specific structure is an NP-hard combinatorial problem and thus designing a general tractable algorithm is challenging. Some useful structured graphs include connected, sparse, multi-component, bipartite, and regular graphs. In this paper, we introduce a unified framework for structured graph learning that combines Gaussian graphical model and spectral graph theory. We propose to convert combinatorial structural constraints into spectral constraints on graph matrices and develop an optimization framework based on block majorization-minimization to solve structured graph learning problem. The proposed algorithms are provably convergent and practically amenable for a number of graph based applications such as data clustering. Extensive numerical experiments with both synthetic and real data sets illustrate the effectiveness of the proposed algorithms. An open source R package containing the code for all the experiments is available at https://CRAN.R-project.org/package=spectralGraphTopology.},
  file     = {:FILES/2020 - Kumar2020 - A unified framework for structured graph learning via spectral constraints.pdf:PDF},
  groups   = {machine learning},
  url      = {http://jmlr.org/papers/v21/19-276.html},
}

@InProceedings{Pilgrim2017,
  author    = {Pilgrim, Ryan and Zhu, Junan and Baron, Dror and Bajwa, Waheed U.},
  booktitle = {2017 55th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  title     = {Generalized geometric programming for rate allocation in consensus},
  year      = {2017},
  month     = {10},
  pages     = {374--381},
  abstract  = {Distributed averaging, or distributed average consensus, is a common method for computing the sample mean of the data dispersed among the nodes of a network in a decentralized manner. By iteratively exchanging messages with neighbors, the nodes of the network can converge to an agreement on the sample mean of their initial states. In real-world scenarios, these messages are subject to bandwidth and power constraints, which motivates the design of a lossy compression strategy. Few prior works consider the rate allocation problem from the perspective of constrained optimization, which provides a principled method for the design of lossy compression schemes, allows for the relaxation of certain assumptions, and offers performance guarantees. We show for Gaussian-distributed initial states with entropy-coded scalar quantization and vector quantization that the coding rates for distributed averaging can be optimized through generalized geometric programming. In the absence of side information from past states, this approach finds a rate allocation over nodes and iterations that minimizes the aggregate coding rate required to achieve a target mean square error within a finite run time. Our rate allocation is compared to some of the prior art through numerical simulations. The results motivate the incorporation of side-information through differential or predictive coding to improve rate-distortion performance.},
  doi       = {10.1109/ALLERTON.2017.8262762},
  file      = {:FILES/2017 - Pilgrim2017 - Generalized geometric programming for rate allocation in consensus.pdf:PDF},
  groups    = {SGP},
  keywords  = {data compression;entropy codes;Gaussian distribution;geometric programming;iterative methods;mean square error methods;minimisation;quantisation (signal);radio networks;rate distortion theory;generalized geometric programming;distributed averaging;average consensus;sample mean;decentralized manner;initial states;real-world scenarios;power constraints;lossy compression strategy;rate allocation problem;constrained optimization;mean square error;rate-distortion performance;aggregate coding rate;coding rates;vector quantization;entropy-coded scalar quantization;lossy compression schemes;Quantization (signal);Encoding;Optimization;Wireless sensor networks;Distributed databases;Resource management;Face recognition;Compression;consensus;geometric programming;optimization;source coding},
}

@Article{Tao2017,
  author   = {Tao, Qinghua and Huang, Xiaolin and Wang, Shuning and Li, Li},
  journal  = {Journal of Global Optimization},
  title    = {Adaptive block coordinate {DIRECT} algorithm},
  year     = {2017},
  issn     = {1573-2916},
  number   = {4},
  pages    = {797--822},
  volume   = {69},
  abstract = {DIviding RECTangles (DIRECT) is an efficient and popular method in dealing with bound constrained optimization problems. However, DIRECT suffers from dimension curse, since its computational complexity soars when dimension increases. Besides, DIRECT also converges slowly when the objective function is flat. In this paper, we propose a coordinate DIRECT algorithm, which coincides with the spirits of other coordinate update algorithms. We transform the original problem into a series of sub-problems, where only one or several coordinates are selected to optimize and the rest keeps fixed. For each sub-problem, coordinately dividing the feasible domain enjoys low computational burden. Besides, we develop adaptive schemes to keep the efficiency and flexibility to tackle different functions. Specifically, we use block coordinate update, of which the size could be adaptively selected, and we also employ sequential quadratic programming to conduct the local search to efficiently accelerate the convergence even when the objective function is flat. With these techniques, the proposed algorithm achieves promising performance on both efficiency and accuracy in numerical experiments.},
  doi      = {10.1007/s10898-017-0541-x},
  file     = {:FILES/2017 - Tao2017 - Adaptive block coordinate {DIRECT} algorithm.pdf:PDF},
  groups   = {global optimization},
  refid    = {Tao2017},
  url      = {https://doi.org/10.1007/s10898-017-0541-x},
}

@Article{Yang2012,
  author   = {Zai Yang and Cishen Zhang and Lihua Xie},
  journal  = {IEEE Transactions on Signal Processing},
  title    = {Robustly stable signal recovery in compressed sensing with structured matrix perturbation},
  year     = {2012},
  issn     = {1941-0476},
  month    = sep,
  number   = {9},
  pages    = {4658--4671},
  volume   = {60},
  abstract = {The sparse signal recovery in the standard compressed sensing (CS) problem requires that the sensing matrix be known a priori. Such an ideal assumption may not be met in practical applications where various errors and fluctuations exist in the sensing instruments. This paper considers the problem of compressed sensing subject to a structured perturbation in the sensing matrix. Under mild conditions, it is shown that a sparse signal can be recovered by l1 minimization and the recovery error is at most proportional to the measurement noise level, which is similar to the standard CS result. In the special noise free case, the recovery is exact provided that the signal is sufficiently sparse with respect to the perturbation level. The formulated structured sensing matrix perturbation is applicable to the direction of arrival estimation problem, so has practical relevance. Algorithms are proposed to implement the l1 minimization problem and numerical simulations are carried out to verify the results obtained.},
  doi      = {10.1109/TSP.2012.2201152},
  file     = {:FILES/2012 - Yang2012 - Robustly stable signal recovery in compressed sensing with structured matrix perturbation.pdf:PDF},
  groups   = {Compressive sensing},
  keywords = {compressed sensing;direction-of-arrival estimation;matrix algebra;minimisation;robustly stable signal recovery;compressed sensing;structured matrix perturbation;sparse signal recovery;l1 minimization;recovery error;measurement noise level;sensing matrix perturbation;direction of arrival estimation;Sensors;Robustness;Standards;Sparse matrices;Vectors;Minimization;Noise;Alternating algorithm;compressed sensing;direction of arrival estimation;stable signal recovery;structured matrix perturbation},
}

@Article{Diab2020,
  author   = {Mohammed Diab and Mihai Pomarlan and Daniel Be{\ss}ler and Aliakbar Akbari and Jan Rosell and John Bateman and Michael Beetz},
  journal  = {Robotics and Autonomous Systems},
  title    = {{SkillMaN} -- {A} skill-based robotic manipulation framework based on perception and reasoning},
  year     = {2020},
  issn     = {0921-8890},
  note     = {\#68},
  pages    = {103653},
  volume   = {134},
  abstract = {One of the problems that service robotics deals with is to bring mobile manipulators to work in semi-structured human scenarios, which requires an efficient and flexible way to execute every-day tasks, like serve a cup in a cluttered environment. Usually, for those tasks, the combination of symbolic and geometric levels of planning is necessary, as well as the integration of perception models with knowledge to guide both planning levels, resulting in a sequence of actions or skills which, according to the current knowledge of the world, may be executed. This paper proposes a planning and execution framework, called SkillMaN, for robotic manipulation tasks, which is equipped with a module with experiential knowledge (learned from its experience or given by the user) on how to execute a set of skills, like pick-up, put-down or open a drawer, using workflows as well as robot trajectories. The framework also contains an execution assistant with geometric tools and reasoning capabilities to manage how to actually execute the sequence of motions to perform a manipulation task (which are forwarded to the executor module), as well as the capacity to store the relevant information to the experiential knowledge for further usage, and the capacity to interpret the actual perceived situation (in case the preconditions of an action do not hold) and to feed back the updated state to the planner to resume from there, allowing the robot to adapt to non-expected situations. To evaluate the viability of the proposed framework, an experiment has been proposed involving different skills performed with various types of objects in different scene contexts.},
  doi      = {10.1016/j.robot.2020.103653},
  file     = {:FILES/2020 - Diab2020 - SkillMaN - A Skill-based Robotic Manipulation Framework based on Perception and Reasoning.pdf:PDF},
  groups   = {robot, 知识库调研报告},
  keywords = {Manipulation planning, Semantic Skill, Navigation, Every-day tasks, Adaptation, Knowledge-based Reasoning},
  url      = {http://www.sciencedirect.com/science/article/pii/S0921889020304930},
}

@InProceedings{Kuffner2000,
  author    = {J. J. {Kuffner} and S. M. {LaValle}},
  booktitle = {Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065)},
  title     = {{RRT-connect}: {An} efficient approach to single-query path planning},
  year      = {2000},
  address   = {San Francisco, CA, USA},
  month     = {April},
  pages     = {995--1001},
  publisher = {IEEE},
  volume    = {2},
  abstract  = {A simple and efficient randomized algorithm is presented for solving single-query path planning problems in high-dimensional configuration spaces. The method works by incrementally building two rapidly-exploring random trees (RRTs) rooted at the start and the goal configurations. The trees each explore space around them and also advance towards each other through, the use of a simple greedy heuristic. Although originally designed to plan motions for a human arm (modeled as a 7-DOF kinematic chain) for the automatic graphic animation of collision-free grasping and manipulation tasks, the algorithm has been successfully applied to a variety of path planning problems. Computed examples include generating collision-free motions for rigid objects in 2D and 3D, and collision-free manipulation motions for a 6-DOF PUMA arm in a 3D workspace. Some basic theoretical analysis is also presented.},
  comment   = {生成collision free path of robot arm},
  doi       = {10.1109/ROBOT.2000.844730},
  file      = {:FILES/2000 - Kuffner2000 - RRT-connect- An efficient approach to single-query path planning.pdf:PDF},
  groups    = {path planning},
  issn      = {1050-4729},
  keywords  = {path planning;search problems;computational geometry;robots;RRT-connect;single-query path planning;randomized algorithm;high-dimensional configuration spaces;rapidly-exploring random trees;simple greedy heuristic;human arm;7-DOF kinematic chain;automatic graphic animation;collision-free grasping;collision-free manipulation;collision-free motions;rigid objects;6-DOF PUMA arm;3D workspace;Path planning;Computer science;Space exploration;Algorithm design and analysis;Humans;Animation;Robotic assembly;Buildings;Tree graphs;Kinematics},
  url       = {https://ieeexplore.ieee.org/document/844730},
}

@Article{Hoffmann2001,
  author   = {Hoffmann, J\"org and Nebel, Bernhard},
  journal  = {Journal of Artificial Intelligence Research},
  title    = {The {FF} planning system: {Fast} plan generation through heuristic search},
  year     = {2001},
  month    = may,
  volume   = {14},
  abstract = {We describe and evaluate the algorithmic techniques that are used in the FF planning system. Like the HSP system, FF relies on forward state space search, using a heuristic that estimates goal distances by ignoring delete lists. Unlike HSP's heuristic, our method does not assume facts to be independent. We introduce a novel search strategy that combines hill-climbing with systematic search, and we show how other powerful heuristic information can be extracted and used to prune the search space. FF was the most successful automatic planner at the recent AIPS-2000 planning competition. We review the results of the competition, give data for other benchmark domains, and investigate the reasons for the runtime performance of FF compared to HSP.},
  doi      = {10.1613/jair.855},
  file     = {:FILES/2001 - Hoffmann2001 - The FF planning system- Fast plan generation through heuristic search.pdf:PDF},
  groups   = {motion planning},
  url      = {https://www.jair.org/index.php/jair/article/view/10276},
}

@Article{Wang2017,
  author   = {Quan Wang and Zhendong Mao and Bin Wang and Li Guo},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  title    = {Knowledge graph embedding: {A} survey of approaches and applications},
  year     = {2017},
  issn     = {1558-2191},
  month    = {Dec},
  number   = {12},
  pages    = {2724-2743},
  volume   = {29},
  abstract = {Knowledge graph (KG) embedding is to embed components of a KG including entities and relations into continuous vector spaces, so as to simplify the manipulation while preserving the inherent structure of the KG. It can benefit a variety of downstream tasks such as KG completion and relation extraction, and hence has quickly gained massive attention. In this article, we provide a systematic review of existing techniques, including not only the state-of-the-arts but also those with latest trends. Particularly, we make the review based on the type of information used in the embedding task. Techniques that conduct embedding using only facts observed in the KG are first introduced. We describe the overall framework, specific model design, typical training procedures, as well as pros and cons of such techniques. After that, we discuss techniques that further incorporate additional information besides facts. We focus specifically on the use of entity types, relation paths, textual descriptions, and logical rules. Finally, we briefly introduce how KG embedding can be applied to and benefit a wide variety of downstream tasks such as KG completion, relation extraction, question answering, and so forth.},
  doi      = {10.1109/TKDE.2017.2754499},
  file     = {:FILES/2017 - Wang2017 - Knowledge graph embedding- A survey of approaches and applications.pdf:PDF},
  groups   = {representation},
  keywords = {graph theory;learning (artificial intelligence);knowledge graph embedding;KG embedding;relation extraction;KG completion;continuous vector spaces;Statistical analysis;Knowledge discovery;Graphical models;Matrix decomposition;Systematics;Market research;Semantics;Statistical relational learning;knowledge graph embedding;latent factor models;tensor/matrix factorization models},
  url      = {https://ieeexplore.ieee.org/document/8047276},
}

@InProceedings{Li2019kg,
  author     = {Li, Ruiping and Cheng, Xiang},
  booktitle  = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  title      = {{DIVINE}: {A} generative adversarial imitation learning framework for knowledge graph reasoning},
  year       = {2019},
  address    = {Hong Kong, China},
  month      = nov,
  pages      = {2642--2651},
  publisher  = {Association for Computational Linguistics},
  abstract   = {Knowledge graphs (KGs) often suffer from sparseness and incompleteness. Knowledge graph reasoning provides a feasible way to address such problems. Recent studies on knowledge graph reasoning have shown that reinforcement learning (RL) based methods can provide state-of-the-art performance. However, existing RL-based methods require numerous trials for path-finding and rely heavily on meticulous reward engineering to fit specific dataset, which is inefficient and laborious to apply to fast-evolving KGs. To this end, in this paper, we present DIVINE, a novel plug-and-play framework based on generative adversarial imitation learning for enhancing existing RL-based methods. DIVINE guides the path-finding process, and learns reasoning policies and reward functions self-adaptively through imitating the demonstrations automatically sampled from KGs. Experimental results on two benchmark datasets show that our framework improves the performance of existing RL-based methods while eliminating extra reward engineering.},
  comment    = {见Excel},
  doi        = {10.18653/v1/D19-1266},
  file       = {:FILES/2019 - Li2019kg - DIVINE- A generative adversarial imitation learning framework for knowledge graph reasoning.pdf:PDF},
  groups     = {reasoning, imitation learning},
  readstatus = {skimmed},
  url        = {https://www.aclweb.org/anthology/D19-1266},
}

@Article{Hussein2017,
  author     = {Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
  journal    = {ACM Computing Surveys},
  title      = {Imitation learning: {A} survey of learning methods},
  year       = {2017},
  issn       = {0360-0300},
  month      = apr,
  number     = {2},
  volume     = {50},
  abstract   = {Imitation learning techniques aim to mimic human behavior in a given task. An agent (a learning machine) is trained to perform a task from demonstrations by learning a mapping between observations and actions. The idea of teaching by imitation has been around for many years; however, the field is gaining attention recently due to advances in computing and sensing as well as rising demand for intelligent applications. The paradigm of learning by imitation is gaining popularity because it facilitates teaching complex tasks with minimal expert knowledge of the tasks. Generic imitation learning methods could potentially reduce the problem of teaching a task to that of providing demonstrations, without the need for explicit programming or designing reward functions specific to the task. Modern sensors are able to collect and transmit high volumes of data rapidly, and processors with high computational power allow fast processing that maps the sensory data to actions in a timely manner. This opens the door for many potential AI applications that require real-time perception and reaction such as humanoid robots, self-driving vehicles, human computer interaction, and computer games, to name a few. However, specialized algorithms are needed to effectively and robustly learn models as learning by imitation poses its own set of challenges. In this article, we survey imitation learning methods and present design options in different steps of the learning process. We introduce a background and motivation for the field as well as highlight challenges specific to the imitation problem. Methods for designing and evaluating imitation learning tasks are categorized and reviewed. Special attention is given to learning methods in robotics and games as these domains are the most popular in the literature and provide a wide array of problems and methodologies. We extensively discuss combining imitation learning approaches using different sources and methods, as well as incorporating other motion learning methods to enhance imitation. We also discuss the potential impact on industry, present major applications, and highlight current and future research directions.},
  address    = {New York, NY, USA},
  articleno  = {21},
  doi        = {10.1145/3054912},
  file       = {:FILES/2017 - Hussein2017 - Imitation learning- A survey of learning methods.pdf:PDF},
  groups     = {imitation learning},
  issue_date = {June 2017},
  keywords   = {self-improvement, feature representations, robotics, reinforcement learning, deep learning, intelligent agents, Imitation learning, learning from experience, learning from demonstrations},
  numpages   = {35},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3054912},
}

@Article{Wu2019,
  author        = {Tianxing Wu and Arijit Khan and Huan Gao and Cheng Li},
  journal       = {CoRR},
  title         = {Efficiently embedding dynamic knowledge graphs},
  year          = {2019},
  volume        = {abs/1910.06708},
  abstract      = {Knowledge graph (KG) embedding encodes the entities and relations from a KG into low-dimensional vector spaces to support various applications such as KG completion, question answering, and recommender systems. In real world, knowledge graphs (KGs) are dynamic and evolve over time with addition or deletion of triples. However, most existing models focus on embedding static KGs while neglecting dynamics. To adapt to the changes in a KG, these models need to be re-trained on the whole KG with a high time cost.
In this paper, to tackle the aforementioned problem, we propose a new context-aware Dynamic Knowledge Graph Embedding (DKGE) method which supports the embedding learning in an online fashion. DKGE introduces two different representations (i.e., knowledge embedding and contextual element embedding) for each entity and each relation, in the joint modeling of entities and relations as well as their contexts, by employing two attentive graph convolutional networks, a gate strategy, and translation operations. This effectively helps limit the impacts of a KG update in certain regions, not in the entire graph, so that DKGE can rapidly acquire the updated KG embedding by a proposed online learning algorithm. Furthermore, DKGE can also learn KG embedding from scratch. Experiments on the tasks of link prediction and question answering in a dynamic environment demonstrate the effectiveness and efficiency of DKGE.},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1910-06708.bib},
  comment       = {见Excel，讨论存在变化时，如何retrain model，思路是基于puTransE，对变化节点及其neighbor，分别训练一个关于节点和关于边的NN，最后进行整合，从而保证projection的准确性，即h+r=t},
  eprint        = {1910.06708},
  file          = {:FILES/2019 - Wu2019 - Efficiently embedding dynamic knowledge graphs.pdf:PDF},
  groups        = {representation, dynamic KG},
  timestamp     = {Wed, 16 Oct 2019 16:25:53 +0200},
  url           = {http://arxiv.org/abs/1910.06708},
}

@InProceedings{Trivedi2017,
  author    = {Rakshit Trivedi and Hanjun Dai and Yichen Wang and Le Song},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  title     = {{Know-Evolve}: {Deep} temporal reasoning for dynamic knowledge graphs},
  year      = {2017},
  address   = {International Convention Centre, Sydney, Australia},
  editor    = {Doina Precup and Yee Whye Teh},
  month     = {06--11 Aug},
  pages     = {3462--3471},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {70},
  abstract  = {The availability of large scale event data with time stamps has given rise to dynamically evolving knowledge graphs that contain temporal information for each edge. Reasoning over time in such dynamic knowledge graphs is not yet well understood. To this end, we present Know-Evolve, a novel deep evolutionary knowledge network that learns non-linearly evolving entity representations over time. The occurrence of a fact (edge) is modeled as a multivariate point process whose intensity function is modulated by the score for that fact computed based on the learned entity embeddings. We demonstrate significantly improved performance over various relational learning approaches on two large scale real-world datasets. Further, our method effectively predicts occurrence or recurrence time of a fact which is novel compared to prior reasoning approaches in multi-relational setting.},
  file      = {:FILES/2017 - Trivedi2017 - Know-Evolve- Deep temporal reasoning for dynamic knowledge graphs.pdf:PDF},
  groups    = {representation},
  url       = {http://proceedings.mlr.press/v70/trivedi17a.html},
}

@InProceedings{Deng2020,
  author     = {Deng, Songgaojun and Rangwala, Huzefa and Ning, Yue},
  booktitle  = {Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  title      = {Dynamic knowledge graph based multi-event forecasting},
  year       = {2020},
  address    = {New York, NY, USA},
  pages      = {1585–1595},
  publisher  = {Association for Computing Machinery},
  series     = {KDD '20},
  abstract   = {Modeling concurrent events of multiple types and their involved actors from open-source social sensors is an important task for many domains such as health care, disaster relief, and financial analysis. Forecasting events in the future can help human analysts better understand global social dynamics and make quick and accurate decisions. Anticipating participants or actors who may be involved in these activities can also help stakeholders to better respond to unexpected events. However, achieving these goals is challenging due to several factors: (i) it is hard to filter relevant information from large-scale input, (ii) the input data is usually high dimensional, unstructured, and Non-IID (Non-independent and identically distributed) and (iii) associated text features are dynamic and vary over time. Recently, graph neural networks have demonstrated strengths in learning complex and relational data. In this paper, we study a temporal graph learning method with heterogeneous data fusion for predicting concurrent events of multiple types and inferring multiple candidate actors simultaneously. In order to capture temporal information from historical data, we propose Glean, a graph learning framework based on event knowledge graphs to incorporate both relational and word contexts. We present a context-aware embedding fusion module to enrich hidden features for event actors. We conducted extensive experiments on multiple real-world datasets and show that the proposed method is competitive against various state-of-the-art methods for social event prediction and also provides much-need interpretation capabilities.},
  comment    = {见Excel，用于人机协同disassembly，框架性创新，技术上没有体现。},
  doi        = {10.1145/3394486.3403209},
  file       = {:FILES/2020 - Deng2020 - Dynamic knowledge graph based multi-event forecasting.pdf:PDF},
  groups     = {dynamic KG},
  isbn       = {9781450379984},
  keywords   = {multi-event forecasting, knowledge graphs, word graphs},
  location   = {Virtual Event, CA, USA},
  numpages   = {11},
  readstatus = {read},
  url        = {https://doi.org/10.1145/3394486.3403209},
}

@Article{Ding2019,
  author    = {Yiwen Ding and Wenjun Xu and Zhihao Liu and Zude Zhou and Duc Truong Pham},
  journal   = {Procedia CIRP},
  title     = {Robotic task oriented knowledge graph for human-robot collaboration in disassembly},
  year      = {2019},
  issn      = {2212-8271},
  note      = {11th CIRP Conference on Industrial Product-Service Systems},
  pages     = {105--110},
  volume    = {83},
  abstract  = {Traditional disassembly methods, such as manual and robotic disassembly, are no longer competent for the requirement of the complexity of the disassembly product. Therefore, the human-robot collaboration concept can be introduced to realize a novel disassembly system, towards increasing the flexibility and adaptability of them. In order to facilitate the efficient and smooth human-robot collaboration in disassembly, it is necessary to make the disassembly system more intelligent. In this paper, a robotic knowledge graph is proposed to provide an assistant for those who lack the relevant knowledge to complete the disassembly task. By natural language processing method, this paper extracts entities and relationships from the disassembly data to build a knowledge base in the form of knowledge graph. Combining graph-based knowledge representation, a prototype system is developed for human to acquire, analyze and manage the disassembly knowledge. Finally, a case study demonstrates that the proposed robotic knowledge graph has savings in terms of disassembly time, idle time and human workload, and it can be applied to assist human operator in disassembly by providing human and robots with various kinds of the needed knowledge.},
  doi       = {10.1016/j.procir.2019.03.121},
  file      = {:FILES/2019 - Ding2019 - Robotic Task Oriented Knowledge Graph for Human-Robot Collaboration in Disassembly.pdf:PDF},
  groups    = {robot},
  keywords  = {human-robot collaboration, product disassembly, knowledge graph, knowledge base},
  timestamp = {2021-03-12},
  url       = {http://www.sciencedirect.com/science/article/pii/S2212827119304263},
}

@InProceedings{Wang2019robotKG,
  author    = {Shuai Wang and Yu Zhang and Zhiyong Liao},
  booktitle = {Proceedings of the 3rd International Conference on Computer Engineering, Information Science \& Application Technology (ICCIA 2019)},
  title     = {Review on the knowledge graph in robotics domain},
  year      = {2019},
  pages     = {424--431},
  publisher = {Atlantis Press},
  series    = {Advances in Computer Science Research},
  comment   = {见Excel，价值不大。},
  doi       = {https://doi.org/10.2991/iccia-19.2019.65},
  file      = {:FILES/2019 - Wang2019robotKG - Review on the knowledge graph in robotics domain.pdf:PDF},
  groups    = {robot},
  isbn      = {978-94-6252-760-7},
  issn      = {2352-538X},
  url       = {https://doi.org/10.2991/iccia-19.2019.65},
}

@Misc{Liu2020KG,
  author        = {Zhiyu Liu and Meng Jiang and Hai Lin},
  title         = {A graph-based spatial temporal logic for knowledge representation and automated reasoning in cognitive robots},
  year          = {2020},
  archiveprefix = {arXiv},
  comment       = {见Excel，也是基于规则（logics）的推理，其知识图谱描述了节点的时间和空间信息，是基于graph的，},
  eprint        = {2001.07205},
  file          = {:FILES/2020 - Liu2020KG - A graph-based spatial temporal logic for knowledge representation and automated reasoning in cognitive robots.pdf:PDF},
  groups        = {robot},
  primaryclass  = {cs.LO},
  readstatus    = {skimmed},
}

@Article{Ersen2017,
  author   = {Ersen, Mustafa and Oztop, Erhan and Sariel, Sanem},
  journal  = {IEEE Robotics Automation Magazine},
  title    = {Cognition-enabled robot manipulation in human environments: {Requirements}, recent work, and open problems},
  year     = {2017},
  issn     = {1558-223X},
  month    = sep,
  number   = {3},
  pages    = {108--122},
  volume   = {24},
  abstract = {Service robots are expected to play an important role in our daily lives as our companions in home and work environments in the near future. An important requirement for fulfilling this expectation is to equip robots with skills to perform everyday manipulation tasks, the success of which is crucial for most home chores, such as cooking, cleaning, and shopping. Robots have been used successfully for manipulation tasks in wellstructured and controlled factory environments for decades. Designing skills for robots working in uncontrolled human environments raises many potential challenges in various subdisciplines, such as computer vision, automated planning, and human-robot interaction. In spite of the recent progress in these fields, there are still challenges to tackle. This article outlines problems in different research areas related to mobile manipulation from the cognitive perspective, reviews recently published works and the state-of-the-art approaches to address these problems, and discusses open problems to be solved to realize robot assistants that can be used in manipulation tasks in unstructured human environments.},
  doi      = {10.1109/MRA.2016.2616538},
  file     = {:FILES/2017 - Ersen2017 - Cognition-enabled robot manipulation in human environments- Requirements, recent work, and open problems.pdf:PDF},
  groups   = {robots},
  keywords = {cognition;manipulators;mobile robots;service robots;cognition-enabled robot manipulation;human environments;service robots;mobile manipulation;robot assistants;Robot sensing systems;Cognition;Service robots;Human factors;Knowledge based systems;Assistive technologies},
  url      = {https://ieeexplore.ieee.org/document/7894169},
}

@TechReport{Saxena2015,
  author      = {Ashutosh Saxena and Ashesh Jain and Ozan Sener and Aditya Jami and Dipendra K. Misra and Hema S. Koppula},
  institution = {Cornell University},
  title       = {{RoboBrain}: {Large-scale} knowledge engine for robots},
  year        = {2015},
  note        = {International Symposium on Robotics Research (ISRR)},
  comment     = {机器人相关KG，平台，采用属性图存储形式，知识规模较大，推理采用图结构遍历的方式},
  eprint      = {1412.0691},
  file        = {:FILES/2015 - Saxena2015 - RoboBrain- Large-scale knowledge engine for robots.pdf:PDF},
  groups      = {robot, 知识库调研报告},
  readstatus  = {read},
  url         = {https://arxiv.org/abs/1412.0691},
}

@Article{Sheth2019,
  author     = {Amit Sheth and Swati Padhee and Amelie Gyrard},
  journal    = {IEEE Internet Computing},
  title      = {Knowledge graphs and knowledge networks: {The} story in brief},
  year       = {2019},
  issn       = {1941-0131},
  month      = jul,
  number     = {4},
  pages      = {67--75},
  volume     = {23},
  abstract   = {Knowledge Graphs (KGs) represent real-world noisy raw information in a structured form, capturing relationships between entities. However, for dynamic real-world applications such as social networks, recommender systems, computational biology, relational knowledge representation has emerged as a challenging research problem where there is a need to represent the changing nodes, attributes, and edges over time. The evolution of search engine responses to user queries in the last few years is partly because of the role of KGs such as Google KG. KGs are significantly contributing to various AI applications from link prediction, entity relations prediction, node classification to recommendation and question answering systems. This article is an attempt to summarize the journey of KG for AI.},
  comment    = {见Excel，类似于评论文章，没用},
  doi        = {10.1109/MIC.2019.2928449},
  file       = {:FILES/2019 - Sheth2019 - Knowledge graphs and knowledge networks- the story in brief.pdf:PDF},
  groups     = {knowledge graph},
  keywords   = {graph theory;knowledge representation;query processing;question answering (information retrieval);recommender systems;search engines;social networking (online);knowledge networks;KGs;real-world noisy raw information;structured form;social networks;recommender systems;computational biology;relational knowledge representation;search engine responses;AI applications;entity relations prediction;question answering systems;knowledge graphs;link prediction;node classification;Photonic crystal fibers;Optical fiber losses;Propagation losses;Optical polarization;Network theory (graphs)},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/document/8874979},
}

@Article{Paulius2019,
  author     = {David Paulius and Yu Sun},
  journal    = {Robotics and Autonomous Systems},
  title      = {A survey of knowledge representation in service robotics},
  year       = {2019},
  issn       = {0921-8890},
  pages      = {13--30},
  volume     = {118},
  abstract   = {Within the realm of service robotics, researchers have placed a great amount of effort into learning, understanding, and representing motions as manipulations for task execution by robots. The task of robot learning and problem-solving is very broad, as it integrates a variety of tasks such as object detection, activity recognition, task/motion planning, localization, knowledge representation and retrieval, and the intertwining of perception/vision and machine learning techniques. In this paper, we solely focus on knowledge representations and notably how knowledge is typically gathered, represented, and reproduced to solve problems as done by researchers in the past decades. In accordance with the definition of knowledge representations, we discuss the key distinction between such representations and useful learning models that have extensively been introduced and studied in recent years, such as machine learning, deep learning, probabilistic modeling, and semantic graphical structures. Along with an overview of such tools, we discuss the problems which have existed in robot learning and how they have been built and used as solutions, technologies or developments (if any) which have contributed to solving them. Finally, we discuss key principles that should be considered when designing an effective knowledge representation.},
  doi        = {10.1016/j.robot.2019.03.005},
  file       = {:FILES/2019 - Paulius2019 - A survey of knowledge representation in service robotics.pdf:PDF},
  groups     = {representation, robot, 知识库调研报告},
  keywords   = {Knowledge representation, Robot learning, Task planning, Domestic robots, Service robotics, read},
  readstatus = {read},
  url        = {http://www.sciencedirect.com/science/article/pii/S0921889018303506},
}

@PhdThesis{Jain2016,
  author = {Jain, Ashesh},
  school = {Cornell University},
  title  = {Learning from natural human interactions for assistive robots},
  year   = {2016},
  month  = may,
  file   = {:FILES/2016 - Jain2016 - Learning from natural human interactions for assistive robots.pdf:PDF},
  groups = {knowledge graph},
  url    = {http://asheshjain.org/pdfs/AsheshJainPhdThesis.pdf},
}

@Article{Schaal1999,
  author   = {Stefan Schaal},
  journal  = {Trends in Cognitive Sciences},
  title    = {Is imitation learning the route to humanoid robots?},
  year     = {1999},
  issn     = {1364-6613},
  number   = {6},
  pages    = {233--242},
  volume   = {3},
  abstract = {This review investigates two recent developments in artificial intelligence and neural computation: learning from imitation and the development of humanoid robots. It is postulated that the study of imitation learning offers a promising route to gain new insights into mechanisms of perceptual motor control that could ultimately lead to the creation of autonomous humanoid robots. Imitation learning focuses on three important issues: efficient motor learning, the connection between action and perception, and modular motor control in the form of movement primitives. It is reviewed here how research on representations of, and functional connections between, action and perception have contributed to our understanding of motor acts of other beings. The recent discovery that some areas in the primate brain are active during both movement perception and execution has provided a hypothetical neural basis of imitation. Computational approaches to imitation learning are also described, initially from the perspective of traditional AI and robotics, but also from the perspective of neural network models and statistical-learning research. Parallels and differences between biological and computational approaches to imitation are highlighted and an overview of current projects that actually employ imitation learning for humanoid robots is given.},
  doi      = {https://doi.org/10.1016/S1364-6613(99)01327-3},
  file     = {:FILES/1999 - Schaal1999 - Is imitation learning the route to humanoid robots.pdf:PDF},
  groups   = {robots},
  keywords = {Motor control, Learning, Imitation, Humanoid robot, Action-perception coupling, Mirror neurons},
  url      = {http://www.sciencedirect.com/science/article/pii/S1364661399013273},
}

@Article{Zhu2020KG,
  author   = {Lin Zhu and Nan Li and Luyi Bai and Yunqing Gong and Yizong Xing},
  journal  = {IEEE Access},
  title    = {{stRDFS}: {Spatiotemporal} knowledge graph modeling},
  year     = {2020},
  issn     = {2169-3536},
  pages    = {129043--129057},
  volume   = {8},
  abstract = {In Semantic Web, modeling knowledge graph based on RDF becomes more and more popular. There is quite a lot of spatiotemporal information in Semantic Web, and recent works focus on not only general data but also spatiotemporal data. Existing efforts are mainly to add spatiotemporal labels to RDF, which expand RDF triple into quad or quintuple. However, extra labels often cause additional overhead for the system and lead to inefficient information organization management. In order to overcome this limitation, we propose an stRDFS model by labeling properties with spatiotemporal features and the corresponding determination methods of topological relations among different spatiotemporal entities. stRDFS considers spatiotemporal attribute as a part of the RDF model, which can record spatiotemporal information without changing the current RDF standard. Our approach improves the ability of recording and linking spatiotemporal data. More importantly, depending on formatting of spatiotemporal attributes in stRDFS, it will improve the semantic inferring ability, and the users are not required to be familiar with the underlying representations of spatiotemporal data.},
  doi      = {10.1109/ACCESS.2020.3008688},
  file     = {:FILES/2020 - Zhu2020KG - stRDFS- Spatiotemporal knowledge graph modeling.pdf:PDF},
  groups   = {representation},
  keywords = {graph theory;semantic Web;spatiotemporal attribute;spatiotemporal information;current RDF standard;linking spatiotemporal data;semantic inferring ability;spatiotemporal knowledge graph modeling;Semantic Web;general data;spatiotemporal labels;RDF triple;inefficient information organization management;stRDFS model;spatiotemporal features;spatiotemporal entities;Spatiotemporal phenomena;Resource description framework;Data models;Standards;Tools;Object oriented modeling;Knowledge graph;spatiotemporal data;stRDFS},
}

@Misc{Ji2021,
  author        = {Shaoxiong Ji and Shirui Pan and Erik Cambria and Pekka Marttinen and Philip S. Yu},
  title         = {A survey on knowledge graphs: {Representation}, acquisition and applications},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2002.00388},
  file          = {:FILES/2021 - Ji2021 - A survey on knowledge graphs- Representation, acquisition and applications.pdf:PDF},
  groups        = {knowledge graph},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2002.00388},
}

@Article{Tenorth2013,
  author     = {Moritz Tenorth and Michael Beetz},
  journal    = {The International Journal of Robotics Research},
  title      = {{KnowRob}: {A} knowledge processing infrastructure for cognition-enabled robots},
  year       = {2013},
  month      = may,
  note       = {\#70},
  number     = {5},
  pages      = {566--590},
  volume     = {32},
  abstract   = {Autonomous service robots will have to understand vaguely described tasks, such as “set the table” or “clean up”. Performing such tasks as intended requires robots to fully, precisely, and appropriately parameterize their low-level control programs. We propose knowledge processing as a computational resource for enabling robots to bridge the gap between vague task descriptions and the detailed information needed to actually perform those tasks in the intended way. In this article, we introduce the KnowRobknowledge processing system that is specifically designed to provide autonomous robots with the knowledge needed for performing everyday manipulation tasks. The system allows the realization of “virtual knowledge bases”: collections of knowledge pieces that are not explicitly represented but computed on demand from the robot’s internal data structures, its perception system, or external sources of information. This article gives an overview of the different kinds of knowledge, the different inference mechanisms, and interfaces for acquiring knowledge from external sources, such as the robot’s perception system, observations of human activities, Web sites on the Internet, as well as Web-based knowledge bases for information exchange between robots. We evaluate the system’s scalability and present different integrated experiments that show its versatility and comprehensiveness.},
  comment    = {机器人相关知识库平台，目前影响力最高的知识库平台，定义了Robots、Object、Task、Situational以及可扩展的知识框架，表达丰富，易扩展},
  doi        = {10.1177/0278364913481635},
  file       = {:FILES/2013 - Tenorth2013 - KnowRob- A knowledge processing infrastructure for cognition-enabled robots.pdf:PDF},
  groups     = {robot},
  publisher  = {IEEE},
  readstatus = {read},
  url        = {https://journals.sagepub.com/doi/abs/10.1177/0278364913481635#articleCitationDownloadContainer},
}

@InProceedings{Beetz2010,
  author     = {Michael Beetz and Lorenz M\"{o}senlechner and Moritz Tenorth},
  booktitle  = {2010 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  title      = {{CRAM} -- {A} cognitive robot abstract machine for everyday manipulation in human environments},
  year       = {2010},
  month      = {Oct},
  pages      = {1012--1017},
  abstract   = {This paper describes CRAM (Cognitive Robot Abstract Machine) as a software toolbox for the design, the implementation, and the deployment of cognition-enabled autonomous robots performing everyday manipulation activities. CRAM equips autonomous robots with lightweight reasoning mechanisms that can infer control decisions rather than requiring the decisions to be preprogrammed. This way CRAM-programmed autonomous robots are much more flexible, reliable, and general than control programs that lack such cognitive capabilities. CRAM does not require the whole domain to be stated explicitly in an abstract knowledge base. Rather, it grounds symbolic expressions in the knowledge representation into the perception and actuation routines and into the essential data structures of the control programs. In the accompanying video, we show complex mobile manipulation tasks performed by our household robot that were realized using the CRAM infrastructure.},
  comment    = {KG platform for robot,},
  doi        = {10.1109/IROS.2010.5650146},
  file       = {:FILES/2010 - Beetz2010 - CRAM -- A cognitive robot abstract machine for everyday manipulation in human environments.pdf:PDF},
  groups     = {robot, task understanding},
  issn       = {2153-0866},
  keywords   = {cognitive systems;knowledge representation;manipulators;mobile robots;program compilers;robot programming;symbol manipulation;cognitive robot abstract machine;human environment;software toolbox;cognition enabled autonomous robots;lightweight reasoning mechanism;infer control decision;CRAM programmed autonomous robots;cognitive capability;abstract knowledge base;symbolic expression;knowledge representation;control programs;complex mobile manipulation activity;household robot;Cognition;Computer architecture;Robot control;Robot sensing systems;Kernel;Trajectory},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/5650146},
}

@PhdThesis{Moesenlechner2016,
  author = {Lorenz M\"{o}senlechner},
  school = {Technische Universit\"{a}T M\"{u}nchen},
  title  = {The cognitive robot abstract machine: {A} framework for cognitive robotics},
  year   = {2016},
  month  = feb,
  type   = {phdthesis},
  file   = {:FILES/2016 - Moesenlechner2016 - The cognitive robot abstract machine A framework for cognitive robotics.pdf:PDF},
  groups = {robot},
}

@PhdThesis{Tenorth2011,
  author = {Moritz M. Tenorth},
  school = {Technische Universit\"{a}T M\"{u}nchen},
  title  = {Knowledge processing for autonomous robots},
  year   = {2011},
  month  = nov,
  type   = {phdthesis},
  file   = {:FILES/2011 - Tenorth2011 - Knowledge processing for autonomous robots.pdf:PDF},
  groups = {robot},
}

@Article{Winkler2014,
  author  = {Jan Winkler and Moritz Tenorth and Asil Bozcuo\v{g}lu and Michael Beetz},
  journal = {Advances in Cognitive Systems},
  title   = {{CRAM}\textsubscript{m} -- {Memories} for everyday robotic manipulation activities},
  year    = {2014},
  month   = jul,
  pages   = {47--66},
  volume  = {3},
  file    = {:FILES/2014 - Winkler2014 - CRAMm -- Memories for everyday robotic manipulation activities.pdf:PDF},
  groups  = {robot, 知识库调研报告},
  url     = {http://www.cogsys.org/journal/volume-3},
}

@Article{Wang2020robot,
  author   = {Zhongli Wang and Guohui Tian and Xuyang Shao},
  journal  = {Knowledge-Based Systems},
  title    = {Home service robot task planning using semantic knowledge and probabilistic inference},
  year     = {2020},
  issn     = {0950-7051},
  pages    = {106174},
  volume   = {204},
  abstract = {In the face of unstructured home environment, home service robots are inevitably confronted with uncertainty and incompleteness of environment information. How to make the home service robot obtain enough environment information and plan a discrete sequence of actions through task planning is the key problem of robot intelligence. In this paper, a hierarchical task network based on semantic knowledge and probabilistic inference method is proposed. We use the object location ontology, the location relation between dynamic and static objects to build semantic knowledge of home environment, and build the probability model between dynamic and static objects, as well as between static objects and home scenes. The location of the object is determined by the semantic knowledge and the probability model. Hierarchical task network is selected as an engine of task planner, which can be provided with the location information to improve the autonomy and effectiveness of robot task planning. In order to prevent task execution failure and enhance the adaptability of robot to unstructured home environment, a mechanism of task execution diagnosis and replanning is designed. Experimental results in simulation and real home environment demonstrate that our method can effectively improve the performance of service robot task planning and generate better task execution sequence.},
  doi      = {10.1016/j.knosys.2020.106174},
  file     = {:FILES/2020 - Wang2020robot - Home service robot task planning using semantic knowledge and pro inference.pdf:PDF},
  groups   = {knowledge graph, robot},
  keywords = {Task planning, Home environment, Semantic knowledge, Probabilistic inference, Hierarchical task network, Task execution diagnosis},
  url      = {http://www.sciencedirect.com/science/article/pii/S0950705120304093},
}

@Article{MohseniKabir2020,
  author  = {Anahita {Mohseni-Kabir} and Manuela {Veloso} and Maxim {Likhachev}},
  journal = {Proceedings of the International Conference on Automated Planning and Scheduling},
  title   = {Efficient robot planning for achieving multiple independent partially observable tasks that evolve over time},
  year    = {2020},
  pages   = {202--211},
  volume  = {30},
  file    = {:FILES/2020 - MohseniKabir2020 - Efficient Robot Planning for Achieving MultipleIndependent Partially Observable Tasks That Evolve over Time.pdf:PDF},
  groups  = {motion planning},
  url     = {https://academic.microsoft.com/paper/3037364072/related/search?q=Efficient Robot Planning for Achieving Multiple Independent Partially Observable Tasks That Evolve over Time&qe=Or(Id%3D2947242251%2CId%3D2987879486%2CId%3D2606859755%2CId%3D2961713522%2CId%3D2140471031%2CId%3D2111312002%2CId%3D2966885078%2CId%3D2767338161%2CId%3D2013511016%2CId%3D1592089241%2CId%3D2615739689%2CId%3D2565402511%2CId%3D622931714%2CId%3D2017332349%2CId%3D1575707588%2CId%3D2128635427%2CId%3D3106159194%2CId%3D1490584238%2CId%3D2297635611%2CId%3D2555502398)&f=&orderBy=0},
}

@Article{Gao2020KG,
  author   = {Yunjun Gao and Tianming Zhang and Linshan Qiu and Qingyuan Linghu and Gang Chen},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  title    = {Time-respecting flow graph pattern matching on temporal graphs},
  year     = {2020},
  issn     = {1558-2191},
  pages    = {1--1},
  abstract = {Graph pattern matching has been extensively investigated on general graphs without time information over decades. Nevertheless, few studies focus on temporal graphs, where a relationship between two vertices takes place at a specific moment and lingers for some time. In this paper, we propose a new notion so-called time-respecting flow graph, in which all paths are time-respecting (i.e., a sequence of contacts with non-decreasing time), and one vertex is distinguished as the root, from which other vertices can be reached via a time-respecting path. Based on this, we explore the problem of time-respecting flow graph pattern matching on temporal graphs. This problem motivates important applications in epidemiology, information diffusion, crime detection, etc. To address it, we present one baseline algorithm as well as two optimized algorithms that utilize several efficient matching strategies and topological sort based technique to boost efficiency. Extensive experimental evaluation using both real and synthetic data sets demonstrates the effectiveness and efficiency of our proposed algorithms. Compared with baseline method, our optimized algorithms could achieve up to three orders of magnitude speedup.},
  doi      = {10.1109/TKDE.2020.2968901},
  file     = {:FILES/2020 - Gao2020KG - Time-respecting flow graph pattern matching on temporal graphs.pdf:PDF},
  groups   = {dynamic KG},
  keywords = {Pattern matching;Computational modeling;Diseases;Topology;Schedules;Flow graphs;Software algorithms;Temporal Graph;Pattern Matching;Graph Mining;Algorithm},
  url      = {https://ieeexplore.ieee.org/document/8967169},
}

@Article{Zhang2020dcnnKG,
  author   = {Zhaoli Zhang and Zhifei Li and Hai Liu and Neal N. Xiong},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  title    = {Multi-scale dynamic convolutional network for knowledge graph embedding},
  year     = {2020},
  issn     = {1558-2191},
  pages    = {1--1},
  abstract = {Knowledge graphs are large graph-structured knowledge bases with incomplete or partial information. Numerous studies have focused on knowledge graph embedding to identify the embedded representation of entities and relations, thereby predicting missing relations between entities. Previous embedding models primarily regard (subject entity, relation, and object entity) triplet as translational distance or semantic matching in vector space. However, these models only learn a few expressive features and hard to handle complex relations, i.e., 1-to-N, N-to-1, and N-to-N, in knowledge graphs. To overcome these issues, we introduce a multi-scale dynamic convolutional network (M-DCN) model for knowledge graph embedding. This model features topnotch performance and an ability to generate richer and more expressive feature embeddings than its counterparts. The subject entity and relation embeddings in M-DCN are composed in an alternating pattern in the input layer, which helps extract additional feature interactions and increase the expressiveness. Multi-scale lters are generated in the convolution layer to learn different characteristics among input embeddings. Specically, the weights of these lters are dynamically related to each relation to model complex relations. The performance of M-DCN on the ve benchmark datasets is tested via experiments. Results show that the model can effectively handle complex relations and achieve state-of-the-art link prediction results on most evaluation metrics.},
  doi      = {10.1109/TKDE.2020.3005952},
  file     = {:FILES/2020 - Zhang2020dcnnKG - Multi-scale dynamic convolutional network for knowledge graph embedding.pdf:PDF},
  groups   = {dynamic KG},
  keywords = {Computational modeling;Convolution;Semantics;Predictive models;Feature extraction;Knowledge engineering;Computer architecture;knowledge graphs;knowledge graph embedding;complex relations;link prediction;convolutional network},
  url      = {https://ieeexplore.ieee.org/document/9130149},
}

@Article{Gu2020,
  author   = {Yu Gu and Kaiqiang Yu and Zhen Song and Jianzhong Qi and Zhigang Wang and Ge Yu and Rui Zhang},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  title    = {Distributed hypergraph processing using intersection graphs},
  year     = {2020},
  issn     = {1558-2191},
  pages    = {1--1},
  abstract = {The advent of online applications such as social networks has led to an unprecedented scale of data and complex relationships among data. Hypergraphs are introduced to represent complex relationships that may involve more than two entities. A hypergraph is a generalized form of a graph, where edges are generalized to hyperedges. Each hyperedge may consist of any number of vertices. The flexibility of hyperedges also brings challenges in distributed hypergraph processing. In particular, a hypergraph is more difficult to be partitioned and distributed among k workers with balanced partitions. In this paper, we propose to convert a hypergraph into an intersection graph before partitioning by leveraging the inherent shared relationships among hypergraphs. We explore the intersection graph construction method and the corresponding partition strategy which can achieve the goal of evenly distributing vertices and hyperedges across workers, while yielding a significant communication reduction. We also design a distributed processing framework named Hyraph that can directly run hypergraph analysis algorithms on our intersection graphs. Experimental results on real datasets confirm the effectiveness of our techniques and the efficiency of the Hyraph framework.},
  comment  = {这篇文章是构造了一种hyperedge，即一条边可以有多个顶点，有意思。},
  doi      = {10.1109/TKDE.2020.3022014},
  file     = {:FILES/2020 - Gu2020 - Distributed hypergraph processing using intersection graphs.pdf:PDF},
  groups   = {representation},
  keywords = {Bipartite graph;Distributed databases;Partitioning algorithms;Electronic mail;Heuristic algorithms;Knowledge engineering;Data engineering;Hypergraphs;shared relationships;intersection graphs;distributed processing;graph processing},
  url      = {https://ieeexplore.ieee.org/document/9187569},
}

@Article{Guo2020,
  author   = {Qingyu Guo and Fuzhen Zhuang and Chuan Qin and Hengshu Zhu and Xing Xie and Hui Xiong and Qing He},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  title    = {A survey on knowledge graph-based recommender systems},
  year     = {2020},
  issn     = {1558-2191},
  pages    = {1-1},
  abstract = {To solve the information explosion problem and enhance user experience in various online applications, recommender systems have been developed to model users' preferences. Although numerous efforts have been made toward more personalized recommendations, recommender systems still suffer from several challenges, such as data sparsity and cold-start problems. In recent years, generating recommendations with the knowledge graph as side information has attracted considerable interest. Such an approach can not only alleviate the above mentioned issues for a more accurate recommendation, but also provide explanations for recommended items. In this paper, we conduct a systematical survey of knowledge graph-based recommender systems. We collect recently published papers in this field, and group them into three categories, i.e., embedding-based methods, connection-based methods, and propagation-based methods. Also, we further subdivide each category according to the characteristics of these approaches. Moreover, we investigate the proposed algorithms by focusing on how the papers utilize the knowledge graph for accurate and explainable recommendation. Finally, we propose several potential research directions in this field.},
  doi      = {10.1109/TKDE.2020.3028705},
  file     = {:FILES/2020 - Guo2020 - A survey on knowledge graph-based recommender systems.pdf:PDF},
  groups   = {knowledge graph},
  keywords = {Recommender systems;Motion pictures;Feature extraction;Avatars;Machine learning;Electronic mail;Blood;Knowledge Graph;Recommender System;Explainable Recommendation},
  url      = {https://ieeexplore.ieee.org/document/9216015},
}

@Misc{Pauly2020,
  author        = {Leo Pauly and Wisdom C. Agboh and David C. Hogg and Raul Fuentes},
  title         = {{O2A}: {One-shot} observational learning with action vectors},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {1810.07483},
  file          = {:FILES/2020 - Pauly2020 - O2A - One-shot observational learning with action vectors.pdf:PDF},
  groups        = {imitation learning},
  primaryclass  = {cs.RO},
  url           = {https://arxiv.org/abs/1810.07483},
}

@Misc{xujiying2019,
  author  = {仵冀颍},
  month   = sep,
  title   = {让机器人看一眼就能模仿：{One-Shot}模仿学习发展情况},
  year    = {2019},
  comment = {介绍了三篇文章;
此外，还有知乎帖子：
 https://zhuanlan.zhihu.com/p/25688750},
  groups  = {imitation learning},
  url     = {https://zhuanlan.zhihu.com/p/83774235},
}

@Misc{Huang2019,
  author        = {De-An Huang and Danfei Xu and Yuke Zhu and Animesh Garg and Silvio Savarese and Li Fei-Fei and Juan Carlos Niebles},
  title         = {Continuous relaxation of symbolic planner for one-shot imitation learning},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1908.06769},
  file          = {:FILES/2019 - Huang2019 - Continuous relaxation of symbolic planner for one-shot imitation learning.pdf:PDF},
  groups        = {imitation learning},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/1908.06769},
}

@Article{Fang2021,
  author   = {Yuan Fang and Wenqing Lin and Vincent W. Zheng and Min Wu and Jiaqi Shi and Kevin Chen-Chuan Chang and Xiao-Li Li},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  title    = {Metagraph-based learning on heterogeneous graphs},
  year     = {2021},
  issn     = {1558-2191},
  month    = {Jan},
  number   = {1},
  pages    = {154-168},
  volume   = {33},
  abstract = {Data in the form of graphs are prevalent, ranging from biological and social networks to citation graphs and the Web. In particular, most real-world graphs are heterogeneous, containing objects of multiple types, which present new opportunities for many problems on graphs. Consider a typical proximity search problem on graphs, which boils down to measuring the proximity between two given nodes. Most earlier studies on homogeneous or bipartite graphs only measure a generic form of proximity, without accounting for different “semantic classes”—for instance, on a social network two users can be close for different reasons, such as being classmates or family members, which represent two distinct semantic classes. Learning these semantic classes are made possible on heterogeneous graphs through the concept of metagraphs. In this study, we identify metagraphs as a novel and effective means to characterize the common structures for a desired class of proximity. Subsequently, we propose a family of metagraph-based proximity, and employ a learning-to-rank technique that automatically learns the right parameters to suit the desired semantic class. In terms of efficiency, we develop a symmetry-based matching algorithm to speed up the computation of metagraph instances. Empirically, extensive experiments reveal that our metagraph-based proximity substantially outperforms the best competitor by more than 10 percent, and our matching algorithm can reduce matching time by more than half. As a further generalization, we aim to derive a general node and edge representation for heterogeneous graphs, in order to support arbitrary machine learning tasks beyond proximity search. In particular, we propose the finer-grained anchored metagraph, which is capable of discriminating the roles of nodes within the same metagraph. Finally, further experiments on the general representation show that we can outperform the state of the art significantly and consistently across various machine learning tasks.},
  comment  = {这篇文章是将KG中存在不同类别的节点，或者节点因不同原因而聚类在一起，所以提出了一种metagraph，来表达异构图。},
  doi      = {10.1109/TKDE.2019.2922956},
  file     = {:FILES/2021 - Fang2021 - Metagraph-based learning on heterogeneous graphs.pdf:PDF},
  groups   = {reasoning},
  keywords = {Social networking (online);Semantics;Machine learning;Search problems;Particle measurements;Computational efficiency;Task analysis;Semantic proximity search;meta-structures;graph mining;heterogeneous graph representation},
  url      = {https://ieeexplore.ieee.org/document/8744385},
}

@Article{Sun2019,
  author   = {Guohao Sun and Guanfeng Liu and Yan Wang and Mehmet A. Orgun and Quan Z. Sheng and Xiaofang Zhou},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  title    = {Incremental graph pattern based node matching with multiple updates},
  year     = {2019},
  issn     = {1558-2191},
  pages    = {1--1},
  abstract = {Graph Pattern based Node Matching (GPNM) has been proposed to find all the matches of the nodes in a data graph GD based on a given pattern graph GP. GPNM has been increasingly adopted in many applications such as group finding and expert recommendation, in which data graphs are frequently updated over time. Moreover, many typical pattern graphs frequently and repeatedly appear in users' queries in a short period of time. The existing GPNM methods have to perform an incremental GPNM procedure for each update in GD. In this paper, we first analyze the elimination relationships between multiple updates in GD and the hierarchical structure between these elimination relationships. Then, we generate an Elimination Hierarchy Tree (EH-Tree) to index the elimination relationships and propose an EH-Tree based GPNM method, called EH-GPNM. EH-GPNM first delivers the GPNM result of an initial query, and then delivers the GPNM result of a subsequent query, based on the initial GPNM result and the multiple updates of GD that occur between those two queries. The experimental results on five real-world social graphs demonstrate that our proposed EH-GPNM is much more efficient than the state-of-the-art GPNM methods},
  doi      = {10.1109/TKDE.2019.2942294},
  file     = {:FILES/2019 - Sun2019 - Incremental graph pattern based node matching with multiple updates.pdf:PDF},
  groups   = {query},
  keywords = {Pattern matching;Indexes;Facebook;Sun;Fans;Computational modeling;Graph pattern matching;updates of graph;elimination relationship},
  url      = {https://ieeexplore.ieee.org/document/8844795},
}

@InProceedings{Wang2019b,
  author    = {Shuai Wang and Yu Zhang and Zhiyong Liao},
  booktitle = {2019 Chinese Automation Congress (CAC)},
  title     = {Building domain-specific knowledge graph for unmanned combat vehicle decision making under uncertainty},
  year      = {2019},
  month     = nov,
  pages     = {4718--4721},
  abstract  = {With the development of intelligent war, unmanned vehicle plays an more and more important role in the future war. As an important part of the ground unmanned vehicle system, unmanned combat vehicles have been a hot spot for researchers to improve vehicle autonomy. knowledge is the foundation of intelligence and is of great significance for improving the vehicle autonomy. This paper proposes to build the knowledge graph in unmanned combat vehicle domain. The paper firstly uses the ontology to build the pattern layer of the knowledge graph. In order to fully express the uncertainty of the domain knowledge, the ontology is probabilistically extended to support the representation of uncertain knowledge. Then build a reasoning network based on the knowledge graph to support the reasoning of uncertain knowledge, and finally prove the feasibility of the knowledge graph through an example.},
  comment   = {考虑了KG中可能存在的不确定性，从而依概率进行推断},
  doi       = {10.1109/CAC48633.2019.8996418},
  file      = {:FILES/2019 - Wang2019b - Building domain-specific knowledge graph for unmanned combat vehicle decision making under uncertainty.pdf:PDF},
  groups    = {representation},
  issn      = {2688-0938},
  keywords  = {decision making;graph theory;inference mechanisms;military vehicles;mobile robots;ontologies (artificial intelligence);probability;domain-specific knowledge graph;unmanned combat vehicle decision making;intelligent war;ground unmanned vehicle system;vehicle autonomy;uncertain knowledge;reasoning network;Ontologies;Robots;Probabilistic logic;Cognition;Task analysis;Random variables;unmanned combat vehicles;knowledge graph;probabilistic ontology;Multi Entity Bayesian Networks (MEBN)},
  url       = {https://ieeexplore.ieee.org/document/8996418},
}

@InProceedings{Cao2019,
  author     = {Cao, Chao and Preda, Marius and Zaharia, Titus},
  booktitle  = {The 24th International Conference on 3D Web Technology},
  title      = {{3D} point cloud compression: {A} survey},
  year       = {2019},
  address    = {New York, NY, USA},
  pages      = {1–-9},
  publisher  = {Association for Computing Machinery},
  series     = {Web3D '19},
  abstract   = {In recent years, 3D point clouds have enjoyed a great popularity for representing both static and dynamic 3D objects. When compared to 3D meshes, they offer the advantage of providing a simpler, denser and more close-to-reality representation. However, point clouds always carry a huge amount of data. For a typical example of a point cloud with 0.7 million points per 3D frame at 30 fps, the point cloud raw video needs a bandwidth around 500MB/s. Thus, efficient compression methods are mandatory for ensuring the storage/transmission of such data, which include both geometry and attribute information. In the last years, the issue of 3D point cloud compression (3D-PCC) has emerged as a new field of research. In addition, an ISO/MPEG standardization process on 3D-PCC is currently on-going. In this paper, a comprehensive overview of the 3D-PCC state-of-the-art methods is proposed. Different families of approaches are identified, described in details and summarized, including 1D traversal compression, 2D-oriented techniques, which take leverage of existing 2D image/video compression technologies and finally purely 3D approaches, based on a direct analysis of the 3D data.},
  comment    = {【note \#69】},
  doi        = {10.1145/3329714.3338130},
  file       = {:FILES/2019 - Cao2019 - 3D point cloud compression- A survey.pdf:PDF},
  groups     = {cloudpoint},
  isbn       = {9781450367981},
  keywords   = {3D point cloud, compression, survey},
  location   = {LA, CA, USA},
  readstatus = {skimmed},
  url        = {https://doi.org/10.1145/3329714.3338130},
}

@Article{Huang2019a,
  author   = {Xiaolin Huang and Haiyan Yang and Yixing Huang and Lei Shi and Fan He and Andreas Maier and Ming Yan},
  journal  = {Signal Processing},
  title    = {Robust mixed one-bit compressive sensing},
  year     = {2019},
  issn     = {0165-1684},
  pages    = {161--168},
  volume   = {162},
  abstract = {When a measurement falls outside the quantization or measurable range, it becomes saturated and cannot be used in conventional signal recovery methods. Aiming at acquiring information from noisy saturated and regular measurements, we in this paper propose a new signal recovery method called mixed one-bit compressive sensing (M1bit-CS) and develop an efficient algorithm in the framework of alternating direction methods of multipliers. Numerical experiments on one-dimensional symmetric signals and two-dimensional image reconstruction from computed tomography verify the effectiveness of M1bit-CS on signal recovery from saturated measurements.},
  doi      = {https://doi.org/10.1016/j.sigpro.2019.04.011},
  file     = {:FILES/2019 - Huang2019a - Robust mixed one-bit compressive sensing.pdf:PDF},
  groups   = {Compressive sensing},
  keywords = {Compressive sensing, One-bit, Signal recovery, Image reconstruction},
  url      = {http://www.sciencedirect.com/science/article/pii/S0165168419301306},
}

@Article{Huang2018a,
  author   = {Xiaolin Huang and Ming Yan},
  journal  = {Signal Processing},
  title    = {Nonconvex penalties with analytical solutions for one-bit compressive sensing},
  year     = {2018},
  issn     = {0165-1684},
  pages    = {341--351},
  volume   = {144},
  abstract = {One-bit measurements widely exist in the real world and can be used to recover sparse signals. This task is known as one-bit compressive sensing (1bit-CS). In this paper, we propose novel algorithms based on both convex and non-convex sparsity-inducing penalties for robust 1bit-CS. We consider the dual problem, which has only one variable and provides a sufficient condition to verify whether a solution is globally optimal or not. For positive homogeneous penalties, a globally optimal solution can be obtained in two steps: a proximal operator and a normalization step. For other penalties, we solve the dual problem, and it needs to evaluate the proximal operators for many times. Then we provide fast algorithms for finding analytical solutions for three penalties: minimax concave penalty (MCP), ℓ0 norm, and sorted ℓ1 penalty. Specifically, our algorithm is more than 200 times faster than the existing algorithm for MCP. Its efficiency is comparable to the algorithm for the ℓ1 penalty in time, while its performance is much better than ℓ1. Among these penalties, sorted ℓ1 is most robust to noise in different settings.},
  doi      = {https://doi.org/10.1016/j.sigpro.2017.10.023},
  file     = {:FILES/2018 - Huang2018a - Nonconvex penalties with analytical solutions for one-bit compressive sensing.pdf:PDF},
  groups   = {Compressive sensing},
  keywords = {One-bit compressed sensing, Non-convex penalty, Analytical solutions},
  url      = {http://www.sciencedirect.com/science/article/pii/S0165168417303821},
}

@Article{Navarrete2018,
  author     = {Javier Navarrete and Diego Viejo and Miguel Cazorla},
  journal    = {Pattern Recognition Letters},
  title      = {Compression and registration of {3D} point clouds using {GMMs}},
  year       = {2018},
  issn       = {0167-8655},
  pages      = {8--15},
  volume     = {110},
  abstract   = {3D data sensors provide an enormous amount of information. It is necessary to develop efficient methods to manage this information under certain time, bandwidth or storage space requirements. In this work, we propose a 3D compression and decompression method. This method also allows the use of the compressed data for a registration process. First, points are selected and grouped, using a 3D-model based on planar surfaces. Next, we use a fast variant of Gaussian Mixture Models and an Expectation-Maximization algorithm to replace the points grouped in the previous step with a set of Gaussian distributions. These learned models can be used as features to find matches between two consecutive poses and apply 3D pose registration using RANSAC. Finally, the 3D map can be obtained by decompressing the models.},
  comment    = {见Excel},
  doi        = {https://doi.org/10.1016/j.patrec.2018.03.017},
  file       = {:FILES/2018 - Navarrete2018 - Compression and registration of 3D point clouds using GMMs.pdf:PDF},
  groups     = {cloudpoint},
  keywords   = {3D compression, 3D registration},
  readstatus = {read},
  url        = {http://www.sciencedirect.com/science/article/pii/S0167865518300989},
}

@InProceedings{Shao2017,
  author    = {Yiting Shao and Zhaobin Zhang and Zhu Li and Kui Fan and Ge Li},
  booktitle = {2017 IEEE Visual Communications and Image Processing (VCIP)},
  title     = {Attribute compression of {3D} point clouds using {Laplacian} sparsity optimized graph transform},
  year      = {2017},
  month     = dec,
  pages     = {1--4},
  abstract  = {3D sensing and content capturing have made significant progress in recent years and the MPEG standardization organization is launching a new project on immersive media with point cloud compression (PCC) as one key corner stone. In this work, we introduce a new binary tree based point cloud partition and explore the graph signal processing tools, especially the graph transform with optimized Laplacian sparsity, to achieve better energy compaction and compression efficiency. The resulting rate-distortion operating points are convex-hull optimized over the existing Lagrangian solutions. Simulation results on the latest high quality point cloud content from the MPEG PCC demonstrate the transform efficiency and rate-distortion (R-D) optimal potential of the proposed solutions.},
  doi       = {10.1109/VCIP.2017.8305131},
  file      = {:FILES/2017 - Shao2017 - Attribute compression of 3D point clouds using Laplacian sparsity optimized graph transform.pdf:PDF},
  groups    = {cloudpoint},
  keywords  = {computer graphics;data compression;Laplace transforms;rate distortion theory;trees (mathematics);3D point clouds;MPEG standardization organization;point cloud compression;binary tree based point cloud partition;graph signal processing tools;optimized Laplacian sparsity;energy compaction;compression efficiency;resulting rate-distortion operating points;latest high quality point cloud content;MPEG PCC;attribute compression;Laplacian sparsity optimized graph transform;Three-dimensional displays;Training;Octrees;Laplace equations;Discrete cosine transforms;Quantization (signal);Point cloud compression;Graph transform;Binary tree;Laplacian sparsity;Lagrangian optimization},
  url       = {https://ieeexplore.ieee.org/document/8305131},
}

@InProceedings{Auer2007,
  author    = {Auer, S{\"o}ren and Bizer, Christian and Kobilarov, Georgi and Lehmann, Jens and Cyganiak, Richard and Ives, Zachary},
  booktitle = {The Semantic Web},
  title     = {{DBpedia}: {A} nucleus for a web of open data},
  year      = {2007},
  address   = {Berlin, Heidelberg},
  editor    = {Aberer, Karl and Choi, Key-Sun and Noy, Natasha and Allemang, Dean and Lee, Kyung-Il and Nixon, Lyndon and Golbeck, Jennifer and Mika, Peter and Maynard, Diana and Mizoguchi, Riichiro and Schreiber, Guus and Cudr{\'e}-Mauroux, Philippe},
  pages     = {722--735},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {DBpedia is a community effort to extract structured information from Wikipedia and to make this information available on the Web. DBpedia allows you to ask sophisticated queries against datasets derived from Wikipedia and to link other datasets on the Web to Wikipedia data. We describe the extraction of the DBpedia datasets, and how the resulting information is published on the Web for human- and machine-consumption. We describe some emerging applications from the DBpedia community and show how website authors can facilitate DBpedia content within their sites. Finally, we present the current status of interlinking DBpedia with other open datasets on the Web and outline how DBpedia could serve as a nucleus for an emerging Web of open data.},
  comment   = {supported by crowdsourcing. common-sense knowledge},
  doi       = {10.1007/978-3-540-76298-0_52},
  file      = {:FILES/2007 - Auer2007 - DBpedia- A nucleus for a web of open data.pdf:PDF},
  groups    = {knowledge graph},
  isbn      = {978-3-540-76298-0},
  url       = {https://link.springer.com/chapter/10.1007/978-3-540-76298-0_52},
}

@InProceedings{Bollacker2008,
  author    = {Bollacker, Kurt and Evans, Colin and Paritosh, Praveen and Sturge, Tim and Taylor, Jamie},
  booktitle = {Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data},
  title     = {Freebase: {A} collaboratively created graph database for structuring human knowledge},
  year      = {2008},
  address   = {New York, NY, USA},
  pages     = {1247–1250},
  publisher = {Association for Computing Machinery},
  series    = {SIGMOD '08},
  abstract  = {Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Freebase currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications.},
  comment   = {supported by crowdsourcing, common-sense knowledge},
  doi       = {10.1145/1376616.1376746},
  file      = {:FILES/2008 - Bollacker2008 - Freebase- A collaboratively created graph database for structuring human knowledge.pdf:PDF},
  groups    = {knowledge graph},
  isbn      = {9781605581026},
  keywords  = {tuple store, collaborative systems, semantic network},
  location  = {Vancouver, Canada},
  numpages  = {4},
  url       = {https://doi.org/10.1145/1376616.1376746},
}

@Book{Fellbaum2005,
  editor    = {Christiane Fellbaum},
  publisher = {The MIT Press},
  title     = {{WordNet}: {An} electronic lexical database},
  year      = {2005},
  address   = {Cambridge},
  isbn      = {9780262061971},
  comment   = {lexical knowledge. 这是总结性成果，起始于1985年。manually created knowledge base},
  file      = {:FILES/1998 - Fellbaum2005 - WordNet- An electronic lexical database.pdf:PDF},
  groups    = {knowledge graph, 知识库调研报告},
  url       = {https://mitpress.mit.edu/books/wordnet;https://wordnet.princeton.edu/},
}

@Article{Lenat1995,
  author     = {Lenat, Douglas B.},
  journal    = {Communications of the ACM},
  title      = {{CYC}: {A} large-scale investment in knowledge infrastructure},
  year       = {1995},
  issn       = {0001-0782},
  month      = nov,
  number     = {11},
  pages      = {33–38},
  volume     = {38},
  abstract   = {Since 1984, a person-century of effort has gone into building CYC, a universal schema of roughly 105 general concepts spanning human reality. Most of the time has been spent codifying knowledge about these concepts; approximately 106 commonsense axioms have been handcrafted for and entered into CYC's knowledge base, and millions more have been inferred and cached by CYC. This article examines the fundamental assumptions of doing such a large-scale project, reviews the technical lessons learned by the developers, and surveys the range of applications that are or soon will be enabled by the technology.},
  address    = {New York, NY, USA},
  doi        = {10.1145/219717.219745},
  file       = {:FILES/1995 - Lenat1995 - CYC - A large-scale investment in knowledge infrastructure.pdf:PDF},
  groups     = {knowledge graph},
  issue_date = {Nov. 1995},
  numpages   = {6},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/219717.219745},
}

@InProceedings{Suchanek2007,
  author    = {Suchanek, Fabian M. and Kasneci, Gjergji and Weikum, Gerhard},
  booktitle = {Proceedings of the 16th International Conference on World Wide Web},
  title     = {Yago: {A} core of semantic knowledge},
  year      = {2007},
  address   = {New York, NY, USA},
  pages     = {697–706},
  publisher = {Association for Computing Machinery},
  series    = {WWW '07},
  abstract  = {We present YAGO, a light-weight and extensible ontology with high coverage and quality. YAGO builds on entities and relations and currently contains more than 1 million entities and 5 million facts. This includes the Is-A hierarchy as well as non-taxonomic relations between entities (such as HASONEPRIZE). The facts have been automatically extracted from Wikipedia and unified with WordNet, using a carefully designed combination of rule-based and heuristic methods described in this paper. The resulting knowledge base is a major step beyond WordNet: in quality by adding knowledge about individuals like persons, organizations, products, etc. with their semantic relationships - and in quantity by increasing the number of facts by more than an order of magnitude. Our empirical evaluation of fact correctness shows an accuracy of about 95\%. YAGO is based on a logically clean model, which is decidable, extensible, and compatible with RDFS. Finally, we show how YAGO can be further extended by state-of-the-art information extraction techniques.},
  comment   = {automatic information extraction for mining knowledge.},
  doi       = {10.1145/1242572.1242667},
  file      = {:FILES/2007 - Suchanek2007 - Yago- A core of semantic knowledge.pdf:PDF},
  groups    = {knowledge graph},
  isbn      = {9781595936547},
  keywords  = {wikipedia, WordNet},
  location  = {Banff, Alberta, Canada},
  numpages  = {10},
  url       = {https://doi.org/10.1145/1242572.1242667},
}

@InProceedings{Carlson2010,
  author    = {Carlson, Andrew and Betteridge, Justin and Kisiel, Bryan and Settles, Burr and Hruschka, Estevam R. and Mitchell, Tom M.},
  booktitle = {Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence},
  title     = {Toward an architecture for never-ending language learning},
  year      = {2010},
  address   = {Atlanta, Georgia},
  pages     = {1306–1313},
  publisher = {AAAI Press},
  series    = {AAAI'10},
  abstract  = {We consider here the problem of building a never-ending language learner; that is, an intelligent computer agent that runs forever and that each day must (1) extract, or read, information from the web to populate a growing structured knowledge base, and (2) learn to perform this task better than on the previous day. In particular, we propose an approach and a set of design principles for such an agent, describe a partial implementation of such a system that has already learned to extract a knowledge base containing over 242,000 beliefs with an estimated precision of 74\% after running for 67 days, and discuss lessons learned from this preliminary attempt to build a never-ending learning agent.},
  comment   = {NELL. automatic information extraction for mining knowledge.},
  doi       = {10.5555/2898607.2898816},
  file      = {:FILES/2010 - Carlson2010 - Toward an architecture for never-ending language learning.pdf:PDF},
  groups    = {knowledge graph},
  numpages  = {8},
  url       = {https://dl.acm.org/doi/10.5555/2898607.2898816},
}

@InProceedings{Deng2009,
  author    = {J. {Deng} and W. {Dong} and R. {Socher} and L. {Li} and {Kai Li} and {Li Fei-Fei}},
  booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
  title     = {{ImageNet}: {A} large-scale hierarchical image database},
  year      = {2009},
  address   = {Miami, FL, USA},
  month     = {June},
  pages     = {248--255},
  publisher = {IEEE},
  abstract  = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
  doi       = {10.1109/CVPR.2009.5206848},
  file      = {:FILES/2009 - Deng2009 - ImageNet- A large-scale hierarchical image database.pdf:PDF},
  groups    = {knowledge graph, 知识库调研报告},
  issn      = {1063-6919},
  keywords  = {computer vision;image resolution;image retrieval;Internet;multimedia computing;ontologies (artificial intelligence);trees (mathematics);very large databases;visual databases;ImageNet database;large-scale hierarchical image database;Internet;image retrieval;multimedia data;large-scale ontology;wordNet structure;image resolution;subtree;computer vision;Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
  url       = {https://ieeexplore.ieee.org/document/5206848},
}

@InProceedings{Beetz2015,
  author    = {Michael Beetz and Moritz Tenorth and Jan Winkler},
  booktitle = {2015 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {{Open-EASE}},
  year      = {2015},
  address   = {Seattle, WA, USA},
  month     = may,
  pages     = {1983--1990},
  publisher = {IEEE},
  abstract  = {Making future autonomous robots capable of accomplishing human-scale manipulation tasks requires us to equip them with knowledge and reasoning mechanisms. We propose Open-EASE, a remote knowledge representation and processing service that aims at facilitating these capabilities. Open-EASE gives its users unprecedented access to the knowledge of leading-edge autonomous robotic agents. It also provides the representational infrastructure to make inhomogeneous experience data from robots and human manipulation episodes semantically accessible, and is complemented by a suite of software tools that enable researchers and robots to interpret, analyze, visualize, and learn from the experience data. Using Open-EASE users can retrieve the memorized experiences of manipulation episodes and ask queries regarding to what the robot saw, reasoned, and did as well as how the robot did it, why, and what effects it caused.},
  comment   = {build a knowledge engine for robots. the knowledge is represented as formal statements using pre-defined templates.},
  doi       = {10.1109/ICRA.2015.7139458},
  file      = {:FILES/2015 - Beetz2015 - Open-EASE.pdf:PDF},
  groups    = {robot, 知识库调研报告},
  issn      = {1050-4729},
  keywords  = {human-robot interaction;knowledge representation;mobile robots;software tools;knowledge processing service;human-scale manipulation;knowledge mechanism;reasoning mechanism;Open-Ease;remote knowledge representation;leading-edge autonomous robotic agents;software tools;Data visualization;Robot sensing systems;Robot kinematics;Cognition;Knowledge based systems;Databases},
  url       = {https://ieeexplore.ieee.org/document/7139458},
}

@Article{Segal2013,
  author   = {Segal, Ben and Iwen, M. A.},
  journal  = {Numerical Algorithms},
  title    = {Improved sparse fourier approximation results: {Faster} implementations and stronger guarantees},
  year     = {2013},
  issn     = {1572-9265},
  month    = jun,
  number   = {2},
  pages    = {239--263},
  volume   = {63},
  abstract = {We study the problem of quickly estimating the best k-term Fourier representation for a given periodic function f: [0, 2π] → ℂ. Solving this problem requires the identification of k of the largest magnitude Fourier series coefficients of f in worst case k2 · logO(1)N time. Randomized sublinear-time Monte Carlo algorithms, which have a small probability of failing to output accurate answers for each input signal, have been developed for solving this problem (Gilbert et al. 2002, 2005). These methods were implemented as the Ann Arbor Fast Fourier Transform (AAFFT) and empirically evaluated in Iwen et al. (Commun Math Sci 5(4):981-998, 2007). In this paper we present a new implementation, called the Gopher Fast Fourier Transform (GFFT), of more recently developed sparse Fourier transform techniques (Iwen, Found Comput Math 10(3):303-338, 2010, Appl Comput Harmon Anal, 2012). Experiments indicate that GFFT is faster than AAFFT. In addition to our empirical evaluation, we also consider the existence of sublinear-time Fourier approximation methods with deterministic approximation guarantees for functions whose sequences of Fourier series coefficents are compressible. In particular, we prove the existence of sublinear-time Las Vegas Fourier Transforms which improve on the recent deterministic Fourier approximation results of Iwen (Found Comput Math 10(3):303-338, 2010, Appl Comput Harmon Anal, 2012) for Fourier compressible functions by guaranteeing accurate answers while using an asymptotically near-optimal number of function evaluations.},
  doi      = {10.1007/s11075-012-9621-7},
  file     = {:FILES/2013 - Segal2013 - Improved sparse fourier approximation results- Faster implementations and stronger guarantees.pdf:PDF},
  groups   = {approximation},
  refid    = {Segal2013},
  url      = {https://link.springer.com/article/10.1007/s11075-012-9621-7},
}

@InProceedings{Beetz2018,
  author    = {Michael Beetz and Daniel Be{\ss}ler and Andrei Haidu and Mihai Pomarlan and Asil Kaan Bozcuo{\v{g}}lu and Georg Bartels},
  booktitle = {2018 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {{Know Rob} 2.0 -- {A} 2nd generation knowledge processing framework for cognition-enabled robotic agents},
  year      = {2018},
  address   = {Brisbane, QLD, Australia},
  month     = may,
  pages     = {512--519},
  publisher = {IEEE},
  abstract  = {In this paper we present KnowRob2, a second generation knowledge representation and reasoning framework for robotic agents. KnowRob2 is an extension and partial redesign of KnowRob, currently one of the most advanced knowledge processing systems for robots that has enabled them to successfully perform complex manipulation tasks such as making pizza, conducting chemical experiments, and setting tables. The knowledge base appears to be a conventional first-order time interval logic knowledge base, but it exists to a large part only virtually: many logical expressions are constructed on demand from data structures of the control program, computed through robotics algorithms including ones for motion planning and solving inverse kinematics problems, and log data stored in noSQL databases. Novel features and extensions of KnowRob2 substantially increase the capabilities of robotic agents of acquiring open-ended manipulation skills and competence, reasoning about how to perform manipulation actions more realistically, and acquiring commonsense knowledge.},
  doi       = {10.1109/ICRA.2018.8460964},
  file      = {:FILES/2018 - Beetz2018 - Know Rob 2.0 — A 2nd generation knowledge processing framework for cognition-enabled robotic agents.pdf:PDF},
  groups    = {robot, 知识库调研报告},
  issn      = {2577-087X},
  keywords  = {knowledge based systems;knowledge representation;manipulator kinematics;manipulators;service robots;complex manipulation tasks;chemical experiments;first-order time interval logic knowledge base;logical expressions;robotics algorithms;motion planning;open-ended manipulation skills;commonsense knowledge;2nd generation knowledge processing framework;cognition-enabled robotic agents;generation knowledge representation;advanced knowledge;inverse kinematic problem solving;KnowRob2.0;Robots;Cognition;Data structures;Ontologies;Task analysis;Knowledge based systems;Physics},
  url       = {https://ieeexplore.ieee.org/document/8460964},
}

@InProceedings{Paulius2016,
  author    = {Paulius, David and Huang, Yongqiang and Milton, Roger and Buchanan, William D. and Sam, Jeanine and Sun, Yu},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Functional object-oriented network for manipulation learning},
  year      = {2016},
  address   = {Daejeon, South Korea},
  month     = oct,
  pages     = {2655--2662},
  publisher = {IEEE},
  doi       = {10.1109/IROS.2016.7759413},
  file      = {:FILES/2016 - Paulius2016 - Functional object-oriented network for manipulation learning.pdf:PDF},
  groups    = {robot},
  issn      = {2153-0866},
  url       = {https://ieeexplore.ieee.org/abstract/document/7759413},
}

@InProceedings{Paulius2018,
  author     = {Paulius, David and Jelodar, Ahmad B. and Sun, Yu},
  booktitle  = {2018 IEEE International Conference on Robotics and Automation (ICRA)},
  title      = {Functional object-oriented network: {Construction} \& expansion},
  year       = {2018},
  address    = {Brisbane, QLD, Australia},
  month      = may,
  pages      = {5935--5941},
  publisher  = {IEEE},
  abstract   = {We build upon the functional object-oriented network (FOON), a structured knowledge representation which is constructed from observations of human activities and manipulations. A FOON can be used for representing object-motion affordances. Knowledge retrieval through graph search allows us to obtain novel manipulation sequences using knowledge spanning across many video sources, hence the novelty in our approach. However, we are limited to the sources collected. To further improve the performance of knowledge retrieval as a follow up to our previous work, we discuss generalizing knowledge to be applied to objects which are similar to what we have in FOON without manually annotating new sources of knowledge. We discuss two means of generalization: 1) expanding our network through the use of object similarity to create new functional units from those we already have, and 2) compressing the functional units by object categories rather than specific objects. We discuss experiments which compare the performance of our knowledge retrieval algorithm with both expansion and compression by categories.},
  comment    = {note \#71},
  doi        = {10.1109/ICRA.2018.8460200},
  file       = {:FILES/2018 - Paulius2018 - Functional Object-Oriented Network- Construction + Expansion.pdf:PDF},
  groups     = {robot, 知识库调研报告},
  issn       = {2577-087X},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/8460200},
}

@Article{Diab2019,
  author         = {Diab, Mohammed and Akbari, Aliakbar and Ud Din, Muhayy and Rosell, Jan},
  journal        = {Sensors},
  title          = {{PMK}--{A} knowledge processing framework for autonomous robotics perception and manipulation},
  year           = {2019},
  issn           = {1424-8220},
  number         = {5},
  pages          = {1166},
  volume         = {19},
  abstract       = {Autonomous indoor service robots are supposed to accomplish tasks, like serve a cup, which involve manipulation actions. Particularly, for complex manipulation tasks which are subject to geometric constraints, spatial information and a rich semantic knowledge about objects, types, and functionality are required, together with the way in which these objects can be manipulated. In this line, this paper presents an ontological-based reasoning framework called Perception and Manipulation Knowledge (PMK) that includes: (1) the modeling of the environment in a standardized way to provide common vocabularies for information exchange in human-robot or robot-robot collaboration, (2) a sensory module to perceive the objects in the environment and assert the ontological knowledge, (3) an evaluation-based analysis of the situation of the objects in the environment, in order to enhance the planning of manipulation tasks. The paper describes the concepts and the implementation of PMK, and presents an example demonstrating the range of information the framework can provide for autonomous robots.},
  article-number = {1166},
  comment        = {扩展of【Diab2018】},
  doi            = {10.3390/s19051166},
  file           = {:FILES/2019 - Diab2019 - PMK--A knowledge processing framework for autonomous robotics perception and manipulation.pdf:PDF},
  groups         = {robot, 知识库调研报告},
  readstatus     = {read},
  url            = {https://www.mdpi.com/1424-8220/19/5/1166},
}

@Article{Sun2019RTPO,
  author         = {Sun, Xiaolei and Zhang, Yu and Chen, Jing},
  journal        = {Electronics},
  title          = {{RTPO}: {A} domain knowledge base for robot task planning},
  year           = {2019},
  issn           = {2079-9292},
  number         = {10},
  pages          = {1105},
  volume         = {8},
  abstract       = {Knowledge can enhance the intelligence of robots high-level decision-making. However, there is no specific domain knowledge base for robot task planning in this field. Aiming to represent the knowledge in robot task planning, the Robot Task Planning Ontology (RTPO) is first designed and implemented in this work, so that robots can understand and know how to carry out task planning to reach the goal state. In this paper, the RTPO is divided into three parts: task ontology, environment ontology, and robot ontology, followed by a detailed description of these three types of knowledge, respectively. The OWL (Web Ontology Language) is adopted to represent the knowledge in robot task planning. Then, the paper proposes a method to evaluate the scalability and responsiveness of RTPO. Finally, the corresponding task planning algorithm is designed based on RTPO, and then the paper conducts experiments on the basis of the real robot TurtleBot3 to verify the usability of RTPO. The experimental results demonstrate that RTPO has good performance in scalability and responsiveness, and the robot can achieve given high-level tasks based on RTPO.},
  article-number = {1105},
  doi            = {10.3390/electronics8101105},
  file           = {:FILES/2019 - Sun2019a - RTPO- A domain knowledge base for robot task planning.pdf:PDF},
  groups         = {robot, 知识库调研报告},
  readstatus     = {read},
  url            = {https://www.mdpi.com/2079-9292/8/10/1105},
}

@Misc{Hogan2021,
  author        = {Aidan Hogan and Eva Blomqvist and Michael Cochez and Claudia d'Amato and Gerard de Melo and Claudio Gutierrez and Jos\'{e} Emilio Labra Gayo and Sabrina Kirrane and Sebastian Neumaier and Axel Polleres and Roberto Navigli and Axel-Cyrille Ngonga Ngomo and Sabbir M. Rashid and Anisa Rula and Lukas Schmelzeisen and Juan Sequeda and Steffen Staab and Antoine Zimmermann},
  title         = {Knowledge graphs},
  year          = {2021},
  abstract      = {In this paper we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After some opening remarks, we motivate and contrast various graph-based data models and query languages that are used for knowledge graphs. We discuss the roles of schema, identity, and context in knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We summarise methods for the creation, enrichment, quality assessment, refinement, and publication of knowledge graphs. We provide an overview of prominent open knowledge graphs and enterprise knowledge graphs, their applications, and how they use the aforementioned techniques. We conclude with high-level future research directions for knowledge graphs.},
  archiveprefix = {arXiv},
  comment       = {综述},
  eprint        = {2003.02320},
  file          = {:FILES/2021 - Hogan2021 - Knowledge graphs.pdf:PDF},
  groups        = {knowledge graph},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2003.02320},
}

@InProceedings{Ehrlinger2016,
  author    = {Ehrlinger, Lisa and W{\"o}{\ss}, Wolfram},
  booktitle = {SEMANTiCS (Posters, Demos, SuCCESS)},
  title     = {Towards a definition of knowledge graphs},
  year      = {2016},
  abstract  = {Recently, the term knowledge graph has been used frequently
in research and business, usually in close association with
Semantic Web technologies, linked data, large-scale data
analytics and cloud computing. Its popularity is clearly influenced by the introduction of Google’s Knowledge Graph
in 2012, and since then the term has been widely used without a definition. A large variety of interpretations has hampered the evolution of a common understanding of knowledge
graphs. Numerous research papers refer to Google’s Knowledge Graph, although no official documentation about the
used methods exists. The prerequisite for widespread academic and commercial adoption of a concept or technology is
a common understanding, based ideally on a definition that
is free from ambiguity. We tackle this issue by discussing
and defining the term knowledge graph, considering its history and diversity in interpretations and use. Our goal is to
propose a definition of knowledge graphs that serves as basis
for discussions on this topic and contributes to a common
vision.},
  added-at  = {2017-12-16T11:15:46.000+0100},
  biburl    = {https://www.bibsonomy.org/bibtex/2bef3c699eeb69778c02467ccc13bc99c/thoni},
  comment   = {讨论了KG的定义},
  file      = {:FILES/2016 - Ehrlinger2016 - Towards a definition of knowledge graphs.pdf:PDF},
  groups    = {knowledge graph},
  interhash = {33750938d78af869dd800db08b39c1b8},
  intrahash = {bef3c699eeb69778c02467ccc13bc99c},
  keywords  = {knowledge graph defintion citedby:scholar:count:4 citedby:scholar:timestamp:2017-12-16},
  timestamp = {2017-12-16T11:15:46.000+0100},
}

@InCollection{Steup2020,
  author    = {Steup, Matthias and Neta, Ram},
  booktitle = {The {Stanford} Encyclopedia of Philosophy},
  publisher = {Metaphysics Research Lab, Stanford University},
  title     = {Epistemology},
  year      = {2020},
  edition   = {{Fall} 2020},
  editor    = {Edward N. Zalta},
  file      = {:FILES/2020 - Steup2020 - Epistemology.pdf:PDF},
  groups    = {knowledge graph, 知识库调研报告},
  url       = {https://plato.stanford.edu/archives/fall2020/entries/epistemology/},
}

@InProceedings{Diab2018,
  author    = {Diab, Mohammed and Muhayyuddin and Akbari, Aliakbar and Rosell, Jan},
  booktitle = {ROBOT 2017: Third Iberian Robotics Conference},
  title     = {An ontology framework for physics-based manipulation planning},
  year      = {2018},
  address   = {Cham},
  editor    = {Ollero, Anibal and Sanfeliu, Alberto and Montano, Luis and Lau, Nuno and Cardeira, Carlos},
  pages     = {452--464},
  publisher = {Springer International Publishing},
  abstract  = {In manipulation planning, dynamic interactions between the objects and the robots play a significant role. In this scope, dynamic engines allow to consider them within motion planners, giving rise to physics-based motion planners that consider the purposeful manipulation of objects. In this context, the representation of knowledge regarding how the objects have to be manipulated eases a semantic-based reasoning that reduces the computational cost of physics-based planners. In this work, an ontology framework is proposed to organize the knowledge needed for physics-based manipulation planning, allowing to derive manipulation regions and behaviors. A semantic map is constructed to categorize and assign the manipulation constraints based on the robot, the objects and the type of actions. The ontology framework can be queried using Description Language to obtain the necessary knowledge for the robot to manipulate the objects in its environment.},
  comment   = {继承【Lim2011】},
  file      = {:FILES/2018 - Diab2018 - An ontology framework for physics-based manipulation planning.pdf:PDF},
  groups    = {robot},
  isbn      = {978-3-319-70833-1},
  url       = {https://link.springer.com/chapter/10.1007/978-3-319-70833-1_37},
}

@Article{Lim2011,
  author   = {Gi Hyun Lim and Il Hong Suh and Hyowon Suh},
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans},
  title    = {Ontology-based unified robot knowledge for service robots in indoor environments},
  year     = {2011},
  issn     = {1558-2426},
  month    = may,
  number   = {3},
  pages    = {492--509},
  volume   = {41},
  abstract = {A significant obstacle for service robots is the execution of complex tasks in real environments. For example, it is not easy for service robots to find objects that are partially observable and are located at a place which is not identical but near the place where the robots saw them previously. To overcome the challenge effectively, robot knowledge represented as a semantic network can be extremely useful. This paper presents an ontology-based unified robot knowledge framework that integrates low-level data with high-level knowledge for robot intelligence. This framework consists of two sections: knowledge description and knowledge association. Knowledge description includes comprehensively integrated robot knowledge derived from low-level knowledge regarding perceptual features, part objects, metric maps, and primitive behaviors, as well as high-level knowledge about perceptual concepts, objects, semantic maps, tasks, and contexts. Knowledge association uses logical inference with both unidirectional and bidirectional rules. This characteristic enables reasoning to be performed even when only a partial information is available. The experimental results that demonstrate the advantages of using the proposed knowledge framework are also presented.},
  doi      = {10.1109/TSMCA.2010.2076404},
  file     = {:FILES/2011 - Lim2011 - Ontology-based unified robot knowledge for service robots in indoor environments.pdf:PDF},
  groups   = {robot},
  keywords = {knowledge representation;ontologies (artificial intelligence);service robots;ontology based unified robot knowledge;service robots;robot knowledge representation;knowledge description;knowledge association;Robot sensing systems;Service robots;Ontologies;Context;Semantics;Robot kinematics;Intelligent service robot;knowledge association;knowledge description;ontology-based knowledge;unified robot knowledge},
  url      = {https://ieeexplore.ieee.org/abstract/document/5605259},
}

@Article{Brueggemann2021,
  author   = {Sven Br\"{u}ggemann and Corrado Possieri},
  journal  = {IEEE Control Systems Letters},
  title    = {On the use of difference of log-sum-exp neural networks to solve data-driven model predictive control tracking problems},
  year     = {2021},
  issn     = {2475-1456},
  month    = oct,
  number   = {4},
  pages    = {1267--1272},
  volume   = {5},
  abstract = {We employ Difference of Log-Sum-Exp neural networks to generate a data-driven feedback controller based on Model Predictive Control (MPC) to track a given reference trajectory. By using this class of networks to approximate the MPC-related cost function subject to the given system dynamics and input constraint, we avoid two of the main bottlenecks of classical MPC: the availability of an accurate model for the system being controlled, and the computational cost of solving the MPC-induced optimization problem. The former is tackled by exploiting the universal approximation capabilities of this class of networks. The latter is alleviated by making use of the difference-of-convex-functions structure of these networks. Furthermore, we show that the system driven by the MPC-neural structure is practically stable.},
  doi      = {10.1109/LCSYS.2020.3032083},
  file     = {:FILES/2021 - Brueggemann2021 - On the use of difference of log-sum-exp neural networks to solve data-driven model predictive control tracking problems.pdf:PDF},
  groups   = {LSEO},
  keywords = {approximation theory;convex programming;feedback;function approximation;neurocontrollers;nonlinear control systems;optimal control;predictive control;nonlinear systems;cost function approximation;system dynamics;reference trajectory tracking;data-driven feedback controller;data-driven model predictive control tracking problems;Log-Sum-Exp neural networks;MPC-neural structure;difference-of-convex-functions structure;MPC-induced optimization problem;Computational modeling;Artificial neural networks;Trajectory;Optimization;Approximation algorithms;Predictive control;Predictive control for nonlinear systems;neural networks;optimal control;uncertain systems},
  priority = {prio1},
  url      = {https://ieeexplore.ieee.org/document/9229181},
}

@TechReport{IEEEStd1872-2015,
  institution = {IEEE},
  title       = {{IEEE} standard ontologies for robotics and automation},
  year        = {2015},
  month       = apr,
  abstract    = {A core ontology that specifies the main, most general concepts, relations, and axioms of robotics and automation (R\&A) is defined in this standard, which is intended as a reference for knowledge representation and reasoning in robots, as well as a formal reference vocabulary for communicating knowledge about R\&A between robots and humans. This standard is composed of a core ontology about R\&A, called CORA, together with other ontologies that give support to CORA.},
  comment     = {OWL formatted ontology can be found via https://github.com/srfiorini/IEEE1872-owl},
  doi         = {10.1109/IEEESTD.2015.7084073},
  file        = {:FILES/2015 - IEEEStd1872-2015 - IEEE standard ontologies for robotics and automation.pdf:PDF},
  groups      = {robot},
  journal     = {IEEE Std 1872-2015},
  keywords    = {IEEE standards;ontologies (artificial intelligence);robots;IEEE standard ontologies;robotics and automation;knowledge representation;reasoning;formal reference vocabulary;CORA;IEEE Std 1872-2015;IEEE standards;Ontologies;Automation;Robots;Accuracy;IEEE Robotics and Automation Society;automation;core ontology;IEEE 1872(TM);methodology;ontology;robotics},
  pages       = {1--60},
  url         = {https://ieeexplore.ieee.org/document/7084073},
}

@Article{Riazuelo2015,
  author   = {Louis {Riazuelo} and Moritz {Tenorth} and Daniel {Di Marco} and Marta {Salas} and Dorian {Gálvez-L\'{o}pez} and Lorenz {M\"{o}senlechner} and Lars {Kunze} and Michael {Beetz} and Juan D. {Tard\'{o}s} and Luis {Montano} and Jos\'{e} M. Mart\'{i}nez {Montiel}},
  journal  = {IEEE Transactions on Automation Science and Engineering},
  title    = {{RoboEarth} semantic mapping: {A} cloud enabled knowledge-based approach},
  year     = {2015},
  issn     = {1558-3783},
  month    = apr,
  number   = {2},
  pages    = {432--443},
  volume   = {12},
  abstract = {The vision of the RoboEarth project is to design a knowledge-based system to provide web and cloud services that can transform a simple robot into an intelligent one. In this work, we describe the RoboEarth semantic mapping system. The semantic map is composed of: 1) an ontology to code the concepts and relations in maps and objects and 2) a SLAM map providing the scene geometry and the object locations with respect to the robot. We propose to ground the terminological knowledge in the robot perceptions by means of the SLAM map of objects. RoboEarth boosts mapping by providing: 1) a subdatabase of object models relevant for the task at hand, obtained by semantic reasoning, which improves recognition by reducing computation and the false positive rate; 2) the sharing of semantic maps between robots; and 3) software as a service to externalize in the cloud the more intensive mapping computations, while meeting the mandatory hard real time constraints of the robot. To demonstrate the RoboEarth cloud mapping system, we investigate two action recipes that embody semantic map building in a simple mobile robot. The first recipe enables semantic map building for a novel environment while exploiting available prior information about the environment. The second recipe searches for a novel object, with the efficiency boosted thanks to the reasoning on a semantically annotated map. Our experimental results demonstrate that, by using RoboEarth cloud services, a simple robot can reliably and efficiently build the semantic maps needed to perform its quotidian tasks. In addition, we show the synergetic relation of the SLAM map of objects that grounds the terminological knowledge coded in the ontology.},
  doi      = {10.1109/TASE.2014.2377791},
  groups   = {robot, 知识库调研报告},
  keywords = {cloud computing;control engineering computing;intelligent robots;mobile robots;object recognition;ontologies (artificial intelligence);SLAM (robots);Web services;RoboEarth semantic mapping system;cloud enabled knowledge-based approach;Web services;cloud services;intelligent robot;ontology;SLAM map;scene geometry;object locations;object model subdatabase;semantic reasoning;software as a service;mobile robot;Semantics;Knowledge based systems;Search problems;Simultaneous localization and mapping;Navigation;Visualization;Cloud mapping;knowledge representation;object recognition;semantic mapping;visual SLAM},
  url      = {https://ieeexplore.ieee.org/document/7015601},
}

@Article{Galarraga2015,
  author   = {Gal\'{a}raga, Luis and Teflioudi, Christina and Hose, Katja and Suchanek, Fabian M.},
  journal  = {The VLDB Journal},
  title    = {Fast rule mining in ontological knowledge bases with {AMIE}+},
  year     = {2015},
  issn     = {0949-877X},
  number   = {6},
  pages    = {707--730},
  volume   = {24},
  abstract = {Recent advances in information extraction have led to huge knowledge bases (KBs), which capture knowledge in a machine-readable format. Inductive logic programming (ILP) can be used to mine logical rules from these KBs, such as “If two persons are married, then they (usually) live in the same city.” While ILP is a mature field, mining logical rules from KBs is difficult, because KBs make an open-world assumption. This means that absent information cannot be taken as counterexamples. Our approach AMIE (Galárraga et al. in WWW, 2013) has shown how rules can be mined effectively from KBs even in the absence of counterexamples. In this paper, we show how this approach can be optimized to mine even larger KBs with more than 12M statements. Extensive experiments show how our new approach, AMIE$$+$$+, extends to areas of mining that were previously beyond reach.},
  doi      = {10.1007/s00778-015-0394-1},
  groups   = {知识库调研报告},
  url      = {https://doi.org/10.1007/s00778-015-0394-1},
}

@Article{Chu2019,
  author   = {Fu-Jen {Chu} and Ruinian {Xu} and Landan {Seguin} and Patricio A. {Vela}},
  journal  = {IEEE Robotics and Automation Letters},
  title    = {Toward affordance detection and ranking on novel objects for real-wrld robotic manipulation},
  year     = {2019},
  issn     = {2377-3766},
  month    = oct,
  number   = {4},
  pages    = {4070--4077},
  volume   = {4},
  abstract = {This letter presents a framework to detect and rank affordances of novel objects to assist with robotic manipulation tasks. The framework segments the affordance map of unseen objects using region-based affordance segmentation. Detected affordances define an initial state from which to generate action primitives for manipulation via the planning domain definition language (PDDL). The proposed category-agnostic affordance segmentation approach generalizes learned affordances to unseen objects by utilizing binary classification on proposed instance masks. The predicted pixel-wise level affordances are ranked by KL-divergence, augmenting the available affordance choices for manipulation tasks with non-primary affordances of an object. Experimental results show that the proposed method achieves state-of-the-art performance on affordance segmentation of novel objects, and outperforms baselines on affordance ranking. Actual robotic manipulation scenarios demonstrate the use of affordance detection with PDDL-generated action primitives for task execution. Prediction of ranked affordances on unseen objects provides flexibility to accomplish goal-oriented tasks.},
  doi      = {10.1109/LRA.2019.2930364},
  groups   = {知识库调研报告},
  keywords = {image segmentation;learning (artificial intelligence);manipulators;object detection;planning (artificial intelligence);robot vision;unseen objects;predicted pixel-wise level affordances;available affordance choices;nonprimary affordances;affordance ranking;actual robotic manipulation scenarios;PDDL-generated action primitives;ranked affordances;real-world robotic manipulation;robotic manipulation tasks;framework segments;affordance map;detected affordances;initial state;planning domain definition language;category-agnostic affordance segmentation approach;affordance detection;Planning;Robots;Task analysis;Image segmentation;Deep learning;Semantics;Tools;Perception for grasping and manipulation;deep learning in robotics and automation;RGB-D perception},
  url      = {https://ieeexplore.ieee.org/document/8770077},
}

@Article{Zhang2012,
  author   = {Wanpeng Zhang and Lincheng {Shen} and Jing {Chen}},
  journal  = {Journal of Systems Engineering and Electronics},
  title    = {Learning and fatigue inspired method for optimized {HTN} planning},
  year     = {2012},
  issn     = {1004-4132},
  month    = apr,
  number   = {2},
  pages    = {233--241},
  volume   = {23},
  abstract = {Learning is widely used in intelligent planning to shorten the planning process or improve the plan quality. This paper aims at introducing learning and fatigue into the classical hierarchical task network (HTN) planning process so as to create better high-quality plans quickly. The process of HTN planning is mapped during a depth-first search process in a problem-solving agent, and the models of learning in HTN planning is conducted similar to the learning depth-first search (LDFS). Based on the models, a learning method integrating HTN planning and LDFS is presented, and a fatigue mechanism is introduced to balance exploration and exploitation in learning. Finally, experiments in two classical domains are carried out in order to validate the effectiveness of the proposed learning and fatigue inspired method.},
  doi      = {10.1109/JSEE.2012.00030},
  groups   = {知识库调研报告},
  keywords = {Planning;Fatigue;Learning systems;Modeling;Search problems;hierarchical task network (HTN) planning;learning;fatigue},
  url      = {https://ieeexplore.ieee.org/document/6190873},
}

@Article{Ge2020,
  author   = {Congcong Ge and Yunjun Gao and Xiaoye Miao and Bin Yao and Haobo Wang},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  title    = {A hybrid data cleaning framework using {Markov} logic networks},
  year     = {2020},
  issn     = {1558-2191},
  pages    = {1--1},
  abstract = {With the increase of dirty data, data cleaning turns into a crux of data analysis. The accuracy limitation of the existing integrity constraints-based cleaning approaches results from insufficient rules. In this paper, we present a novel hybrid data cleaning framework on top of Markov logic networks (MLNs), termed as MLNClean, which is capable of learning instantiated rules to supplement the insufficient integrity constraints. MLNClean consists of two steps, i.e., pre-processing and two-stage data cleaning. In the pre-processing step, MLNClean first infers a set of probable instantiated rules according to MLNs and then builds a two-layer MLN index structure to generate multiple data versions and facilitate the cleaning process. In the two-stage data cleaning step, MLNClean first presents a concept of reliability score to clean errors within each data version separately, and afterward eliminates the conflict values among different data version using a novel concept of fusion score. Considerable experimental results on both real and synthetic scenarios demonstrate the effectiveness of MLNClean in practice.},
  doi      = {10.1109/TKDE.2020.3012472},
  file     = {:FILES/2020 - Ge2020 - A hybrid data cleaning framework using {Markov} logic networks.pdf:PDF},
  groups   = {知识库调研报告},
  keywords = {Cleaning;Maintenance engineering;Dictionaries;Indexes;Markov processes;Integrated circuits;Hospitals;Data Cleaning;Integrity Constraints;Markov Logic Network},
  url      = {https://ieeexplore.ieee.org/document/9151362},
}

@Article{Cui2020a,
  author   = {Jiaxu {Cui} and Bo {Yang} and Bingyi {Sun} and Xia {Hu} and Jiming {Liu}},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  title    = {Scalable and parallel deep {Bayesian} optimization on attributed graphs},
  year     = {2020},
  issn     = {2162-2388},
  pages    = {1--14},
  abstract = {We propose a general and scalable global optimization framework directly operating on annotated graph data by introducing a Bayesian graph neural network to approximate the expensive-to-evaluate objectives. It prevents the cubical complexity of Gaussian processes and can scale linearly with the number of observations. Its parallelized variant makes it scalable. We provide strict theoretical support on its convergence. Intensive experiments conducted on both artificial and real-world problems, including molecular discovery and urban road network design, demonstrate the effectiveness of the proposed methods compared with the current state of the art.},
  doi      = {10.1109/TNNLS.2020.3027552},
  groups   = {知识库调研报告},
  keywords = {Optimization;Bayes methods;Probabilistic logic;Task analysis;Roads;Convergence;Attributed graphs;Bayesian optimization;graph neural networks (GNNs);structure optimization.},
  url      = {https://ieeexplore.ieee.org/document/9222328},
}

@Article{Kunze2018,
  author   = {Lars {Kunze} and Nick {Hawes} and Tom {Duckett} and Marc {Hanheide} and Tom\'{a}\v{s} {Krajník}},
  journal  = {IEEE Robotics and Automation Letters},
  title    = {Artificial intelligence for long-term robot autonomy: {A} survey},
  year     = {2018},
  issn     = {2377-3766},
  month    = oct,
  number   = {4},
  pages    = {4023--4030},
  volume   = {3},
  abstract = {Autonomous systems will play an essential role in many applications across diverse domains including space, marine, air, field, road, and service robotics. They will assist us in our daily routines and perform dangerous, dirty, and dull tasks. However, enabling robotic systems to perform autonomously in complex, real-world scenarios over extended time periods (i.e., weeks, months, or years) poses many challenges. Some of these have been investigated by subdisciplines of Artificial Intelligence (AI) including navigation and mapping, perception, knowledge representation and reasoning, planning, interaction, and learning. The different subdisciplines have developed techniques that, when re-integrated within an autonomous system, can enable robots to operate effectively in complex, long-term scenarios. In this letter, we survey and discuss AI techniques as “enablers” for long-term robot autonomy, current progress in integrating these techniques within long-running robotic systems, and the future challenges and opportunities for AI in long-term autonomy.},
  doi      = {10.1109/LRA.2018.2860628},
  file     = {:FILES/2018 - Kunze2018 - Artificial intelligence for long-term robot autonomy- A survey.pdf:PDF},
  groups   = {知识库调研报告},
  keywords = {learning (artificial intelligence);mobile robots;service robots;user modelling;autonomous system;dangerous tasks;dull tasks;real-world scenarios;AI;knowledge representation;reasoning;long-term robot autonomy;artificial intelligence;dirty tasks;Navigation;Planning;Task analysis;Roads;Autonomous robots;Autonomous agents;AI-based methods;long-term autonomy},
  url      = {https://ieeexplore.ieee.org/abstract/document/8421618},
}

@Article{Sun2019cloudpoint,
  author     = {Xuebin {Sun} and Han {Ma} and Yuxiang {Sun} and Ming {Liu}},
  journal    = {IEEE Robotics and Automation Letters},
  title      = {A novel point cloud compression algorithm based on clustering},
  year       = {2019},
  issn       = {2377-3766},
  month      = apr,
  number     = {2},
  pages      = {2132--2139},
  volume     = {4},
  abstract   = {Due to the enormous volume of point cloud data, transmitting and storing the data requires large bandwidth and storage space. It could be a critical bottleneck, especially in tasks such as autonomous driving. In this letter, we propose a novel point cloud compression algorithm based on clustering. The proposed scheme starts with a range image-based segmentation step, which segments the three-dimensional (3-D) range data into ground and main objects. Then, it introduces a novel prediction method according to the segmented regions' shape. This prediction method is inspired by the depth modeling modes used in 3-D high-efficiency video coding for depth map coding. Finally, the few prediction residual is efficiently compressed with several lossless or lossy data compression techniques. Experimental results show that the proposed algorithm can largely eliminate the spatial redundant information of the point cloud data. The lossless compression scheme reaches a compression ratio of nearly 5\%, which means that the point cloud is compressed to 5\% of its original size without any distance distortion. Compared with other methods, the proposed compression algorithm also shows better performance.},
  doi        = {10.1109/LRA.2019.2900747},
  file       = {:FILES/2019 - Sun2019cloudpoint - A novel point cloud compression algorithm based on clustering.pdf:PDF},
  groups     = {cloudpoint},
  keywords   = {data compression;image coding;image segmentation;pattern clustering;prediction theory;video coding;point cloud data;lossless compression scheme;compression ratio;range image-based segmentation step;segmented regions;point cloud compression algorithm;prediction method;video coding;data compression techniques;distance distortion;depth map coding;three-dimensional range data;clustering;Three-dimensional displays;Image coding;Laser radar;Image segmentation;Encoding;Redundancy;Octrees;Range Sensing;automation technologies for smart cities;SLAM},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/8648155},
}

@Article{Zhu2014,
  author   = {Xiao Xiang {Zhu} and Richard {Bamler}},
  journal  = {IEEE Signal Processing Magazine},
  title    = {Superresolving {SAR} tomography for multidimensional imaging of urban areas: {Compressive} sensing-based {TomoSAR} inversion},
  year     = {2014},
  issn     = {1558-0792},
  month    = jul,
  number   = {4},
  pages    = {51--58},
  volume   = {31},
  abstract = {With reference to the current status of VHR spaceborne tomographic SAR inversion presented in this article, the following conclusions can be drawn: VHR tomographic SAR inversion is able to reconstruct the shape and motion of individual buildings and entire city areas. SR is crucial and possible, e.g., using CS, for VHR tomographic SAR inversion for urban infrastructure. The motion or deformation of buildings is often nonlinear (periodic, accelerating, stepwise, etc.). Multicomponent nonlinear motion of multiple scatterers can be separated. The 4-D point clouds retrieved by VHR TomoSAR has a point density comparable to LiDAR and can be potentially used for dynamic city model reconstruction.},
  doi      = {10.1109/MSP.2014.2312098},
  file     = {:FILES/2014 - Zhu2014 - Superresolving SAR tomography for multidimensional imaging of urban areas- Compressive sensing-based TomoSAR inversion.pdf:PDF},
  groups   = {cloudpoint},
  keywords = {compressed sensing;image motion analysis;image reconstruction;radar imaging;radar resolution;synthetic aperture radar;tomography;VHR spaceborne tomographic SAR inversion;shape reconstruction;motion reconstruction;building deformation;urban infrastructure;multicomponent nonlinear motion;multiple scatterers;4D point clouds;point density;LiDAR;dynamic city model reconstruction;synthetic aperture radar;very high spatial resolution SAR tomography;multidimensional imaging;urban areas;compressive sensing-based TomoSAR inversion;Synthetic aperture radar;Tomography;Mathematical model;Signal resolution;Signal processing algorithms;Signal to noise ratio;Urban areas},
  url      = {https://ieeexplore.ieee.org/abstract/document/6832819},
}

@Misc{Paulius2020,
  author        = {David Paulius and Kelvin Sheng Pei Dong and Yu Sun},
  title         = {Task planning with a weighted functional object-oriented network},
  year          = {2020},
  abstract      = {In reality, there is still much to be done for robots to be able to perform manipulation actions with full autonomy. Complicated manipulation tasks, such as cooking, may still require a person to perform some actions that are very risky for a robot to perform. On the other hand, some other actions may be very risky for a human with physical disabilities to perform. Therefore, it is necessary to balance the workload of a robot and a human based on their limitations while minimizing the effort needed from a human in a collaborative robot (cobot) set-up. This paper proposes a new version of our functional object-oriented network (FOON) that integrates weights in its functional units to reflect a robot's chance of successfully executing an action of that functional unit. The paper also presents a task planning algorithm for the weighted FOON to allocate manipulation action load to the robot and human to achieve optimal performance while minimizing human effort. Through a number of experiments, this paper shows several successful cases in which using the proposed weighted FOON and the task planning algorithm allow a robot and a human to successfully complete complicated tasks together with higher success rates than a robot doing them alone.},
  archiveprefix = {arXiv},
  eprint        = {1905.00502},
  file          = {:FILES/2020 - Paulius2020 - Task planning with a weighted functional object-oriented network.pdf:PDF},
  groups        = {robot},
  primaryclass  = {cs.RO},
  url           = {https://arxiv.org/abs/1905.00502},
}

@Article{Wang2015KB,
  author   = {Wang, William Yang and Mazaitis, Kathryn and Lao, Ni and Cohen, William W.},
  journal  = {Machine Learning},
  title    = {Efficient inference and learning in a large knowledge base},
  year     = {2015},
  issn     = {1573-0565},
  month    = apr,
  number   = {1},
  pages    = {101--126},
  volume   = {100},
  abstract = {One important challenge for probabilistic logics is reasoning with very large knowledge bases (KBs) of imperfect information, such as those produced by modern web-scale information extraction systems. One scalability problem shared by many probabilistic logics is that answering queries involves “grounding” the query--i.e., mapping it to a propositional representation--and the size of a “grounding” grows with database size. To address this bottleneck, we present a first-order probabilistic language called ProPPR in which approximate “local groundings” can be constructed in time independent of database size. Technically, ProPPR is an extension to stochastic logic programs that is biased towards short derivations; it is also closely related to an earlier relational learning algorithm called the path ranking algorithm. We show that the problem of constructing proofs for this logic is related to computation of personalized PageRank on a linearized version of the proof space, and based on this connection, we develop a provably-correct approximate grounding scheme, based on the PageRank-Nibble algorithm. Building on this, we develop a fast and easily-parallelized weight-learning algorithm for ProPPR. In our experiments, we show that learning for ProPPR is orders of magnitude faster than learning for Markov logic networks; that allowing mutual recursion (joint learning) in KB inference leads to improvements in performance; and that ProPPR can learn weights for a mutually recursive program with hundreds of clauses defining scores of interrelated predicates over a KB containing one million entities.},
  doi      = {10.1007/s10994-015-5488-x},
  file     = {:FILES/2015 - Wang2015KB - Efficient inference and learning in a large knowledge base.pdf:PDF},
  groups   = {reasoning},
  url      = {https://link.springer.com/article/10.1007/s10994-015-5488-x},
}

@Article{Chen2020KB,
  author   = {Xiaojun Chen and Shengbin Jia and Yang Xiang},
  journal  = {Expert Systems with Applications},
  title    = {A review: {Knowledge} reasoning over knowledge graph},
  year     = {2020},
  issn     = {0957-4174},
  month    = mar,
  pages    = {112948},
  volume   = {141},
  abstract = {Mining valuable hidden knowledge from large-scale data relies on the support of reasoning technology. Knowledge graphs, as a new type of knowledge representation, have gained much attention in natural language processing. Knowledge graphs can effectively organize and represent knowledge so that it can be efficiently utilized in advanced applications. Recently, reasoning over knowledge graphs has become a hot research topic, since it can obtain new knowledge and conclusions from existing data. Herein we review the basic concept and definitions of knowledge reasoning and the methods for reasoning over knowledge graphs. Specifically, we dissect the reasoning methods into three categories: rule-based reasoning, distributed representation-based reasoning and neural network-based reasoning. We also review the related applications of knowledge graph reasoning, such as knowledge graph completion, question answering, and recommender systems. Finally, we discuss the remaining challenges and research opportunities for knowledge graph reasoning.},
  doi      = {10.1016/j.eswa.2019.112948},
  file     = {:FILES/2020 - Chen2020KB - A review- Knowledge reasoning over knowledge graph.pdf:PDF},
  groups   = {reasoning},
  keywords = {Knowledge graph, Reasoning, Rule-based reasoning, Distributed representation-based reasoning, Neural network-based reasoning},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417419306669},
}

@Article{Wang2020KB-RL,
  author   = {Qi Wang and Yongsheng Hao and Jie Cao},
  journal  = {Knowledge-Based Systems},
  title    = {{ADRL}: {An} attention-based deep reinforcement learning framework for knowledge graph reasoning},
  year     = {2020},
  issn     = {0950-7051},
  month    = jun,
  pages    = {105910},
  volume   = {197},
  abstract = {Knowledge graph reasoning is one of the key technologies for knowledge graph construction, which plays an important part in application scenarios such as vertical search and intelligent question answering. It is intended to infer the desired entity from the entities and relations that already exist in the knowledge graph. Most current methods for reasoning, such as embedding-based methods, globally embed all entities and relations, and then use the similarity of vectors to infer relations between entities or whether given triples are true. However, in real application scenarios, we require a clear and interpretable target entity as the output answer. In this paper, we propose a novel attention-based deep reinforcement learning framework (ADRL) for learning multi-hop relational paths, which improves the efficiency, generalization capacity, and interpretability of conventional approaches through the structured perception of deep learning and relational reasoning of reinforcement learning. We define the entire process of reasoning as a Markov decision process. First, we employ CNN to map the knowledge graph to a low-dimensional space, and a message-passing mechanism to sense neighbor entities at each level, and then employ LSTM to memorize and generate a sequence of historical trajectories to form a policy and value functions. We design a relational module that includes a self-attention mechanism that can infer and share the weights of neighborhood entity vectors and relation vectors. Finally, we employ the actor–critic algorithm to optimize the entire framework. Experiments confirm the effectiveness and efficiency of our method on several benchmark data sets.},
  doi      = {10.1016/j.knosys.2020.105910},
  file     = {:FILES/2020 - Wang2020KB-RL - ADRL- An attention-based deep reinforcement learning framework for knowledge graph reasoning.pdf:PDF},
  groups   = {reasoning},
  keywords = {Knowledge graph, Knowledge reasoning, Reinforcement learning, Deep learning, Attention},
  url      = {https://www.sciencedirect.com/science/article/pii/S0950705120302525},
}

@InProceedings{PellissierTanon2016,
  author    = {Pellissier Tanon, Thomas and Vrande\v{c}i\'{c}, Denny and Schaffert, Sebastian and Steiner, Thomas and Pintscher, Lydia},
  booktitle = {Proceedings of the 25th International Conference on World Wide Web},
  title     = {From freebase to {Wikidata}: {The} great migration},
  year      = {2016},
  address   = {Republic and Canton of Geneva, CHE},
  pages     = {1419–1428},
  publisher = {International World Wide Web Conferences Steering Committee},
  series    = {WWW '16},
  abstract  = {Collaborative knowledge bases that make their data freely available in a machine-readable form are central for the data strategy of many projects and organizations. The two major collaborative knowledge bases are Wikimedia's Wikidata and Google's Freebase. Due to the success of Wikidata, Google decided in 2014 to offer the content of Freebase to the Wikidata community. In this paper, we report on the ongoing transfer efforts and data mapping challenges, and provide an analysis of the effort so far. We describe the Primary Sources Tool, which aims to facilitate this and future data migrations. Throughout the migration, we have gained deep insights into both Wikidata and Freebase, and share and discuss detailed statistics on both knowledge bases.},
  doi       = {10.1145/2872427.2874809},
  file      = {:FILES/2016 - PellissierTanon2016 - From freebase to Wikidata- The great migration.pdf:PDF},
  groups    = {knowledge graph},
  isbn      = {9781450341431},
  keywords  = {wikidata, freebase, semantic web, crowdsourcing systems},
  location  = {Montr\'{e}al, Qu\'{e}bec, Canada},
  numpages  = {10},
  url       = {https://doi.org/10.1145/2872427.2874809},
}

@Article{Li2021bb,
  author   = {Zhongguo Li and Zhen Dong and Zhongchao Liang and Zhengtao Ding},
  journal  = {Automatica},
  title    = {Surrogate-based distributed optimisation for expensive black-box functions},
  year     = {2021},
  issn     = {0005-1098},
  pages    = {109407},
  volume   = {125},
  abstract = {This paper considers distributed optimisation problems with black-box functions using surrogate-assisted methods. Since the cost functions and their derivatives are usually impossible to be expressed by explicit functions due to the complexity of modern systems, function calls have to be performed to obtain those values. Moreover, the cost functions are often expensive to evaluate, and therefore designers prefer to reduce the number of evaluations. In this paper, surrogate-based methods are utilised to approximate the true functions, and conditions for constructing smooth and convex surrogates are established, by which the requirements for explicit functions are eliminated. To improve the quality of surrogate models, a distance-based infill strategy is proposed to balance the exploitation and exploration, which guarantees the density of the decision sequence in a compact set. Then, a distributed optimisation algorithm is developed to solve the reformulated auxiliary sub-problems, and the convergence of the proposed algorithm is established via Lyapunov theory. Simulation examples are provided to validate the effectiveness of the theoretical development and demonstrate the potential significance of the framework.},
  doi      = {https://doi.org/10.1016/j.automatica.2020.109407},
  file     = {:FILES/2021 - Li2021bb - Surrogate-based distributed optimisation for expensive black-box functions.pdf:PDF},
  groups   = {interesting articles},
  keywords = {Distributed algorithms, Expensive optimisation methods, Black-box functions, Surrogate models, Multi-agent systems},
  url      = {https://www.sciencedirect.com/science/article/pii/S0005109820306099},
}

@Article{Ning2021,
  author   = {Chao Ning and Fengqi You},
  journal  = {Automatica},
  title    = {Online learning based risk-averse stochastic {MPC} of constrained linear uncertain systems},
  year     = {2021},
  issn     = {0005-1098},
  pages    = {109402},
  volume   = {125},
  abstract = {This paper investigates the problem of designing data-driven stochastic Model Predictive Control (MPC) for linear time-invariant systems under additive stochastic disturbance, whose probability distribution is unknown but can be partially inferred from data. We propose a novel online learning based risk-averse stochastic MPC framework in which Conditional Value-at-Risk (CVaR) constraints on system states are required to hold for a family of distributions called an ambiguity set. The ambiguity set is constructed from disturbance data by leveraging a Dirichlet process mixture model that is self-adaptive to the underlying data structure and complexity. Specifically, the structural property of multimodality is exploited, so that the first- and second-order moment information of each mixture component is incorporated into the ambiguity set. A novel constraint tightening strategy is then developed based on an equivalent reformulation of distributionally robust CVaR constraints over the proposed ambiguity set. As more data are gathered during the runtime of the controller, the ambiguity set is updated online using real-time disturbance data, which enables the risk-averse stochastic MPC to cope with time-varying disturbance distributions. The online variational inference algorithm employed does not require all collected data be learned from scratch, and therefore the proposed MPC is endowed with the guaranteed computational complexity of online learning. The guarantees on recursive feasibility and closed-loop stability of the proposed MPC are established via a safe update scheme. Numerical examples are used to illustrate the effectiveness and advantages of the proposed MPC.},
  doi      = {10.1016/j.automatica.2020.109402},
  file     = {:FILES/2021 - Ning2021 - Online learning based risk-averse stochastic MPC of constrained linear uncertain systems.pdf:PDF},
  groups   = {identification-toread},
  keywords = {Online learning, Stochastic model predictive control, Distributionally robust chance constraints, Dirichlet process mixture model, Data-driven control},
  url      = {https://www.sciencedirect.com/science/article/pii/S000510982030604X},
}

@Article{Vau2021,
  author   = {Bernard Vau and Henri Bourlès},
  journal  = {Automatica},
  title    = {Closed-loop output error identification algorithms with predictors based on generalized orthonormal transfer functions: {Convergence} conditions and bias distribution},
  year     = {2021},
  issn     = {0005-1098},
  pages    = {109377},
  volume   = {125},
  abstract = {This paper proposes an improved version of closed-loop output-error identification algorithms, where the predictor is established on a generalized basis of orthonormal transfer functions. It is shown that the selection of the basis poles impacts the convergence conditions and the bias distribution of the schemes. These algorithms present several advantages: They are able to identify in closed-loop fast sampled systems, stiff systems (with modes spread over three decades or more), and reduced order models. Moreover, they are suitable for unstable systems or controllers. A simulation example shows the effectiveness of this approach. These algorithms can be employed in an open-loop context by using a straightforward simplification.},
  doi      = {10.1016/j.automatica.2020.109377},
  file     = {:FILES/2021 - Vau2021 - Closed-loop output error identification algorithms with predictors based on generalized orthonormal transfer functions- {Convergence} conditions and bias distribution.pdf:PDF},
  groups   = {identification-toread},
  keywords = {Closed-loop identification, Stiff systems identification, Orthonormal transfer functions bases},
  url      = {https://www.sciencedirect.com/science/article/pii/S0005109820305793},
}

@InProceedings{Behravan2017,
  author    = {Vahid Behravan and Gurjeet Singh and Patric Y. Chiang},
  booktitle = {2017 IEEE 2nd International Conference on Signal and Image Processing (ICSIP)},
  title     = {Adaptive compressive-sensing of {3D} point clouds},
  year      = {2017},
  address   = {Singapore},
  month     = aug,
  pages     = {188--192},
  abstract  = {In this paper we propose a mechanism for adaptive compressive-sensing of 3D point cloud. One problem with conventional compressive-sensing algorithm is a-priori fixed compression rate. In this work, we show that there is a correlation between sparsity of point cloud and number of edge points. The algorithm uses this information to estimate sparsity of input point cloud and adaptively change compression rate to achieve the same reconstruction error.},
  doi       = {10.1109/SIPROCESS.2017.8124530},
  file      = {:FILES/2017 - Behravan2017 - Adaptive compressive-sensing of 3D point clouds.pdf:PDF},
  groups    = {cloudpoint},
  keywords  = {compressed sensing;data compression;image reconstruction;3D point cloud;a-priori fixed compression rate;edge points;input point cloud;adaptive compressive-sensing algorithm;point cloud sparsity;Three-dimensional displays;Laser radar;Sensors;Image edge detection;Two dimensional displays;Image coding;Cameras;adaptive compressive-sensing;point cloud;LiDAR},
  priority  = {prio1},
  url       = {https://ieeexplore.ieee.org/abstract/document/8124530},
}

@InProceedings{Behravan2016,
  author    = {Vahid Behravan and Gurjeet Singh and Patrick Y. Chiang},
  booktitle = {2016 12th International Conference on Computational Intelligence and Security (CIS)},
  title     = {A framework for compressive-sensing of {3D} point clouds},
  year      = {2016},
  month     = {Dec},
  pages     = {69--72},
  abstract  = {In this paper we propose a framework for analyzing 3D point cloud data compression using compressive-sensing. This framework uses real 3D point clouds and investigates different error sources that may affect performance of the system. Experimental results show that excluding edge points from error calculation gives us better criteria to decide the best compression ratio in the system.},
  doi       = {10.1109/CIS.2016.0024},
  file      = {:FILES/2016 - Behravan2016 - A framework for compressive-sensing of 3D point clouds.pdf:PDF},
  groups    = {cloudpoint},
  keywords  = {compressed sensing;data analysis;data compression;optical radar;compressive-sensing;3D point cloud data compression ratio;error sources;LiDAR;Three-dimensional displays;Laser radar;Image coding;Image reconstruction;Image edge detection;Two dimensional displays;Sensors;compressive-sensing;point cloud;LiDAR},
}

@Misc{Javed2020,
  author        = {Mohammed Javed and {MD} Meraz and Pavan Chakraborty},
  title         = {A quick review on recent trends in {3D} point cloud data compression techniques and the challenges of direct processing in {3D} compressed domain},
  year          = {2020},
  archiveprefix = {arXiv},
  eprint        = {2007.05038},
  file          = {:FILES/2020 - Javed2020 -  quick review on recent trends in 3D point cloud data compression techniques and the challenges of direct processing in 3D compressed domain.pdf:PDF},
  groups        = {cloudpoint},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2007.05038},
}

@InProceedings{Stancic2016,
  author    = {Ivo Stan\v{c}i\'{c} and Milos Brajovi\'{c} and Irena Orovi\'{c} and Josip Musi\'{c}},
  booktitle = {2016 24th International Conference on Software, Telecommunications and Computer Networks (SoftCOM)},
  title     = {Compressive sensing for reconstruction of {3D} point clouds in smart systems},
  year      = {2016},
  address   = {Split, Croatia},
  month     = sep,
  pages     = {1--5},
  publisher = {IEEE},
  abstract  = {Performing an accurate 3D surface scan of everyday objects is sometimes difficult to achieve. Using the 3D scanner as a main sensor in a fast-moving mobile robot emphasizes this issue even further. When small robots with limited payload are considered, the professional Lidar systems are not likely to be embedded due to their weight, dimensions and/or high cost. Introduction of simple structured-light scanners makes possible fast scanning, effective robot detection and evasion of obstacles. Nevertheless, some obstacles may still be difficult to detect and recognize, primarily due to limitations of scanner's hardware which results in a low number of reconstructed surface points. In this paper a compressed sensing technique, primarily used for the reconstruction of 2D images, is utilized to enhance the quality of 3D scan, by increasing the number of reconstructed 3D points to the scanner's theoretical maximum. Obtained results demonstrated the feasibility of the approach in terms of mean square error.},
  doi       = {10.1109/SOFTCOM.2016.7772129},
  file      = {:FILES/2016 - Stancic2016 - Compressive sensing for reconstruction of 3D point clouds in smart systems.pdf:PDF},
  groups    = {cloudpoint},
  issn      = {1847-358X},
  keywords  = {compressed sensing;image reconstruction;mean square error methods;robot vision;compressive sensing;3D point cloud reconstruction;smart systems;3D scanner;mobile robot;structured-light scanners;robot detection;obstacle evasion;2D image reconstruction;3D scan quality;3D point reconstruction;mean square error;Cameras;Two dimensional displays;Three-dimensional displays;Image reconstruction;Robot sensing systems;Discrete cosine transforms},
  url       = {https://ieeexplore.ieee.org/document/7772129},
}


@Article{张习民2014,
  author  = {张习民 and 余小清 and 万旺根 and 张娟},
  journal = {应用科学学报},
  title   = {压缩感知点云数据压缩},
  year    = {2014},
  month   = dec,
  number  = {5},
  pages   = {458--462},
  volume  = {32},
  doi     = {10.3969/j.issn.0255-8297.2014.05.004},
  file    = {:FILES/2014 - 张习民2014 - 压缩感知点云数据压缩.pdf:PDF},
  groups  = {cloudpoint},
  url     = {http://d.wanfangdata.com.cn/periodical/yykxxb201405004},
}

@InCollection{Wang2020CS,
  author    = {Weiwei Wang and Hui Yuan and Hao Liu and Qi Liu},
  booktitle = {Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
  publisher = {Springer International Publishing},
  title     = {Compressive-sensing based codec of the {Y} color component for point cloud},
  year      = {2020},
  isbn      = {978-3-030-44750-2},
  pages     = {249--258},
  abstract  = {The point cloud obtained by the 3D laser scanner contains a very large amount of data, in order to transmit the point cloud data as much as possible with the limited bandwidth, the effective compression of point cloud data has become a problem that needs to be solved urgently nowadays. In this paper, we use the compressive sensing theory to compress and reconstruct one of the point features, that is, the Y color component, served as the signal. We also use the K-SVD algorithm to explore the signal’s sparsity according to its unique structural features, the K-SVD algorithm can learns a sparse basis matrix that is common to all point cloud models used in our experiments. For experimental results, we use rate-distortion metric. The results show that for each point cloud model, our method can achieve a higher probability to reconstruct the original data after compressed.},
  doi       = {10.1007/978-3-030-44751-9_22},
  file      = {:FILES/2020 - Wang2020CS - Compressive-sensing based codec of the Y color component for point cloud.pdf:PDF},
  groups    = {cloudpoint},
  keywords  = {Compressive sensing, K-SVD algorithm, Pointcloud},
  url       = {https://link.springer.com/chapter/10.1007/978-3-030-44751-9_22},
}

@Article{Salloum2018,
  author   = {Salloum, Maher and Fabian, Nathan D. and Hensinger, David M. and Lee, Jina and Allendorf, Elizabeth M. and Bhagatwala, Ankit and Blaylock, Myra L. and Chen, Jacqueline H. and Templeton, Jeremy A. and Tezaur, Irina},
  journal  = {Data Science and Engineering},
  title    = {Optimal compressed sensing and reconstruction of unstructured mesh datasets},
  year     = {2018},
  issn     = {2364-1541},
  month    = aug,
  number   = {1},
  pages    = {1--23},
  volume   = {3},
  abstract = {Exascale computing promises quantities of data too large to efficiently store and transfer across networks in order to be able to analyze and visualize the results. We investigate compressed sensing (CS) as an in situ method to reduce the size of the data as it is being generated during a large-scale simulation. CS works by sampling the data on the computational cluster within an alternative function space such as wavelet bases and then reconstructing back to the original space on visualization platforms. While much work has gone into exploring CS on structured datasets, such as image data, we investigate its usefulness for point clouds such as unstructured mesh datasets often found in finite element simulations. We sample using a technique that exhibits low coherence with tree wavelets found to be suitable for point clouds. We reconstruct using the stagewise orthogonal matching pursuit algorithm that we improved to facilitate automated use in batch jobs. We analyze the achievable compression ratios and the quality and accuracy of reconstructed results at each compression ratio. In the considered case studies, we are able to achieve compression ratios up to two orders of magnitude with reasonable reconstruction accuracy and minimal visual deterioration in the data. Our results suggest that, compared to other compression techniques, CS is attractive in cases where the compression overhead has to be minimized and where the reconstruction cost is not a significant concern.},
  doi      = {10.1007/s41019-017-0042-4},
  file     = {:FILES/2018 - Salloum2018 - Optimal compressed sensing and reconstruction of unstructured mesh datasets.pdf:PDF},
  groups   = {cloudpoint},
  url      = {https://doi.org/10.1007/s41019-017-0042-4},
}

@Article{Liu2019Point,
  author         = {Liu, Weiping and Sun, Jia and Li, Wanyi and Hu, Ting and Wang, Peng},
  journal        = {Sensors},
  title          = {Deep learning on point clouds and its application: {A} survey},
  year           = {2019},
  issn           = {1424-8220},
  number         = {19},
  volume         = {19},
  abstract       = {Point cloud is a widely used 3D data form, which can be produced by depth sensors, such as Light Detection and Ranging (LIDAR) and RGB-D cameras. Being unordered and irregular, many researchers focused on the feature engineering of the point cloud. Being able to learn complex hierarchical structures, deep learning has achieved great success with images from cameras. Recently, many researchers have adapted it into the applications of the point cloud. In this paper, the recent existing point cloud feature learning methods are classified as point-based and tree-based. The former directly takes the raw point cloud as the input for deep learning. The latter first employs a k-dimensional tree (Kd-tree) structure to represent the point cloud with a regular representation and then feeds these representations into deep learning models. Their advantages and disadvantages are analyzed. The applications related to point cloud feature learning, including 3D object classification, semantic segmentation, and 3D object detection, are introduced, and the datasets and evaluation metrics are also collected. Finally, the future research trend is predicted.},
  article-number = {4188},
  doi            = {10.3390/s19194188},
  file           = {:FILES/2019 - Liu2019Point - Deep learning on point clouds and its application- A survey.pdf:PDF},
  groups         = {cloudpoint},
  keywords       = {feature learning; deep learning; point cloud; application of point cloud},
  url            = {https://www.mdpi.com/1424-8220/19/19/4188},
}

@Article{OlivaresAlarcos2019,
  author    = {{Olivares-Alarcos}, Alberto and Be{\ss}ler, Daniel and Khamis, Alaa and Goncalves, Paulo and Habib, Maki K. and {Bermejo-Alonso}, Julita and Barreto, Marcos and Diab, Mohammed and Rosell, Jan and Quintas, Jo{\~{a}}o and Olszewska, Joanna and Nakawala, Hirenkumar and Pignaton, Edison and Gyrard, Amelie and Borgo, Stefano and Aleny\`{a}, Guillem and Beetz, Michael and Li, Howard},
  journal   = {The Knowledge Engineering Review},
  title     = {A review and comparison of ontology-based approaches to robot autonomy},
  year      = {2019},
  month     = dec,
  number    = {0},
  pages     = {1--29},
  volume    = {34},
  doi       = {10.1017/S0269888919000237},
  file      = {:FILES/2019 - OlivaresAlarcos2019 - A review and comparison of ontology-based approaches to robot autonomy.pdf:PDF},
  groups    = {robot},
  publisher = {Cambridge University Press},
  url       = {https://www.cambridge.org/core/journals/knowledge-engineering-review/article/abs/review-and-comparison-of-ontologybased-approaches-to-robot-autonomy/C0EF5777394264ABA95B28DBEA215FFF#metrics},
}

@Conference{Tenorth2012,
  author    = {Moritz Tenorth and Michael Beetz},
  booktitle = {2012 AAAI Spring Symposium Series},
  title     = {Knowledge processing for autonomous robot control},
  year      = {2012},
  address   = {Stanford University,},
  month     = mar,
  pages     = {1--7},
  abstract  = {Successfully accomplishing everyday manipulation tasks requires robots to have substantial knowledge about the objects they interact with, the environment they operate in as well as about the properties and effects of the actions they perform. Often, this knowledge is implicitly contained in manually written control programs, which makes it hard for the robot to adapt to newly acquired information or to re-use knowledge in a different context. By explicitly representing this knowledge, control decisions can be formulated as inference tasks which can be sent as queries to a knowledge base. This allows the robot to take all information it has at query time into account to generate answers, leading to better flexibility, adaptability to changing situations, robustness, and the ability to re-use knowledge once acquired. In this paper, we report on our work towards a practical and grounded knowledge representation and inference system. The system is specifically designed to meet the challenges created by using knowledge processing techniques on autonomous robots, including specialized inference methods, grounding of symbolic knowledge in the robot's control structures, and the acquisition of the different kinds of knowledge a robot needs.},
  file      = {:FILES/2012 - Tenorth2012 - Knowledge processing for autonomous robot control.pdf:PDF},
  groups    = {robot},
  keywords  = {Knowledge Representation; Robotics; Knowledge Acquisition},
  url       = {https://www.aaai.org/ocs/index.php/SSS/SSS12/paper/view/4258},
}

@InBook{Hertzberg2016,
  author    = {Hertzberg, Joachim and Chatila, Raja and Hertzberg, Joachim and Pecora, Federico},
  editor    = {Siciliano, Bruno and Khatib, Oussama},
  pages     = {207--223},
  publisher = {Springer Berlin Heidelberg},
  title     = {{AI} reasoning methods for robotics},
  year      = {2016},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-319-32550-7},
  abstract  = {Artificial intelligence (AI) reasoning technology involving, e.g., inference, planning, and learning, has a track record with a healthy number of successful applications. So, can it be used as a toolbox of methods for autonomous mobile robots? Not necessarily, as reasoning on a mobile robot about its dynamic, partially known environment may differ substantially from that in knowledge-based pure software systems, where most of the named successes have been registered.},
  booktitle = {Springer Handbook of Robotics},
  doi       = {10.1007/978-3-319-32552-1_14},
  file      = {:FILES/2016 - Hertzberg2016 - AI reasoning methods for robotics.pdf:PDF},
  groups    = {reasoning, robot},
  url       = {https://link.springer.com/chapter/10.1007/978-3-319-32552-1_14#citeas},
}

@Conference{Bessler2020,
  author    = {Daniel Be{\ss}ler and Robert Porzel and Pomarlan Mihai and Michael Beetz and Rainer Malaka and John Bateman},
  booktitle = {Proceedings of the 24th European Conference on Artificial Intelligence (ECAI)},
  title     = {A formal model of affordances for flexible robotic task execution},
  year      = {2020},
  address   = {Santiago de Compostela, Spain},
  pages     = {1--8},
  abstract  = {One of the key reasoning tasks of robotic agents is inferring possible actions that can be accomplished with a given object
at hand. This cognitive task is commonly referred to as inferring the
affordances of objects. In this paper, we propose a novel conceptualization of affordances and its realization as a description logic ontology. The key idea of the framework is that it proposes candidate
affordances through inference, and that these can then be validated
through physics-based simulation. We showcase the practical use of
our conceptualization by means of demonstrating what competency
questions an agent equipped with it can answer. The proposed formal model is implemented as a TBox OWL ontology of affordances
based on the DOLCE Ultra Light + DnS foundational ontology},
  file      = {:FILES/2020 - Bessler2020 - A formal model of affordances for flexible robotic task execution.pdf:PDF},
  groups    = {reasoning},
  url       = {https://digital.ecai2020.eu/accepted-papers-main-conference/},
}

@InProceedings{Schuster2012,
  author    = {Martin J. Schuster and Dominik Jain and Moritz Tenorth and Michael Beetz},
  booktitle = {2012 IEEE International Conference on Robotics and Automation},
  title     = {Learning organizational principles in human environments},
  year      = {2012},
  address   = {Saint Paul, MN, USA},
  month     = may,
  pages     = {3867--3874},
  publisher = {IEEE},
  abstract  = {In the context of robotic assistants in human everyday environments, pick and place tasks are beginning to be competently solved at the technical level. The question of where to place objects or where to pick them up from, among other higher-level reasoning tasks, is therefore gaining practical relevance. In this work, we consider the problem of identifying the organizational structure within an environment, i.e. the problem of determining organizational principles that would allow a robot to infer where to best place a particular, previously unseen object or where to reasonably search for a particular type of object given past observations about the allocation of objects to locations in the environment. This problem can be reasonably formulated as a classification task. We claim that organizational principles are governed by the notion of similarity and provide an empirical analysis of the importance of various features in datasets describing the organizational structure of kitchens. For the aforementioned classification tasks, we compare standard classification methods, reaching average accuracies of at least 79\% in all scenarios. We thereby show that, in particular, ontology-based similarity measures are well-suited as highly discriminative features. We demonstrate the use of learned models of organizational principles in a kitchen environment on a real robot system, where the robot identifies a newly acquired item, determines a suitable location and then stores the item accordingly.},
  doi       = {10.1109/ICRA.2012.6224553},
  file      = {:FILES/2012 - Schuster2012 - Learning organizational principles in human environments.pdf:PDF},
  groups    = {robot, reasoning},
  issn      = {1050-4729},
  keywords  = {control engineering computing;home automation;learning (artificial intelligence);mobile robots;ontologies (artificial intelligence);pattern classification;service robots;learning organizational principles;human environments;robotic assistants;human everyday environments;pick and place tasks;higher-level reasoning tasks;organizational structure;object allocation;kitchens;classification tasks;standard classification methods;ontology-based similarity measures;learned models;kitchen environment;real robot system;Software;Robots;Glass;Machine learning;Shape},
  url       = {https://ieeexplore.ieee.org/document/6224553},
}

@InProceedings{Kunze2012,
  author    = {Lars Kunze and Michael {Beetz} and Manabu {Saito} and Haseru {Azuma} and Kei {Okada} and Masayuki {Inaba}},
  booktitle = {2012 IEEE International Conference on Robotics and Automation},
  title     = {Searching objects in large-scale indoor environments: {A} decision-theoretic approach},
  year      = {2012},
  address   = {Saint Paul, MN, USA},
  month     = may,
  pages     = {4385--4390},
  abstract  = {Many of today's mobile robots are supposed to perform everyday manipulation tasks autonomously. However, in large-scale environments, a task-related object might be out of the robot's reach. Hence, the robot first has to search for the object in its environment before it can perform the task. In this paper, we present a decision-theoretic approach for searching objects in large-scale environments using probabilistic environment models and utilities associated with object locations. We demonstrate the feasibility of our approach by integrating it into a robot system and by conducting experiments where the robot is supposed to search different objects with various strategies in the context of fetch-and-delivery tasks within a multi-level building.},
  doi       = {10.1109/ICRA.2012.6224965},
  file      = {:FILES/2012 - Kunze2012 - Searching objects in large-scale indoor environments- A decision-theoretic approach.pdf:PDF},
  groups    = {robot},
  issn      = {1050-4729},
  keywords  = {decision theory;mobile robots;probability;large-scale indoor environment;mobile robot;manipulation task;task-related object;object search;decision-theoretic approach;probabilistic environment model;object location;robot system;fetch-and-delivery task;multilevel building;Robots;Search problems;Semantics;Elevators;Probabilistic logic;Databases},
  url       = {https://ieeexplore.ieee.org/document/6224965},
}

@InProceedings{Beetz2011,
  author    = {Michael {Beetz} and Ulrich {Klank} and Ingo {Kresse} and Alexis {Maldonado} and Lorenz {M\"{o}senlechner} and Dejan {Pangercic} and Thomas {R\"{u}hr} and Moritz {Tenorth}},
  booktitle = {2011 11th IEEE-RAS International Conference on Humanoid Robots},
  title     = {Robotic roommates making pancakes},
  year      = {2011},
  address   = {Bled, Slovenia},
  month     = oct,
  pages     = {529--536},
  publisher = {IEEE},
  abstract  = {In this paper we report on a recent public experiment that shows two robots making pancakes using web instructions. In the experiment, the robots retrieve instructions for making pancakes from the World Wide Web and generate robot action plans from the instructions. This task is jointly performed by two autonomous robots: The first robot opens and closes cupboards and drawers, takes a pancake mix from the refrigerator, and hands it to the robot B. The second robot cooks and flips the pancakes, and then delivers them back to the first robot. While the robot plans in the scenario are all percept-guided, they are also limited in different ways and rely on manually implemented sub-plans for parts of the task. We will thus discuss the potential of the underlying technologies as well as the research challenges raised by the experiment.},
  comment   = {using knowrob to make pancakes},
  doi       = {10.1109/Humanoids.2011.6100855},
  file      = {:FILES/2011 - Beetz2011 - Robotic roommates making pancakes.pdf:PDF},
  groups    = {robot},
  issn      = {2164-0580},
  keywords  = {humanoid robots;Internet;mobile robots;service robots;pancake making;autonomous robots;World Wide Web;Web instructions;robotic roommates;Containers;Knowledge based systems;Refrigerators;Robot kinematics;Three dimensional displays;Libraries},
  url       = {https://ieeexplore.ieee.org/document/6100855},
}

@InProceedings{Pangercic2010,
  author    = {Dejan {Pangercic} and Moritz {Tenorth} and Dominik {Jain} and Michael {Beetz}},
  booktitle = {2010 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  title     = {Combining perception and knowledge processing for everyday manipulation},
  year      = {2010},
  address   = {Taipei, Taiwan},
  month     = oct,
  pages     = {1065--1071},
  publisher = {IEEE},
  abstract  = {This paper describes and discusses the K-COPMAN (Knowledge-enabled Cognitive Perception for Manipulation) system, which enables autonomous robots to generate symbolic representations of perceived objects and scenes and to infer answers to complex queries that require the combination of perception and knowledge processing. Using K-COPMAN, the robot can solve inference tasks such as identifying items that are likely to be missing on a breakfast table. To the programmer K-COPMAN, is presented as a logic programming system that can be queried just like a symbolic knowledge base. Internally, K-COPMAN is realized through a data structure framework together with a library of state-of-the-art perception mechanisms for mobile manipulation in human environments. Key features of K-COPMAN are that it can make a robot environment-aware and that it supports goal-directed as well as passive perceptual processing. K-COPMAN is fully integrated into an autonomous mobile manipulation robot and is realized within the open-source robot library ROS.},
  doi       = {10.1109/IROS.2010.5651006},
  file      = {:FILES/2010 - Pangercic2010 - Combining perception and knowledge processing for everyday manipulation.pdf:PDF},
  groups    = {robot},
  issn      = {2153-0866},
  keywords  = {knowledge representation;logic programming;manipulators;mobile robots;query processing;visual perception;knowledge processing;symbolic representation;complex query;inference tasks;breakfast table;programmer K-CoPMAN;logic programming system;symbolic knowledge base;data structure framework;state-of-the-art perception mechanism;human environment;passive perceptual processing;autonomous mobile manipulation robot;open source robot library ROS;Robot sensing systems;Robot kinematics;Clouds;Servers;Cognition;Probabilistic logic},
  url       = {https://ieeexplore.ieee.org/document/5651006},
}

@InProceedings{Tenorth2012a,
  author    = {Moritz {Tenorth} and Alexander {Clifford Perzylo} and Reinhard {Lafrenz} and Michael {Beetz}},
  booktitle = {2012 IEEE International Conference on Robotics and Automation},
  title     = {The {RoboEarth} language: {Representing} and exchanging knowledge about actions, objects, and environments},
  year      = {2012},
  address   = {Saint Paul, MN, USA},
  month     = may,
  pages     = {1284--1289},
  publisher = {IEEE},
  abstract  = {The community-based generation of content has been tremendously successful in the World Wide Web - people help each other by providing information that could be useful to others. We are trying to transfer this approach to robotics in order to help robots acquire the vast amounts of knowledge needed to competently perform everyday tasks. RoboEarth is intended to be a web community by robots for robots to autonomously share descriptions of tasks they have learned, object models they have created, and environments they have explored. In this paper, we report on the formal language we developed for encoding this information and present our approaches to solve the inference problems related to finding information, to determining if information is usable by a robot, and to grounding it on the robot platform.},
  comment   = {using knowrob to exchange info between robots on serving a drink},
  doi       = {10.1109/ICRA.2012.6224812},
  file      = {:FILES/2012 - Tenorth2012a - The RoboEarth language- Representing and exchanging knowledge about actions, objects, and environments.pdf:PDF},
  groups    = {robot},
  issn      = {1050-4729},
  keywords  = {control engineering computing;formal languages;Internet;robots;RoboEarth language;community-based generation;content generation;World Wide Web;robotics;Web community;formal language;inference problems;robot platform;Robot kinematics;Solid modeling;Semantics;Ontologies;Navigation;Knowledge based systems},
  url       = {https://ieeexplore.ieee.org/document/6224812},
}

@Article{Beetz2012,
  author   = {Michael {Beetz} and Dominik {Jain} and Lorenz {Mosenlechner} and Moritz {Tenorth} and Lars {Kunze} and Nico {Blodow} and Dejan {Pangercic}},
  journal  = {Proceedings of the IEEE},
  title    = {Cognition-enabled autonomous robot control for the realization of home chore task intelligence},
  year     = {2012},
  issn     = {1558-2256},
  month    = aug,
  number   = {8},
  pages    = {2454--2471},
  volume   = {100},
  abstract = {This article gives an overview of cognition-enabled robot control, a computational model for controlling autonomous service robots to achieve home chore task intelligence. For the realization of task intelligence, this computational model puts forth three core principles, which essentially involve the combination of reactive behavior specifications represented as semantically interpretable plans with inference mechanisms that enable flexible decision making. The representation of behavior specifications as plans enables the robot to not only execute the behavior specifications but also to reason about them and alter them during execution. We provide a description of a complete system for cognition-enabled robot control that implements the three core principles, demonstrating the feasibility of our approach.},
  comment  = {CRAM:},
  doi      = {10.1109/JPROC.2012.2200552},
  file     = {:FILES/2012 - Beetz2012 - Cognition-enabled autonomous robot control for the realization of home chore task intelligence.pdf:PDF},
  groups   = {robot},
  keywords = {cognitive systems;decision making;home automation;inference mechanisms;intelligent robots;service robots;cognition-enabled autonomous robot control;home chore task intelligence realization;computational model;autonomous service robots;reactive behavior specifications;semantically interpretable plans;inference mechanisms;flexible decision making;behavior specification representation;behavior specification execution;Cognition;Robot control;Decision making;Robot sensing systems;Process control;Navigation;Service robots;Intelligent systems;Quality assessment;Behavioral science;Autonomous;computational model;reactive behavior;robot control;specifications;task intelligence},
  url      = {https://ieeexplore.ieee.org/document/6235978},
}

@Article{Tenorth2011a,
  author   = {Moritz {Tenorth} and Ulrich {Klank} and Dejan {Pangercic} and Michael {Beetz}},
  journal  = {IEEE Robotics Automation Magazine},
  title    = {Web-enabled robots},
  year     = {2011},
  issn     = {1558-223X},
  month    = jun,
  number   = {2},
  pages    = {58--68},
  volume   = {18},
  abstract = {In this article, we describe and discuss the use of information that is available in the World Wide Web and intended for human use as a knowledge resource for autonomous service robots. To this end, we introduce several categories of Web sites that can serve as information sources and explain which kinds of information they provide. We then investigate several information processing methods that can access these Web sites to provide robots with necessary knowledge for performing everyday manipulation tasks. The use of the Web as a knowledge resource is a promising alternative to the hard and tedious task of coding comprehensive specific knowledge bases for robots.},
  doi      = {10.1109/MRA.2011.940993},
  file     = {:FILES/2011 - Tenorth2011a - Web-enabled robots.pdf:PDF},
  groups   = {robot},
  keywords = {Internet;robots;Web-enabled robots;World Wide Web;knowledge resource;autonomous service robots;Web sites;information sources;information processing method;knowledge bases;Robot programmig;Knowledge engineering;Web sites;Human factors;Knowledge based systems;Solid modeling;Semantic Web},
  url      = {https://ieeexplore.ieee.org/document/5876223},
}

@Article{Beetz2010a,
  author    = {Beetz, Michael and Tenorth, Moritz and Jain, Dominik and Bandouch, Jan},
  journal   = {Technology and Disability},
  title     = {Towards automated models of activities of daily life},
  year      = {2010},
  issn      = {1878-643X},
  number    = {1-2},
  pages     = {27--40},
  volume    = {22},
  abstract  = {We propose automated probabilistic models of everyday activities (AM-EvA) as a novel technical means for the perception, interpretation, and analysis of everyday manipulation tasks and activities of daily life. AM-EvAs are detailed, comprehensive models describing human actions at various levels of abstraction from raw poses and trajectories to motions, actions and activities. They integrate several kinds of action models in a common, knowledge-based framework to combine observations of human activities with a-priori knowledge about actions. AM-EvAs enable robots and technical systems to analyze actions in the complete situation and activity context. They make the classification and assessment of actions and situations objective and can justify the probabilistic interpretation with respect to the activities the concepts have been learned from. AM-EvAs allow to analyze and compare the way humans perform actions which can help with autonomy assessment and diagnosis. We describe in this paper the concept and implementation of the AM-EvA system and show example results from the observation and analysis of table-setting episodes.},
  doi       = {10.3233/TAD-2010-0285},
  file      = {:FILES/2010 - Beetz2010a - Towards automated models of activities of daily life.pdf:PDF},
  groups    = {robot},
  keywords  = {Activity modeling, knowledge-based action analysis, human motion tracking},
  publisher = {IOS Press},
  url       = {https://content.iospress.com/articles/technology-and-disability/tad00285},
}

@InProceedings{Lemaignan2010,
  author    = {S\'{e}verin {Lemaignan} and Raquel {Ros} and Lorenz {M\"{o}senlechner} and Rachid {Alami} and Michael {Beetz}},
  booktitle = {2010 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  title     = {{ORO}, a knowledge management platform for cognitive architectures in robotics},
  year      = {2010},
  address   = {Taipei, Taiwan},
  month     = oct,
  pages     = {3548--3553},
  publisher = {IEEE},
  abstract  = {This paper presents an embeddable knowledge processing framework, along with a common-sense ontology, designed for robotics. We believe that a direct and explicit integration of cognition is a compulsory step to enable human-robots interaction in semantic-rich human environments like our houses. The OpenRobots Ontology (ORO) kernel allows to turn previously acquired symbols into concepts linked to each other. It enables in turn reasoning and the implementation of other advanced cognitive functions like events, categorization, memory management and reasoning on parallel cognitive models. We validate this framework on several cognitive scenarii that have been implemented on three different robotic architectures.},
  doi       = {10.1109/IROS.2010.5649547},
  file      = {:FILES/2010 - Lemaignan2010 - ORO, a knowledge management platform for cognitive architectures in robotics.pdf:PDF},
  groups    = {robot},
  issn      = {2153-0866},
  keywords  = {cognition;human-robot interaction;inference mechanisms;intelligent robots;knowledge management;ontologies (artificial intelligence);parallel architectures;knowledge management;ORO;OpenRobots ontology;cognitive architecture;knowledge processing;common sense ontology;human robots interaction;reasoning;parallel cognitive model;Robots;Humans;Ontologies;Cognition;Computer architecture;Games;Resource description framework},
  url       = {https://ieeexplore.ieee.org/document/5649547},
}

@InProceedings{Niles2001,
  author    = {Niles, Ian and Pease, Adam},
  booktitle = {Proceedings of the International Conference on Formal Ontology in Information Systems - Volume 2001},
  title     = {Towards a standard upper ontology},
  year      = {2001},
  address   = {New York, NY, USA},
  month     = oct,
  pages     = {2--9},
  publisher = {Association for Computing Machinery},
  series    = {FOIS '01},
  abstract  = {The Suggested Upper Merged Ontology (SUMO) is an upper level
ontology that has been proposed as a starter document for The
Standard Upper Ontology Working Group, an IEEE-sanctioned working
group of collaborators from the fields of engineering, philosophy,
and information science. The SUMO provides definitions for
general-purpose terms and acts as a foundation for more specific
domain ontologies. In this paper we outline the strategy used to
create the current version of the SUMO, discuss some of the
challenges that we faced in constructing the ontology, and describe
in detail its most general concepts and the relations between them.},
  doi       = {10.1145/505168.505170},
  groups    = {knowledge graph},
  isbn      = {1581133774},
  keywords  = {ontologies, knowledge interchange format},
  location  = {Ogunquit, Maine, USA},
  numpages  = {8},
  url       = {https://dl.acm.org/doi/abs/10.1145/505168.505170},
}

@InProceedings{Banko2007,
  author    = {Banko, Michele and Cafarella, Michael J. and Soderland, Stephen and Broadhead, Matt and Etzioni, Oren},
  booktitle = {Proceedings of the 20th International Joint Conference on Artifical Intelligence (IJCAI)},
  title     = {Open information extraction from the {Web}},
  year      = {2007},
  address   = {San Francisco, CA, USA},
  pages     = {2670--2676},
  publisher = {Morgan Kaufmann Publishers Inc.},
  abstract  = {Traditionally, Information Extraction (IE) has focused on satisfying precise, narrow, pre-specified requests from small homogeneous corpora (e.g., extract the location and time of seminars from a set of announcements). Shifting to a new domain requires the user to name the target relations and to manually create new extraction rules or hand-tag new training examples. This manual labor scales linearly with the number of target relations.This paper introduces Open IE (OIE), a new extraction paradigm where the system makes a single data-driven pass over its corpus and extracts a large set of relational tuples without requiring any human input. The paper also introduces TEXTRUNNER, a fully implemented, highly scalable OIE system where the tuples are assigned a probability and indexed to support efficient extraction and exploration via user queries.We report on experiments over a 9,000,000 Web page corpus that compare TEXTRUNNER with KNOWITALL, a state-of-the-art Web IE system. TEXTRUNNER achieves an error reduction of 33\% on a comparable set of extractions. Furthermore, in the amount of time it takes KNOWITALL to perform extraction for a handful of pre-specified relations, TEXTRUNNER extracts a far broader set of facts reflecting orders of magnitude more relations, discovered on the fly. We report statistics on TEXTRUNNER's 11,000,000 highest probability tuples, and show that they contain over 1,000,000 concrete facts and over 6,500,000 more abstract assertions.},
  file      = {:FILES/2007 - Banko2007 - Open information extraction from the {Web}.pdf:PDF},
  groups    = {knowledge graph},
  url       = {https://www.ijcai.org/Abstract/07/429},
}

@Article{Etzioni2008,
  author    = {Etzioni, Oren and Banko, Michele and Soderland, Stephen and Weld, Daniel S.},
  journal   = {Communications of the ACM},
  title     = {Open information extraction from the {Web}},
  year      = {2008},
  issn      = {0001-0782},
  month     = dec,
  number    = {12},
  pages     = {68--74},
  volume    = {51},
  abstract  = {Targeted IE methods are transforming into open-ended techniques.},
  address   = {New York, NY, USA},
  doi       = {10.1145/1409360.1409378},
  file      = {:FILES/2008 - Etzioni2008 - Open information extraction from the Web.pdf:PDF},
  groups    = {robot},
  publisher = {Association for Computing Machinery},
  url       = {https://dl.acm.org/doi/10.1145/1409360.1409378},
}

@InProceedings{Gupta2004,
  author    = {Gupta, Rakesh and Kochenderfer, Mykel J.},
  booktitle = {Proceedings of the 19th National Conference on Artifical Intelligence},
  title     = {Common sense data acquisition for indoor mobile robots},
  year      = {2004},
  address   = {San Jose, California},
  pages     = {605--610},
  publisher = {AAAI Press},
  series    = {AAAI'04},
  abstract  = {Common sense knowledge can be efficiently collected from non-experts over the web in a similar fashion to the Open Mind family of distributed knowledge capture projects. We describe the collection of common sense data through the Open Mind Indoor Common Sense (OMICS) website. We restrict the domain to indoor home and office environments to obtain dense knowledge. The knowledge was collected through sentence templates that were generated dynamically based on previous user input. Entries were converted into relations and saved into a database. We discuss the results of this online collaborative effort and describe two applications of the collected data to indoor mobile robots. We discuss active desire selection based on current beliefs and commands and a room-labeling application based on probability estimates from the common sense knowledge base.},
  file      = {:FILES/2004 - Gupta2004 - Common Sense Data Acquisition for Indoor Mobile Robots.pdf:PDF},
  groups    = {robot},
  isbn      = {0262511835},
  numpages  = {6},
  url       = {https://dl.acm.org/doi/10.5555/1597148.1597246},
}

@InProceedings{Kunze2011,
  author    = {Lars {Kunze} and Tobias {Roehm} and Michael {Beetz}},
  booktitle = {2011 IEEE International Conference on Robotics and Automation},
  title     = {Towards semantic robot description languages},
  year      = {2011},
  address   = {Shanghai, China},
  month     = may,
  pages     = {5589--5595},
  publisher = {IEEE},
  abstract  = {There is a semantic gap between simple but high-level action instructions like “Pick up the cup with the right hand” and low-level robot descriptions that model, for example, the structure and kinematics of a robot's manipulator. Currently, programmers bridge this gap by mapping abstract instructions to parametrized algorithms and rigid body parts of a robot within their control programs. By linking descriptions of robot components, i.e. sensors, actuators and control programs, via capabilities to actions in an ontology we equip robots with knowledge about themselves that allows them to infer the required components for performing a given action. Thereby a robot that is instructed by an end-user, a programmer, or even another robot to perform a certain action, can assess itself whether it is able and how to perform the requested action. This self-knowledge for robots could considerably change the way of robot control, robot interaction, robot programming, and multi-robot communication.},
  doi       = {10.1109/ICRA.2011.5980170},
  file      = {:FILES/2011 - Kunze2011 - Towards semantic robot description languages.pdf:PDF},
  groups    = {robot},
  issn      = {1050-4729},
  keywords  = {ontologies (artificial intelligence);programming language semantics;robot programming;semantic robot description languages;abstract instructions;rigid body parts;control programs;robot components;ontology;robot control;robot interaction;robot programming;multirobot communication;Robot sensing systems;Collision avoidance;Inference algorithms;Kinematics;Joints},
  url       = {https://ieeexplore.ieee.org/document/5980170},
}

@Article{Pierce1997,
  author   = {David Pierce and Benjamin J. Kuipers},
  journal  = {Artificial Intelligence},
  title    = {Map learning with uninterpreted sensors and effectors},
  year     = {1997},
  issn     = {0004-3702},
  number   = {1},
  pages    = {169--227},
  volume   = {92},
  abstract = {This paper presents a set of methods by which a learning agent can learn a sequence of increasingly abstract and powerful interfaces to control a robot whose sensorimotor apparatus and environment are initially unknown. The result of the learning is a rich hierarchical model of the robot's world (its sensorimotor apparatus and environment). The learning methods rely on generic properties of the robot's world such as almost-everywhere smooth effects of motor control signals on sensory features. At the lowest level of the hierarchy, the learning agent analyzes the effects of its motor control signals in order to define a new set of control signals, one for each of the robot's degrees of freedom. It uses a generate-and-test approach to define sensory features that capture important aspects of the environment. It uses linear regression to learn models that characterize context-dependent effects of the control signals on the learned features. It uses these models to define high-level control laws for finding and following paths defined using constraints on the learned features. The agent abstracts these control laws, which interact with the continuous environment, to a finite set of actions that implement discrete state transitions. At this point, the agent has abstracted the robot's continuous world to a finite-state world and can use existing methods to learn its structure. The learning agent's methods are evaluated on several simulated robots with different sensorimotor systems and environments.},
  doi      = {https://doi.org/10.1016/S0004-3702(96)00051-3},
  file     = {:FILES/1997 - Pierce1997 - Map learning with uninterpreted sensors and effectors.pdf:PDF},
  groups   = {unsorted},
  keywords = {Spatial semantic hierarchy, Map learning, Cognitive maps, Feature learning, Abstract interfaces, Action models, Changes of representation},
  url      = {https://www.sciencedirect.com/science/article/pii/S0004370296000513},
}

@Article{Sturm2009,
  author   = {J\"{u}rgen Sturm and Christian Plagemann and Wolfram Burgard},
  journal  = {Journal of Physiology-Paris},
  title    = {Body schema learning for robotic manipulators from visual self-perception},
  year     = {2009},
  issn     = {0928-4257},
  note     = {Neurorobotics},
  number   = {3},
  pages    = {220--231},
  volume   = {103},
  abstract = {We present an approach to learning the kinematic model of a robotic manipulator arm from scratch using self-observation via a single monocular camera. We introduce a flexible model based on Bayesian networks that allows a robot to simultaneously identify its kinematic structure and to learn the geometrical relationships between its body parts as a function of the joint angles. Further, we show how the robot can monitor the prediction quality of its internal kinematic model and how to adapt it when its body changes—for example due to failure, repair, or material fatigue. In experiments carried out both on real and simulated robotic manipulators, we verified the validity of our approach for real-world problems such as end-effector pose prediction and end-effector pose control.},
  doi      = {https://doi.org/10.1016/j.jphysparis.2009.08.005},
  file     = {:FILES/2009 - Sturm2009 - Body schema learning for robotic manipulators from visual self-perception.pdf:PDF},
  groups   = {unsorted},
  keywords = {Robotics, Machine learning, Self-perception, Sensor–motor learning, Body schema},
  url      = {https://www.sciencedirect.com/science/article/pii/S0928425709000461},
}

@InProceedings{Tenorth2012b,
  author    = {Moritz {Tenorth} and Michael {Beetz}},
  booktitle = {2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  title     = {A unified representation for reasoning about robot actions, processes, and their effects on objects},
  year      = {2012},
  address   = {Vilamoura-Algarve, Portugal},
  month     = oct,
  pages     = {1351--1358},
  publisher = {IEEE},
  abstract  = {Mobile manipulation robots are becoming more and more common and begin to extend their task spectrum towards more general housework activities. The sequence of actions needed to accomplish such tasks can be obtained from instructions on the Internet originally written for humans. While giving valuable information about the types of actions and some of their parameters, these instructions usually lack information that humans consider to be obvious. In this paper, we investigate how we can equip robots with sufficient knowledge and inference mechanisms to competently detect and fill such knowledge gaps in descriptions of everyday activities. We present methods for projecting the effects of actions and processes, for inferring action parameters like the objects and locations to be used, and introduce representations for reasoning about object transformations resulting from the effects of actions.},
  doi       = {10.1109/IROS.2012.6385529},
  file      = {:FILES/2012 - Tenorth2012b - A unified representation for reasoning about robot actions, processes, and their effects on objects.pdf:PDF},
  groups    = {robot},
  issn      = {2153-0866},
  keywords  = {inference mechanisms;Internet;mobile robots;path planning;service robots;unified reasoning representation;robot actions;robot process;mobile manipulation robots;general housework activities;Internet;inference mechanisms;robot knowledge;action parameters;object transformations;Ontologies;Propulsion},
  url       = {https://ieeexplore.ieee.org/document/6385529},
}

@InProceedings{Moesenlechner2010,
  author    = {Lorenz {M\"{o}senlechner} and Nikolaus {Demmel} and Michael {Beetz}},
  booktitle = {2010 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  title     = {Becoming action-aware through reasoning about logged plan execution traces},
  year      = {2010},
  address   = {Taipei, Taiwan},
  month     = oct,
  pages     = {2231--2236},
  publisher = {IEEE},
  abstract  = {Robots that know what they are doing can solve their tasks more reliably, flexibly, and efficiently. They can even explain what they were doing, how and why. In this paper we describe a system that not only is capable of executing flexible and reliable plans on a robotic platform but can also explain control decisions and the reason for specific actions, diagnose the cause of failures and answer queries about the robot's beliefs. For instance, when queried why it opened the cupboard door, the robot might answer that it did so because it believed Michael's cup to be in there. This type of reasoning is not only helpful for debugging but also provides the mechanisms for complex monitoring and failure handling that is not based on local failures and exception handling but on the expressive formulation of error patterns in first order logics. Our system is based on semantic annotations of plans, a fast logging mechanism and the computation of predicates in a first-order representation based on the execution trace.},
  doi       = {10.1109/IROS.2010.5650989},
  file      = {:FILES/2010 - Moesenlechner2010 - Becoming action-aware through reasoning about logged plan execution traces.pdf:PDF},
  groups    = {robot},
  issn      = {2153-0866},
  keywords  = {belief networks;cognitive systems;failure analysis;intelligent robots;program debugging;query processing;logged plan execution trace;flexible plan;reliable plan;robotic platform;failure diagnosis;query answering;complex monitoring;failure handling;first-order representation;action-aware robot;robot belief;program debugging;Navigation;Cognition;Data structures;Semantics;Process control;Robot control},
  url       = {https://ieeexplore.ieee.org/document/5650989/references#references},
}

@InProceedings{Kunze2010,
  author    = {Kunze, Lars and Tenorth, Moritz and Beetz, Michael},
  booktitle = {KI 2010: Advances in Artificial Intelligence},
  title     = {Putting people's common sense into knowledge bases of household robots},
  year      = {2010},
  address   = {Berlin, Heidelberg},
  editor    = {Dillmann, R{\"u}diger and Beyerer, J{\"u}rgen and Hanebeck, Uwe D. and Schultz, Tanja},
  pages     = {151--159},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Unlike people, household robots cannot rely on commonsense knowledge when accomplishing everyday tasks. We believe that this is one of the reasons why they perform poorly in comparison to humans. By integrating extensive collections of commonsense knowledge into mobile robot's knowledge bases, the work proposed in this paper enables robots to flexibly infer control decisions under changing environmental conditions. We present a system that converts commonsense knowledge from the large Open Mind Indoor Common Sense database from natural language into a Description Logic representation that allows for automated reasoning and for relating it to other sources of knowledge.},
  comment   = {Xie2015: Use patterns to transform short NL instructions in OMICS into internal rep. 只适用于phrases of some forms with poor extendibility.只从OMICS中提取知识},
  doi       = {10.1007/978-3-642-16111-7_17},
  file      = {:FILES/2010 - Kunze2010 - Putting people's common sense into knowledge bases of household robots.pdf:PDF},
  groups    = {robot, task understanding},
  isbn      = {978-3-642-16111-7},
  keywords  = {Ontological Concept, Everyday Task, Commonsense Knowledge, Causal Rule, Commonsense Reasoning},
  url       = {https://link.springer.com/chapter/10.1007/978-3-642-16111-7_17},
}

@Article{Waibel2011,
  author   = {Markus {Waibel} and Michael {Beetz} and Javier {Civera} and Raffaello {D'Andrea} and Jos {Elfring} and Dorian {G\'{a}lvez-L\'{o}pez} and Kai {H\"{a}ussermann} and Rob {Janssen} and J. M. M. {Montiel} and Alexander {Perzylo} and Bj\"{o}rn {Schie{\ss}le} and Moritz {Tenorth} and Oliver {Zweigle} and Ren\'{e} V. {De Molengraft}},
  journal  = {IEEE Robotics Automation Magazine},
  title    = {{RoboEarth}},
  year     = {2011},
  issn     = {1558-223X},
  month    = jun,
  number   = {2},
  pages    = {69--82},
  volume   = {18},
  abstract = {Humans can use the Internet to share knowledge and to help each other accomplish complex tasks. Until now, robots have not taken advantage of this opportunity. Sharing knowledge between robots requires methods to effectively encode, exchange, and reuse data. In this article, we present the design and first implementation of a system for sharing knowledge between robots.},
  doi      = {10.1109/MRA.2011.941632},
  file     = {:FILES/2011 - Waibel2011 - RoboEarth.pdf:PDF},
  groups   = {robot},
  keywords = {control engineering computing;Internet;knowledge management;multi-robot systems;RoboEarth;Internet;knowledge sharing;robots;Robot kinematics;Robot sensing systems;Service robots;Distributed databases;Semantics;Information exchange;Knowledge transfer},
  url      = {https://ieeexplore.ieee.org/document/5876227/authors#authors},
}

@Article{Sterling1987,
  author   = {Leon {Sterling} and Ehud {Shapiro} and Randy {Garrett}},
  journal  = {IEEE Expert},
  title    = {The art of {Prolog}},
  year     = {1987},
  issn     = {2374-9407},
  month    = jun,
  number   = {2},
  pages    = {106--107},
  volume   = {2},
  doi      = {10.1109/MEX.1987.4307074},
  file     = {:FILES/1987 - Sterling1987 - The art of Prolog.pdf:PDF},
  groups   = {representation},
  keywords = {Book reviews},
  url      = {https://ieeexplore.ieee.org/document/4307074},
}

@Book{Getoor2007,
  author    = {Getoor, Lise and Taskar, Ben},
  publisher = {The MIT Press},
  title     = {Introduction to statistical relational learning},
  year      = {2007},
  isbn      = {0262072882},
  groups    = {representation},
}

@Article{Beckett2004,
  author  = {Beckett, Dave and Mcbride, Brian},
  journal = {W3C Recommendation},
  title   = {{RDF/XML} syntax specification},
  year    = {2004},
  month   = jan,
  volume  = {10},
  groups  = {representation},
}

@TechReport{Motik2012,
  author      = {Boris Motik and Peter F. Patel-Schneider and Bijan Parsia},
  institution = {W3C},
  title       = {{OWL} 2 web ontology language: {Structural} specification and functional-style},
  year        = {2012},
  month       = dec,
  file        = {:FILES/2012 - Motik2012 - OWL 2 web ontology language- Structural specification and functional-style.pdf:PDF},
  groups      = {representation},
  url         = {https://www.w3.org/TR/2012/REC-owl2-syntax-20121211/},
}

@InProceedings{Matuszek2006,
  author = {Matuszek, Cynthia and Cabral, John and Witbrock, Michael and DeOliveira, John},
  title  = {An introduction to the syntax and content of {Cyc}},
  year   = {2006},
  month  = {01},
  pages  = {44-49},
  file   = {:FILES/2006 - Matuszek2006 - An introduction to the syntax and content of Cyc.pdf:PDF},
  groups = {representation},
}

@InProceedings{Fahlman2006,
  author    = {Fahlman, Scott E.},
  booktitle = {Knowledge Science, Engineering and Management},
  title     = {Marker-passing inference in the {Scone} knowledge-base system},
  year      = {2006},
  address   = {Berlin, Heidelberg},
  editor    = {Lang, J{\'e}r{\^o}me and Lin, Fangzhen and Wang, Ju},
  pages     = {114--126},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {The Scone knowledge-base system, currently being developed at Carnegie Mellon University, implements search and inference operations using a set of marker-passing algorithms. These were originally designed for a massively parallel hardware architecture but now are implemented completely in software. The algorithms are fast, relatively simple, and they support efficient implementation of the most heavily used KB features. This paper describes these marker-passing algorithms, their strengths and limitations, and how they are used in Scone.},
  doi       = {10.1007/11811220_11},
  file      = {:FILES/2006 - Fahlman2006 - Marker-passing inference in the Scone knowledge-base system.pdf:PDF},
  groups    = {representation},
  isbn      = {978-3-540-37035-2},
  url       = {https://link.springer.com/chapter/10.1007/11811220_11},
}

@InProceedings{Tenorth2010,
  author     = {Moritz {Tenorth} and Daniel {Nyga} and Michael {Beetz}},
  booktitle  = {Proceedings of the 2010 IEEE International Conference on Robotics and Automation (ICRA)},
  title      = {Understanding and executing instructions for everyday manipulation tasks from the {World Wide Web}},
  year       = {2010},
  address    = {Anchorage, AK, USA},
  month      = may,
  pages      = {1486--1491},
  publisher  = {IEEE},
  abstract   = {Service robots will have to accomplish more and more complex, open-ended tasks and regularly acquire new skills. In this work, we propose a new approach to the problem of generating plans for such household robots. Instead composing them from atomic actions - the common approach in robot planning - we propose to transform task descriptions on web sites like ehow.com into executable robot plans. We present methods for automatically converting the instructions from natural language into a formal, logic-based representation, for resolving the word senses using the WordNet database and the Cyc ontology, and for exporting the generated plans into the mobile robot's plan language RPL. We discuss the problem of inferring information that is missing in these descriptions and the problem of grounding the abstract task descriptions in the perception and action system, and we propose techniques for solving them. The whole system works autonomously without human interaction. It has successfully been tested with a set of about 150 natural language directives, of which up to 80\% could be correctly transformed.},
  comment    = {疑问：1. word sense disambiguation的算法没有说具体如何实现的。2. 【13】关于虚拟场景的建立。
Ji2016: NL instructions from web to generate plan},
  doi        = {10.1109/ROBOT.2010.5509955},
  file       = {:FILES/2010 - Tenorth2010 - Understanding and executing instructions for everyday manipulation tasks from the World Wide Web.pdf:PDF},
  groups     = {robot, task understanding},
  issn       = {1050-4729},
  keywords   = {control engineering computing;Internet;mobile robots;ontologies (artificial intelligence);service robots;manipulation task;World Wide Web;service robot;household robot;robot planning;logic-based representation;WordNet database;Cyc ontology;mobile robot;RPL;abstract task description;natural language;Web sites;Robot sensing systems;Robotics and automation;Natural languages;Service robots;Databases;Ontologies;Mobile robots;Grounding;Humans, read},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/5509955/citations#citations},
}

@Article{Zhou2021,
  author   = {Yuren {Zhou} and Yi {Xiang} and Xiaoyu {He}},
  journal  = {IEEE Transactions on Evolutionary Computation},
  title    = {Constrained multiobjective optimization: {Test} problem construction and performance evaluations},
  year     = {2021},
  issn     = {1941-0026},
  month    = feb,
  number   = {1},
  pages    = {172--186},
  volume   = {25},
  abstract = {Constrained multiobjective optimization abounds in practical applications and is gaining growing attention in the evolutionary computation community. Artificial test problems are critical to the progress in this research area. Nevertheless, many of them lack important characteristics, such as scalability and variable dependencies, which may be essential in benchmarking modern evolutionary algorithms. This article first proposes a new framework for constrained test problem construction. This framework splits a decision vector into position and distance variables and forces their optimal values to lie on a nonlinear hypersurface such that the interdependencies can be introduced among the position ones and among the distance ones individually. In this framework, two kinds of constraints are designed to introduce convergence-hardness and diversity-hardness, respectively. The first kind introduces infeasible barriers in approaching the optima, and at the same time, makes the position and distance variables interrelate with each other. The second kind restricts the feasible optimal regions such that different shapes of Pareto fronts can be obtained. Based on this framework, we construct 16 scalable and constrained test problems covering a variety of difficulties. Then, in the second part of this article, we evaluate the performance of some state of the art on the proposed test problems, showing that they are quite challenging and there is room for further enhancement of the existing algorithms. Finally, we discuss in detail the source of difficulties presented in these new problems.},
  doi      = {10.1109/TEVC.2020.3011829},
  file     = {:FILES/2021 - Zhou2021 - Constrained multiobjective optimization- Test problem construction and performance evaluations.pdf:PDF},
  groups   = {multi-objective},
  keywords = {Optimization;Evolutionary computation;Shape;Maintenance engineering;Performance evaluation;Benchmark testing;Convergence;Constraint optimization;evolutionary algorithms;local search;multi/many-objective optimization},
  url      = {https://ieeexplore.ieee.org/document/9149679},
}

@Article{Hao2021,
  author   = {Xingxing {Hao} and Rong {Qu} and Jing {Liu}},
  journal  = {IEEE Transactions on Evolutionary Computation},
  title    = {A unified framework of graph-based evolutionary multitasking hyper-heuristic},
  year     = {2021},
  issn     = {1941-0026},
  month    = feb,
  number   = {1},
  pages    = {35--47},
  volume   = {25},
  abstract = {In recent research, hyper-heuristics have attracted increasing attention in various fields. The most appealing feature of hyper-heuristics is that they aim to provide more generalized solutions to optimization problems by searching in a high-level space of heuristics instead of direct problem domains. Despite the promising findings in hyper-heuristics, the design of more general search methodologies still presents a key research. Evolutionary multitasking is a relatively new evolutionary paradigm which attempts to solve multiple optimization problems simultaneously. It exploits the underlying similarities among different optimization tasks by transferring information among them, thus accelerating the optimization of all tasks. Inherently, hyper-heuristics and evolutionary multitasking are similar in the following three ways: 1) they both operate on third-party search spaces; 2) high-level search methodologies are universal; and 3) they both conduct cross-domain optimization. To integrate their advantages effectively, i.e., the knowledge-transfer and cross-domain optimization of evolutionary multitasking and the search in the heuristic spaces of hyper-heuristics, in this article, a unified framework of evolutionary multitasking graph-based hyper-heuristic (EMHH) is proposed. To assess the generality and effectiveness of the EMHH, population-based graph-based hyper-heuristics integrated with evolutionary multitasking to solve exam timetabling and graph-coloring problems, separately and simultaneously, are studied. The experimental results demonstrate the effectiveness, efficiency, and increased the generality of the proposed unified framework compared with single-tasking hyper-heuristics.},
  doi      = {10.1109/TEVC.2020.2991717},
  file     = {:FILES/2021 - Hao2021 - A unified framework of graph-based evolutionary multitasking hyper-heuristic.pdf:PDF},
  groups   = {multi-objective},
  keywords = {Optimization;Task analysis;Multitasking;Schedules;Search problems;Scheduling;Linear programming;Evolutionary multitasking;exam timetabling;graph coloring;hyper-heuristics},
  url      = {https://ieeexplore.ieee.org/document/9084121},
}

@Article{Blank2021,
  author   = {Julian {Blank} and Kalyanmoy {Deb} and Yashesh {Dhebar} and Sunith {Bandaru} and Haitham {Seada}},
  journal  = {IEEE Transactions on Evolutionary Computation},
  title    = {Generating well-spaced points on a unit simplex for evolutionary many-objective optimization},
  year     = {2021},
  issn     = {1941-0026},
  month    = feb,
  number   = {1},
  pages    = {48--60},
  volume   = {25},
  abstract = {Most evolutionary many-objective optimization (EMaO) algorithms start with a description of a number of the predefined set of reference points on a unit simplex. So far, most studies have used the Das and Dennis’s structured approach for generating well-spaced reference points. Due to the highly structured nature of the procedure, this method cannot produce an arbitrary number of points, which is desired in an EMaO application. Although a layer-wise implementation has been suggested, EMO researchers always felt the need for a more generic approach. Motivated by earlier studies, we introduce a metric for defining well-spaced points on a unit simplex and propose a number of viable methods for generating such a set. We compare the proposed methods on a variety of performance metrics such as hypervolume (HV), deviation in triangularized simplices, distance of the closest point pair, and variance of the geometric means to nearest neighbors in up to 15-D spaces. We show that an iterative improvement based on Riesz  $s$ -energy is able to effectively find an arbitrary number of well-spaced points even in higher-dimensional spaces. Reference points created using the proposed Riesz  $s$ -energy method for a number of standard combinations of objectives and reference points as well as a source code written in Python are available publicly at https://www.egr.msu.edu/coinlab/blankjul/uniform.},
  doi      = {10.1109/TEVC.2020.2992387},
  file     = {:FILES/2021 - Blank2021 - Generating well-spaced points on a unit simplex for evolutionary many-objective optimization.pdf:PDF},
  groups   = {multi-objective},
  keywords = {Hypercubes;Optimization;Measurement;Indexes;Computational modeling;Sociology;Statistics;Das–Dennis points;diversity preservation;many-objective optimization;reference points;Riesz s-energy},
  url      = {https://ieeexplore.ieee.org/document/9086772/media#media},
}

@Article{Tian2021,
  author   = {Ye {Tian} and Tao {Zhang} and Jianhua {Xiao} and Xingyi {Zhang} and Yaochu {Jin}},
  journal  = {IEEE Transactions on Evolutionary Computation},
  title    = {A coevolutionary framework for constrained multiobjective optimization problems},
  year     = {2021},
  issn     = {1941-0026},
  month    = feb,
  number   = {1},
  pages    = {102--116},
  volume   = {25},
  abstract = {Constrained multiobjective optimization problems (CMOPs) are challenging because of the difficulty in handling both multiple objectives and constraints. While some evolutionary algorithms have demonstrated high performance on most CMOPs, they exhibit bad convergence or diversity performance on CMOPs with small feasible regions. To remedy this issue, this article proposes a coevolutionary framework for constrained multiobjective optimization, which solves a complex CMOP assisted by a simple helper problem. The proposed framework evolves one population to solve the original CMOP and evolves another population to solve a helper problem derived from the original one. While the two populations are evolved by the same optimizer separately, the assistance in solving the original CMOP is achieved by sharing useful information between the two populations. In the experiments, the proposed framework is compared to several state-of-the-art algorithms tailored for CMOPs. High competitiveness of the proposed framework is demonstrated by applying it to 47 benchmark CMOPs and the vehicle routing problem with time windows.},
  doi      = {10.1109/TEVC.2020.3004012},
  file     = {:FILES/2021 - Tian2021 - A coevolutionary framework for constrained multiobjective optimization problems.pdf:PDF},
  groups   = {multi-objective},
  keywords = {Sociology;Statistics;Optimization;Constraint handling;Evolutionary computation;Convergence;Vehicle routing;Coevolution;constrained multiobjective optimization;evolutionary algorithm;vehicle routing problem},
  url      = {https://ieeexplore.ieee.org/document/9122020},
}

@Article{Yu2021,
  author   = {Guo {Yu} and Yaochu {Jin} and Markus {Olhofer}},
  journal  = {IEEE Transactions on Evolutionary Computation},
  title    = {A multiobjective evolutionary algorithm for finding knee regions using two localized dominance relationships},
  year     = {2021},
  issn     = {1941-0026},
  month    = feb,
  number   = {1},
  pages    = {145--158},
  volume   = {25},
  abstract = {In preference-based optimization, knee points are considered the naturally preferred tradeoff solutions, especially when the decision maker has little a priori knowledge about the problem to be solved. However, identifying all convex knee regions of a Pareto front remains extremely challenging, in particular in a high-dimensional objective space. This article presents a new evolutionary multiobjective algorithm for locating knee regions using two localized dominance relationships. In the environmental selection, the  $\alpha $ -dominance is applied to each subpopulation partitioned by a set of predefined reference vectors, thereby guiding the search toward different potential knee regions while removing possible dominance resistant solutions. A knee-oriented-dominance measure making use of the extreme points is then proposed to detect knee solutions in convex knee regions and discard solutions in concave knee regions. Our experimental results demonstrate that the proposed algorithm outperforms the state-of-the-art knee identification algorithms on a majority of multiobjective optimization test problems having up to eight objectives and a hybrid electric vehicle controller design problem with seven objectives.},
  doi      = {10.1109/TEVC.2020.3008877},
  file     = {:FILES/2021 - Yu2021 - A multiobjective evolutionary algorithm for finding knee regions using two localized dominance relationships.pdf:PDF},
  groups   = {multi-objective},
  keywords = {Pareto optimization;Convergence;Resistance;Sociology;Evolutionary computation;α-dominance;knee-oriented dominance;knees;multiobjective evolutionary optimization;preference},
  url      = {https://ieeexplore.ieee.org/document/9139367},
}

@Article{Yang2021,
  author   = {Ming {Yang} and Aimin {Zhou} and Changhe {Li} and Xin {Yao}},
  journal  = {IEEE Transactions on Evolutionary Computation},
  title    = {An efficient recursive differential grouping for large-scale continuous problems},
  year     = {2021},
  issn     = {1941-0026},
  month    = feb,
  number   = {1},
  pages    = {159--171},
  volume   = {25},
  abstract = {Cooperative co-evolution (CC) is an efficient and practical evolutionary framework for solving large-scale optimization problems. The performance of CC is affected by the variable decomposition. An accurate variable decomposition can help to improve the performance of CC on solving an optimization problem. The variable grouping methods usually spend many computational resources obtaining an accurate variable decomposition. To reduce the computational cost on the decomposition, we propose an efficient recursive differential grouping (ERDG) method in this article. By exploiting the historical information on examining the interrelationship between the variables of an optimization problem, ERDG is able to avoid examining some interrelationship and spend much less computation than other recursive differential grouping methods. Our experimental results and analysis suggest that ERDG is a competitive method for decomposing large-scale continuous problems and improves the performance of CC for solving the large-scale optimization problems.},
  doi      = {10.1109/TEVC.2020.3009390},
  file     = {:FILES/2021 - Yang2021 - An efficient recursive differential grouping for large-scale continuous problems.pdf:PDF},
  groups   = {multi-objective},
  keywords = {Optimization;Computational efficiency;Geology;Computer science;Electronic mail;Computational complexity;Automation;Cooperative co-evolution (CC);decomposition;large-scale global optimization},
  url      = {https://ieeexplore.ieee.org/document/9141328},
}

@Article{Richardson2006,
  author   = {Richardson, Matthew and Domingos, Pedro},
  journal  = {Machine Learning},
  title    = {Markov logic networks},
  year     = {2006},
  issn     = {1573-0565},
  month    = jan,
  number   = {1},
  pages    = {107--136},
  volume   = {62},
  abstract = {We propose a simple approach to combining first-order logic and probabilistic graphical models in a single representation. A Markov logic network (MLN) is a first-order knowledge base with a weight attached to each formula (or clause). Together with a set of constants representing objects in the domain, it specifies a ground Markov network containing one feature for each possible grounding of a first-order formula in the KB, with the corresponding weight. Inference in MLNs is performed by MCMC over the minimal subset of the ground network required for answering the query. Weights are efficiently learned from relational databases by iteratively optimizing a pseudo-likelihood measure. Optionally, additional clauses are learned using inductive logic programming techniques. Experiments with a real-world database and knowledge base in a university domain illustrate the promise of this approach.},
  doi      = {10.1007/s10994-006-5833-1},
  file     = {:FILES/2006 - Richardson2006 - Markov logic networks.pdf:PDF},
  groups   = {reasoning},
  url      = {https://doi.org/10.1007/s10994-006-5833-1},
}

@TechReport{Jain2009,
  author      = {Dominik Jain and Stefan Waldherr and Michael Beetz},
  institution = {{IAS} Group, Fakult\"{a}t f\"{u}r Informatik, Technische Universit\"{a}t M\"{u}nchen},
  title       = {{Bayesian} logic networks},
  year        = {2009},
  file        = {:FILES/2009 - Jain2009 - Bayesian logic networks.pdf:PDF},
  groups      = {reasoning},
  url         = {https://ias.in.tum.de/people/beetz?key=jain09blns},
}

@Article{Sirin2007,
  author   = {Evren Sirin and Bijan Parsia and Bernardo Cuenca Grau and Aditya Kalyanpur and Yarden Katz},
  journal  = {Journal of Web Semantics},
  title    = {Pellet: {A} practical {OWL-DL} reasoner},
  year     = {2007},
  issn     = {1570-8268},
  month    = jun,
  note     = {Software Engineering and the Semantic Web},
  number   = {2},
  pages    = {51--53},
  volume   = {5},
  abstract = {In this paper, we present a brief overview of Pellet: a complete OWL-DL reasoner with acceptable to very good performance, extensive middleware, and a number of unique features. Pellet is the first sound and complete OWL-DL reasoner with extensive support for reasoning with individuals (including nominal support and conjunctive query), user-defined datatypes, and debugging support for ontologies. It implements several extensions to OWL-DL including a combination formalism for OWL-DL ontologies, a non-monotonic operator, and preliminary support for OWL/Rule hybrid reasoning. Pellet is written in Java and is open source.},
  comment  = {DL reasoner},
  doi      = {10.1016/j.websem.2007.03.004},
  file     = {:FILES/2007 - Sirin2007 - Pellet- A practical OWL-DL reasoner.pdf:PDF},
  groups   = {reasoning},
  keywords = {Web Ontology Language, Description logics, Tableau Theorem Proving},
  url      = {https://www.sciencedirect.com/science/article/pii/S1570826807000169},
}

@InProceedings{Shearer2008,
  author    = {Shearer, Rob and Motik, Boris and Horrocks, Ian},
  booktitle = {Proceedings of the Fifth OWLED Workshop on OWL: Experiences and Directions, collocated with the 7th International Semantic Web Conference (ISWC-2008)},
  title     = {{HermiT}: {A} highly-efficient {OWL} reasoner},
  year      = {2008},
  address   = {Karlsruhe, Germany},
  month     = jan,
  pages     = {1--10},
  volume    = {432},
  file      = {:FILES/2008 - Shearer2008 - HermiT- A highly-efficient OWL reasoner.pdf:PDF},
  groups    = {reasoning},
}

@InProceedings{Haarslev2001,
  author    = {Haarslev, Volker and M\"{o}ller, Ralf},
  booktitle = {Automated Reasoning},
  title     = {{RACER} system description},
  year      = {2001},
  address   = {Berlin, Heidelberg},
  editor    = {Gor\'{e}, Rajeev and Leitsch, Alexander and Nipkow, Tobias},
  pages     = {701--705},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {RACER implements a TBox and ABox reasoner for the logic SℌIQ. RACER was the first full-fledged ABox description logic system for a very expressive logic and is based on optimized sound and complete algorithms. RACER also implements a decision procedure for modal logic satisfability problems (possibly with global axioms).},
  file      = {:FILES/2001 - Haarslev2001 - RACER system description.pdf:PDF},
  groups    = {reasoning},
  isbn      = {978-3-540-45744-2},
  url       = {https://link.springer.com/chapter/10.1007/3-540-45744-5_59},
}

@InProceedings{Vassiliadis2009,
  author    = {Vassiliadis, Vangelis and Wielemaker, Jan and Mungall, Chris},
  booktitle = {Proceedings of the 6th International Conference on OWL: Experiences and Directions - Volume 529},
  title     = {Processing {OWL2} ontologies using {Thea}: {An} application of logic programming},
  year      = {2009},
  address   = {Aachen, DEU},
  pages     = {89–-98},
  publisher = {CEUR-WS.org},
  series    = {OWLED'09},
  abstract  = {Traditional object-oriented programming languages can be difficult to use when working with ontologies, leading to the creation of domain-specific languages designed specifically for ontology processing. Prolog, with its logic-based, declarative semantics offers many advantages as a host programming language for querying and processing OWL2 ontologies. The SWI-Prolog semweb library provides some support for OWL but until now there has been a lack of any library providing direct and comprehensive support for OWL2.We have developed Thea, a library based directly on the OWL2 functional-style syntax, allowing storage and manipulation of axioms as a Prolog database. Thea can translate ontologies to Description Logic programs but the emphasis is on using Prolog as an application programming and processing language rather than a reasoning engine. Thea offers the ability to seamless connect to the java OWL API and OWLLink servers. Thea also includes support for SWRL.In this paper we provide examples of using Thea for processing ontologies, and compare the results to alternative methods. Thea is available from GitHub: http://github.com/vangelisv/thea.},
  comment   = {Proglog library for reasoning},
  file      = {:FILES/2009 - Vassiliadis2009 - Processing OWL2 ontologies using Thea- An application of logic programming.pdf:PDF},
  groups    = {reasoning},
  location  = {Chantilly, VA},
  numpages  = {10},
  url       = {https://dl.acm.org/doi/10.5555/2890046.2890056},
}

@Book{Bishop2006,
  author    = {Christopher M. Bishop},
  publisher = {Springer-Verlag New York},
  title     = {Pattern recognition and machine learning},
  year      = {2006},
  isbn      = {9780387310732},
  series    = {Information science and statistics},
  groups    = {reasoning},
  url       = {https://www.springer.com/cn/book/9780387310732},
}

@InProceedings{Pangercic2011,
  author    = {Dejan Pangercic and Vladimir Haltakov and Michael Beetz},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Workshop on Active Semantic Perception and Object Search in the Real World},
  title     = {Fast and robust object detection in household environments using vocabulary trees with {SIFT} descriptors},
  year      = {2011},
  address   = {San Francisco, CA, USA},
  month     = sep,
  publisher = {IEEE},
  comment   = {这篇文章在官网上没有，是改写成期刊文章了还是撤稿了？还是workshop文章不检索？},
  file      = {:FILES/2011 - Pangercic2011 - Fast and robust object detection in household environments using vocabulary trees with SIFT descriptors.pdf:PDF},
  groups    = {robot},
}

@InProceedings{Thielscher2000,
  author    = {Thielscher, Michael},
  booktitle = {Proceedings of the Seventh International Conference on Principles of Knowledge Representation and Reasoning},
  title     = {Representing the knowledge of a robot},
  year      = {2000},
  address   = {San Francisco, CA, USA},
  pages     = {109--120},
  publisher = {Morgan Kaufmann Publishers Inc.},
  series    = {KR'00},
  file      = {:FILES/2000 - Thielscher2000 - Representing the knowledge of a robot.pdf:PDF},
  groups    = {robot},
  location  = {Breckenridge, Colorado, USA},
  url       = {https://dl.acm.org/doi/10.5555/3087011.3087024},
}

@Article{Rusu2008,
  author   = {Radu Bogdan Rusu and Zoltan Csaba Marton and Nico Blodow and Mihai Dolha and Michael Beetz},
  journal  = {Robotics and Autonomous Systems},
  title    = {Towards {3D} point cloud based object maps for household environments},
  year     = {2008},
  issn     = {0921-8890},
  note     = {Semantic Knowledge in Robotics},
  number   = {11},
  pages    = {927--941},
  volume   = {56},
  abstract = {This article investigates the problem of acquiring 3D object maps of indoor household environments, in particular kitchens. The objects modeled in these maps include cupboards, tables, drawers and shelves, which are of particular importance for a household robotic assistant. Our mapping approach is based on PCD (point cloud data) representations. Sophisticated interpretation methods operating on these representations eliminate noise and resample the data without deleting the important details, and interpret the improved point clouds in terms of rectangular planes and 3D geometric shapes. We detail the steps of our mapping approach and explain the key techniques that make it work. The novel techniques include statistical analysis, persistent histogram features estimation that allows for a consistent registration, resampling with additional robust fitting techniques, and segmentation of the environment into meaningful regions.},
  doi      = {https://doi.org/10.1016/j.robot.2008.08.005},
  file     = {:FILES/2008 - Rusu2008 - Towards 3D point cloud based object maps for household environments.pdf:PDF},
  groups   = {robot},
  keywords = {Environment object model, Point cloud data, Geometrical reasoning},
  url      = {https://www.sciencedirect.com/science/article/pii/S0921889008001140},
}

@Article{Vasudevan2008,
  author   = {Shrihari Vasudevan and Roland Siegwart},
  journal  = {Robotics and Autonomous Systems},
  title    = {Bayesian space conceptualization and place classification for semantic maps in mobile robotics},
  year     = {2008},
  issn     = {0921-8890},
  note     = {From Sensors to Human Spatial Concepts},
  number   = {6},
  pages    = {522--537},
  volume   = {56},
  abstract = {The future of robots, as our companions is dependent on their ability to understand, interpret and represent the environment in a human compatible manner. Towards this aim, this work attempts to create a hierarchical probabilistic concept-oriented representation of space, based on objects. Specifically, it details efforts taken towards learning and generating concepts and attempts to classify places using the concepts gleaned. Several algorithms, from naive ones using only object category presence to more sophisticated ones using both objects and relationships, are proposed. Both learning and inference use the information encoded in the underlying representation-objects and relative spatial information between them. The approaches are based on learning from exemplars, clustering and the use of Bayesian network classifiers. The approaches are generative. Further, even though they are based on learning from exemplars, they are not ontology specific; i.e. they do not assume the use of any particular ontology. The presented algorithms rely on a robots inherent high-level feature extraction capability (object recognition and structural element extraction) capability to actually form concept models and infer them. Thus, this report presents methods that could enable a robot to to link sensory information to increasingly abstract concepts (spatial constructs). Such a conceptualization and the representation that results thereof would enable robots to be more cognizant of their surroundings and yet, compatible to us. Experiments on conceptualization and place classification are reported. Thus, the theme of this work is—conceptualization and classification for representation and spatial cognition.},
  doi      = {https://doi.org/10.1016/j.robot.2008.03.005},
  file     = {:FILES/2008 - Vasudevan2008 - Bayesian space conceptualization and place classification for semantic maps in mobile robotics.pdf:PDF},
  groups   = {robot},
  keywords = {Conceptualization of space, Place classification, Bayesian inference, Spatial cognition, Robot mapping, Semantic mapping},
  url      = {https://www.sciencedirect.com/science/article/pii/S092188900800033X},
}

@Article{Zender2008,
  author   = {H. Zender and O. {Martínez Mozos} and P. Jensfelt and G.-J. M. Kruijff and W. Burgard},
  journal  = {Robotics and Autonomous Systems},
  title    = {Conceptual spatial representations for indoor mobile robots},
  year     = {2008},
  issn     = {0921-8890},
  note     = {From Sensors to Human Spatial Concepts},
  number   = {6},
  pages    = {493--502},
  volume   = {56},
  abstract = {We present an approach for creating conceptual representations of human-made indoor environments using mobile robots. The concepts refer to spatial and functional properties of typical indoor environments. Following different findings in spatial cognition, our model is composed of layers representing maps at different levels of abstraction. The complete system is integrated in a mobile robot endowed with laser and vision sensors for place and object recognition. The system also incorporates a linguistic framework that actively supports the map acquisition process, and which is used for situated dialogue. Finally, we discuss the capabilities of the integrated system.},
  comment  = {Walter2013:augmented lower-level metric maps with higher-level topological and/or semantic information. 在office中，semantic layer model room category and their relationship with the labels of objects in the room,并利用这些user specified object labels来对room type进行分类。
Duvallet2016: using the robot’s sensor observations to update its representation of the world},
  doi      = {https://doi.org/10.1016/j.robot.2008.03.007},
  file     = {:FILES/2008 - Zender2008 - Conceptual spatial representations for indoor mobile robots.pdf:PDF},
  groups   = {robot, task understanding},
  keywords = {Spatial representation, Conceptual map, Mapping, Service robots, Mobile robots},
  url      = {https://www.sciencedirect.com/science/article/pii/S0921889008000304},
}

@InProceedings{Limketkai2005,
  author    = {Limketkai, Benson and Liao, Lin and Fox, Dieter},
  booktitle = {Proceedings of the 19th International Joint Conference on Artificial Intelligence},
  title     = {Relational object maps for mobile robots},
  year      = {2005},
  address   = {San Francisco, CA, USA},
  pages     = {1471–-1476},
  publisher = {Morgan Kaufmann Publishers Inc.},
  series    = {IJCAI'05},
  abstract  = {Mobile robot map building is the task of generating a model of an environment from sensor data. Most existing approaches to mobile robot mapping either build topological representations or generate accurate, metric maps of an environment. In this paper we introduce relational object maps, a novel approach to building metric maps that represent individual objects such as doors or walls. We show how to extend relational Markov networks in order to reason about a hierarchy of objects and the spatial relationships between them. Markov chain Monte Carlo is used for efficient inference and to learn the parameters of the model. We show that the spatial constraints modeled by our mapping technique yield drastic improvements for labeling line segments extracted from laser range-finders.},
  groups    = {robot},
  location  = {Edinburgh, Scotland},
}

@InProceedings{Tenorth2010a,
  author    = {Moritz {Tenorth} and Lars {Kunze} and Dominik {Jain} and Michael {Beetz}},
  booktitle = {2010 10th IEEE-RAS International Conference on Humanoid Robots},
  title     = {{KNOWROB-MAP} - knowledge-linked semantic object maps},
  year      = {2010},
  address   = {Nashville, TN, USA},
  month     = dec,
  pages     = {430--435},
  publisher = {IEEE},
  abstract  = {Autonomous household robots are supposed to accomplish complex tasks like cleaning the dishes which involve both navigation and manipulation within the environment. For navigation, spatial information is mostly sufficient, but manipulation tasks raise the demand for deeper knowledge about objects, such as their types, their functions, or the way how they can be used. We present KNOWROB-MAP, a system for building environment models for robots by combining spatial information about objects in the environment with encyclopedic knowledge about the types and properties of objects, with common-sense knowledge describing what the objects can be used for, and with knowledge derived from observations of human activities by learning statistical relational models. In this paper, we describe the concept and implementation of KNOWROB-MAP and present several examples demonstrating the range of information the system can provide to autonomous robots.},
  doi       = {10.1109/ICHR.2010.5686350},
  file      = {:FILES/2010 - Tenorth2010a - KNOWROB-MAP - knowledge-linked semantic object maps.pdf:PDF},
  groups    = {robot},
  issn      = {2164-0580},
  keywords  = {encyclopaedias;knowledge engineering;mobile robots;service robots;statistical analysis;KNOWROB-MAP;knowledge-linked semantic object maps;autonomous household robots;manipulation tasks;encyclopedic knowledge;common-sense knowledge;statistical relational models;Semantics;Knowledge based systems;Data structures;Robot sensing systems;Knowledge representation;Containers},
  url       = {https://ieeexplore.ieee.org/document/5686350/citations#citations},
}

@Article{Galindo2008,
  author   = {Cipriano Galindo and Juan-Antonio Fernández-Madrigal and Javier González and Alessandro Saffiotti},
  journal  = {Robotics and Autonomous Systems},
  title    = {Robot task planning using semantic maps},
  year     = {2008},
  issn     = {0921-8890},
  note     = {Semantic Knowledge in Robotics},
  number   = {11},
  pages    = {955--966},
  volume   = {56},
  abstract = {Task planning for mobile robots usually relies solely on spatial information and on shallow domain knowledge, such as labels attached to objects and places. Although spatial information is necessary for performing basic robot operations (navigation and localization), the use of deeper domain knowledge is pivotal to endow a robot with higher degrees of autonomy and intelligence. In this paper, we focus on semantic knowledge, and show how this type of knowledge can be profitably used for robot task planning. We start by defining a specific type of semantic maps, which integrates hierarchical spatial information and semantic knowledge. We then proceed to describe how these semantic maps can improve task planning in two ways: extending the capabilities of the planner by reasoning about semantic information, and improving the planning efficiency in large domains. We show several experiments that demonstrate the effectiveness of our solutions in a domain involving robot navigation in a domestic environment.},
  doi      = {https://doi.org/10.1016/j.robot.2008.08.007},
  file     = {:FILES/2008 - Galindo2008 - Robot task planning using semantic maps.pdf:PDF},
  groups   = {robot},
  keywords = {Task planning, Robot maps, Mobile robotics, Knowledge representation, Cognitive robotics},
  url      = {https://www.sciencedirect.com/science/article/pii/S0921889008001188},
}

@InProceedings{Ros2010,
  author    = {Raquel {Ros} and S\'{e}verin {Lemaignan} and E. Akin {Sisbot} and Rachid {Alami} and Jasmin {Steinwender} and Kathaina {Hamann} and Felix {Warneken}},
  booktitle = {19th International Symposium in Robot and Human Interactive Communication},
  title     = {Which one? {Grounding} the referent based on efficient human-robot interaction},
  year      = {2010},
  address   = {Viareggio, Italy},
  month     = sep,
  pages     = {570--575},
  publisher = {IEEE},
  abstract  = {In human-robot interaction, a robot must be prepared to handle possible ambiguities generated by a human partner. In this work we propose a set of strategies that allow a robot to identify the referent when the human partner refers to an object giving incomplete information, i.e. an ambiguous description. Moreover, we propose the use of an ontology to store and reason on the robot's knowledge to ease clarification, and therefore, improve interaction. We validate our work through both simulation and two real robotic platforms performing two tasks: a daily-life situation and a game.},
  doi       = {10.1109/ROMAN.2010.5598719},
  file      = {:FILES/2010 - Ros2010 - Which one Grounding the referent based on efficient human-robot interaction.pdf:PDF},
  groups    = {robot},
  issn      = {1944-9437},
  keywords  = {human-robot interaction;ontologies (artificial intelligence);human-robot interaction;ambiguous description;ontology;robot knowledge;Robots;Humans;Visualization;Ontologies;Glass;Computational modeling;Color},
  url       = {https://ieeexplore.ieee.org/document/5598719},
}

@InProceedings{Simeon2001,
  author    = {Sim\'{e}on, Thierry and Laumond, Jean-Paul and Lamiraux, Florent},
  booktitle = {Proceedings of the IEEE International Symposium on Assembly and Task Planning},
  title     = {{Move3D}: {A} generic platform for path planning},
  year      = {2001},
  address   = {Fukuoka, Japan},
  month     = may,
  pages     = {25--30},
  publisher = {IEEE},
  doi       = {10.1109/ISATP.2001.928961},
  file      = {:FILES/2001 - Simeon2001 - Move3D-A generic platform for path planning.pdf:PDF},
  groups    = {robot},
  isbn      = {0-7803-7004-X},
  url       = {https://ieeexplore.ieee.org/document/928961?arnumber=928961&tag=1},
}

@Article{Daoutis2012,
  author   = {Daoutis, Marios and Coradeschi, Silvia and Loutfi, Amy},
  journal  = {International Journal on Artificial Intelligence Tools},
  title    = {Cooperative knowledge based perceptual anchoring},
  year     = {2012},
  number   = {03},
  pages    = {1250012},
  volume   = {21},
  abstract = {In settings where heterogenous robotic systems interact with humans, information from the environment must be systematically captured, organized and maintained in time. In this work, we propose a model for connecting perceptual information to semantic information in a multi-agent setting. In particular, we present semantic cooperative perceptual anchoring, that captures collectively acquired perceptual information and connects it to semantically expressed commonsense knowledge. We describe how we implemented the proposed model in a smart environment, using different modern perceptual and knowledge representation techniques. We present the results of the system and investigate different scenarios in which we use the commonsense together with perceptual knowledge, for communication, reasoning and exchange of information.},
  doi      = {10.1142/S0218213012500121},
  file     = {:FILES/2012 - Daoutis2012 - Cooperative knowledge based perceptual anchoring.pdf:PDF},
  groups   = {robot},
  url      = {https://www.worldscientific.com/action/showCitFormats?doi=10.1142/S0218213012500121},
}

@Article{Daoutis2009,
  author    = {Daoutis, Marios and Coradeshi, Silvia and Loutfi, Amy},
  journal   = {Journal of Ambient Intelligent Smart Environments},
  title     = {Grounding commonsense knowledge in intelligent systems},
  year      = {2009},
  issn      = {1876-1364},
  month     = dec,
  number    = {4},
  pages     = {311–-321},
  volume    = {1},
  abstract  = {Ambient environments which integrate a number of sensing devices and actuators intended for use by human users need to be able to express knowledge about objects, their functions and their properties to assist in the performance of everyday tasks. For this to occur perceptual data must be grounded to symbolic information that in its turn can be used in the communication with the human. For symbolic information to be meaningful it should be part of a rich knowledge base that includes an ontology of concepts and common sense. In this work we present an integration between ResearchCyc and an anchoring framework that mediates the connection between the perceptual information in an intelligent home environment and the reasoning system. Through simple dialogues we validate how objects placed in the home environment are grounded by a network of sensors and made available to a larger KB where reasoning is exploited. This first integration work is a step towards integrating the richness of a KRR system developed over many years in isolation, with a physically embedded intelligent system.},
  doi       = {10.3233/AIS-2009-0040},
  file      = {:FILES/2009 - Daoutis2009 - Grounding commonsense knowledge in intelligent systems.pdf:PDF},
  groups    = {robot},
  keywords  = {intelligent home, human robot interaction, commonsense knowledge representation, Physical symbol grounding},
  publisher = {IOS Press},
  url       = {https://content.iospress.com/articles/journal-of-ambient-intelligence-and-smart-environments/ais040},
}

@InProceedings{IHS2007,
  author    = {Il Hong Suh and Gi Hyun Lim and Wonil Hwang and Hyowon Suh and Jung-Hwa Choi and Young-Tack Park},
  booktitle = {2007 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  title     = {Ontology-based multi-layered robot knowledge framework {(OMRKF)} for robot intelligence},
  year      = {2007},
  address   = {San Diego, CA, USA},
  month     = oct,
  pages     = {429--436},
  publisher = {IEEE},
  abstract  = {An ontology-based multi-layered robot knowledge framework (OMRKF) is proposed to implement robot intelligence to be useful in a robot environment. OMRKF consists of four classes of knowledge (KClass), axioms and two types of rules. Four KClasses including perception, model, activity and context class are organized in a hierarchy of three knowledge levels (KLevel) and three ontology layers (OLayer). The axioms specify the semantics of concepts and relational constraints between ontological elements in each OLayer. One type of rule is designed for relationships between concepts in the same KClasses but in different KLevels. These rules will be used in a way of unidirectional reasoning. And, the other types of rules are also designed for association between concepts in different KLevels and different KClasses to be used in a way of bi-directional reasoning. These features will let OMRKF enable a robot to integrate robot knowledge from levels of sensor data and primitive behaviors to levels of symbolic data and contextual information regardless of class of knowledge. To show the validities of our proposed OMRKF, several experimental results will be illustrated, where some queries can be possibly answered by using uni-directional rules as well as bi-directional rules even with partial and uncertain information.},
  doi       = {10.1109/IROS.2007.4399082},
  file      = {:FILES/2007 - IHS2007 - Ontology-based multi-layered robot knowledge framework (OMRKF) for robot intelligence.pdf:PDF},
  groups    = {robot},
  issn      = {2153-0866},
  keywords  = {inference mechanisms;intelligent robots;mobile robots;ontologies (artificial intelligence);path planning;service robots;ontology-based multilayered robot knowledge framework;robot intelligence;unidirectional reasoning;bidirectional reasoning;path planning;robot environment;KClass;knowledge level;OLayer;relational constraints;Intelligent robots;Ontologies;Robot sensing systems;Humans;Bidirectional control;Navigation;USA Councils;Data structures;Grounding},
  url       = {https://ieeexplore.ieee.org/document/4399082},
}

@InProceedings{Prasad2020,
  author    = {Pranav Krishna {Prasad} and Wolfgang {Ertel}},
  booktitle = {2020 5th International Conference on Robotics and Automation Engineering (ICRAE)},
  title     = {Knowledge acquisition and reasoning systems for service robots: {A} short review of the state of the art},
  year      = {2020},
  address   = {Singapore, Singapore},
  month     = {Nov},
  pages     = {36--45},
  publisher = {IEEE},
  abstract  = {Understanding the environment is an essential capability for mobile service robots to achieve autonomy. While this has proven to be a very challenging task, researchers have come up with a variety of solutions to enable robots to interact with and understand the environment around them. This capability allows robots to make more intelligent decisions using acquired knowledge. In parallel, equipping robots with situation awareness capability is also of equal importance since the semantic context of various entities can change with the change in the situation. This paper aims to deliver a review of the state of the art artificial intelligence approaches taken by researchers to enable robots to acquire and process knowledge of their environment and situation leading to robotic awareness. The focal points include various techniques used for knowledge acquisition, decision management, reasoning, situation awareness, human-robot interaction, and planning. The goal is to compile the modern techniques used in this field based on which future research directions could be defined.},
  doi       = {10.1109/ICRAE50850.2020.9310835},
  file      = {:FILES/2020 - Prasad2020 - Knowledge acquisition and reasoning systems for service robots- A short review of the state of the art.pdf:PDF},
  groups    = {robot, reasoning},
  keywords  = {Robots;Task analysis;Semantics;Knowledge acquisition;Cognition;Semantic Web;Solid modeling;Artificial Intelligence;environmental awareness;human-robot interaction;knowledge acquisition;situation awareness;reasoning;service robots},
  url       = {https://ieeexplore.ieee.org/document/9310835},
}

@Article{Rockafellar1976,
  author  = {Rockafellar, R. Tyrrell},
  journal = {SIAM Journal on Control and Optimization},
  title   = {Monotone operators and the proximal point algorithm},
  year    = {1976},
  issn    = {0363-0129},
  number  = {5},
  pages   = {877--898},
  volume  = {14},
  doi     = {10.1137/0314056},
  file    = {:FILES/1976 - Rockafellar1976 - Monotone operators and the proximal point algorithm.pdf:PDF},
  groups  = {proximal bundle method},
  url     = {https://epubs.siam.org/doi/10.1137/0314056},
}

@Article{Ziemke2001,
  author   = {Ziemke, Tom},
  journal  = {Foundations of Science},
  title    = {The construction of ‘reality’ in the robot: {Constructivist} perspectives on situated artificial intelligence and adaptive robotics},
  year     = {2001},
  issn     = {1572-8471},
  number   = {1},
  pages    = {163--233},
  volume   = {6},
  abstract = {This paper discusses different approaches incognitive science and artificial intelligenceresearch from the perspective of radicalconstructivism, addressing especially theirrelation to the biologically based theories ofvon Uexküll, Piaget as well as Maturana andVarela. In particular recent work in ‘New AI’ and adaptive robotics on situated and embodiedintelligence is examined, and we discuss indetail the role of constructive processes asthe basis of situatedness in both robots andliving organisms.},
  comment  = {the small world used in KnowRob 2, to reconstruct the environment in a game engine.},
  doi      = {10.1023/A:1011394317088},
  file     = {:FILES/2001 - Ziemke2001 - The construction of ‘reality’ in the robot- {Constructivist} perspectives on situated artificial intelligence and adaptive robotics.pdf:PDF},
  groups   = {robot},
  url      = {https://link.springer.com/article/10.1023/A:1011394317088},
}

@Article{Celikkanat2015,
  author   = {Hande \c{C}elikkanat and G\"{u}ner {Orhan} and Sinan {Kalkan}},
  journal  = {IEEE Transactions on Autonomous Mental Development},
  title    = {A probabilistic concept web on a humanoid robot},
  year     = {2015},
  issn     = {1943-0612},
  month    = jun,
  number   = {2},
  pages    = {92--106},
  volume   = {7},
  abstract = {It is now widely accepted that concepts and conceptualization are key elements towards achieving cognition on a humanoid robot. An important problem on this path is the grounded representation of individual concepts and the relationships between them. In this article, we propose a probabilistic method based on Markov Random Fields to model a concept web on a humanoid robot where individual concepts and the relations between them are captured. In this web, each individual concept is represented using a prototype-based conceptualization method that we proposed in our earlier work. Relations between concepts are linked to the cooccurrences of concepts in interactions. By conveying input from perception, action, and language, the concept web forms rich, structured, grounded information about objects, their affordances, words, etc. We demonstrate that, given an interaction, a word, or the perceptual information from an object, the corresponding concepts in the web are activated, much the same way as they are in humans. Moreover, we show that the robot can use these activations in its concept web for several tasks to disambiguate its understanding of the scene.},
  doi      = {10.1109/TAMD.2015.2418678},
  file     = {:FILES/2015 - Celikkanat2015 - A probabilistic concept web on a humanoid robot.pdf:PDF},
  groups   = {robot},
  keywords = {humanoid robots;Markov processes;probability;random processes;cognition;prototype-based conceptualization;Markov random field;humanoid robot;probabilistic concept web;Robot sensing systems;Semantics;Birds;Prototypes;Humanoid robots;Dementia;Concepts;conceptualization;concept web;Markov Random Fields},
  url      = {https://ieeexplore.ieee.org/document/7073587},
}

@InCollection{Hayes1981,
  author    = {Patrick J. Hayes},
  booktitle = {Readings in Artificial Intelligence},
  publisher = {Morgan Kaufmann},
  title     = {The frame problem and related problems in artificial intelligence},
  year      = {1981},
  editor    = {Bonnie Lynn Webber and Nils J. Nilsson},
  isbn      = {978-0-934613-03-3},
  pages     = {223--230},
  abstract  = {Summary
The frame problem arises in attempts to formalise problem–solving processes involving interactions with a complex world. It concerns the difficulty of keeping track of the consequences of the performance of an action in, or more generally of the making of some alteration to, a representation of the world. The paper contains a survey of the problem, showing how it arises in several contexts and relating it to some traditional problems in philosophical logic. In the second part of the paper several suggested partial solutions to the problem are outlined and compared. This comparison necessitates an analysis of what is meant by a representation of a robot's environment. Different notions of representation give rise to different proposed solutions. It is argued that a theory of causal relationships is a necessity for any general solution. The significance of this, and the problem in general, for natural (human and animal) problem solving is discussed, and several desiderata for efficient representational schemes are outlined.},
  doi       = {https://doi.org/10.1016/B978-0-934613-03-3.50020-9},
  file      = {:FILES/1981 - Hayes1981 - The frame problem and related problems in artificial intelligence.pdf:PDF},
  groups    = {knowledge graph},
  url       = {https://www.sciencedirect.com/science/article/pii/B9780934613033500209},
}

@InProceedings{Aertbelien2014,
  author    = {Erwin {Aertbeli\"{e}n} and Joris {De Schutter}},
  booktitle = {2014 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  title     = {{eTaSL/eTC}: {A} constraint-based task specification language and robot controller using expression graphs},
  year      = {2014},
  address   = {Chicago, IL, USA},
  month     = sep,
  pages     = {1540--1546},
  publisher = {IEEE},
  abstract  = {This paper presents a new framework for constraint-based task specification of robot controllers. A task specification language (eTaSL) is defined as well as a corresponding implementation of a controller (eTC). This new framework is based on feature variables and a new concept referred to as expression graphs. It avoids some of the common pitfalls in previous frameworks, and provides a flexible and composable way to define robot control tasks. An architecture for a robot controller is proposed, as well as an implementation that can execute tasks described in the new specification language. Typical usage patterns for the new framework are explained on an example consisting of a kinematically redundant, bi-manual task on a PR2 robot. A comparison with existing frameworks shows the advantages of the new approach.},
  doi       = {10.1109/IROS.2014.6942760},
  file      = {:FILES/2014 - Aertbelien2014 - eTaSL-eTC- A constraint-based task specification language and robot controller using expression graphs.pdf:PDF},
  groups    = {robot},
  issn      = {2153-0866},
  keywords  = {control engineering computing;graph theory;redundant manipulators;specification languages;eTaSL;task specification language;eTC;expression graphs;feature variables;robot controller architecture;kinematically redundant task;PR2 robot;Joints;Optimization;Context;Trajectory;Robot kinematics;Collision avoidance},
  url       = {https://ieeexplore.ieee.org/document/6942760},
}

@Article{Morgenstern2001,
  author   = {Morgenstern, Leora},
  journal  = {Studia Logica},
  title    = {Mid-sized axiomatizations of commonsense problems: {A} case study in egg cracking},
  year     = {2001},
  issn     = {1572-8730},
  month    = apr,
  number   = {3},
  pages    = {333--384},
  volume   = {67},
  abstract = {We present an axiomatization of a problem in commonsense reasoning, characterizing the proper procedure for cracking an egg and transferring its contents to a bowl. The axiomatization is mid-sized, larger than toy problems such as the Yale Shooting Problem or the Suitcase Problem, but much smaller than the comprehensive axiomatizations associated with CYC and HPKB. This size of axiomatization permits the development of non-trivial, reusable core theories of commonsense reasoning, acts as a testbed for existing theories of commonsense reasoning, and encourages the discovery of new problems in commonsense reasoning.},
  doi      = {10.1023/A:1010512415344},
  file     = {:FILES/2001 - Morgenstern2001 - Mid-sized axiomatizations of commonsense problems- A case study in egg cracking.pdf:PDF},
  groups   = {robot},
  url      = {https://link.springer.com/article/10.1023/A:1010512415344},
}

@InProceedings{Tenorth2014,
  author    = {Tenorth, Moritz and Bartels, Georg and Beetz, Michael},
  booktitle = {Proceedings of the Twenty-First European Conference on Artificial Intelligence},
  title     = {Knowledge-based specification of robot motions},
  year      = {2014},
  address   = {Prague, Czech Republic},
  pages     = {873–-878},
  publisher = {IOS Press},
  series    = {ECAI'14},
  abstract  = {In many cases, the success of a manipulation action performed by a robot is determined by how it is executed and by how the robot moves during the action. Examples are tasks such as unscrewing a bolt, pouring liquids and flipping a pancake. This aspect is often abstracted away in AI planning and action languages that assume that an action is successful as long as all preconditions are fulfilled. In this paper we investigate how constraint-based motion representations used in robot control can be combined with a semantic knowledge base in order to let a robot reason about movements and to automatically generate executable motion descriptions that can be adapted to different robots, objects and tools.},
  groups    = {robot},
  isbn      = {9781614994183},
  numpages  = {6},
  url       = {http://ebooks.iospress.nl/publication/37052},
}

@InProceedings{Fang2016,
  author    = {Zhou {Fang} and Georg {Bartels} and Michael {Beetz}},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Learning models for constraint-based motion parameterization from interactive physics-based simulation},
  year      = {2016},
  address   = {Daejeon, Korea (South)},
  month     = oct,
  pages     = {4005--4012},
  publisher = {IEEE},
  abstract  = {For robotic agents to perform manipulation tasks in human environments at a human level or higher, they need to be able to relate the physical effects of their actions to how they are executing them; small variations in execution can have very different consequences. This paper proposes a framework for acquiring and applying action knowledge from naive user demonstrations in an interactive simulation environment under varying conditions. The framework combines a flexible constraint-based motion control approach with games-with-a-purpose-based learning using Random Forest Regression. The acquired action models are able to produce context-sensitive constraint-based motion descriptions to perform the learned action. A pouring experiment is conducted to test the feasibility of the suggested approach and shows the learned system can perform comparable to its human demonstrators.},
  doi       = {10.1109/IROS.2016.7759590},
  file      = {:FILES/2016 - Fang2016 - Learning models for constraint-based motion parameterization from interactive physics-based simulation.pdf:PDF},
  groups    = {robot},
  issn      = {2153-0866},
  keywords  = {flexible manipulators;game theory;human-robot interaction;motion control;regression analysis;learning models;constraint-based motion parameterization;interactive physics-based simulation;robotic agents;manipulation tasks;human environments;action knowledge;naive user demonstrations;interactive simulation environment;flexible constraint-based motion control;games-with-a-purpose-based learning;random forest regression;action models;context-sensitive constraint-based motion descriptions;Robot sensing systems;Vegetation;Predictive models;Motion control;Reliability;Physics},
  url       = {https://ieeexplore.ieee.org/document/7759590},
}

@Article{Kehoe2015,
  author   = {Ben Kehoe and Sachin {Patil} and Pieter {Abbeel} and Ken {Goldberg}},
  journal  = {IEEE Transactions on Automation Science and Engineering},
  title    = {A survey of research on cloud robotics and automation},
  year     = {2015},
  issn     = {1558-3783},
  month    = apr,
  number   = {2},
  pages    = {398--409},
  volume   = {12},
  abstract = {The Cloud infrastructure and its extensive set of Internet-accessible resources has potential to provide significant benefits to robots and automation systems. We consider robots and automation systems that rely on data or code from a network to support their operation, i.e., where not all sensing, computation, and memory is integrated into a standalone system. This survey is organized around four potential benefits of the Cloud: 1) Big Data: access to libraries of images, maps, trajectories, and descriptive data; 2) Cloud Computing: access to parallel grid computing on demand for statistical analysis, learning, and motion planning; 3) Collective Robot Learning: robots sharing trajectories, control policies, and outcomes; and 4) Human Computation: use of crowdsourcing to tap human skills for analyzing images and video, classification, learning, and error recovery. The Cloud can also improve robots and automation systems by providing access to: a) datasets, publications, models, benchmarks, and simulation tools; b) open competitions for designs and systems; and c) open-source software. This survey includes over 150 references on results and open challenges. A website with new developments and updates is available at: http://goldberg.berkeley.edu/cloud-robotics/.},
  doi      = {10.1109/TASE.2014.2376492},
  file     = {:FILES/2015 - Kehoe2015 - A survey of research on cloud robotics and automation.pdf:PDF},
  groups   = {robot},
  keywords = {cloud computing;control engineering computing;grid computing;groupware;learning (artificial intelligence);outsourcing;parallel processing;robots;cloud robotics;automation system;Big Data;cloud computing;parallel grid computing;collective robot learning;robots sharing trajectory;human computation;crowdsourcing;Robot sensing systems;Automation;Cloud computing;Robot kinematics;Computational modeling;Big data;cloud automation;cloud computing;cloud robotics;crowdsourcing;open source},
  url      = {https://ieeexplore.ieee.org/document/7006734/citations?tabFilter=papers#citations},
}

@Article{Garcia2014,
  author   = {Daniel Hernández García and Concepción A. Monje and Carlos Balaguer},
  journal  = {IFAC Proceedings Volumes},
  title    = {Knowledge base representation for humanoid robot skills},
  year     = {2014},
  issn     = {1474-6670},
  note     = {19th IFAC World Congress},
  number   = {3},
  pages    = {3042--3047},
  volume   = {47},
  abstract = {The ultimate goal for humanoid robotics research is to develop humanoid robotic systems capable and flexible enough to handle the challenge of working alongside human in complex natural environments performing everyday tasks. To reach this goal it is key to develop appropriate structures in which to organize the acquire knowledge in a manner that allows the system to retrieve it in order to use it to fulfil its missions. In this work a knowledge base representation of the robot skills knowledge organized in terms of the relationships between objects, actions and event frames is proposed.},
  doi      = {https://doi.org/10.3182/20140824-6-ZA-1003.02229},
  file     = {:FILES/2014 - Garcia2014 - Knowledge base representation for humanoid robot skills.pdf:PDF},
  groups   = {robot},
  url      = {https://www.sciencedirect.com/science/article/pii/S1474667016420744},
}

@Article{Liu2013,
  author   = {Dian Liu and Hong-wei Wang and Kuang-yu Liu and Jian Wang},
  journal  = {IFAC Proceedings Volumes},
  title    = {An ontology-based emergency domain knowledge model for {HTN} planning},
  year     = {2013},
  issn     = {1474-6670},
  note     = {13th IFAC Symposium on Large Scale Complex Systems: Theory and Applications},
  number   = {13},
  pages    = {377--382},
  volume   = {46},
  abstract = {Hierarchy task network (HTN) planning, as one of AI planning approaches, has been widely used in the emergency decision making for action planning in recent years, in which domain knowledge plays an important role. The special and complicated characteristics of emergency domain knowledge make it difficult to model, hindering the application of HTN planning to emergency action plan development. Though ontology modeling can get over the difficulty, existing ontology models for the emergency domain knowledge are either incomplete or not applicable for HTN planning. This paper aims at constructing emergency domain knowledge ontology applicable for HTN planner SHOP2 which can effectively support the emergency action plan development. An approach of translating an emergency domain knowledge model into a SHOP2 domain is also discussed in the paper. Finally an implementation of our work is roughly introduced.},
  doi      = {https://doi.org/10.3182/20130708-3-CN-2036.00110},
  file     = {:FILES/2013 - Liu2013 - An ontology-based emergency domain knowledge model for HTN planning.pdf:PDF},
  groups   = {robot},
  keywords = {Emergency action plan development, HTN planning, SHOP2, emergency domain knowledge ontology, translation},
  url      = {https://www.sciencedirect.com/science/article/pii/S1474667016302865},
}

@InProceedings{Tenorth2013a,
  author    = {Moritz {Tenorth} and Koji {Kamei} and Satoru {Satake} and Takahiro {Miyashita} and Norihiro {Hagita}},
  booktitle = {2013 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  title     = {Building knowledge-enabled cloud robotics applications using the ubiquitous network robot platform},
  year      = {2013},
  month     = {Nov},
  pages     = {5716-5721},
  abstract  = {In this paper, we discuss how networked robot architectures can facilitate the development, deployment, management and adaptation of distributed robotic applications. Our aim is to modularize applications by factoring out environment, task-, domain-, and robot-specific knowledge components and representing them explicitly in a formal knowledge base that is shared between the robots and service applications. Robot control decisions can then be formulated in terms of inference tasks that are evaluated based on this knowledge during task execution. The explicit and modular knowledge representation allows human operators with different areas of expertise to adapt the respective parts of the knowledge independently. We implemented this concept by integrating knowledge representation methods of the RoboEarth project with the distributed task execution capabilities of the Ubiquitous Network Robot Platform.},
  doi       = {10.1109/IROS.2013.6697184},
  file      = {:FILES/2013 - Tenorth2013a - Building knowledge-enabled cloud robotics applications using the ubiquitous network robot platform.pdf:PDF},
  issn      = {2153-0866},
  keywords  = {cloud computing;knowledge based systems;knowledge representation;service robots;ubiquitous computing;knowledge-enabled cloud robotic applications;ubiquitous network robot platform;distributed robotic applications;robot-specific knowledge components;domain-specific knowledge components;task-specific knowledge components;formal knowledge base system;robot control decisions;inference tasks;task execution;modular knowledge representation;RoboEarth project;Robot kinematics;Knowledge based systems;Robot sensing systems;Ontologies;Semantics;Hardware},
  url       = {https://ieeexplore.ieee.org/document/6697184},
}

@Article{AlMoadhen2013,
  author   = {Ahmed {Al-Moadhen} and Renxi Qiu and Michael Packianather and Ze Ji and Rossi Setchi},
  journal  = {Procedia Computer Science},
  title    = {Integrating robot task planner with common-sense knowledge base to improve the efficiency of planning},
  year     = {2013},
  issn     = {1877-0509},
  note     = {17th International Conference in Knowledge Based and Intelligent Information and Engineering Systems - KES2013},
  pages    = {211-220},
  volume   = {22},
  abstract = {This paper presents a developed approach for intelligently generating symbolic plans by mobile robots acting in domestic environments, such as offices and houses. The significance of the approach lies in developing a new framework that consists of the new modeling of high-level robot actions and then their integration with common-sense knowledge in order to support a robotic task planner. This framework will enable interactions between the task planner and the semantic knowledge base directly. By using common-sense domain knowledge, the task planner will take into consideration the properties and relations of objects and places in its environment, before creating semantically related actions that will represent a plan. This plan will accomplish the user order. The robot task planner will use the available domain knowledge to check the next related actions to the current one and the action's conditions met will be chosen. Then the robot will use the immediately available knowledge information to check whether the plan outcomes are met or violated.},
  doi      = {https://doi.org/10.1016/j.procs.2013.09.097},
  file     = {:FILES/2013 - AlMoadhen2013 - Integrating robot task planner with common-sense knowledge base to improve the efficiency of planning.pdf:PDF},
  groups   = {robot},
  keywords = {Task Planner, Common-Sense knowledge, Semantic Action Model, Semantic Network, ConceptNet.},
  url      = {https://www.sciencedirect.com/science/article/pii/S1877050913008909},
}

@InProceedings{Sarthou2019,
  author    = {Sarthou, Guillaume and Clodic, Aur{\'e}lie and Alami, Rachid},
  booktitle = {Proceedings of the Combined Workshop on Spatial Language Understanding ({S}p{LU}) and Grounded Communication for Robotics ({R}obo{NLP})},
  title     = {Semantic spatial representation: {A} unique representation of an environment based on an ontology for robotic applications},
  year      = {2019},
  address   = {Minneapolis, Minnesota},
  month     = jun,
  pages     = {50--60},
  publisher = {Association for Computational Linguistics},
  abstract  = {It is important, for human-robot interaction, to endow the robot with the knowledge necessary to understand human needs and to be able to respond to them. We present a formalized and unified representation for indoor environments using an ontology devised for a route description task in which a robot must provide explanations to a person. We show that this representation can be used to choose a route to explain to a human as well as to verbalize it using a route perspective. Based on ontology, this representation has a strong possibility of evolution to adapt to many other applications. With it, we get the semantics of the environment elements while keeping a description of the known connectivity of the environment. This representation and the illustration algorithms, to find and verbalize a route, have been tested in two environments of different scales.},
  doi       = {10.18653/v1/W19-1606},
  file      = {:FILES/2019 - Sarthou2019 - Semantic spatial representation- A unique representation of an environment based on an ontology for robotic applications.pdf:PDF},
  groups    = {robot},
  url       = {https://www.aclweb.org/anthology/W19-1606},
}

@InProceedings{Sallami2019,
  author    = {Yoan {Sallami} and S\'{e}verin {Lemaignan} and Aur\'{e}lie {Clodic} and Rachid {Alami}},
  booktitle = {2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Simulation-based physics reasoning for consistent scene estimation in an {HRI} context},
  year      = {2019},
  address   = {Macau, China},
  month     = nov,
  pages     = {7834--7841},
  publisher = {IEEE},
  abstract  = {Reasoning about spatial and geometric relations between objects in a tabletop human-robot interaction is a challenge due to the perception not being always consistent: objects placed on a table seem to be slightly in the air; they overlap; they disappear due to occlusions. Yet, interpreting and anchoring perceptual data in a physically consistent estimation of the scene is a crucial ability for humans, and thus robots in HRI context. In this paper we present a simulation-based physics reasoner integrated in a lightweight situation-assessment framework called Underworlds, that allows the robot to stabilize objects and build at run-time a consistent estimation of the scene, even for entirely hidden objects, while inferring the actions performed by its human partner.},
  doi       = {10.1109/IROS40897.2019.8968106},
  file      = {:FILES/2019 - Sallami2019 - Simulation-based physics reasoning for consistent scene estimation in an {HRI} context.pdf:PDF},
  groups    = {robot},
  issn      = {2153-0866},
  keywords  = {cognitive systems;human-robot interaction;inference mechanisms;robot vision;Underworlds;situation-assessment framework;perceptual data;tabletop human-robot interaction;geometric relations;spatial relations;consistent scene estimation;simulation-based physics reasoning;human partner;hidden objects;HRI context},
  url       = {https://ieeexplore.ieee.org/document/8968106},
}

@Article{Afanasev2021,
  author   = {Vsevolod A. Afanasev and Ren\‘{e} {van Bevern} and Oxana Yu. Tsidulko},
  journal  = {Operations Research Letters},
  title    = {The hierarchical {Chinese} postman problem: {The} slightest disorder makes it hard, yet disconnectedness is manageable},
  year     = {2021},
  issn     = {0167-6377},
  month    = mar,
  number   = {2},
  pages    = {270--277},
  volume   = {49},
  abstract = {The Hierarchical Chinese Postman Problem is finding a shortest traversal of all edges of a graph respecting precedence constraints given by a partial order on classes of edges. We show that the special case with connected classes is NP-hard even on orders decomposable into a chain and an incomparable class. For the case with linearly ordered (possibly disconnected) classes, we get 5/3-approximations and fixed-parameter algorithms by transferring results from the Rural Postman Problem.},
  doi      = {https://doi.org/10.1016/j.orl.2021.01.017},
  file     = {:FILES/2021 - Afanasev2021 - The hierarchical Chinese postman problem- The slightest disorder makes it hard, yet disconnectedness is manageable.pdf:PDF},
  groups   = {global optimization},
  keywords = {Approximation algorithm, Fixed-parameter algorithm, NP-hardness, Arc routing, Rural Postman Problem, Temporal graphs},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167637721000262},
}

@Article{Jiang2021,
  author   = {Jie Jiang and Shengjie Li},
  journal  = {Operations Research Letters},
  title    = {On complexity of multistage stochastic programs under heavy tailed distributions},
  year     = {2021},
  issn     = {0167-6377},
  month    = mar,
  number   = {2},
  pages    = {265--269},
  volume   = {49},
  abstract = {In this paper, the complexity of sample average approximation (SAA) of multistage stochastic programs under heavy tailed distributions is investigated. Specifically, we estimate confidence levels when the accuracy parameter and sample size are given under independently and identically distributed (iid) and non-iid conditional samples, respectively. Different from the existing works, we emphasize the impact of heavy tailed distributions, non-iid conditional sampling and stages dependence of the random process in multistage stochastic programs.},
  doi      = {https://doi.org/10.1016/j.orl.2021.01.016},
  file     = {:FILES/2021 - Jiang2021 - On complexity of multistage stochastic programs under heavy tailed distributions.pdf:PDF},
  groups   = {global optimization},
  keywords = {Multistage stochastic programming, Non-iid, Rate of convergence, Heavy tailed distribution},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167637721000250},
}

@Article{Bugg2021,
  author   = {Caleb Bugg and Anil Aswani},
  journal  = {Operations Research Letters},
  title    = {Logarithmic sample bounds for sample average approximation with capacity- or budget-constraints},
  year     = {2021},
  issn     = {0167-6377},
  month    = mar,
  number   = {2},
  pages    = {231--238},
  volume   = {49},
  abstract = {Sample Average Approximation (SAA) is used to approximately solve stochastic optimization problems. In practice, SAA requires much fewer samples than predicted by existing theoretical bounds that ensure the SAA solution is close to optimal. Here, we derive new sample-size bounds for SAA that, for certain problems, are logarithmic (existing bounds are polynomial) in problem dimension. Notably, our new bounds provide a theoretical explanation for the success of SAA for many capacity- or budget-constrained optimization problems.},
  doi      = {https://doi.org/10.1016/j.orl.2021.01.007},
  file     = {:FILES/2021 - Bugg2021 - Logarithmic sample bounds for sample average approximation with capacity- or budget-constraints.pdf:PDF},
  groups   = {global optimization},
  keywords = {Sample average approximation, Sample bounds, Stochastic complexity},
  url      = {https://www.sciencedirect.com/science/article/pii/S016763772100016X},
}

@Article{Bertsimas2021,
  author   = {Dimitris Bertsimas and Jack Dunn and Yuchen Wang},
  journal  = {Operations Research Letters},
  title    = {Near-optimal nonlinear regression trees},
  year     = {2021},
  issn     = {0167-6377},
  month    = mar,
  number   = {2},
  pages    = {201--206},
  volume   = {49},
  abstract = {We propose Near-optimal Nonlinear Regression Trees with hyperplane splits (NNRTs) that use a polynomial prediction function in the leaf nodes, which we solve by stochastic gradient methods. On synthetic data, we show experimentally that the algorithm converges to the global optimal. We compare NNRTs, ORT-LH, Multivariate Adaptive Regression Splines (MARS), Random Forests (RF) and XGBoost on 40 real-world datasets and show that overall NNRTs have a performance edge over all other methods.},
  doi      = {https://doi.org/10.1016/j.orl.2021.01.002},
  file     = {:FILES/2021 - Bertsimas2021 - Near-optimal nonlinear regression trees.pdf:PDF},
  groups   = {global optimization},
  keywords = {Decision trees, Regression, Nonlinear optimization},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167637721000031},
}

@Article{Zhang2021,
  author   = {Jie Zhang and Shuang Lin and Yi Zhang},
  journal  = {Operations Research Letters},
  title    = {Asymptotic analysis for a stochastic semidefinite programming},
  year     = {2021},
  issn     = {0167-6377},
  month    = mar,
  number   = {2},
  pages    = {164--170},
  volume   = {49},
  abstract = {Stochastic semidefinite programming (SSDP) is a new class of optimization problems with a wide variety of applications. In this article, asymptotic analysis results of sample average approximation estimator for SSDP are established. Asymptotic analysis result already existing for stochastic nonlinear programming is extended to SSDP, that is, the conditions ensuring the convergence in distribution of sample average approximation estimator for SSDP to a multivariate normal are obtained and the corresponding covariance matrix is described in a closed form.},
  doi      = {10.1016/j.orl.2020.12.008},
  file     = {:FILES/2021 - Zhang2021 - Asymptotic analysis for a stochastic semidefinite programming.pdf:PDF},
  groups   = {global optimization},
  keywords = {Stochastic semidefinite programming, Asymptotic analysis, Sample average approximation (SAA), Convergence in distribution},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167637720301966},
}

@Article{Orlowska1984,
  author     = {Ewa Orłowska and Zdzisław Pawlak},
  journal    = {International Journal of Man-Machine Studies},
  title      = {Expressive power of knowledge representation systems},
  year       = {1984},
  issn       = {0020-7373},
  number     = {5},
  pages      = {485--500},
  volume     = {20},
  abstract   = {In this article we attempt to clarify some aspects of expressive power of knowledge representation systems. We show that information about objects provided by a system is given up to an indiscernibility relation determined by the system and hence it is incomplete in a sense. We discuss the influence of this kind of incompleteness on definability of concepts in terms of knowledge given by a system. We consider indiscernibility relations as a tool for representing expressive power of systems, and develop a logic in which properties of knowledge representation systems related to definability can be expressed and proved. We present a complete set of axioms and inference rules for the logic.},
  doi        = {10.1016/S0020-7373(84)80023-1},
  file       = {:FILES/1984 - Orlowska1984 - Expressive power of knowledge representation systems.pdf:PDF},
  groups     = {representation},
  readstatus = {skimmed},
  url        = {https://www.sciencedirect.com/science/article/pii/S0020737384800231},
}

@Book{Brachman2004,
  author    = {Ronald Brachman and Hector Levesque},
  publisher = {Morgan Kaufmann},
  title     = {Knowledge representation and reasoning},
  year      = {2004},
  isbn      = {9781558609327},
  month     = jun,
  series    = {The Morgan Kaufmann Series in Artificial Intelligence},
  groups    = {representation},
}

@InProceedings{Chen2019a,
  author    = {Baogui Chen and Zhuoyang Li and Siyuan {Shen} and Zhipeng {Zou} and Tieke {He}},
  booktitle = {2019 IEEE 19th International Conference on Software Quality, Reliability and Security Companion (QRS-C)},
  title     = {Judicial kowledge reasoning based on representation learning},
  year      = {2019},
  address   = {Sofia, Bulgaria},
  month     = jul,
  pages     = {84--88},
  publisher = {IEEE},
  abstract  = {This paper explores and defines a judicial knowledge reasoning model based on representation learning. The judicial judgment documents of our country collect data in xml format, and represent the key information of the case through the form of attribute-value. In the judicial documents, there is a specific relationship between the information. In order to describe this relationship and predict the element values in the xml through this relationship, this paper makes full use of the data characteristics and the theory of representation learning, and uses the judgment document data as the judicial knowledge base. Construct a judicial knowledge reasoning model based on representation learning, and help judicial staff to check for missing gaps and provide reference analysis when writing judgment documents.},
  doi       = {10.1109/QRS-C.2019.00029},
  file      = {:FILES/2019 - Chen2019a - Judicial kowledge reasoning based on representation learning.pdf:PDF},
  groups    = {robot},
  keywords  = {case-based reasoning;inference mechanisms;law administration;learning (artificial intelligence);XML;representation learning;judicial knowledge reasoning model;judicial judgment documents;xml format;judicial documents;specific relationship;judgment document data;judicial knowledge base;judicial staff;writing judgment documents;Knowledge based systems;Semantics;Hidden Markov models;Cognition;Neurons;XML;Predictive models;judicial documents;representation learning;knowledge reasoning},
  url       = {https://ieeexplore.ieee.org/document/8859419},
}

@InProceedings{Zelek1997,
  author     = {John S. Zelek},
  booktitle  = {Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems (IROS)},
  title      = {Human-robot interaction with minimal spanning natural language template for autonomous and tele-operated control},
  year       = {1997},
  month      = sep,
  pages      = {299--305},
  volume     = {1},
  abstract   = {Interaction between robots and humans should be at a level which is accessible and natural for human operators. A lexicon template is proposed for specifying commands for 2D mobile robot navigational tasks. The language lexicon is a minimal spanning semantic set for human 2D navigational tasks. The task command lexicon consists of a verb, destination, direction and a speed. The destination is a location in the environment defined by a geometric model positioned at a particular spatial location in a globally-referenced Cartesian coordinate space. The task command lexicon has been used as a language template for specifying commands for the SPOTT mobile robot control architecture. It is not the intent that the template serve as the only commands that the robot recognizes, but rather as an internal language that gets mapped onto planning and control constructs. A speech recognition system maps spoken commands onto the proposed internal natural language command template.},
  comment    = {(in tex summary)
Tellex2006: Zelek [18] specifies a lexicon template that he uses to control a mobile robot. Commands are formalized as specifying a verb, destination, direction, and speed.Although his architecture supports a large vocabulary of commands, it can only combine them in ways specified by the template. 

1. 本文提出了一种internal task command lexicon, consisting verb, source （optional）, destination, direction, and speed, for the 2D navigation of robot. 指令输入也是类似menu-based UI, should select values for each element
2.  the lexicon is a minimal spanning subset for human 2D navigational tasks.
3. 本文提出的lexicon是【5】的一种variation
4. verb包括GO and FIND,GO假设destination已知，FIND假设OBJECT的描述已知；定义了intelligent tele-operation， 用以描述没有指定target时的navigation，如forward and left. 
5. object model是2D geometric model, including points, lines, ellipses, rectangles.依赖于robot's priori knowledge and perceptual capabilities.
6. spatial relationships used are sparse, primarily including qualitative distinctions of distance and direction.
7. 分析了动词、介词、空间关系等表达，具有借鉴性，应该是为每种表达定义好distance quantity。
8. 路径规划方法：A potential field technique using harmonic functions【13】},
  doi        = {10.1109/IROS.1997.649069},
  file       = {:FILES/1997 - Zelek1997 - Human-robot interaction with minimal spanning natural language template for autonomous and tele-operated control.pdf:PDF},
  groups     = {task understanding, navigation},
  keywords   = {telerobotics;mobile robots;natural language interfaces;computerised navigation;human-robot interaction;minimal spanning natural language template;autonomous control;tele-operated control;lexicon template;2D mobile robot navigational tasks;language lexicon;minimal spanning semantic set;human 2D navigational tasks;task command lexicon;verb;destination;direction;speed;globally-referenced Cartesian coordinate space;SPOTT mobile robot control architecture;speech recognition system;internal natural language command template;Natural languages;Navigation;Robot kinematics;Speech recognition;Mobile robots;Human robot interaction;Solid modeling;Robot control;Orbital robotics;Vocabulary, read},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/649069},
}

@InProceedings{Tellex2006,
  author     = {Tellex, Stefanie and Roy, Deb},
  booktitle  = {Proceedings of the 1st ACM SIGCHI/SIGART Conference on Human-Robot Interaction},
  title      = {Spatial routines for a simulated speech-controlled vehicle},
  year       = {2006},
  address    = {New York, NY, USA},
  pages      = {156–-163},
  publisher  = {Association for Computing Machinery},
  series     = {HRI '06},
  abstract   = {We have defined a lexicon of words in terms of spatial routines, and used that lexicon to build a speech controlled vehicle in a simulator. A spatial routine is a script composed from a set of primitive operations on occupancy grids, analogous to Ullman's visual routines. The vehicle understands the meaning of context-dependent natural language commands such as "Go across the room." When the system receives a command, it combines definitions from the lexicon according to the parse structure of the command, creating a script that selects a goal for the vehicle. Spatial routines may provide the basis for interpreting spatial language in a broad range of physically situated language understanding systems.},
  comment    = {"本文设计了speech controlled wheelchair to navigate around a simulated world。利用了语音识别结果以及speech understanding, 但是也是基于关键词匹配的。设计了一种grammar and lexicon(语法结构), 从而将NL转换为path and goal，从而机器人可以执行。
1.  created a set of primitive spatial/motor operations over occupancy grids.  defined words in terms of these primitives, creating spatial routines.
2. Our system converts a linguistic utterance into a set of operations on sensor data, which then extract spatial relations appropriate to the utterance.
3. 之前关于controlled wheelchair都没有 directly addressing the situated aspects of language
4. We handcrafted a grammar and a lexicon for the system based on the types of utterances we wished to cover.
5. command的中间表达： The parser creates a series of nested procedure calls based on the grammatical structure of the utterance, such as ``go(right())''
6. language processing module的结果是path and goal, 基于这两个参数robot control module决定采取的controller，包括follow spline, move to angle, and stop. "},
  doi        = {10.1145/1121241.1121269},
  file       = {:FILES/2006 - Tellex2006 - Spatial routines for a simulated speech-controlled vehicle.pdf:PDF;:FILES/notes/Tellex2006.xlsx:Excel 2007+},
  groups     = {task understanding, navigation},
  isbn       = {1595932941},
  keywords   = {spatial language, situated language processing, visual routines, spatial routines, wheelchair, language grounding},
  location   = {Salt Lake City, Utah, USA},
  numpages   = {8},
  readstatus = {read},
  url        = {https://dl.acm.org/doi/10.1145/1121241.1121269},
}

@InProceedings{Kate2005,
  author     = {Rohit J. Kate and Yuk Wah Wong and Raymond J. Mooney},
  booktitle  = {Proceedings of the 20th National Conference on Artificial Intelligence and the 7th Innovative Applications of Artificial Intelligence Conference},
  title      = {Learning to transform natural to formal languages},
  year       = {2005},
  editor     = {Manuela M. Veloso and Subbarao Kambhampati},
  pages      = {1062--1068},
  publisher  = {{AAAI} Press / The {MIT} Press},
  file       = {:FILES/2005 - Kate2005 - Learning to transform natural to formal languages.pdf:PDF},
  groups     = {task understanding},
  keywords   = {skimmed},
  readstatus = {skimmed},
  timestamp  = {Wed, 10 Feb 2021 08:42:45 +0100},
  url        = {http://www.aaai.org/Library/AAAI/2005/aaai05-168.php},
}

@InProceedings{Perkowitz2004,
  author    = {Perkowitz, Mike and Philipose, Matthai and Fishkin, Kenneth and Patterson, Donald J.},
  booktitle = {Proceedings of the 13th International Conference on World Wide Web},
  title     = {Mining models of human activities from the web},
  year      = {2004},
  address   = {New York, NY, USA},
  pages     = {573–-582},
  publisher = {Association for Computing Machinery},
  series    = {WWW '04},
  abstract  = {The ability to determine what day-to-day activity (such as cooking pasta, taking a pill, or watching a video) a person is performing is of interest in many application domains. A system that can do this requires models of the activities of interest, but model construction does not scale well: humans must specify low-level details, such as segmentation and feature selection of sensor data, and high-level structure, such as spatio-temporal relations between states of the model, for each and every activity. As a result, previous practical activity recognition systems have been content to model a tiny fraction of the thousands of human activities that are potentially useful to detect. In this paper, we present an approach to sensing and modeling activities that scales to a much larger class of activities than before. We show how a new class of sensors, based on Radio Frequency Identification (RFID) tags, can directly yield semantic terms that describe the state of the physical world. These sensors allow us to formulate activity models by translating labeled activities, such as 'cooking pasta', into probabilistic collections of object terms, such as 'pot'. Given this view of activity models as text translations, we show how to mine definitions of activities in an unsupervised manner from the web. We have used our technique to mine definitions for over 20,000 activities. We experimentally validate our approach using data gathered from actual human activity as well as simulated data.},
  comment   = {the sensing system consists of RFID.

advantages: 1) no human involved, 2) to mine websites, 3) without extensive NL tools, 4) can scale up to tens of thousands of activities.},
  doi       = {10.1145/988672.988750},
  file      = {:FILES/2004 - Perkowitz2004 - Mining models of human activities from the web.pdf:PDF},
  groups    = {task understanding},
  isbn      = {158113844X},
  keywords  = {rfid, activity models, activity inference, web mining},
  location  = {New York, NY, USA},
  numpages  = {10},
  timestamp = {2021-03-10},
  url       = {https://doi.org/10.1145/988672.988750},
}

@InCollection{Nicola2009,
  author    = {Guarino Nicola and Oberle Daniel and Staab Steffen},
  booktitle = {Handbook on Ontologies},
  publisher = {Springer},
  title     = {What is an ontology?},
  year      = {2009},
  editor    = {Staab, Steffen and Studer, Rudi},
  pages     = {1--17},
  doi       = {10.1007/978-3-540-92673-3},
  groups    = {robot},
  timestamp = {2021-03-12},
  url       = {https://www.springer.com/cn/book/9783540709992},
}

@Article{Beer2014,
  author     = {Beer, Jenay M. and Fisk, Arthur D. and Rogers, Wendy A.},
  journal    = {J. Hum.-Robot Interact.},
  title      = {Toward a Framework for Levels of Robot Autonomy in Human-Robot Interaction},
  year       = {2014},
  month      = jul,
  number     = {2},
  pages      = {74–99},
  volume     = {3},
  abstract   = {Autonomy is a critical construct related to human-robot interaction (HRI) and varies widely across robot platforms. Levels of robot autonomy (LORA), ranging from teleoperation to fully autonomous systems, influence the way in which humans and robots interact with one another. Thus, there is a need to understand HRI by identifying variables that influence---and are influenced by---robot autonomy. Our overarching goal is to develop a framework for LORA in HRI. To reach this goal, our framework draws links between HRI and human-automation interaction, a field with a long history of studying and understanding human-related variables. The construct of autonomy is reviewed and redefined within the context of HRI. Additionally, this framework proposes a process for determining a robot's autonomy level by categorizing autonomy along a 10-point taxonomy. The framework is intended to be treated as a guideline for determining autonomy, categorizing the LORA along a qualitative taxonomy and considering HRI variables (e.g., acceptance, situation awareness, reliability) that may be influenced by the LORA.},
  doi        = {10.5898/JHRI.3.2.Beer},
  groups     = {robot},
  issue_date = {July 2014},
  keywords   = {automation, levels of robot autonomy, autonomy, framework, human-robot interaction},
  numpages   = {26},
  publisher  = {Journal of Human-Robot Interaction Steering Committee},
  timestamp  = {2021-03-12},
  url        = {https://doi.org/10.5898/JHRI.3.2.Beer},
}

@Article{Adoni2020,
  author    = {Adoni, Wilfried Yves Hamilton and Nahhal, Tarik and Krichen, Moez and El byed, Abdeltif and Assayad, Ismail},
  journal   = {Journal of Big Data},
  title     = {{DHPV}: {A} distributed algorithm for large-scale graph partitioning},
  year      = {2020},
  issn      = {2196-1115},
  number    = {1},
  pages     = {76},
  volume    = {7},
  abstract  = {Big graphs are part of the movement of “Not Only SQL” databases (also called NoSQL) focusing on the relationships between data, rather than the values themselves. The data is stored in vertices while the edges model the interactions or relationships between these data. They offer flexibility in handling data that is strongly connected to each other. The analysis of a big graph generally involves exploring all of its vertices. Thus, this operation is costly in time and resources because big graphs are generally composed of millions of vertices connected through billions of edges. Consequently, the graph algorithms are expansive compared to the size of the big graph, and are therefore ineffective for data exploration. Thus, partitioning the graph stands out as an efficient and less expensive alternative for exploring a big graph. This technique consists in partitioning the graph into a set of k sub-graphs in order to reduce the complexity of the queries. Nevertheless, it presents many challenges because it is an NP-complete problem. In this article, we present DPHV (Distributed Placement of Hub-Vertices) an efficient parallel and distributed heuristic for large-scale graph partitioning. An application on a real-world graphs demonstrates the feasibility and reliability of our method. The experiments carried on a 10-nodes Spark cluster proved that the proposed methodology achieves significant gain in term of time and outperforms JA-BE-JA, Greedy, DFEP.},
  doi       = {10.1186/s40537-020-00357-y},
  file      = {:FILES/2020 - Adoni2020 - DHPV- A distributed algorithm for large-scale graph partitioning.pdf:PDF},
  groups    = {knowledge graph},
  timestamp = {2021-03-12},
  url       = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-020-00357-y},
}

@InProceedings{Wang2020c,
  author    = {Wang, Yue and Chen, Qimai and He, Chaobo and Liu, Hai and Wu, Xiyu},
  booktitle = {Proceedings of the 2020 the 4th International Conference on Innovation in Artificial Intelligence},
  title     = {Knowledge base question answering system based on knowledge graph representation learning},
  year      = {2020},
  address   = {New York, NY, USA},
  pages     = {170–179},
  publisher = {Association for Computing Machinery},
  series    = {ICIAI 2020},
  abstract  = {Knowledge Base Question Answering (KBQA) refers that questions are answered by acquiring the relationship or entity from knowledge graph. The knowledge base is being high frequent used in modern question answering systems, which can find the exact answer from the knowledge base and return it to the users. However, due to the flexibility, richness and fuzziness of natural language, it is not easy to match the semantic information of questions with the text answers. How to accurately match these natural language questions with a large number of knowledge graph and improve the accuracy of questions and answers is an urgent problem to be solved. In this paper, we propose a question answering algorithm named TransE-QA based on knowledge graph representation learning to solve Simple QA problem. This algorithm is an end-to-end algorithm for question answering of simple QA problem. TransE and TextCNN are mainly used to represent the knowledge graph and the question. Based on knowledge graph representation learning, we propose a new scoring function, which the answer can be returned directly that required by the question. Besides, based on the TransE-QA algorithm proposed in this paper, we develop a KBQA system to visualize the process. The experiment shows that the algorithm TransE-QA, which proposed in the thesis, achieves 80.2% accuracy on FB5M dataset. It achieves better performance than previous state-of-the-art methods.},
  doi       = {10.1145/3390557.3394296},
  groups    = {reasoning},
  isbn      = {9781450376587},
  keywords  = {Knowledge graph representation learning, Question answering system, Knowledge graph, Knowledge base question answering system},
  location  = {Xiamen, China},
  numpages  = {10},
  timestamp = {2021-03-12},
  url       = {https://doi.org/10.1145/3390557.3394296},
}

@Article{Levesque1987,
  author   = {Levesque, Hector J. and Brachman, Ronald J.},
  journal  = {Computational Intelligence},
  title    = {Expressiveness and tractability in knowledge representation and reasoning},
  year     = {1987},
  number   = {1},
  pages    = {78--93},
  volume   = {3},
  abstract = {A fundamental computational limit on automated reasoning and its effect on knowledge representation is examined. Basically, the problem is that it can be more difficult to reason correctly with one representational language than with another and, moreover, that this difficulty increases dramatically as the expressive power of the language increases. This leads to a tradeoff between the expressiveness of a representational language and its computational tractability. Here we show that this tradeoff can be seen to underlie the differences among a number of existing representational formalisms, in addition to motivating many of the current research issues in knowledge representation.},
  doi      = {10.1111/j.1467-8640.1987.tb00176.x},
  file     = {:FILES/1987 - Levesque1987 - Expressiveness and tractability in knowledge representation and reasoning.pdf:PDF},
  groups   = {knowledge graph},
  keywords = {knowledge representation, description subsumption, complexity of reasoning, first-order logic, frames, semantic networks, databases, représentation de connaissances, complexité, du raisonnement, logique du premier ordre, schémas, réseaux sémantiques, bases de données},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8640.1987.tb00176.x},
}

@PhdThesis{AlMoadhen2015,
  author  = {Al-Moadhen, Ahmed},
  school  = {Cardiff University},
  title   = {Semantic based task planning for domestic service robots},
  year    = {2015},
  address = {United Kingdom},
  month   = apr,
  file    = {:FILES/2015 - AlMoadhen2015 - Semantic based task planning for domestic service robots.pdf:PDF},
  groups  = {robot, task planning},
  url     = {http://orca-mwe.cf.ac.uk/74073/},
}

@InProceedings{Tellex2014,
  author    = {Stefanie Tellex and Ross Knepper and Adrian Li and Daniela Rus and Nicholas Roy},
  booktitle = {Proceedings of Robotics: Science and Systems},
  title     = {Asking for help using inverse semantics},
  year      = {2014},
  address   = {University of California, Berkeley, USA},
  month     = jul,
  comment   = {Thomason2019: generate language requests about shared environment},
  doi       = {10.15607/RSS.2014.X.024},
  file      = {:FILES/2014 - Tellex2014 - Asking for help using inverse semantics.pdf:PDF},
  groups    = {task understanding},
  url       = {http://www.roboticsproceedings.org/rss10/index.html},
}

@InProceedings{Misra2014,
  author     = {Dipendra Kumar Misra and Jaeyong Sung and Kevin Lee and Ashutosh Saxena},
  booktitle  = {Proceedings of Robotics: Science and Systems},
  title      = {Tell me {Dave}: {Context}-sensitive grounding of natural language to manipulation instructions},
  year       = {2014},
  address    = {Berkeley, USA},
  month      = may,
  comment    = {基于条件随机场
Lu2016a: manually create a small set of hand-coded robot actions for primitive tasks though their scalability and generality are limited. manually create environment driven instructions for grounding user instructions in NL to actions.但是规模小，对机器人硬件有要求（机械臂）},
  doi        = {10.15607/RSS.2014.X.005},
  file       = {:FILES/2014 - Misra2014 - Tell me Dave- Context-sensitive grounding of natural language to manipulation instructions.pdf:PDF},
  groups     = {task understanding},
  readstatus = {read},
}

@InProceedings{Mainprice2013,
  author    = {Jim {Mainprice} and Dmitry {Berenson}},
  booktitle = {Proceedings of the 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Human-robot collaborative manipulation planning using early prediction of human motion},
  year      = {2013},
  address   = {Tokyo, Japan},
  month     = nov,
  pages     = {299--306},
  publisher = {IEEE},
  abstract  = {In this paper we present a framework that allows a human and a robot to perform simultaneous manipulation tasks safely in close proximity. The proposed framework is based on early prediction of the human's motion. The prediction system, which builds on previous work in the area of gesture recognition, generates a prediction of human workspace occupancy by computing the swept volume of learned human motion trajectories. The motion planner then plans robot trajectories that minimize a penetration cost in the human workspace occupancy while interleaving planning and execution. Multiple plans are computed in parallel, one for each robot task available at the current time, and the trajectory with the least cost is selected for execution. We test our framework in simulation using recorded human motions and a simulated PR2 robot. Our results show that our framework enables the robot to avoid the human while still accomplishing the robot's task, even in cases where the initial prediction of the human's motion is incorrect. We also show that taking into account the predicted human workspace occupancy in the robot's motion planner leads to safer and more efficient interactions between the user and the robot than only considering the human's current configuration.},
  doi       = {10.1109/IROS.2013.6696368},
  file      = {:FILES/2013 - Mainprice2013 - Human-robot collaborative manipulation planning using early prediction of human motion.pdf:PDF},
  groups    = {task understanding},
  issn      = {2153-0866},
  keywords  = {control engineering computing;human-robot interaction;manipulators;motion control;path planning;trajectory control;human-robot collaborative manipulation planning;manipulation tasks;human motion early prediction;prediction system;human workspace occupancy prediction;human motion trajectories;motion planner;robot trajectories;penetration cost minimization;robot task;PR2 robot simulation;user-robot interactions;Trajectory;Planning;Robot motion;Interference;Robot sensing systems;Computational modeling},
  url       = {https://ieeexplore.ieee.org/document/6696368},
}

@PhdThesis{卢栋才2017,
  author     = {卢栋才},
  school     = {中国科学技术大学},
  title      = {服务机器人任务理解的关键技术研究},
  year       = {2017},
  address    = {安徽，中国},
  month      = may,
  file       = {:FILES/2017 - 卢栋才2017 - 服务机器人任务理解的关键技术研究.caj:},
  groups     = {task understanding},
  keywords   = {服务机器人，人机交互，任务理解和规划，语义解析，元语言框架, read},
  owner      = {University of Science and Technology of China},
  readstatus = {read},
  url        = {https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CDFD&dbname=CDFDLAST2017&filename=1017071228.nh&v=%mmd2BfsPDtkg7jAdWwD9ztCCgq2%mmd2FOrQ8FSqC6jnCoEF7hCY7oeELa0QFoQmNTyLsl1Ks},
}
@PhdThesis{Lu2017PhD,
  author     = {Lu, Dongcai},
  school     = {University of Science and Technology of China},
  title      = {Task understanding for service robots},
  year       = {2017},
  address    = {Hefei, Anhui, China},
  month      = may,
  file       = {:FILES/2017 - 卢栋才2017 - 服务机器人任务理解的关键技术研究.caj:},
  groups     = {task understanding},
  keywords   = {},
  owner      = {University of Science and Technology of China},
  readstatus = {read},
  url        = {https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CDFD&dbname=CDFDLAST2017&filename=1017071228.nh&v=%mmd2BfsPDtkg7jAdWwD9ztCCgq2%mmd2FOrQ8FSqC6jnCoEF7hCY7oeELa0QFoQmNTyLsl1Ks},
}

@Article{Misra2016,
  author     = {Dipendra Kumar Misra and Jaeyong Sung and Kevin Lee and Ashutosh Saxena},
  journal    = {The International Journal of Robotics Research},
  title      = {Tell me {Dave}: {Context}-sensitive grounding of natural language to manipulation instructions},
  year       = {2016},
  number     = {1-3},
  pages      = {281--300},
  volume     = {35},
  abstract   = {It is important for a robot to be able to interpret natural language commands given by a human. In this paper, we consider performing a sequence of mobile manipulation tasks with instructions described in natural language. Given a new environment, even a simple task such as boiling water would be performed quite differently depending on the presence, location and state of the objects. We start by collecting a dataset of task descriptions in free-form natural language and the corresponding grounded task-logs of the tasks performed in an online robot simulator. We then build a library of verb–environment instructions that represents the possible instructions for each verb in that environment, these may or may not be valid for a different environment and task context. We present a model that takes into account the variations in natural language and ambiguities in grounding them to robotic instructions with appropriate environment context and task constraints. Our model also handles incomplete or noisy natural language instructions. It is based on an energy function that encodes such properties in a form isomorphic to a conditional random field. We evaluate our model on tasks given in a robotic simulator and show that it successfully outperforms the state of the art with 61.8\% accuracy. We also demonstrate a grounded robotic instruction sequence on a PR2 robot using the Learning from Demonstration approach.},
  comment    = {This is extension to Misra2014
empirical association model, using the knowledge of the environment where the human locates and which he/she sensors
概率模型，activity + object

VillamarGomez2021 : "a log-linear reward function model was presented to find the possible sequence of instructions considering environment context information to perform tasks, such as cooking handles generalization to new environments and can deal with ambiguities, such as incomplete instructions.However, the instruction disambiguation focuses on finding the subtasks’ sequence to perform when the main instruction does not explicitly describe all the required subtasks.In addition, this method does not consider disambiguation methods, such as spoken interaction, when the entities involved in performing the instruction are not precise."

Zhang2019a"Accuracy is often low given the ambiguity of verbs and incomplete natural language description scenarios. user instructions or high-level tasks are parsed into a series of frame elements based on predefined knowledge. These frame templates come from  domain experts"},
  doi        = {10.1177/0278364915602060},
  file       = {:FILES/2016 - Misra2016 - Tell me Dave- Context-sensitive grounding of natural language to manipulation instructions.pdf:PDF},
  groups     = {task understanding},
  readstatus = {skimmed},
  url        = {https://journals.sagepub.com/doi/10.1177/0278364915602060},
}

@InProceedings{Perera2017,
  author     = {Vittorio Perera and Manuela Veloso},
  booktitle  = {Proceedings of 2017 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},
  title      = {Learning to understand questions on the task history of a service robot},
  year       = {2017},
  address    = {Lisbon, Portugal},
  month      = aug,
  pages      = {304--309},
  publisher  = {IEEE},
  abstract   = {We present a novel approach to enable a mobile service robot to understand questions about the history of tasks it has executed. We frame the problem of understanding such questions as grounding an input sentence to a query that can be executed on the logs recorded by the robot during its runs. We define a query as an operation followed by a set of filters. In order to ground sentence to a query we introduce a joint probabilistic model. The model is composed by a shallow semantic parser and a knowledge base to store and re-use the groundings of a sentence. The Knowledge Base and its predicates are designed to match the structure of a query. Our results show that, by using such Knowledge Base, the approach proposed requires fewer and fewer corrections as users interact with the system.},
  doi        = {10.1109/ROMAN.2017.8172318},
  file       = {:FILES/2017 - Perera2017 - Learning to understand questions on the task history of a service robot.pdf:PDF},
  groups     = {task understanding},
  issn       = {1944-9437},
  keywords   = {grammars;mobile robots;probability;service robots;task history;mobile service robot;joint probabilistic model;shallow semantic parser;knowledge base;query sentence;Robots;Grounding;History;Semantics;Knowledge based systems;Natural languages},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/8172318},
}

@InProceedings{Perera2015,
  author     = {Perera, Vittorio and Veloso, Manuela},
  booktitle  = {Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)},
  title      = {Handling complex commands as service robot task requests},
  year       = {2015},
  address    = {Buenos Aires, Argentina},
  month      = jul,
  pages      = {1177--1183},
  publisher  = {AAAI Press},
  series     = {IJCAI'15},
  abstract   = {We contribute a novel approach to understand, dialogue, plan, and execute complex sentences to command a mobile service robot. We define a complex command as a natural language sentence consisting of sensing-based conditionals, conjunctions, and disjunctions. We introduce a flexible templatebased algorithm to extract such structure from the parse tree of the sentence. As the complexity of the command increases, extracting the right structure using the template-based algorithm decreases becomes more problematic. We introduce two different dialogue approaches that enable the user to confirm or correct the extracted command structure. We present how the structure used to represent complex commands can be directly used for planning and execution by the service robot. We show results on a corpus of 100 complex commands.},
  comment    = {Zhang2019a:use context-free grammar models to parse task requests, the reason these grammar models are ineffective in practice may be that such grammar models have difficulty in modeling long-distance dependency phenomena.


基于{Chen2010}
本文提出了一种template based algorithm来识别NL中的complex commands，并将其分解为atomic commands, under the framework of FrameNet.
1. 是一种递归算法，逐步分解，输入是语法树
2. 需要事先定义各种template，否则难以准确识别复杂的utterance
3. 提出两种dialog system来处理无法识别NL的情况，其一是structure based dialog (每次分解询问是否正确),其二是rephrazing dialog (让人重新组织语言)
4. 没有说明怎么处理NL、识别语音等
5.只有四种结构/operator，and or if then。},
  file       = {:FILES/2015 - Perera2015 - Handling complex commands as service robot task requests.pdf:PDF},
  groups     = {task understanding},
  isbn       = {9781577357384},
  printed    = {Y},
  readstatus = {read},
  url        = {https://www.ijcai.org/proceedings/2015/},
}

@Article{Breuer2012,
  author   = {Breuer, Thomas and Giorgana Macedo, Geovanny R. and Hartanto, Ronny and Hochgeschwender, Nico and Holz, Dirk and Hegger, Frederik and Jin, Zha and M\"{u}ller, Christian and Paulus, Jan and Reckhaus, Michael and \'{A}lvarez Ruiz, Jos\'{e} Antonio and Pl\"{o}ger, Paul G. and Kraetzschmar, Gerhard K.},
  journal  = {Journal of Intelligent \& Robotic Systems},
  title    = {Johnny: {An} autonomous service robot for domestic environments},
  year     = {2012},
  issn     = {1573-0409},
  month    = apr,
  number   = {1},
  pages    = {245--272},
  volume   = {66},
  abstract = {In this article we describe the architecture, algorithms and real-world benchmarks performed by Johnny Jackanapes, an autonomous service robot for domestic environments. Johnny serves as a research and development platform to explore, develop and integrate capabilities required for real-world domestic service applications. We present a control architecture which allows to cope with various and changing domestic service robot tasks. A software architecture supporting the rapid integration of functionality into a complete system is as well presented. Further, we describe novel and robust algorithms centered around multi-modal human robot interaction, semantic scene understanding and SLAM. Evaluation of the complete system has been performed during the last years in the RoboCup@Home competition where Johnnys outstanding performance led to successful participation. The results and lessons learned of these benchmarks are explained in more detail.},
  doi      = {10.1007/s10846-011-9608-y},
  file     = {:FILES/2012 - Breuer2012 - Johnny- An autonomous service robot for domestic environments.pdf:PDF},
  groups   = {task understanding},
  url      = {https://doi.org/10.1007/s10846-011-9608-y},
}

@InProceedings{HadfieldMenell2016,
  author    = {Dylan {Hadfield-Menell} and Christopher Lin and Rohan Chitnis and Stuart Russell and Pieter Abbeel},
  booktitle = {2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Sequential quadratic programming for task plan optimization},
  year      = {2016},
  address   = {Daejeon, Korea (South)},
  month     = oct,
  pages     = {5040--5047},
  publisher = {IEEE},
  abstract  = {We consider the problem of refining an abstract task plan into a motion trajectory. Task and motion planning is a hard problem that is essential to long-horizon mobile manipulation. Many approaches divide the problem into two steps: a search for a task plan and task plan refinement to find a feasible trajectory. We apply sequential quadratic programming to jointly optimize over the parameters in a task plan (e.g., trajectories, grasps, put down locations). We provide two modifications that make our formulation more suitable to task and motion planning. We show how to use movement primitives to reuse previous solutions (and so save optimization effort) without trapping the algorithm in a poor basin of attraction. We also derive an early convergence criterion that lets us quickly detect unsatisfiable constraints so we can re-initialize their variables. We present experiments in a navigation amongst movable objects domain and show substantial improvement in cost over a backtracking refinement algorithm.},
  comment   = {本文虽然提到了task and motion planning，但主要工作还是在motion planning上，即路径规划，该文章是基于trajectory optimization，即通过求解优化问题，得到一系列middle points along the trajectory。优化模型是非线性非凸的，算法是SQP},
  doi       = {10.1109/IROS.2016.7759740},
  file      = {:FILES/2016 - HadfieldMenell2016 - Sequential quadratic programming for task plan optimization.pdf:PDF},
  groups    = {motion planning},
  issn      = {2153-0866},
  keywords  = {Planning;Robots;Trajectory optimization;Quadratic programming;Collision avoidance},
  url       = {https://ieeexplore.ieee.org/document/7759740},
}

@Article{Wells2019,
  author   = {Andrew M. Wells and Neil T. Dantam and Anshumali Shrivastava and Lydia E. Kavraki},
  journal  = {IEEE Robotics and Automation Letters},
  title    = {Learning feasibility for task and motion planning in tabletop environments},
  year     = {2019},
  issn     = {2377-3766},
  month    = apr,
  number   = {2},
  pages    = {1255--1262},
  volume   = {4},
  abstract = {Task and motion planning (TMP) combines discrete search and continuous motion planning. Earlier work has shown that to efficiently find a task-motion plan, the discrete search can leverage information about the continuous geometry. However, incorporating continuous elements into discrete planners presents challenges. We improve the scalability of TMP algorithms in tabletop scenarios with a fixed robot by introducing geometric knowledge into a constraint-based task planner in a robust way. The key idea is to learn a classifier for feasible motions and to use this classifier as a heuristic to order the search for a task-motion plan. The learned heuristic guides the search toward feasible motions and, thus, reduces the total number of motion planning attempts. A critical property of our approach is allowing robust planning in diverse scenes. We train the classifier on minimal exemplar scenes and then use principled approximations to apply the classifier to complex scenarios in a way that minimizes the effect of errors. By combining learning with planning, our heuristic yields order-of-magnitude run time improvements in diverse tabletop scenarios. Even when classification errors are present, properly biasing our heuristic ensures that we will have little computational penalty.},
  doi      = {10.1109/LRA.2019.2894861},
  file     = {:FILES/2019 - Wells2019 - Learning feasibility for task and motion planning in tabletop environments.pdf:PDF},
  groups   = {task planning},
  keywords = {Planning;Task analysis;Probabilistic logic;Scalability;Robots;US Department of Transportation;Trajectory;Motion and path planning;task planning},
  url      = {https://ieeexplore.ieee.org/document/8624442},
}

@Article{Tenorth2017,
  author     = {Moritz Tenorth and Michael Beetz},
  journal    = {Artificial Intelligence},
  title      = {Representations for robot knowledge in the {KnowRob} framework},
  year       = {2017},
  issn       = {0004-3702},
  note       = {Special Issue on AI and Robotics},
  pages      = {151--169},
  volume     = {247},
  abstract   = {In order to robustly perform tasks based on abstract instructions, robots need sophisticated knowledge processing methods. These methods have to supply the difference between the (often shallow and symbolic) information in the instructions and the (detailed, grounded and often real-valued) information needed for execution. For filling these information gaps, a robot first has to identify them in the instructions, reason about suitable information sources, and combine pieces of information from different sources and of different structure into a coherent knowledge base. To this end we propose the KnowRob knowledge processing system for robots. In this article, we discuss why the requirements of a robot knowledge processing system differ from what is commonly investigated in AI research, and propose to re-consider a KR system as a semantically annotated view on information and algorithms that are often already available as part of the robot's control system. We then introduce representational structures and a common vocabulary for representing knowledge about robot actions, events, objects, environments, and the robot's hardware as well as inference procedures that operate on this common representation. The KnowRob system has been released as open-source software and is being used on several robots performing complex object manipulation tasks. We evaluate it through prototypical queries that demonstrate the expressive power and its impact on the robot's performance.},
  comment    = {这篇文章是介绍KnowRob的知识表达形式，以及为何要建立这种表达的原因等内容，其主要特点是建立了对object的某些continuous-valued properties 进行了直接描述，而没有进行discretization},
  doi        = {https://doi.org/10.1016/j.artint.2015.05.010},
  file       = {:FILES/2017 - Tenorth2017 - Representations for robot knowledge in the {KnowRob} framework.pdf:PDF},
  groups     = {representation},
  keywords   = {Knowledge representation, Autonomous robots, Knowledge-enabled robotics},
  readstatus = {skimmed},
  url        = {https://www.sciencedirect.com/science/article/pii/S0004370215000843},
}

@InProceedings{Saoji2020,
  author    = {Siddhant Saoji and Jan Rosell},
  booktitle = {2020 25th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)},
  title     = {Flexibly configuring task and motion planning problems for mobile manipulators},
  year      = {2020},
  address   = {Vienna, Austria},
  month     = sep,
  pages     = {1285--1288},
  publisher = {IEEE},
  volume    = {1},
  abstract  = {Robotic manipulation requires the planning at a symbolic level (task planning) and at a geometric level (motion planning). This paper presents a planning framework for both levels of planning that includes an easy way to configure their interconnection. Motion planning is done using The Kautham Project, which is equipped with the Open Motion Planning Library suite of sampling-based motion planners, and task planning is done using the Fast Forward task planner. Both planning levels can be accessed through Robotic Operating System interfaces using services. A client program then uses these task and motion planning services and an XML configuration file that defines the linkage between symbolic actions and geometric values, to compute the sequence of feasible robot motions that allow to successfully execute a manipulation task. An illustrative example using the TIAGo mobile manipulator in a kitchen environment is presented where the flexibility in configuring different instances of manipulation tasks is shown.},
  doi       = {10.1109/ETFA46521.2020.9212086},
  file      = {:FILES/2020 - Saoji2020 - Flexibly configuring task and motion planning problems for mobile manipulators.pdf:PDF},
  groups    = {task planning},
  issn      = {1946-0759},
  keywords  = {Robotic manipulation;task planning;motion planning},
}

@InProceedings{Guadarrama2013,
  author    = {Sergio Guadarrama and Lorenzo Riano and Dave Golland and Daniel Go\"{o}hring and Yangqing Jia and Dan Klein and Pieter Abbeel and Trevor Darrell},
  booktitle = {Proceedings of the 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Grounding spatial relations for human-robot interaction},
  year      = {2013},
  address   = {Tokyo, Japan},
  month     = nov,
  pages     = {1640--1647},
  publisher = {IEEE},
  abstract  = {We propose a system for human-robot interaction that learns both models for spatial prepositions and for object recognition. Our system grounds the meaning of an input sentence in terms of visual percepts coming from the robot's sensors in order to send an appropriate command to the PR2 or respond to spatial queries. To perform this grounding, the system recognizes the objects in the scene, determines which spatial relations hold between those objects, and semantically parses the input sentence. The proposed system uses the visual and spatial information in conjunction with the semantic parse to interpret statements that refer to objects (nouns), their spatial relationships (prepositions), and to execute commands (actions). The semantic parse is inherently compositional, allowing the robot to understand complex commands that refer to multiple objects and relations such as: “Move the cup close to the robot to the area in front of the plate and behind the tea box”. Our system correctly parses 94\% of the 210 online test sentences, correctly interprets 91\% of the correctly parsed sentences, and correctly executes 89\% of the correctly interpreted sentences.},
  comment   = {grammar model, v+ n 描述spatial relation
empirical association model, using the key aspects, such as preconditions or other details of the actions etc.
Boularias2015:Learn language and perception model for spatial prepositions and for object recognition. Simple relation and no perception uncertainty
Zhang2019a:keyword matching method uses domain dictionary to parses instructions, and the matching results are used as trigger conditions of the frame template
{Anderson2018}：natural language navigation，operating in visually restricted environments requiring limited perception},
  doi       = {10.1109/IROS.2013.6696569},
  file      = {:FILES/2013 - Guadarrama2013 - Grounding spatial relations for human-robot interaction.pdf:PDF},
  groups    = {human robot interaction, task understanding, navigation},
  issn      = {2153-0866},
  keywords  = {Three-dimensional displays;Robot sensing systems;Semantics;Grounding;Adaptation models;Natural languages},
  url       = {https://ieeexplore.ieee.org/document/6696569},
}

@Article{Cybenko1989,
  author     = {Cybenko, G.},
  journal    = {Mathematics of Control, Signals and Systems},
  title      = {Approximation by superpositions of a sigmoidal function},
  year       = {1989},
  issn       = {1435-568X},
  number     = {4},
  pages      = {303--314},
  volume     = {2},
  abstract   = {In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks.},
  comment    = {NN中sigmoidal functions需要是连续且单调递增的，但本文对单调性没有要求。这里的sigmoidal function是一类函数，而不仅仅是S型。},
  doi        = {10.1007/BF02551274},
  file       = {:FILES/1989 - Cybenko1989 - Approximation by superpositions of a sigmoidal function.pdf:PDF},
  groups     = {Neural Network},
  readstatus = {read},
  url        = {https://link.springer.com/article/10.1007/BF02551274},
}

@Article{Hornik1989,
  author     = {Kurt Hornik and Maxwell Stinchcombe and Halbert White},
  journal    = {Neural Networks},
  title      = {Multilayer feedforward networks are universal approximators},
  year       = {1989},
  issn       = {0893-6080},
  number     = {5},
  pages      = {359--366},
  volume     = {2},
  abstract   = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.},
  doi        = {https://doi.org/10.1016/0893-6080(89)90020-8},
  file       = {:FILES/1989 - Hornik1989 - Multilayer feedforward networks are universal approximators.pdf:PDF},
  groups     = {Neural Network},
  keywords   = {Feedforward networks, Universal approximation, Mapping networks, Network representation capability, Stone-Weierstrass Theorem, Squashing functions, Sigma-Pi networks, Back-propagation networks},
  readstatus = {skimmed},
  url        = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
}

@Article{Barron1993,
  author   = {Andrew R. Barron},
  journal  = {IEEE Transactions on Information Theory},
  title    = {Universal approximation bounds for superpositions of a sigmoidal function},
  year     = {1993},
  issn     = {1557-9654},
  month    = may,
  number   = {3},
  pages    = {930--945},
  volume   = {39},
  abstract = {Approximation properties of a class of artificial neural networks are established. It is shown that feedforward networks with one layer of sigmoidal nonlinearities achieve integrated squared error of order O(1/n), where n is the number of nodes. The approximated function is assumed to have a bound on the first moment of the magnitude distribution of the Fourier transform. The nonlinear parameters associated with the sigmoidal nodes, as well as the parameters of linear combination, are adjusted in the approximation. In contrast, it is shown that for series expansions with n terms, in which only the parameters of linear combination are adjusted, the integrated squared approximation error cannot be made smaller than order 1/n/sup 2/d/ uniformly for functions satisfying the same smoothness assumption, where d is the dimension of the input to the function. For the class of functions examined, the approximation rate and the parsimony of the parameterization of the networks are shown to be advantageous in high-dimensional settings.<>},
  comment  = {The purpose of this paper is to examine how the approximation error is related to the number of nodes in the network.},
  doi      = {10.1109/18.256500},
  file     = {:FILES/1993 - Barron1993 - Universal approximation bounds for superpositions of a sigmoidal function.pdf:PDF},
  groups   = {Neural Network},
  keywords = {Artificial neural networks;Fourier transforms;Approximation error;Feeds;Linear approximation;Neural networks;Feedforward neural networks;Information theory;Statistics;Statistical distributions},
  url      = {https://ieeexplore.ieee.org/document/256500},
}

@Article{Leshno1993,
  author   = {Moshe Leshno and Vladimir Ya. Lin and Allan Pinkus and Shimon Schocken},
  journal  = {Neural Networks},
  title    = {Multilayer feedforward networks with a nonpolynomial activation function can approximate any function},
  year     = {1993},
  issn     = {0893-6080},
  number   = {6},
  pages    = {861--867},
  volume   = {6},
  abstract = {Several researchers characterized the activation function under which multilayer feedforward networks can act as universal approximators. We show that most of all the characterizations that were reported thus far in the literature are special cases of the following general result: A standard multilayer feedforward network with a locally bounded piecewise continuous activation function can approximate any continuous function to any degree of accuracy if and only if the network's activation function is not a polynomial. We also emphasize the important role of the threshold, asserting that without it the last theorem does not hold.},
  doi      = {https://doi.org/10.1016/S0893-6080(05)80131-5},
  file     = {:FILES/1993 - Leshno1993 - Multilayer feedforward networks with a nonpolynomial activation function can approximate any function.pdf:PDF},
  groups   = {Neural Network},
  keywords = {Multilayer feedforward networks, Activation functions, Role of threshold, Universal approximation capabilities, (μ) approximation},
  url      = {https://www.sciencedirect.com/science/article/pii/S0893608005801315},
}

@InProceedings{Gallant1988,
  author    = {Ronald A. Gallant and Halbert White},
  booktitle = {IEEE 1988 International Conference on Neural Networks},
  title     = {There exists a neural network that does not make avoidable mistakes},
  year      = {1988},
  address   = {San Diego, CA, USA},
  month     = jul,
  pages     = {657--664},
  publisher = {IEEE},
  abstract  = {The authors show that a multiple-input, single-output, single-hidden-layer feedforward network with (known) hardwired connections from input to hidden layer, monotone squashing at the hidden layer and no squashing at the output embeds as a special case a so-called Fourier network, which yields a Fourier series approximation properties of Fourier series representations. In particular, approximation to any desired accuracy of any square integrable function can be achieved by such a network, using sufficiently many hidden units. In this sense, such networks do not make avoidable mistakes.<>},
  comment   = {activation function to be cosine function, thus nn is equivalent to Fourier series approximation. valid for square integrable function.},
  doi       = {10.1109/ICNN.1988.23903},
  file      = {:FILES/1988 - Gallant1988 - There exists a neural network that does not make avoidable mistakes.pdf:PDF},
  groups    = {Neural Network},
  keywords  = {Neural networks},
  url       = {https://ieeexplore.ieee.org/document/23903},
}

@InProceedings{Telgarsky2016,
  author    = {Matus Telgarsky},
  booktitle = {29th Annual Conference on Learning Theory},
  title     = {Benefits of depth in neural networks},
  year      = {2016},
  address   = {Columbia University, New York, New York, USA},
  editor    = {Vitaly Feldman and Alexander Rakhlin and Ohad Shamir},
  month     = jun,
  pages     = {1517--1539},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {49},
  abstract  = {For any positive integer k, there exist neural networks with $\Theta(k^3)$ layers, $\Theta(1)$ nodes per layer, and $\Theta(1)$ distinct parameters which can not be approximated by networks with $O(k)$ layers unless they are exponentially large -- they must possess $\Omega(2^k)$ nodes. This result is proved here for a class of nodes termed \emph{semi-algebraic} gates which includes the common choices of ReLU, maximum, indicator, and piecewise polynomial functions, therefore establishing benefits of depth against not just standard networks with ReLU gates, but also convolutional networks with ReLU and maximization gates, sum-product networks, and boosted decision trees (in this last case with a stronger separation: $\Omega(2^{k^3})$ total tree nodes are required).},
  file      = {:FILES/2016 - Telgarsky2016 - Benefits of depth in neural networks.pdf:PDF},
  groups    = {Neural Network},
  url       = {http://proceedings.mlr.press/v49/telgarsky16.html},
}

@InProceedings{Goodfellow2013,
  author    = {Ian Goodfellow and David Warde-Farley and Mehdi Mirza and Aaron Courville and Yoshua Bengio},
  booktitle = {Proceedings of the 30th International Conference on Machine Learning},
  title     = {Maxout networks},
  year      = {2013},
  address   = {Atlanta, Georgia, USA},
  editor    = {Sanjoy Dasgupta and David McAllester},
  month     = jun,
  number    = {3},
  pages     = {1319--1327},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {28},
  abstract  = {We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN.},
  file      = {:FILES/2013 - Goodfellow2013 - Maxout networks.pdf:PDF},
  groups    = {Neural Network},
  url       = {http://proceedings.mlr.press/v28/goodfellow13.html},
}

@InProceedings{Montufar2014,
  author    = {Montufar, Guido F. and Pascanu, Razvan and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle = {Advances in neural information processing systems},
  title     = {On the number of linear regions of deep neural networks},
  year      = {2014},
  pages     = {2924--2932},
  publisher = {Curran Associates, Inc.},
  volume    = {4},
  file      = {:FILES/2014 - Montufar2014 - On the number of linear regions of deep neural networks.pdf:PDF},
  groups    = {Neural Network},
}

@InProceedings{Raghu2017,
  author    = {Maithra Raghu and Ben Poole and Jon Kleinberg and Surya Ganguli and Jascha Sohl-Dickstein},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  title     = {On the expressive power of deep neural networks},
  year      = {2017},
  address   = {International Convention Centre, Sydney, Australia},
  editor    = {Doina Precup and Yee Whye Teh},
  month     = aug,
  pages     = {2847--2854},
  publisher = {PMLR},
  volume    = {70},
  abstract  = {We propose a new approach to the problem of neural network expressivity, which seeks to characterize how structural properties of a neural network family affect the functions it is able to compute. Our approach is based on an interrelated set of measures of expressivity, unified by the novel notion of trajectory length, which measures how the output of a network changes as the input sweeps along a one-dimensional path. Our findings show that: (1) The complexity of the computed function grows exponentially with depth (2) All weights are not equal: trained networks are more sensitive to their lower (initial) layer weights (3) Trajectory regularization is a simpler alternative to batch normalization, with the same performance.},
  file      = {:FILES/2017 - Raghu2017 - On the expressive power of deep neural networks.pdf:PDF},
  groups    = {Neural Network},
  url       = {http://proceedings.mlr.press/v70/raghu17a.html},
}

@InProceedings{Lin2018,
  author    = {Lin, Hongzhou and Jegelka, Stefanie},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {{ResNet} with one-neuron hidden layers is a universal approximator},
  year      = {2018},
  address   = {Montr\'{e}al, Canada},
  editor    = {S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett},
  pages     = {1--10},
  publisher = {Curran Associates, Inc.},
  volume    = {31},
  file      = {:FILES/2018 - Lin2018 - {ResNet} with one-neuron hidden layers is a universal approximator.pdf:PDF},
  groups    = {Neural Network},
  url       = {https://proceedings.neurips.cc/paper/2018/file/03bfc1d4783966c69cc6aef8247e0103-Paper.pdf},
}

@InProceedings{Lu2017,
  author    = {Lu, Zhou and Pu, Hongming and Wang, Feicheng and Hu, Zhiqiang and Wang, Liwei},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {The expressive power of neural networks: {A} view from the width},
  year      = {2017},
  editor    = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
  publisher = {Curran Associates, Inc.},
  volume    = {30},
  file      = {:FILES/2017 - Lu2017 - The expressive power of neural networks- {A} view from the width.pdf:PDF},
  groups    = {Neural Network},
  url       = {https://proceedings.neurips.cc/paper/2017/file/32cbf687880eb1674a07bf717761dd3a-Paper.pdf},
}

@Misc{Arora2018,
  author        = {Raman Arora and Amitabh Basu and Poorya Mianjy and Anirbit Mukherjee},
  title         = {Understanding deep neural networks with rectified linear units},
  year          = {2018},
  archiveprefix = {arXiv},
  eprint        = {1611.01491},
  file          = {:FILES/2018 - Arora2018 - Understanding deep neural networks with rectified linear units.pdf:PDF},
  groups        = {Neural Network},
  primaryclass  = {cs.LG},
}

@Misc{Kumar2019a,
  author        = {Abhinav Kumar and Thiago Serra and Srikumar Ramalingam},
  title         = {Equivalent and approximate transformations of deep neural networks},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1905.11428},
  file          = {:FILES/2019 - Kumar2019a - Equivalent and approximate transformations of deep neural networks.pdf:PDF},
  groups        = {Neural Network},
  primaryclass  = {cs.LG},
}

@Article{Lin2019a,
  author   = {Shao-bo Lin},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  title    = {Generalization and expressivity for deep nets},
  year     = {2019},
  issn     = {2162-2388},
  month    = may,
  number   = {5},
  pages    = {1392--1406},
  volume   = {30},
  abstract = {Along with the rapid development of deep learning in practice, theoretical explanations for its success become urgent. Generalization and expressivity are two widely used measurements to quantify theoretical behaviors of deep nets. The expressivity focuses on finding functions expressible by deep nets but cannot be approximated by shallow nets with similar number of neurons. It usually implies the large capacity. The generalization aims at deriving fast learning rate for deep nets. It usually requires small capacity to reduce the variance. Different from previous studies on deep nets, pursuing either expressivity or generalization, we consider both the factors to explore theoretical advantages of deep nets. For this purpose, we construct a deep net with two hidden layers possessing excellent expressivity in terms of localized and sparse approximation. Then, utilizing the well known covering number to measure the capacity, we find that deep nets possess excellent expressive power (measured by localized and sparse approximation) without essentially enlarging the capacity of shallow nets. As a consequence, we derive near-optimal learning rates for implementing empirical risk minimization on deep nets. These results theoretically exhibit advantages of deep nets from the learning theory viewpoint.},
  doi      = {10.1109/TNNLS.2018.2868980},
  file     = {:FILES/2019 - Lin2019a - Generalization and expressivity for deep nets.pdf:PDF},
  groups   = {Neural Network},
  keywords = {Neurons;Sparse representation;Biological neural networks;Machine learning;Learning systems;Power measurement;Risk management;Deep learning;expressivity;generalization;learning theory;localized approximation},
  url      = {https://ieeexplore.ieee.org/document/8475035},
}

@Article{Huang1991,
  author   = {Shih-Chi Huang and Yih-Fang Huang},
  journal  = {IEEE Transactions on Neural Networks},
  title    = {Bounds on the number of hidden neurons in multilayer perceptrons},
  year     = {1991},
  issn     = {1941-0093},
  month    = jan,
  number   = {1},
  pages    = {47--55},
  volume   = {2},
  abstract = {Fundamental issues concerning the capability of multilayer perceptrons with one hidden layer are investigated. The studies are focused on realizations of functions which map from a finite subset of E/sup n/ into E/sup d/. Real-valued and binary-valued functions are considered. In particular, a least upper bound is derived for the number of hidden neurons needed to realize an arbitrary function which maps from a finite subset of E/sup n/ into E/sup d/. A nontrivial lower bound is also obtained for realizations of injective functions. This result can be applied in studies of pattern recognition and database retrieval. An upper bound is given for realizing binary-valued functions that are related to pattern-classification problems.<>},
  doi      = {10.1109/72.80290},
  file     = {:FILES/1991 - Huang1991 - Bounds on the number of hidden neurons in multilayer perceptrons.pdf:PDF},
  groups   = {Neural Network},
  keywords = {Neurons;Multilayer perceptrons;Upper bound;Neural networks;Backpropagation algorithms;Multi-layer neural network;Pattern recognition;Databases;Information retrieval;Pattern classification},
  url      = {https://ieeexplore.ieee.org/document/80290},
}

@Article{Sartori1991,
  author   = {Michael A. Sartori and Panos J. Antsaklis},
  journal  = {IEEE Transactions on Neural Networks},
  title    = {A simple method to derive bounds on the size and to train multilayer neural networks},
  year     = {1991},
  issn     = {1941-0093},
  month    = jul,
  number   = {4},
  pages    = {467--471},
  volume   = {2},
  abstract = {A new derivation is presented for the bounds on the size of a multilayer neural network to exactly implement an arbitrary training set; namely the training set can be implemented with zero error with two layers and with the number of the hidden-layer neurons equal to Hash 1>or=p-1. The derivation does not require the separation of the input space by particular hyperplanes, as in previous derivations. The weights for the hidden layer can be chosen almost arbitrarily, and the weights for the output layer can be found by solving Hash 1+1 linear equations. The method presented exactly solves (M), the multilayer neural network training problem, for any arbitrary training set.<>},
  doi      = {10.1109/72.88168},
  file     = {:FILES/1991 - Sartori1991 - A simple method to derive bounds on the size and to train multilayer neural networks.pdf:PDF},
  groups   = {Neural Network},
  keywords = {Multi-layer neural network;Neural networks;Neurons;Nonlinear equations;Propulsion;Sufficient conditions;Computer networks},
  url      = {https://ieeexplore.ieee.org/document/88168},
}

@Article{Huang1998,
  author   = {Guang-Bin Huang and Haroon A. Babri},
  journal  = {IEEE Transactions on Neural Networks},
  title    = {Upper bounds on the number of hidden neurons in feedforward networks with arbitrary bounded nonlinear activation functions},
  year     = {1998},
  issn     = {1941-0093},
  month    = jan,
  number   = {1},
  pages    = {224--229},
  volume   = {9},
  abstract = {It is well known that standard single-hidden layer feedforward networks (SLFNs) with at most N hidden neurons (including biases) can learn N distinct samples (x/sub i/,t/sub i/) with zero error, and the weights connecting the input neurons and the hidden neurons can be chosen "almost" arbitrarily. However, these results have been obtained for the case when the activation function for the hidden neurons is the signum function. This paper rigorously proves that standard single-hidden layer feedforward networks (SLFNs) with at most N hidden neurons and with any bounded nonlinear activation function which has a limit at one infinity can learn N distinct samples (x/sub i/,t/sub i/) with zero error. The previous method of arbitrarily choosing weights is not feasible for any SLFN. The proof of our result is constructive and thus gives a method to directly find the weights of the standard SLFNs with any such bounded nonlinear activation function as opposed to iterative training algorithms in the literature.},
  doi      = {10.1109/72.655045},
  file     = {:FILES/1998 - Huang1998 - Upper bounds on the number of hidden neurons in feedforward networks with arbitrary bounded nonlinear activation functions.pdf:PDF},
  groups   = {Neural Network},
  keywords = {Neurons;Intelligent networks;Multi-layer neural network;Neural networks;Artificial neural networks;Feedforward neural networks;H infinity control;Joining processes;Iterative methods;Iterative algorithms},
  url      = {https://ieeexplore.ieee.org/document/655045},
}

@InProceedings{Yamasaki1993,
  author    = {Yamasaki, Masami},
  booktitle = {International Conference on Artificial Neural Networks 1993},
  title     = {The lower bound of the capacity for a neural network with multiple hidden layers},
  year      = {1993},
  address   = {London},
  editor    = {Gielen, Stan and Kappen, Bert},
  pages     = {546--549},
  publisher = {Springer London},
  abstract  = {We show the lower bound of the capacity of a hierarchical neural network, having multiple hidden layers whose node unit takes the value of a real number between zero and one as the output of a sigmoid function. It is shown that xx examples in the general position (i.e. no subset of n or less input vectors degenerate) can be memorized by the network which has n input units in the input layer, $h_l$ hidden units in the $l$-th layer of N hidden layers, and a single output unit in the output layer.},
  doi       = {10.1007/978-1-4471-2063-6_150},
  file      = {:FILES/1993 - Yamasaki1993 - The lower bound of the capacity for a neural network with multiple hidden layers.pdf:PDF},
  groups    = {Neural Network},
  isbn      = {978-1-4471-2063-6},
  url       = {https://link.springer.com/chapter/10.1007/978-1-4471-2063-6_150},
}

@Article{Huang2003,
  author   = {Guang-Bin Huang},
  journal  = {IEEE Transactions on Neural Networks},
  title    = {Learning capability and storage capacity of two-hidden-layer feedforward networks},
  year     = {2003},
  issn     = {1941-0093},
  month    = mar,
  number   = {2},
  pages    = {274--281},
  volume   = {14},
  abstract = {The problem of the necessary complexity of neural networks is of interest in applications. In this paper, learning capability and storage capacity of feedforward neural networks are considered. We markedly improve the recent results by introducing neural-network modularity logically. This paper rigorously proves in a constructive method that two-hidden-layer feedforward networks (TLFNs) with 2/spl radic/(m+2)N (/spl Lt/N) hidden neurons can learn any N distinct samples (x/sub i/, t/sub i/) with any arbitrarily small error, where m is the required number of output neurons. It implies that the required number of hidden neurons needed in feedforward networks can be decreased significantly, comparing with previous results. Conversely, a TLFN with Q hidden neurons can store at least Q/sup 2//4(m+2) any distinct data (x/sub i/, t/sub i/) with any desired precision.},
  doi      = {10.1109/TNN.2003.809401},
  file     = {:FILES/2003 - Huang2003 - Learning capability and storage capacity of two-hidden-layer feedforward networks.pdf:PDF},
  groups   = {Neural Network},
  keywords = {Neurons;Neural networks;Multi-layer neural network;Feedforward neural networks;Upper bound},
  url      = {https://ieeexplore.ieee.org/document/1189626?denied=},
}

@Misc{Hardt2018,
  author        = {Moritz Hardt and Tengyu Ma},
  title         = {Identity matters in deep learning},
  year          = {2018},
  archiveprefix = {arXiv},
  eprint        = {1611.04231},
  file          = {:FILES/2018 - Hardt2018 - Identity matters in deep learning.pdf:PDF},
  groups        = {Neural Network},
  primaryclass  = {cs.LG},
  readstatus    = {skimmed},
  url           = {https://arxiv.org/abs/1611.04231},
}

@Article{Mirchandani1989,
  author   = {Gagan Mirchandani and Wei Cao},
  journal  = {IEEE Transactions on Circuits and Systems},
  title    = {On hidden nodes for neural nets},
  year     = {1989},
  issn     = {1558-1276},
  month    = may,
  number   = {5},
  pages    = {661--664},
  volume   = {36},
  abstract = {Recent results indicate that the number of hidden nodes (H) in a feedforward neural net depend only on the number of input training patterns (T). There appear to be conjectures that H is on the order of T-1 and of log/sub 2/T. A proof is given that the maximum number of separable regions (M) in the input space is a function of both H and input space dimension (d). The authors also show that H=M -1 and H=log/sub 2/M are special cases of that formulation. M defines a lower bound on T, the number of input patterns that may be used for training. Application to some experiments are investigated.<>},
  doi      = {10.1109/31.31313},
  file     = {:FILES/1989 - Mirchandani1989 - On hidden nodes for neural nets.pdf:PDF},
  groups   = {Neural Network},
  keywords = {Neural networks;Feedforward neural networks;Multilayer perceptrons;Pattern classification;Shape;Sonar;Random number generation;Computer science;Circuits and systems},
  url      = {https://ieeexplore.ieee.org/document/31313?arnumber=31313},
}

@Article{Zhang2021a,
  author    = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal   = {Communications of the ACM},
  title     = {Understanding deep learning (still) requires rethinking generalization},
  year      = {2021},
  issn      = {0001-0782},
  month     = feb,
  number    = {3},
  pages     = {107--15},
  volume    = {64},
  abstract  = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small gap between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family or to the regularization techniques used during training.Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice.We interpret our experimental findings by comparison with traditional models.We supplement this republication with a new section at the end summarizing recent progresses in the field since the original version of this paper.},
  address   = {New York, NY, USA},
  doi       = {10.1145/3446776},
  file      = {:FILES/2021 - Zhang2021a - Understanding deep learning (still) requires rethinking generalization.pdf:PDF},
  groups    = {Neural Network},
  publisher = {Association for Computing Machinery},
  url       = {https://dl.acm.org/doi/10.1145/3446776},
}

@InProceedings{Zhang2017,
  author     = {Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals},
  booktitle  = {Proceedings of 5th International Conference on Learning Representations (ICLR)},
  title      = {Understanding deep learning requires rethinking generalization},
  year       = {2017},
  address    = {Toulon, France},
  month      = apr,
  pages      = {1--15},
  file       = {:FILES/2017 - Zhang2017 - Understanding deep learning requires rethinking generalization.pdf:PDF},
  groups     = {Neural Network},
  readstatus = {skimmed},
  url        = {https://openreview.net/forum?id=Sy8gdB9xx},
}

@Article{Roy2021,
  author   = {Subhabrata Roy and Abhijit Chandra},
  journal  = {Integration},
  title    = {A survey of {FIR} filter design techniques: {Low-complexity}, narrow transition-band and variable bandwidth},
  year     = {2021},
  issn     = {0167-9260},
  month    = mar,
  pages    = {193--204},
  volume   = {77},
  abstract = {In the present century, digital signal processing (DSP) approaches are considered to be one of the most powerful technologies which may shape the science and technology in coming decades. From 1970 onwards, a drastic revolution took place in a wider domain of DSP which has made it popular in several studies such as radar and sonar signal processing, digital televisions, wireless communication scenarios and other multimedia setup etc. Digital filters form the backbone of this DSP architecture and in point of fact the field of digital filter design has drawn justified recognition from the researchers throughout the world for the last 50 years. In connection to this, thousands of research articles may be found from the literature which had extensively addressed on the design of such filters. In order to meet the requirement of narrow transition-band, finite impulse response (FIR) filters are commonly assumed to be of higher order and accordingly it significantly enhances computational complexity. In regard to this, construction of hardware efficient digital filters had drawn significant consideration which aims to include minimum hardware elements during its application and consequently consumes less power. This review paper illustrates various techniques for the implementation of hardware efficient narrow transition-band FIR filter and investigates a number of favourable attributes which are capable in sustaining the stringent requirements of communication standards. A good number of relevant articles are taken from the literature so as to make a robust and complete review.},
  doi      = {10.1016/j.vlsi.2020.12.001},
  file     = {:FILES/2021 - Roy2021 - A survey of FIR filter design techniques- Low-complexity, narrow transition-band and variable bandwidth.pdf:PDF},
  groups   = {FIR filter design},
  keywords = {Common Subexpression elimination algorithm, Farrow structure, FIR filter, Frequency response masking, Low-complexity, Narrow transition-band, Signed-powers-of-two representation, Variable bandwidth},
  priority = {prio1},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167926020303102},
}

@Article{Srivatsan2020,
  author   = {K. Srivatsan and Nithya Venkatesan},
  journal  = {AEU - International Journal of Electronics and Communications},
  title    = {Farrow structure based {FIR} filter design using hybrid optimization},
  year     = {2020},
  issn     = {1434-8411},
  pages    = {153020},
  volume   = {114},
  abstract = {Farrow structure is an effective structure for designing the digital filters in order to lease the complexity associated with the design. Keeping in mind, the effective and simple design of the digital filters, a method is proposed based on the Farrow structure. The proposed digital FIR filter is designed based on the farrow structure along with hybrid optimization that is designed using the Brain Storm Optimization (BSO) and Artificial Bee Colony (ABC) algorithm, termed as Brain Storm-Artificial Bee Colony (BSABC) algorithm. The proposed algorithm works based on the minimum objective function that depends on the total number of the hardware components especially adders/subtractors employed for the filter design and frequency response. The proposed algorithm operates in such a way that the quality of the filter is sustained with less number of hardware components. The optimal tuning using the proposed algorithm is simulated and analyzed for highlighting the effective method. The analysis is progressed in terms of the number of components employed in the design, fitness, Mean Absolute Error (MAE), and magnitude. The result of the analysis proves that the proposed method is effective over the Least-Square method with the minimum hardware components of 236 with minimum MAE of 0.02.},
  doi      = {10.1016/j.aeue.2019.153020},
  file     = {:FILES/2020 - Srivatsan2020 - Farrow structure based FIR filter design using hybrid optimization.pdf:PDF},
  groups   = {FIR filter design},
  keywords = {Farrow structure, FIR filter design, Brain Storm Optimization, Artificial Bee Colony, Hybrid optimization},
  url      = {https://www.sciencedirect.com/science/article/pii/S1434841119314864},
}

@InProceedings{Kumm2013,
  author    = {Martin Kumm and Kumm M\"{o}ller and Peter Zipf},
  booktitle = {2013 8th International Workshop on Reconfigurable and Communication-Centric Systems-on-Chip (ReCoSoC)},
  title     = {Dynamically reconfigurable {FIR} filter architectures with fast reconfiguration},
  year      = {2013},
  address   = {Darmstadt, Germany},
  month     = jul,
  pages     = {1--8},
  publisher = {IEEE},
  abstract  = {This work compares two finite impulse response (FIR) filter architectures for FPGAs for which the coefficients can be reconfigured during run-time. One is a recently proposed filter architecture based on distributed arithmetic (DA) and the other is based on a LUT multiplication scheme. Instead of using the common internal configuration access port (ICAP) for reconfiguration which is able to change the logic as well as the routing, it is sufficient to reconfigure only the logic in the regarded architectures. This is realized by using the configurable look-up table (CFGLUT) primitive of Xilinx that allows reconfiguration times which are orders of magnitudes faster than using ICAP. The resulting FIR filter architectures achieves reconfiguration times of typically less than 100 ns. They can be reconfigured with arbitrary coefficients that are only limited by their length and word size. As their resource consumptions depend on different parameters of the filter, a detailed comparison is done. It turned out that if the input word size is greater than approximately half the number of coefficients, the LUT based multiplication scheme needs less resources than the DA architecture and vice versa.},
  doi       = {10.1109/ReCoSoC.2013.6581517},
  file      = {:FILES/2013 - Kumm2013 - Dynamically reconfigurable {FIR} filter architectures with fast reconfiguration.pdf:PDF},
  groups    = {FIR filter design},
  keywords  = {Table lookup;Adders;Finite impulse response filters;Field programmable gate arrays;Random access memory;Clocks},
  url       = {https://ieeexplore.ieee.org/document/6581517},
}

@MastersThesis{叶子2020,
  author  = {叶子},
  school  = {中国科学技术大学},
  title   = {基于知识图谱子图融合},
  year    = {2020},
  address = {合肥，安徽},
  month   = may,
  file    = {:FILES/2020 - 叶子2020 - 基于知识图谱子图融合的多关系问答_叶子.caj:caj},
  groups  = {human robot interaction},
}

@PhdThesis{谢炯坤2014,
  author  = {谢炯坤},
  school  = {中国科学技术大学},
  title   = {面向人机交互的自然语言理解的研究},
  year    = {2014},
  address = {合肥，安徽},
  month   = may,
  file    = {:FILES/2014 - 谢炯坤2014 - 面向人机互动的自然语言理解的研究_谢炯坤.caj:caj},
  groups  = {human robot interaction},
}

@Article{Zhu2021,
  author   = {Zhu, Xiaofei and Do, Khoi Duy and Guo, Jiafeng and Xu, Jun and Dietze, Stefan},
  journal  = {Neural Processing Letters},
  title    = {Exploring implicit and explicit geometrical structure of data for deep embedded clustering},
  year     = {2021},
  issn     = {1573-773X},
  number   = {1},
  pages    = {1--16},
  volume   = {53},
  abstract = {Clustering is an essential data analysis technique and has been studied extensively over the last decades. Previous studies have shown that data representation and data structure information are two critical factors for improving clustering performance, and it forms two important lines of research. The first line of research attempts to learn representative features, especially utilizing the deep neural networks, for handling clustering problems. The second concerns exploiting the geometric structure information within data for clustering. Although both of them have achieved promising performance in lots of clustering tasks, few efforts have been dedicated to combine them in a unified deep clustering framework, which is the research gap we aim to bridge in this work. In this paper, we propose a novel approach, Manifold regularized Deep Embedded Clustering (MDEC), to deal with the aforementioned challenge. It simultaneously models data generating distribution, cluster assignment consistency, as well as geometric structure of data in a unified framework. The proposed method can be optimized by performing mini-batch stochastic gradient descent and back-propagation. We evaluate MDEC on three real-world datasets (USPS, REUTERS-10K, and MNIST), where experimental results demonstrate that our model outperforms baseline models and obtains the state-of-the-art performance.},
  doi      = {10.1007/s11063-020-10375-9},
  file     = {:FILES/2021 - Zhu2021 - Exploring Implicit and Explicit Geometrical Structure of Data for Deep Embedded Clustering.pdf:PDF},
  groups   = {interesting articles},
  url      = {https://link.springer.com/article/10.1007/s11063-020-10375-9},
}

@Article{Fushiki2021,
  author   = {Fushiki, Tadayoshi},
  journal  = {Neural Processing Letters},
  title    = {On the selection of the regularization parameter in stacking},
  year     = {2021},
  issn     = {1573-773X},
  number   = {1},
  pages    = {37--48},
  volume   = {53},
  abstract = {Stacking is a model combination technique to improve prediction accuracy. Regularization is usually necessary in stacking because some predictions used in the model combination provide similar predictions. Cross-validation is generally used to select the regularization parameter, but it incurs a high computational cost. This paper proposes two simple low computational cost methods for selecting the regularization parameter. The effectiveness of the methods is examined in numerical experiments. Asymptotic results in a particular setting are also shown.},
  doi      = {10.1007/s11063-020-10378-6},
  file     = {:FILES/2021 - Fushiki2021 - On the Selection of the Regularization Parameter in Stacking.pdf:PDF},
  groups   = {machine learning},
  url      = {https://link.springer.com/article/10.1007/s11063-020-10378-6},
}

@Article{AlvaradoVasquez2020,
  author   = {Biel Piero E. {Alvarado V\'{a}squez} and Fernando Matía},
  journal  = {Engineering Applications of Artificial Intelligence},
  title    = {A tour-guide robot: Moving towards interaction with humans},
  year     = {2020},
  issn     = {0952-1976},
  pages    = {103356},
  volume   = {88},
  abstract = {The aim of this research project is to develop a smart social robot showing sufficient intelligence to work as a tour-guide in different environments. In doing so, both a software and a hardware architecture are proposed, the different modules of which, such as a laser, cameras, platform, face, and voice, among others, control the different components of the robot. Those components are in turn used by other modules designed for navigation and interaction. A sensor fusion for the purposes of localization is implemented by means of an Extended Kalman Filter, which is one of the navigation module components, together with the proposed fuzzy controllers needed for path following. A fuzzy emotion system that controls the face and the voice modules also forms part of this architecture for assisting interaction. Finally, all the modules are controlled with a customized programming language that is a mixture of C, Pascal, and JavaScript. The modules are optimized for immediate execution to achieve realistic human–machine interaction.},
  doi      = {https://doi.org/10.1016/j.engappai.2019.103356},
  file     = {:FILES/2020 - AlvaradoVasquez2020 - A tour-guide robot- Moving towards interaction with humans.pdf:PDF},
  groups   = {human robot interaction},
  keywords = {Fuzzy systems, Emotions, Indoor localization and navigation, Task planning, Social robotics, Human–machine interaction},
  url      = {https://www.sciencedirect.com/science/article/pii/S0952197619302908},
}

@Article{Kiperwasser2016,
  author   = {Kiperwasser, Eliyahu and Goldberg, Yoav},
  journal  = {Transactions of the Association for Computational Linguistics},
  title    = {Simple and accurate dependency parsing using bidirectional {LSTM} feature representations},
  year     = {2016},
  issn     = {2307-387X},
  month    = jul,
  pages    = {313--327},
  volume   = {4},
  abstract = {{We present a simple and effective scheme for dependency parsing which is based on
                    bidirectional-LSTMs (BiLSTMs). Each sentence token is associated with a BiLSTM
                    vector representing the token in its sentential context, and feature vectors are
                    constructed by concatenating a few BiLSTM vectors. The BiLSTM is trained jointly
                    with the parser objective, resulting in very effective feature extractors for
                    parsing. We demonstrate the effectiveness of the approach by applying it to a
                    greedy transition-based parser as well as to a globally optimized graph-based
                    parser. The resulting parsers have very simple architectures, and match or
                    surpass the state-of-the-art accuracies on English and Chinese.}},
  comment  = {依存句法分析},
  doi      = {10.1162/tacl_a_00101},
  file     = {:FILES/2016 - Kiperwasser2016 - Simple and accurate dependency parsing using bidirectional LSTM feature representations.pdf:PDF},
  groups   = {nlp},
  url      = {https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00101/43362/Simple-and-Accurate-Dependency-Parsing-Using},
}

@InProceedings{Dozat2017,
  author    = {Timothy Dozat and Christopher D. Manning},
  booktitle = {Proceedings of 5th International Conference on Learning Representations (ICLR)},
  title     = {Deep biaffine attention for neural dependency parsing},
  year      = {2017},
  address   = {Toulon, France},
  month     = apr,
  pages     = {1--8},
  abstract  = {This paper builds off recent work from Kiperwasser \& Goldberg (2016) using neural attention in a simple graph-based dependency parser. We use a larger but more thoroughly regularized parser than other recent BiLSTM-based approaches, with
biaffine classifiers to predict arcs and labels. Our parser gets state of the art or near state of the art performance on standard treebanks for six different languages, achieving 95.7\% UAS and 94.1\% LAS on the most popular English PTB dataset. This makes it the highest-performing graph-based parser on this benchmark—outperforming Kiperwasser \& Goldberg (2016) by 1.8\% and 2.2\%—and comparable to the highest performing transition-based parser (Kuncoro et al., 2016), which achieves 95.8\% UAS and 94.6\% LAS. We also show which hyperparameter choices had a significant effect on parsing accuracy, allowing us to achieve large gains over other graph-based approaches.},
  comment   = {依存句法分析},
  file      = {:FILES/2017 - Dozat2017 - Deep biaffine attention for neural dependency parsing.pdf:PDF},
  groups    = {machine learning, nlp},
  keywords  = {Natural language processing, Deep learning},
  url       = {https://openreview.net/forum?id=Hk95PK9le&noteId=Hk95PK9le},
}

@InProceedings{Nguyen2018,
  author     = {Nguyen, Quynh and Hein, Matthias},
  booktitle  = {Proceedings of the 35th International Conference on Machine Learning},
  title      = {Optimization landscape and expressivity of deep {CNNs}},
  year       = {2018},
  address    = {Stockholmsm\"{a}ssan, Stockholm, Sweden},
  editor     = {Dy, Jennifer and Krause, Andreas},
  month      = jul,
  pages      = {3730--3739},
  publisher  = {PMLR},
  volume     = {80},
  abstract   = {We analyze the loss landscape and expressiveness of practical deep convolutional neural networks (CNNs) with shared weights and max pooling layers. We show that such CNNs produce linearly independent features at a “wide” layer which has more neurons than the number of training samples. This condition holds e.g. for the VGG network. Furthermore, we provide for such wide CNNs necessary and sufficient conditions for global minima with zero training error. For the case where the wide layer is followed by a fully connected layer we show that almost every critical point of the empirical loss is a global minimum with zero training error. Our analysis suggests that both depth and width are very important in deep learning. While depth brings more representational power and allows the network to learn high level features, width smoothes the optimization landscape of the loss function in the sense that a sufficiently wide network has a well-behaved loss surface with almost no bad local minima.},
  file       = {:FILES/2018 - Nguyen2018 - Optimization landscape and expressivity of deep CNNs.pdf:PDF},
  groups     = {Neural Network},
  readstatus = {skimmed},
  url        = {http://proceedings.mlr.press/v80/nguyen18a.html},
}

@InProceedings{Cohen2016,
  author     = {Cohen, Nadav and Shashua, Amnon},
  booktitle  = {Proceedings of the 33rd International Conference on Machine Learning},
  title      = {Convolutional rectifier networks as generalized tensor decompositions},
  year       = {2016},
  address    = {New York, NY, USA},
  pages      = {955--963},
  series     = {ICML'16},
  abstract   = {Convolutional rectifier networks, i.e. convolutional neural networks with rectified linear activation and max or average pooling, are the cornerstone of modern deep learning. However, despite their wide use and success, our theoretical understanding of the expressive properties that drive these networks is partial at best. On the other hand, we have a much firmer grasp of these issues in the world of arithmetic circuits. Specifically, it is known that convolutional arithmetic circuits possess the property of "complete depth efficiency", meaning that besides a negligible set, all functions realizable by a deep network of polynomial size, require exponential size in order to be realized (or approximated) by a shallow network. In this paper we describe a construction based on generalized tensor decompositions, that transforms convolutional arithmetic circuits into convolutional rectifier networks. We then use mathematical tools available from the world of arithmetic circuits to prove new results. First, we show that convolutional rectifier networks are universal with max pooling but not with average pooling. Second, and more importantly, we show that depth efficiency is weaker with convolutional rectifier networks than it is with convolutional arithmetic circuits. This leads us to believe that developing effective methods for training convolutional arithmetic circuits, thereby fulfilling their expressive potential, may give rise to a deep learning architecture that is provably superior to convolutional rectifier networks but has so far been overlooked by practitioners.},
  comment    = {first to study expressivity of CNN.
本文讨论的是convolutional rectifier network的expressive power and depth efficiency. 本文提出一种transformation from convolutional arithmetic circuits to convolutional rectified networks based on generalized tensor decomposition.前者已被证明具有complete depth efficiency (Cohen et al. 2016). 具体见附件笔记。},
  file       = {:FILES/2016 - Cohen2016 - Convolutional rectifier networks as generalized tensor decompositions.pdf:PDF;:FILES/notes/Cohen2016.docx:Word 2007+},
  groups     = {Neural Network},
  readstatus = {skimmed},
  url        = {http://proceedings.mlr.press/v48/cohenb16.html},
}

@InProceedings{Nguyen2017,
  author    = {Quynh Nguyen and Matthias Hein},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  title     = {The loss surface of deep and wide neural networks},
  year      = {2017},
  address   = {Sydney, Australia},
  editor    = {Precup, Doina and Teh, Yee Whye},
  month     = aug,
  pages     = {2603--2612},
  publisher = {PMLR},
  volume    = {70},
  abstract  = {While the optimization problem behind deep neural networks is highly non-convex, it is frequently observed in practice that training deep networks seems possible without getting stuck in suboptimal points. It has been argued that this is the case as all local minima are close to being globally optimal. We show that this is (almost) true, in fact almost all local minima are globally optimal, for a fully connected network with squared loss and analytic activation function given that the number of hidden units of one layer of the network is larger than the number of training points and the network structure from this layer on is pyramidal.},
  comment   = {training nn的解的最优性。},
  file      = {:FILES/2017 - Nguyen2017 - The loss surface of deep and wide neural networks.pdf:PDF},
  groups    = {Neural Network},
  url       = {http://proceedings.mlr.press/v70/nguyen17a.html},
}

@Misc{Yun2019,
  author        = {Chulhee Yun and Suvrit Sra and Ali Jadbabaie},
  month         = oct,
  title         = {Small {ReLU} networks are powerful memorizers: a tight analysis of memorization capacity},
  year          = {2019},
  archiveprefix = {arXiv},
  eprint        = {1810.07770},
  file          = {:FILES/2019 - Yun2019 - Small {ReLU} networks are powerful memorizers- a tight analysis of memorization capacity.pdf:PDF;:FILES/notes/Yun2019.docx:Word 2007+},
  groups        = {Neural Network},
  primaryclass  = {cs.LG},
  readstatus    = {skimmed},
}

@PhdThesis{萧毅鸿2011,
  author  = {萧毅鸿},
  school  = {南京大学},
  title   = {基于本体的复杂决策任务表示方法与求解技术研究},
  year    = {2011},
  address = {南京, 江苏},
  month   = may,
  file    = {:FILES/2011 - 萧毅鸿2011 - 基于本体的复杂决策任务表示方法与求解技术研究.caj:caj},
  groups  = {task planning},
}

@PhdThesis{李泚泚2020,
  author  = {李泚泚},
  school  = {山东大学},
  title   = {基于本体知识引导的家庭服务机器人抓取策略研究},
  year    = {2020},
  address = {济南, 山东},
  month   = sep,
  file    = {:FILES/2020 - 李泚泚2020 - 基于本体的复杂决策任务表示方法与求解技术研究.caj:},
  groups  = {task planning},
}

@PhdThesis{陈志贤2019,
  author  = {陈志贤},
  school  = {中国科学院大学},
  title   = {面向复杂环境的服务机器人自主规划方法研究},
  year    = {2019},
  address = {深圳, 广东},
  month   = jun,
  file    = {:FILES/2019 - 陈志贤2019 - 面向复杂环境的服务机器人自主规划方法研究.caj:caj},
  groups  = {task planning},
}

@InProceedings{Mavridis2006,
  author    = {Nikolaos Mavridis and Deb Roy},
  booktitle = {Proceedings of the 2006 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Grounded situation models for robots: {Where} words and percepts meet},
  year      = {2006},
  address   = {Beijing, China},
  month     = oct,
  pages     = {4690--4697},
  publisher = {IEEE},
  abstract  = {Our long-term objective is to develop robots that engage in natural language-mediated cooperative tasks with humans. To support this goal, we are developing an amodal representation and associated processes which is called a grounded situation model (GSM). We are also developing a modular architecture in which the GSM resides in a centrally located module, around which there are language, perception, and action-related modules. The GSM acts as a sensor-updated "structured blackboard", that serves as a workspace with contents similar to a "theatrical stage" in the robot's "mind", which might be filled in with present, past or imagined situations. Two main desiderata drive the design of the GSM: first, "parsing" situations into ontological types and relations that reflect human language semantics, and second, allowing bidirectional translation between sensory-derived data/expectations and linguistic descriptions. We present an implemented system that allows of a range of conversational and assistive behavior by a manipulator robot. The robot updates beliefs (held in the GSM) about its physical environment, the human user, and itself, based on a mixture of linguistic, visual and proprioceptive evidence. It can answer basic questions about the present or past and also perform actions through verbal interaction. Most importantly, a novel contribution of our approach is the robot's ability for seamless integration of both language- and sensor-derived information about the situation: for example, the system can acquire parts of situations either by seeing them or by "imagining" them through descriptions given by the user: "There is a red ball at the left". These situations can later be used to create mental imagery and sensory expectations, thus enabling the aforementioned bidirectionality},
  doi       = {10.1109/IROS.2006.282258},
  file      = {:FILES/2006 - Mavridis2006 - Grounded situation models for robots- Where words and percepts meet.pdf:PDF},
  groups    = {task understanding},
  issn      = {2153-0866},
  keywords  = {Robot sensing systems;GSM;Intelligent robots;Cognitive robotics;Laboratories;Human robot interaction;Humanoid robots;Natural languages;Ground support;Ontologies},
  url       = {https://ieeexplore.ieee.org/document/4059158},
}

@Unpublished{Shah2005,
  author  = {Chirag Shah and Rakesh Gupta},
  title   = {Building plans for household tasks from distributed knowledge},
  year    = {2005},
  comment = {{卢栋才2017}提到这是首次使用OMICS来完成用户任务，利用马尔科夫链生成模型技术来做任务理解。},
  file    = {:FILES/2005 - Shah2005 - Building plans for household tasks from distributed knowledge.pdf:PDF},
  groups  = {task understanding},
}

@Article{Xie2015,
  author     = {Xie, Jiongkun and Chen, Xiaoping and Ji, Jianmin},
  journal    = {Web Intelligence},
  title      = {Multi-mode natural language processing for human-robot interaction},
  year       = {2015},
  issn       = {2405-6464},
  number     = {4},
  pages      = {267--278},
  volume     = {13},
  abstract   = {As more and more open knowledge resources become available, it is interesting to explore opportunities of enhancing autonomous agents’ capacities by utilizing the knowledge in these resources, instead of hand-coding knowledge for agents. A major challenge towards this goal lies in the translation of the open knowledge organized in multiple modes, unstructured or semi-structured, into the internal representations of agents. In this paper we present a set of multi-mode NLP techniques to formalize the open knowledge for autonomous agents. Two case studies are reported in which our robot, equipped with the multi-mode NLP techniques, succeeded in acquiring knowledge from the microwave oven manual and from the open knowledge database, OMICS, and solving problems that could not be solved before the robot acquired the knowledge. Experiments for evaluating the performance of our approach show that our approach is promising.},
  comment    = {from {卢栋才2017}: 给定了用户任务和机器人本地知识之间的知识缺口形式化表述，然后通过利用omics知识来填补部分知识缺口来提高任务理解能力。

本文利用OMICS，首次同时对结构化的NL instructions and 半结构化knowledge in OMICS进行形式化表达，将其表示ASP rules，从而可以被robot识别。该multi-mode NLP的主要过程如下：

1.对unstructured NL instruction解析：利用基于CCG的semantic parsing technique将open knowledge 转化为internal rep. I.e. quasi-ASP，进行通过flatten + transformation得到对应的ASP rules。该方法的主要思路是，给定one sentence,利用conditional log-linear model决定其所对应的syntactic parse and semantic form, 模型参数利用CKY algorithm 在给定训练集上进行学习。--是一种分类问题。
2.对semi-structured instructions解析：主要是OMICS。需要从OMICS representation中提取出semantic relations，所利用的方法是本文提出的基于CCG的semantically-augmented rules，自底向上。
3.Retrieval of presupposition: 定义了三种potential relations between entities in the knowledge, i.e. identical, meronomic (describing part_of rel.) and spatial relation (based on hand-crafted knowledge, such as in, at, on. ..), which are extracted from OMICS without perception. 

其优点在于能够从非结构化/半结构化的信息中提取knowledge (rules)，而不用事先指定。需要定义lexical rules to map words to concepts. 是cognitive level knowledge.},
  doi        = {10.3233/WEB-150325},
  file       = {:FILES/2015 - Xie2015 - Multi-mode natural language processing for human-robot interaction.pdf:PDF},
  groups     = {task understanding},
  keywords   = {Multi-mode NLP, open knowledge, autonomous agents, human-robot interaction, semantic parsing},
  priority   = {prio1},
  publisher  = {IOS Press},
  readstatus = {read},
  url        = {https://content.iospress.com/articles/web-intelligence/web325},
}

@InProceedings{Xie2014,
  author    = {Xie, Jiongkun and Chen, Xiaoping},
  booktitle = {Proceedings of the 2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)},
  title     = {Understanding instructions on large scale for human-robot interaction},
  year      = {2014},
  address   = {Warsaw, Poland},
  month     = aug,
  pages     = {175--182},
  publisher = {IEEE},
  volume    = {3},
  abstract  = {Correctly interpreting human instructions is the first step to human-robot interaction. Previous approaches to semantically parsing the instructions relied on large numbers of training examples with annotation to widely cover all words in a domain. Annotating large enough instructions with semantic forms needs exhaustive engineering efforts. Hence, we propose propagating the semantic lexicon to learn a semantic parser from limited annotations, whereas the parser still has the ability of interpreting instructions on a large scale. We assume that the semantically-close words have the same semantic form based on the fact that human usually uses different words to refer to a same object or task. Our approach softly maps the unobserved words/phrases to the semantic forms learned from the annotated copurs through a metric for knowledge-based lexical similarity. Experiments on the collected instructions showed that the semantic parser learned with lexicon propagation outperformed the baseline. Our approach provides an opportunity for the robots to understand the human instructions on a large scale.},
  comment   = {from {卢栋才2017}: 给定了用户任务和机器人本地知识之间的知识缺口形式化表述，然后通过利用omics知识来填补部分知识缺口来提高任务理解能力。},
  doi       = {10.1109/WI-IAT.2014.165},
  file      = {:FILES/2014 - Xie2014 - Understanding instructions on large scale for human-robot interaction.pdf:PDF},
  groups    = {task understanding},
  keywords  = {Semantics;Robots;Measurement;Syntactics;Vectors;Human-robot interaction;Training;Human-Robot Interaction;Instruction Understanding;Semantic Parsing;Lexicon Propagation;Graph-based Semi-supervised Learning},
  url       = {https://ieeexplore.ieee.org/document/6928183},
}

@Article{Chen2013a,
  author   = {Chen, Xiaoping and Xie, Jiongkun and Ji, Jianmin and Sui, Zhiqiang},
  journal  = {Journal of Human-Robot Interaction},
  title    = {Toward open knowledge enabling for human-robot interaction},
  year     = {2013},
  month    = jan,
  number   = {2},
  pages    = {100–-117},
  volume   = {1},
  abstract = {This paper presents an effort to enable robots to utilize open-source knowledge resources autonomously for human-robot interaction. The main challenges include how to extract knowledge in semi-structured and unstructured natural languages, how to make use of multiple types of knowledge in decision making, and how to identify the knowledge that is missing. A set of techniques for multi-mode natural language processing, integrated decision making, and open knowledge searching is proposed. The OK-KeJia robot prototype is implemented and evaluated, with special attention to two tests on 11,615 user tasks and 467 user desires. The experiments show that the overall performance improves remarkably due to the use of appropriate open knowledge.},
  comment  = {from {卢栋才2017}: 给定了用户任务和机器人本地知识之间的知识缺口形式化表述，然后通过利用omics知识来填补部分知识缺口来提高任务理解能力。
Lu2016a: 提出一种formal description来建立user instruction与robot’s local knowledge之间的关系，实现instruction understanding（本文早期工作）
Cui2021: Kejia represents domain knowledge learned through natural language processing and leverages a symbolic planner for problem-solving and planning to provide high-level functions.using open source knowledge to handle the incomplete information},
  doi      = {10.5898/JHRI.1.2.Chen},
  file     = {:FILES/2013 - Chen2013a - Toward open knowledge enabling for human-robot interaction.pdf:PDF},
  groups   = {task understanding},
  keywords = {human-robot interaction, open knowledge, NLP, decision making, social robotics},
  url      = {https://dl.acm.org/doi/10.5898/JHRI.1.2.Chen},
}

@InProceedings{Chen2013b,
  author    = {Chen, Xiaoping and Ji, Jianmin and Sui, Zhiqiang and Xie, Jiongkun},
  booktitle = {Proceedings of the 23rd International Joint Conference on Artificial Intelligence},
  title     = {Handling open knowledge for service robots},
  year      = {2013},
  address   = {Beijing, China},
  month     = aug,
  pages     = {2459--2465},
  publisher = {AAAI Press},
  comment   = {from {卢栋才2017}: 给定了用户任务和机器人本地知识之间的知识缺口形式化表述，然后通过利用omics知识来填补部分知识缺口来提高任务理解能力。
Lu2016a: 前期工作，将user instruction分解为多个primitive tasks基于hierarchical knowledge in open source.利用了多模态NLP,提出一种formal description来建立user instruction与robot’s local knowledge之间的关系，实现instruction understanding（本文早期工作）},
  file      = {:FILES/2013 - Chen2013b - Handling open knowledge for service robots.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.ijcai.org/Abstract/13/362},
}

@InProceedings{Tellex2011,
  author     = {Tellex, Stefanie and Kollar, Thomas and Dickerson, Steven and Walter, Matthew R. and Banerjee, Ashis Gopal and Teller, Seth and Roy, Nicholas},
  booktitle  = {Proceedings of the 25th AAAI Conference on Artificial Intelligence},
  title      = {Understanding natural language commands for robotic navigation and mobile manipulation},
  year       = {2011},
  address    = {San Francisco, California},
  month      = aug,
  pages      = {1507--1514},
  publisher  = {AAAI Press},
  abstract   = {This paper describes a new model for understanding natural language commands given to autonomous systems that perform navigation and mobile manipulation in semi-structured environments. Previous approaches have used models with fixed structure to infer the likelihood of a sequence of actions given the environment and the command. In contrast, our framework, called Generalized Grounding Graphs (G3), dynamically instantiates a probabilistic graphical model for a particular natural language command according to the command's hierarchical and compositional semantic structure. Our system performs inference in the model to successfully find and execute plans corresponding to natural language commands such as "Put the tire pallet on the truck." The model is trained using a corpus of commands collected using crowdsourcing. We pair each command with robot actions and use the corpus to learn the parameters of the model. We evaluate the robot's performance by inferring plans from natural language commands, executing each plan in a realistic robot simulator, and asking users to evaluate the system's performance. We demonstrate that our system can successfully follow many natural language commands from the corpus.},
  comment    = {from {卢栋才2017}:收集了一定量的半结构化的关于移动和操作任务的自然语言指令，首先构建一个SDC树，比如图上的"put the pallet on the truck"任务的sdc树，然后利用sdc树的结构构建一个grounding图谱。最后，在这个图谱上做行动路径规划。
Lu2016a: Grounding the missing semantic roles with the entities in the context
Perera2015: use NL for navigation
Ji2016: Understanding natural language command
Boularias2015:Generalized Grounding Graphs (G3) framework for grounding learning and inference problem in CRF. For all words in a sentence. Same spatial relation clauses. Features used in cost function as in 本文
Hemachandra2015:interpret natural language expressions that provide command manipulation of objects, 需要prior knowledge, language corpus
Howard2014: G3 model for mapping NL instruction to robot actions. it is a a contemporary technique for generating robot actions from natural language instructions, factor graph. NL with objects, locations, and paths.
Howard2014a: NL in object manipulation, G3 model:  exploits the hierarchical structure of language to construct a probabilistic graphical model composed of grounding, correspondence, phrases, and env.  take a brute force approach to constructing the probabilistic graphical models
Hemachandra2014:HRI with NL speech, Mapping NL to the corresponding referents in the robot’s world model, G3 model
Walter2013:enabling robots to interpret natural language commands, G3 model, Symbol grounding problem is in the context of following NL commands
Duvallet2016: Natural language has proven to be effective for commanding robots to manipulate objects. Require a complete semantically-labeled environment model that captures the geometry, location, type, and label of objects and regions in the environment. 没有利用NL instruction中包含的信息来reason uncertainty and infer environment representation.
{Kartmann2020}:基于NL，propose a probabilistic graphical model to map constituents of a natural language command to objects and places as well as robot actions
{Patki2019}:factor graph with a hierarchical structure dictated by the compositional nature of the utterance, symbolic representation, and environment.
{Anderson2018}：natural language navigation, relate natual language to real imagery (labels) as a classification problem，，所有object都已知




propose a grounding graph method to map the NL commands to action sequences. They formulate it as a probabilistic model which takes the NL commands as input and output grounds of the objects, paths, and plans (action sequences). The actions include the navigation and mobile manipulation in a semi-structured env. The core concept of the proposed method is to describe the NL commands as a spatial description clauses (SDCs), which is constructed based on the Stanford dependencies. SDC is a kind of grounding graph whose nodes include random variables (e.g., grounds, field values in SDC, binary grounding indicator) and factors (not shown in SDC). these factors are log-linear functions of hand-selected features, and the weights are trained by maximum likelihood estimation.

文中末尾讨论了本文方法的一些缺点，如无法处理复杂的linguistic phenomena, such as negation, anaphora, conditions, and quantifiers},
  file       = {:FILES/2011 - Tellex2011 - Understanding natural language commands for robotic navigation and mobile manipulation.pdf:PDF;:FILES/notes/Tellex2011.docx:Word_NEW},
  groups     = {task understanding},
  readstatus = {read},
  url        = {https://dl.acm.org/doi/10.5555/2900423.2900661},
}

@InProceedings{Chen2010,
  author    = {Chen, Xiaoping and Ji, Jianmin and Jiang, Jiehui and Jin, Guoqiang and Wang, Feng and Xie, Jiongkun},
  booktitle = {Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  title     = {Developing high-level cognitive functions for service robots},
  year      = {2010},
  address   = {Richland, SC, USA},
  month     = may,
  pages     = {989--996},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  abstract  = {The primary target of this work is human-robot collaboration, especially for service robots in complicated application scenarios. Three assumptions and four requirements are identified. State-of-the-art, general-purpose Natural Language Processing (NLP), Commonsense Reasoning (in particular, ASP), and Robotics techniques are integrated in a layered architecture. The architecture and mechanisms have been implemented on a service robot, Ke Jia. Instead of command languages, small limited segments of natural languages are employed in spoken dialog between Ke Jia and its users. The information in the dialog is extracted, classified and transferred into inner representation by Ke Jia's NLP mechanism, and further used autonomously in problem-solving and planning. A series of case study was conducted on Ke Jia with positive results, verifying its ability of acquiring knowledge through spoken dialog with users, autonomous solving problems by virtue of acquired causal knowledge, and autonomous planning for complex tasks.},
  comment   = {from {卢栋才2017}: 建立了层次化集成系统结构，包括对话系统、NLP、task planning, motion planning, robot control等模块。其中task planning 部分依赖于手写的语义动词知识+规划求解器，扩展性和通用性较低。
Perera2015: Complex commands have been considered as a combination of LSNL (Limited Segments of Natural Language) also for a service robot
Cui2021: Kejia represents domain knowledge learned through natural language processing and leverages a symbolic planner for problem-solving and planning to provide high-level functions

本文提出了一种服务机器人Ke Jia，其由dialog system, NLP, task planning, motion planning, robot control, KB等系统组成。
1. 对话系统所利用的语言是LSNL,是自然语言的一种子集，具有有限词典和简单语法，用以获得各种知识、ASP，或明确执行过程中所要操作的物体等
2. NLP包括三个过程，
2.1 parsing using （Stanford Parser, 得到语法树【12】）+typed dependencies (SDRT[2])
2.2 semantic analysis: 利用parsing结果，构造semantic representation, consisting of 5 type semantic elements, 每种element具有不同的参数，每个word是一种element
2.3 pragmatic analysis: 将得到的logical form转化为ASP
3. task planning对ASP进行求解，得到最优high level plan
4. 生成low level plan可执行，


1. 没有说明ASR的处理方法
2. semantic analysis中element的对应方法没有说，
3. 没有说pragmatic analysis的方法},
  file      = {:FILES/2010 - Chen2010 - Developing high-level cognitive functions for service robots.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9780982657119},
  keywords  = {modeling natural language, knowledge representation, human-robot interaction, cognitive robotics},
  url       = {https://dl.acm.org/doi/10.5555/1838206.1838339},
}

@InProceedings{Buehler2014,
  author    = {Jennifer Elisabeth Buehler and Maurice Pagnucco},
  booktitle = {Proceedings of the 28th AAAI Conference on Artificial Intelligence},
  title     = {A framework for task planning in heterogeneous multi robot systems based on robot capabilities},
  year      = {2014},
  address   = {Qu\'{e}bec City, Qu\'{e}bec, Canada},
  editor    = {Carla E. Brodley and Peter Stone},
  month     = jul,
  pages     = {2527--2533},
  publisher = {AAAI Press},
  abstract  = {In heterogeneous multi-robot teams, robustness and flexibility are increased by the diversity of the robots, each contributing different capabilities. Yet platform-independence is desirable when planning actions for the various robots. We propose a platform-independent model of robot capabilities which we use as a planning domain. We extend existing planning techniques to support two requirements: generating new objects during planning; and, required concurrency of actions due to data flow which can be cyclic. The first requires online action instantiation, the second a small extension of the Planning Domain Definition Language (PDDL): allowing predicates in continuous effects. We evaluate the planner on benchmark domains and present results on an example object transportation task in simulation.},
  comment   = {from {卢栋才2017}: 提出平台独立的机器人功能模型用作规划领域，在规划过程中生成新对象，并且需要并发的动作。首先在线动作实例化，而后利用PDDL，允许谓词连续的效果。},
  file      = {:FILES/2014 - Buehler2014 - A framework for task planning in heterogeneous multi robot systems based on robot capabilities.pdf:PDF},
  groups    = {task understanding},
  isbn      = {978-1-57735-661-5},
  url       = {http://www.aaai.org/ocs/index.php/AAAI/AAAI14/paper/view/8476},
}

@InProceedings{Gaschler2013,
  author    = {Andre Gaschler and Ronald P. A. Petrick and Manuel Giuliani and Markus Rickert and Alois Knoll},
  booktitle = {Proceedings of the 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {{KVP}: {A} knowledge of volumes approach to robot task planning},
  year      = {2013},
  address   = {Tokyo, Japan},
  month     = nov,
  pages     = {202--208},
  publisher = {IEEE},
  abstract  = {Robot task planning is an inherently challenging problem, as it covers both continuous-space geometric reasoning about robot motion and perception, as well as purely symbolic knowledge about actions and objects. This paper presents a novel “knowledge of volumes” framework for solving generic robot tasks in partially known environments. In particular, this approach (abbreviated, KVP) combines the power of symbolic, knowledge-level AI planning with the efficient computation of volumes, which serve as an intermediate representation for both robot action and perception. While we demonstrate the effectiveness of our framework in a bimanual robot bartender scenario, our approach is also more generally applicable to tasks in automation and mobile manipulation, involving arbitrary numbers of manipulators.},
  comment   = {from {卢栋才2017}: 提出一种在部分已知环境中解决通用机器人任务的新颖“体积知识”框架，将符号知识水平的AI规划与体积的有效计算相结合，作为机器人动作和感知两者的中间表示。利用了PKS规划期。},
  doi       = {10.1109/IROS.2013.6696354},
  file      = {:FILES/2013 - Gaschler2013 - {KVP}- {A} knowledge of volumes approach to robot task planning.pdf:PDF},
  groups    = {task understanding},
  issn      = {2153-0866},
  keywords  = {Planning;Robot sensing systems;Collision avoidance;Databases;Cognition},
  url       = {https://ieeexplore.ieee.org/document/6696354},
}

@InProceedings{Zhang2015,
  author     = {Shiqi Zhang and Peter Stone},
  booktitle  = {Proceedings of the 29th AAAI Conference on Artificial Intelligence},
  title      = {{CORPP}: {Commonsense} reasoning and probabilistic planning, as applied to dialog with a mobile robot},
  year       = {2015},
  address    = {Austin, Texas},
  month      = jan,
  pages      = {1--7},
  publisher  = {AAAI Press},
  abstract   = {In order to be fully robust and responsive to a dynamically changing
      real-world environment, intelligent robots will need to engage in a
      variety of simultaneous reasoning modalities. In particular, in this paper
      we consider their needs to i) reason with commonsense knowledge, ii) model
      their nondeterministic action outcomes and partial observability, and iii)
      plan toward maximizing long-term rewards. On one hand, Answer Set
      Programming (ASP) is good at representing and reasoning with commonsense
      and default knowledge, but is ill-equipped to plan under probabilistic
      uncertainty. On the other hand, Partially Observable Markov Decision
      Processes (POMDPs) are strong at planning under uncertainty toward
      maximizing long-term rewards, but are not designed to incorporate
      commonsense knowledge and inference. This paper introduces the CORPP
      algorithm which combines P-log, a probabilistic extension of ASP, with
      POMDPs to integrate commonsense reasoning with planning under uncertainty.
      Our approach is fully implemented and tested on a shopping request
      identification problem both in simulation and on a real robot. Compared
      with existing approaches using P-log or POMDPs individually, we observe
      significant improvements in both efficiency and accuracy.},
  comment    = {from {卢栋才2017}: 提出将Plog与POMDP相结合，得到CORPP算法，将常识推理和不确定性规划相结合，利用nlp对话来识别购物请求。
Lu2017a: Dialog system 基于PoMDP用于机器人,CORPP algorithm 包括commonsense reasoner \& probablistic planner

主要是对话管理，即如何利用对话来决定机器人的action（提问）。

本文是围绕spoken dialog system中的dialog management来进行分析的。
1. 首次在将ASP与POMDP相结合的同时，提出一种probabilistic reasoner来对commonsense knowledge 进行推理。
2. CORPP包含三部分内容
2.1 logical reasoner: 通过查询内存或数据库来实现，输入为facts or defaults, 即环境或人的状态等，输出是一系列worlds, i.e., a set of answers
2.2 probabilistic reasoner: 基于P-log的推理，并为每种world分配概率
2.3 probabilistic planner: 利用POMDP和先验概率得到机器人应该做的action，
3.场景是在校园中shopping request identification，

不足：
1. ASP的defaults or facts需要人为制定
2. probabilistic reasoning 的possibility需要人为制定，
3. 对话系统可以实现两种question, i,e, polar question (binary answers) and wh-question, 应该是识别回答中的关键词，问题是action
4. POMDP solver在large, complex state-action space中难以实现real-time operations
5.本文对SR、SG、等问题没有讨论。},
  file       = {:FILES/2015 - Zhang2015 - CORPP- Commonsense reasoning and probabilistic planning, as applied to dialog with a mobile robot.pdf:PDF},
  groups     = {task understanding, dialog system},
  readstatus = {read},
  url        = {https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/9918},
}

@Article{Hanheide2017,
  author     = {Marc Hanheide and Moritz G\"{o}belbecker and Graham S. Horn and Andrzej Pronobis and Kristoffer Sj\"{o}\"{o} and Alper Aydemir and Patric Jensfelt and Charles Gretton and Richard Dearden and Miroslav Janicek and Hendrik Zender and Geert-Jan Kruijff and Nick Hawes and Jeremy L. Wyatt},
  journal    = {Artificial Intelligence},
  title      = {Robot task planning and explanation in open and uncertain worlds},
  year       = {2017},
  issn       = {0004-3702},
  pages      = {119--150},
  volume     = {247},
  abstract   = {A long-standing goal of AI is to enable robots to plan in the face of uncertain and incomplete information, and to handle task failure intelligently. This paper shows how to achieve this. There are two central ideas. The first idea is to organize the robot's knowledge into three layers: instance knowledge at the bottom, commonsense knowledge above that, and diagnostic knowledge on top. Knowledge in a layer above can be used to modify knowledge in the layer(s) below. The second idea is that the robot should represent not just how its actions change the world, but also what it knows or believes. There are two types of knowledge effects the robot's actions can have: epistemic effects (I believe X because I saw it) and assumptions (I'll assume X to be true). By combining the knowledge layers with the models of knowledge effects, we can simultaneously solve several problems in robotics: (i) task planning and execution under uncertainty; (ii) task planning and execution in open worlds; (iii) explaining task failure; (iv) verifying those explanations. The paper describes how the ideas are implemented in a three-layer architecture on a mobile robot platform. The robot implementation was evaluated in five different experiments on object search, mapping, and room categorization.},
  comment    = {1. from {卢栋才2017}: 知识表示方面：将知识分为三个层次，底层的实例知识、上层常识、顶部诊断知识。较上层可修改较下层知识，
2. 本文将的是利用感知系统来进行plan \& replan的过程，基于的还是first order logic。 采用了switching planner, consisting determistic planner and probabilistic planner,前者可以快速产生一种plan，而后者在action effect有多种可能时被采用。
3. 同时也考虑了failure时的解释，以及利用assumptive action进行replan的过程。
4. 其中用了对话系统，文本输入，语音输出，未提及具体的实现工具。生成问题的方法参考[54]
5. default knowledge 来源于OMICS，belief state由[13]估计得到。},
  doi        = {10.1016/j.artint.2015.08.008},
  file       = {:FILES/2017 - Hanheide2017 - Robot task planning and explanation in open and uncertain worlds.pdf:PDF},
  groups     = {task planning, representation, task understanding, explanation},
  keywords   = {Open-world planning, Planning under uncertainty, Commonsense knowledge, Mobile robotics, Probabilistic reasoning, Failure explanation, Assumptive planning, Retaskability},
  priority   = {prio1},
  readstatus = {skimmed},
  url        = {https://www.sciencedirect.com/science/article/pii/S000437021500123X},
}

@Article{Hawes2017,
  author     = {Nick {Hawes} and Christopher {Burbridge} and Ferdian {Jovan} and Lars {Kunze} and Bruno {Lacerda} and Lenka {Mudrova} and Jay {Young} and Jeremy {Wyatt} and Denise {Hebesberger} and Tobias {Kortner} and Rares {Ambrus} and Nils {Bore} and John {Folkesson} and Patric {Jensfelt} and Lucas {Beyer} and Alexander {Hermans} and Bastian {Leibe} and Aitor {Aldoma} and Thomas {Faulhammer} and Michael {Zillich} and Markus {Vincze} and Eris {Chinellato} and Muhannad {Al-Omari} and Paul {Duckworth} and Yiannis {Gatsoulis} and David C. {Hogg} and Anthony G. {Cohn} and Christian {Dondrup} and Jaime {Pulido Fentanes} and Tomas {Krajnik} and Joao M. {Santos} and Tom {Duckett} and Marc {Hanheide}},
  journal    = {IEEE Robotics Automation Magazine},
  title      = {The {STRANDS} project: {Long}-term autonomy in everyday environments},
  year       = {2017},
  issn       = {1558-223X},
  month      = sep,
  number     = {3},
  pages      = {146--156},
  volume     = {24},
  abstract   = {Thanks to the efforts of the robotics and autonomous systems community, the myriad applications and capacities of robots are ever increasing. There is increasing demand from end users for autonomous service robots that can operate in real environments for extended periods. In the Spatiotemporal Representations and Activities for Cognitive Control in Long-Term Scenarios (STRANDS) project (http://strandsproject.eu), we are tackling this demand head-on by integrating state-of-the-art artificial intelligence and robotics research into mobile service robots and deploying these systems for long-term installations in security and care environments. Our robots have been operational for a combined duration of 104 days over four deployments, autonomously performing end-user-defined tasks and traversing 116 km in the process. In this article, we describe the approach we used to enable long-term autonomous operation in everyday environments and how our robots are able to use their long run times to improve their own performance.},
  comment    = {SpatioTemporal Representations and Activities for Cognitive Control in Long-Term Scenarios (STRANDS) project: 将人工智能技术融入mobile service robots in security and care environments.
1. indoor task env的特点：less physically risky, higher degree of short- to medium-term physical variability. 
2. long term operation 本文用了104天
3. 这是一篇介绍性文章，总体介绍了STANDS能做什么，做的怎么样，以及为什么这么做等问题。
4. 其中涉及的human robot interaction主要是机器人作为information terminal to present weather, news, etc. 主要工作围绕如何确定spatial and temporal information of the happening of interaction to predict when and where the next interaction will happen, so that it can provide such information more efficiently},
  doi        = {10.1109/MRA.2016.2636359},
  file       = {:FILES/2017 - Hawes2017 - The STRANDS project- Long-term autonomy in everyday environments.pdf:PDF},
  groups     = {task understanding},
  keywords   = {Autonomous systems;Service robots;Spatiotemporal phenomena;Artificial intelligence;Cognition;Real-time systems;Mobile robots;Performance evaluation;Machine learning;Navigation},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/document/7948740},
}

@Article{Cui2021,
  author     = {Cui, Guowei and Shuai, Wei and Chen, Xiaoping},
  journal    = {Future Internet},
  title      = {Semantic task planning for service robots in open worlds},
  year       = {2021},
  issn       = {1999-5903},
  month      = feb,
  number     = {2},
  pages      = {49},
  volume     = {13},
  abstract   = {This paper presents a planning system based on semantic reasoning for a general-purpose service robot, which is aimed at behaving more intelligently in domains that contain incomplete information, under-specified goals, and dynamic changes. First, Two kinds of data are generated by Natural Language Processing module from the speech: (i) action frames and their relationships; (ii) the modifier used to indicate some property or characteristic of a variable in the action frame. Next, the task’s goals are generated from these action frames and modifiers. These goals are represented as AI symbols, combining world state and domain knowledge, which are used to generate plans by an Answer Set Programming solver. Finally, the plan’s actions are executed one by one, and continuous sensing grounds useful information, which makes the robot use contingent knowledge to adapt to dynamic changes and faults. For each action in the plan, the planner gets its preconditions and effects from domain knowledge, so during the execution of the task, the environmental changes, especially those conflict with the actions, not only the action being performed but also the subsequent actions, can be detected and handled as early as possible. A series of case studies are used to evaluate the system and verify its ability to acquire knowledge through dialogue with users, solve problems with the acquired causal knowledge, and plan for complex tasks autonomously in the open world.},
  doi        = {10.3390/fi13020049},
  file       = {:FILES/2021 - Cui202 - Semantic task planning for service robots in open worlds.pdf:PDF},
  groups     = {task understanding, task planning, ontology based},
  owner      = {University of Science and Technology of China},
  printed    = {Y},
  readstatus = {skimmed},
  url        = {https://www.mdpi.com/1999-5903/13/2/49},
}

@InProceedings{Zakershahrak2020,
  author    = {Mehrdad Zakershahrak and Ze {Gong} and Nikhillesh {Sadassivam} and Yu {Zhang}},
  booktitle = {2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Online explanation generation for planning tasks in human-robot teaming},
  year      = {2020},
  address   = {Las Vegas, NV, USA},
  month     = oct,
  pages     = {6304--6310},
  publisher = {IEEE},
  abstract  = {As AI becomes an integral part of our lives, the development of explainable AI, embodied in the decision-making process of an AI or robotic agent, becomes imperative. For a robotic teammate, the ability to generate explanations to justify its behavior is one of the key requirements of explainable agency. Prior work on explanation generation has been focused on supporting the rationale behind the robot's decision or behavior. These approaches, however, fail to consider the mental demand for understanding the received explanation. In other words, the human teammate is expected to understand an explanation no matter how much information is presented. In this work, we argue that explanations, especially those of a complex nature, should be made in an online fashion during the execution, which helps spread out the information to be explained and thus reduce the mental workload of humans in highly cognitive demanding tasks. However, a challenge here is that the different parts of an explanation may be dependent on each other, which must be taken into account when generating online explanations. To this end, a general formulation of online explanation generation is presented with three variations satisfying different "online" properties. The new explanation generation methods are based on a model reconciliation setting introduced in our prior work. We evaluated our methods both with human subjects in a simulated rover domain, using NASA Task Load Index (TLX), and synthetically with ten different problems across two standard IPC domains. Results strongly suggest that our methods generate explanations that are perceived as less cognitively demanding and much preferred over the baselines and are computationally efficient.},
  doi       = {10.1109/IROS45743.2020.9341792},
  file      = {:FILES/2020 - Zakershahrak2020 - Online explanation generation for planning tasks in human-robot teaming.pdf:PDF},
  groups    = {explanation},
  issn      = {2153-0866},
  keywords  = {NASA;Planning;Task analysis;Artificial intelligence;Standards;Intelligent robots;Load modeling},
  url       = {https://ieeexplore.ieee.org/document/9341792},
}

@InProceedings{Chakraborti2020,
  author     = {Chakraborti, Tathagata and Sreedharan, Sarath and Kambhampati, Subbarao},
  booktitle  = {Proceedings of the 29th International Joint Conference on Artificial Intelligence (IJCAI-20)},
  title      = {The emerging landscape of explainable automated planning \& decision making},
  year       = {2020},
  editor     = {Christian Bessiere},
  month      = jul,
  note       = {Survey track},
  pages      = {4803--4811},
  publisher  = {International Joint Conferences on Artificial Intelligence Organization},
  abstract   = {In this paper, we provide a comprehensive outline of the different threads of work in Explainable AI Planning (XAIP) that has emerged as a focus area in the last couple of years and contrast that with earlier efforts in the field in terms of techniques, target users, and delivery mechanisms. We hope that the survey will provide guidance to new researchers in automated planning towards the role of explanations in the effective design of human-in-the-loop systems, as well as provide the established researcher with some perspective on the evolution of the exciting world of explainable planning.},
  comment    = {这篇文章讲的是关于explannability of AI for HRI.,是一篇综述文章,没有具体看,暂时没有这方面的研究兴趣.},
  doi        = {10.24963/ijcai.2020/669},
  file       = {:FILES/2020 - Chakraborti2020 - The emerging landscape of explainable automated planning  decision making.pdf:PDF},
  groups     = {explanation},
  keywords   = {skimmed},
  readstatus = {skimmed},
  url        = {https://www.ijcai.org/Proceedings/2020/669},
}

@Article{Wang2019c,
  author     = {Wang, Yi and Zhang, Shiqi and Lee, Joohyung},
  journal    = {Theory and Practice of Logic Programming},
  title      = {Bridging commonsense reasoning and probabilistic planning via a probabilistic action language},
  year       = {2019},
  month      = sep,
  number     = {5-6},
  pages      = {1090–-1106},
  volume     = {19},
  abstract   = {To be responsive to dynamically changing real-world environments, an intelligent agent needs to perform complex sequential decision-making tasks that are often guided by commonsense knowledge. The previous work on this line of research led to the framework called "interleaved commonsense reasoning and probabilistic planning" (icorpp), which used P-log for representing commmonsense knowledge and Markov Decision Processes (MDPs) or Partially Observable MDPs (POMDPs) for planning under uncertainty. A main limitation of icorpp is that its implementation requires non-trivial engineering efforts to bridge the commonsense reasoning and probabilistic planning formalisms. In this paper, we present a unified framework to integrate icorpp's reasoning and planning components. In particular, we extend probabilistic action language pBC+ to express utility, belief states, and observation as in POMDP models. Inheriting the advantages of action languages, the new action language provides an elaboration tolerant representation of POMDP that reflects commonsense knowledge. The idea led to the design of the system pbcplus2pomdp, which compiles a pBC+ action description into a POMDP model that can be directly processed by off-the-shelf POMDP solvers to compute an optimal policy of the pBC+ action description. Our experiments show that it retains the advantages of icorpp while avoiding the manual efforts in bridging the commonsense reasoner and the probabilistic planner.},
  comment    = {本文讲的是在存在不确定性+belief state等条件下,利用commonsense knowledge进行推理和sequential decision making的方法.主要基于P-log和POMDP,相较于ICORPP,本文的方法搭建了一个两种方法的桥梁.},
  doi        = {10.1017/S1471068419000371},
  file       = {:FILES/2019 - Wang2019c - Bridging commonsense reasoning and probabilistic planning via a probabilistic action language.pdf:PDF},
  groups     = {task planning},
  keywords   = {skimmed},
  owner      = {Arizona State University},
  publisher  = {Cambridge University Press},
  readstatus = {skimmed},
  url        = {https://www.cambridge.org/core/journals/theory-and-practice-of-logic-programming/article/abs/bridging-commonsense-reasoning-and-probabilistic-planning-via-a-probabilistic-action-language/B25EEFE24FA629357D425FC632466411},
}

@InProceedings{Abdulaziz2019,
  author    = {Mohammad Abdulaziz and Charles Gretton and Michael Norrish},
  booktitle = {10th International Conference on Interactive Theorem Proving (ITP 2019)},
  title     = {A verified compositional algorithm for {AI} planning},
  year      = {2019},
  address   = {Dagstuhl, Germany},
  editor    = {John Harrison and John O'Leary and Andrew Tolmach},
  pages     = {4:1--4:19},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  series    = {Leibniz International Proceedings in Informatics (LIPIcs)},
  volume    = {141},
  doi       = {10.4230/LIPIcs.ITP.2019.4},
  file      = {:FILES/2019 - Abdulaziz2019 - A verified compositional algorithm for {AI} planning.pdf:PDF},
  groups    = {task planning},
  isbn      = {978-3-95977-122-1},
  issn      = {1868-8969},
  keywords  = {AI Planning, Compositional Algorithms, Algorithm Verification, Transition Systems},
  url       = {http://drops.dagstuhl.de/opus/volltexte/2019/11059},
}

@Article{Lacerda2019,
  author   = {Bruno Lacerda and Fatma Faruq and David Parker and Nick Hawes},
  journal  = {The International Journal of Robotics Research},
  title    = {Probabilistic planning with formal performance guarantees for mobile service robots},
  year     = {2019},
  month    = aug,
  number   = {9},
  pages    = {1098--1123},
  volume   = {38},
  abstract = {We present a framework for mobile service robot task planning and execution, based on the use of probabilistic verification techniques for the generation of optimal policies with attached formal performance guarantees. Our approach is based on a Markov decision process model of the robot in its environment, encompassing a topological map where nodes represent relevant locations in the environment, and a range of tasks that can be executed in different locations. The navigation in the topological map is modeled stochastically for a specific time of day. This is done by using spatio-temporal models that provide, for a given time of day, the probability of successfully navigating between two topological nodes, and the expected time to do so. We then present a methodology to generate cost optimal policies for tasks specified in co-safe linear temporal logic. Our key contribution is to address scenarios in which the task may not be achievable with probability one. We introduce a task progression function and present an approach to generate policies that are formally guaranteed to, in decreasing order of priority: maximize the probability of finishing the task; maximize progress towards completion, if this is not possible; and minimize the expected time or cost required. We illustrate and evaluate our approach with a scalability evaluation in a simulated scenario, and report on its implementation in a robot performing service tasks in an office environment for long periods of time.},
  doi      = {10.1177/0278364919856695},
  file     = {:FILES/2019 - Lacerda2019 - Probabilistic planning with formal performance guarantees for mobile service robots.pdf:PDF},
  groups   = {task planning},
  keywords = {Mobile service robots, planning under uncertainty, Markov decision processes, linear temporal logic},
  url      = {https://journals.sagepub.com/doi/10.1177/0278364919856695},
}

@Article{Zhang2019a,
  author     = {Shuyou {Zhang} and Junjie {Jiang} and Zaixing {He} and Xinyue {Zhao} and Jinhui {Fang}},
  journal    = {IEEE Access},
  title      = {A novel slot-gated model combined with a key verb context feature for task request understanding by service robots},
  year       = {2019},
  issn       = {2169-3536},
  month      = jul,
  pages      = {105937--105947},
  volume     = {7},
  abstract   = {Spoken language understanding (SLU) is a fundamental to service robot handling of natural language task requests. There are two main basic problems in SLU, namely, intent determination (ID) and slot filling (SF). The slot-gated recurrent neural network joint model for the two tasks has been proven to be superior to the single model, and has achieved the most advanced performance. However, in the context of task requests for home service robots, there exists a phenomenon that the information about a current word is strongly dependent on key verbs in the sentence, and it is difficult to capture this relation well with current methods. In this paper, we extract the key instructional verb containing greater core task information based on dependency parsing, and construct a feature that combines the key verb with its contextual information to solve this problem. To further improve the performance of the slot-gated model, we consider the strong relations between intent and slot. By introducing intent attention vectors into the slot attention vectors through the global-level gate and element-level gate, a novel dual slot-gated mechanism is proposed to explicitly model the complex relations between the results of the ID tasks and SF prediction tasks and optimize the global prediction results. Our experimental results on the ATIS dataset and an extended home service task (SRTR) dataset based on FrameNet show that the proposed method outperforms the most advanced methods in both tasks. Especially, for SRTR, the results of SF, ID, and sentence-level semantic frame-filling are improved by 1.7\%, 1.1\%, and 1.7\%, respectively.},
  comment    = {in the [tex] note.},
  doi        = {10.1109/ACCESS.2019.2931576},
  file       = {:FILES/2019 - Zhang2019a - A novel slot-gated model combined with a key verb context feature for task request understanding by service robots.pdf:PDF;:FILES/notes/Zhang2019a.xlsx:Excel 2007+},
  groups     = {task understanding, classification based},
  keywords   = {Task analysis;Context modeling;Natural languages;Service robots;Semantics;Logic gates;Human–robot interaction;service robots;slot-gated mechanism;spoken language understanding;verb context feature, read},
  printed    = {Y},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/8778650},
}

@InProceedings{Liu2019b,
  author     = {Qingping Liu and Jia Zhang and Bin Xin and Hao Zhang},
  booktitle  = {Proceedings of the 2019 3rd International Symposium on Autonomous Systems (ISAS)},
  title      = {Overview of task understanding of unmanned combat systems},
  year       = {2019},
  address    = {Shanghai, China},
  month      = may,
  pages      = {434--438},
  publisher  = {IEEE},
  abstract   = {Unmanned combat systems, as new weapons to overturn the rules of future war, have been the focus of research and development of military powers. To realize the efficient combat coordination between human and unmanned systems, the task understanding of unmanned combat systems is critical. Concerning the task understanding problems of unmanned combat systems, the basic concepts and significance are first discussed Then the existing methods for the task understanding of unmanned systems are summarized and analyzed A general process of the task understanding of unmanned combat systems and a task understanding framework based on deep learning are proposed The process defines the inputs, outputs, and triggering conditions. The deep learning based framework is capable of dealing with complex combat situations, which has certain reference significance for the task understanding of unmanned combat systems.},
  comment    = {本文介绍了一种TU方法，用于无人战斗系统，本文的方法只是一种框架性，没有具体的实现细节，是属于端到端的，即输入是指令以及环境信息，输出是打击目标和task decomposition scheme。
1. 环境信息包括： battlefield situation/environment information, status of the unmanned system, commands,
2. 采用了DL model
问题：
1. DL模型结构未知
2. 输入输出形式未知
3. 缺少实验验证
4. 没有考虑样本大小对模型及训练过程的影响
5. task decomposition shceme和task planning 的区别未知},
  doi        = {10.1109/ISASS.2019.8757706},
  file       = {:FILES/2019 - Liu2019b - Overview of task understanding of unmanned combat systems.pdf:PDF},
  groups     = {task understanding},
  keywords   = {unmanned combat systems;task understanding;human-machine cooperation;autonomy, read},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/8757706},
}

@InProceedings{Everett2019,
  author    = {Michael {Everett} and Justin {Miller} and Jonathan P. {How}},
  booktitle = {2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Planning beyond the sensing horizon using a learned context},
  year      = {2019},
  address   = {Macau, China},
  month     = nov,
  pages     = {1064--1071},
  publisher = {IEEE},
  abstract  = {Last-mile delivery systems commonly propose the use of autonomous robotic vehicles to increase scalability and efficiency. The economic inefficiency of collecting accurate prior maps for navigation motivates the use of planning algorithms that operate in unmapped environments. However, these algorithms typically waste time exploring regions that are unlikely to contain the delivery destination. Context is key information about structured environments that could guide exploration toward the unknown goal location, but the abstract idea is difficult to quantify for use in a planning algorithm. Some approaches specifically consider contextual relationships between objects, but would perform poorly in object-sparse environments like outdoors. Recent deep learning-based approaches consider context too generally, making training/transferability difficult. Therefore, this work proposes a novel formulation of utilizing context for planning as an image-to-image translation problem, which is shown to extract terrain context from semantic gridmaps, into a metric that an exploration-based planner can use. The proposed framework has the benefit of training on a static dataset instead of requiring a time-consuming simulator. Across 42 test houses with layouts from satellite images, the trained algorithm enables a robot to reach its goal 189\% faster than with a context-unaware planner, and within 63\% of the optimal path computed with a prior map. The proposed algorithm is also implemented on a vehicle with a forward-facing camera in a high-fidelity, Unreal simulation of neighborhood houses.},
  doi       = {10.1109/IROS40897.2019.8967550},
  file      = {:FILES/2019 - Everett2019 - Planning beyond the sensing horizon using a learned context.pdf:PDF},
  groups    = {task planning},
  issn      = {2153-0866},
  url       = {https://ieeexplore.ieee.org/document/8967550},
}

@Article{Bacciu2019,
  author   = {Bacciu, Davide and Di Rocco, Maurizio and Dragone, Mauro and Gallicchio, Claudio and Micheli, Alessio and Saffiotti, Alessandro},
  journal  = {Computational Intelligence},
  title    = {An ambient intelligence approach for learning in smart robotic environments},
  year     = {2019},
  number   = {4},
  pages    = {1060--1087},
  volume   = {35},
  abstract = {Abstract Smart robotic environments combine traditional (ambient) sensing devices and mobile robots. This combination extends the type of applications that can be considered, reduces their complexity, and enhances the individual values of the devices involved by enabling new services that cannot be performed by a single device. To reduce the amount of preparation and preprogramming required for their deployment in real-world applications, it is important to make these systems self-adapting. The solution presented in this paper is based upon a type of compositional adaptation where (possibly multiple) plans of actions are created through planning and involve the activation of pre-existing capabilities. All the devices in the smart environment participate in a pervasive learning infrastructure, which is exploited to recognize which plans of actions are most suited to the current situation. The system is evaluated in experiments run in a real domestic environment, showing its ability to proactively and smoothly adapt to subtle changes in the environment and in the habits and preferences of their user(s), in presence of appropriately defined performance measuring functions.},
  comment  = {本文假设指令已知，主要围绕多智能体（robotic ecology）家庭场景中的任务规划，或self adaptation展开研究。},
  doi      = {10.1111/coin.12233},
  file     = {:FILES/2019 - Bacciu2019 - An ambient intelligence approach for learning in smart robotic environments.pdf:PDF},
  groups   = {task planning},
  keywords = {adaptive planning, ambient intelligence, recurrent neural networks, robotic ecology, self-adaptive system, smart environment},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/coin.12233},
}

@TechReport{Sridharan2016,
  author      = {Mohan Sridharan},
  institution = {University of Auckland},
  title       = {Towards an architecture for representation, reasoning and learning in human-robot collaboration},
  year        = {2016},
  note        = {2016 AAAI Spring Symposium Series: Technical Reports},
  abstract    = {Robots collaborating with humans need to represent knowledge, reason, and learn, at the sensorimotor level and the cognitive level. This paper summarizes the capabilities of an architecture that combines the comple- mentary strengths of declarative programming, proba- bilistic graphical models, and reinforcement learning, to represent, reason with, and learn from, qualitative and quantitative descriptions of incomplete domain knowledge and uncertainty. Representation and reasoning is based on two tightly-coupled domain representations at different resolutions. For any given task, the coarse- resolution symbolic domain representation is translated to an Answer Set Prolog program, which is solved to provide a tentative plan of abstract actions, and to explain unexpected outcomes. Each abstract action is implemented by translating the relevant subset of the corresponding fine-resolution probabilistic representation to a partially observable Markov decision process (POMDP). Any high probability beliefs, obtained by the execution of actions based on the POMDP policy, update the coarse-resolution representation. When incomplete knowledge of the rules governing the domain dynamics results in plan execution not achieving the desired goal, the coarse-resolution and fine-resolution representations are used to formulate the task of incrementally and interactively discovering these rules as a reinforcement learning problem. These capabilities are illustrated in the context of a mobile robot deployed in an indoor office domain.},
  file        = {:FILES/2016 - Sridharan2016 - Towards an architecture for representation, reasoning and learning in human-robot collaboration.pdf:PDF},
  groups      = {human robot interaction},
  keywords    = {Knowledge representation, Human-robot Collaboration, POMDP, Answer Set Prolog, Reinforcement Learning},
  pages       = {172--178},
  url         = {https://www.aaai.org/ocs/index.php/SSS/SSS16/paper/view/12771},
}

@Article{CoxJr2020,
  author   = {Cox Jr., Louis Anthony},
  journal  = {Risk Analysis},
  title    = {Answerable and unanswerable questions in risk analysis with open-world novelty},
  year     = {2020},
  month    = nov,
  number   = {S1},
  pages    = {2144--2177},
  volume   = {40},
  abstract = {Abstract Decision analysis and risk analysis have grown up around a set of organizing questions: what might go wrong, how likely is it to do so, how bad might the consequences be, what should be done to maximize expected utility and minimize expected loss or regret, and how large are the remaining risks? In probabilistic causal models capable of representing unpredictable and novel events, probabilities for what will happen, and even what is possible, cannot necessarily be determined in advance. Standard decision and risk analysis questions become inherently unanswerable (“undecidable”) for realistically complex causal systems with “open-world” uncertainties about what exists, what can happen, what other agents know, and how they will act. Recent artificial intelligence (AI) techniques enable agents (e.g., robots, drone swarms, and automatic controllers) to learn, plan, and act effectively despite open-world uncertainties in a host of practical applications, from robotics and autonomous vehicles to industrial engineering, transportation and logistics automation, and industrial process control. This article offers an AI/machine learning perspective on recent ideas for making decision and risk analysis (even) more useful. It reviews undecidability results and recent principles and methods for enabling intelligent agents to learn what works and how to complete useful tasks, adjust plans as needed, and achieve multiple goals safely and reasonably efficiently when possible, despite open-world uncertainties and unpredictable events. In the near future, these principles could contribute to the formulation and effective implementation of more effective plans and policies in business, regulation, and public policy, as well as in engineering, disaster management, and military and civil defense operations. They can extend traditional decision and risk analysis to deal more successfully with open-world novelty and unpredictable events in large-scale real-world planning, policymaking, and risk management.},
  doi      = {10.1111/risa.13553},
  file     = {:FILES/2020 - CoxJr2020 - Answerable and unanswerable questions in risk analysis with open-world novelty.pdf:PDF},
  groups   = {human robot interaction},
  keywords = {Decision analysis, risk analysis},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/risa.13553},
}

@Article{Sridharan2019,
  author   = {Mohan Sridharan and Michael Gelfond and Shiqi Zhang and Jeremy Wyatt},
  journal  = {Journal of Artificial Intelligence Research},
  title    = {{REBA}: {A} refinement-based architecture for knowledge representation and reasoning in robotics},
  year     = {2019},
  month    = jun,
  pages    = {87--180},
  volume   = {65},
  abstract = {This article describes REBA, a knowledge representation and reasoning architecture for robots that is based on tightly-coupled transition diagrams of the domain at two different levels of granularity. An action language is extended to support non-boolean fluents and non-deterministic causal laws, and used to describe the domain's transition diagrams, with the fine-resolution transition diagram being defined as a refinement of the coarse-resolution transition diagram. The coarse-resolution system description, and a history that includes prioritized defaults, are translated into an Answer Set Prolog (ASP) program. For any given goal, inference in the ASP program provides a plan of abstract actions. To implement each such abstract action, the robot automatically zooms to the part of the fine-resolution transition diagram relevant to this action. The zoomed fine-resolution system description, and a probabilistic representation of the uncertainty in sensing and actuation, are used to construct a partially observable Markov decision process (POMDP). The policy obtained by solving the POMDP is invoked repeatedly to implement the abstract action as a sequence of concrete actions. The fine-resolution outcomes of executing these concrete actions are used to infer coarse-resolution outcomes that are added to the coarse-resolution history and used for subsequent coarse-resolution reasoning. The architecture thus combines the complementary strengths of declarative programming and probabilistic graphical models to represent and reason with non-monotonic logic-based and probabilistic descriptions of uncertainty and incomplete domain knowledge. In addition, we describe a general methodology for the design of software components of a robot based on these knowledge representation and reasoning tools, and provide a path for proving the correctness of these components. The architecture is evaluated in simulation and on a mobile robot finding and moving target objects to desired locations in indoor domains, to show that the architecture supports reliable and efficient reasoning with violation of defaults, noisy observations and unreliable actions, in complex domains.},
  doi      = {10.1613/jair.1.11524},
  file     = {:FILES/2019 - Sridharan2019 - REBA- A refinement-based architecture for knowledge representation and reasoning in robotics.pdf:PDF},
  groups   = {representation},
  keywords = {Knowledge representation, logic programming, probabilistic reasoning, Robotics, Reasoning about actions and change, Qualitative reasoning},
  url      = {https://jair.org/index.php/jair/article/view/11524},
}

@Article{Liao2020,
  author   = {Zhiyong {Liao} and Yu {Zhang} and Junren {Luo} and Weilin {Yuan}},
  journal  = {IEEE Access},
  title    = {{TSM}: {Topological} scene map for representation in indoor environment understanding},
  year     = {2020},
  issn     = {2169-3536},
  month    = oct,
  pages    = {185870--185884},
  volume   = {8},
  abstract = {In the field of robotics, it is crucial to obtain a comprehensive semantic understanding of a scene for many applications. Based on the behavioral topological map and scene graph, we propose to employ a semantic map named Topological Scene Map (TSM) for representation in indoor environment understanding. The behavioral topological map we constructed expresses the spatial connection relations and semantically describes the navigation behavior between adjacent topological nodes. The scene graph promotes the TSM to record the objects that appear in the scene and the relations between objects. The addition of spatial and semantic relations makes the expression of the scene more specific, which improves the robot's abilities of scene understanding and human-robotic interaction. In this article, we design a method for topological map construction and apply a novel approach to generate a scene graph from RGB-D data. The semantic representation of the environment generated in the experiments verifies that the TSM construction framework models the scene efficiently and the TSM is conducive to the realization of human-robotic interaction.},
  doi      = {10.1109/ACCESS.2020.3029324},
  file     = {:FILES/2020 - Liao2020 - TSM- Topological scene map for representation in indoor environment understanding.pdf:PDF},
  groups   = {representation},
  keywords = {Semantics;Navigation;Robots;Task analysis;Measurement;Indoor environments;Adaptation models;Scene graph generation;topological map construction;semantic map},
  url      = {https://ieeexplore.ieee.org/document/9216084},
}

@InProceedings{Rosen2020,
  author    = {Eric {Rosen} and Nishanth {Kumar} and Nakul {Gopalan} and Daniel {Ullman} and George {Konidaris} and Stefanie {Tellex}},
  booktitle = {2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Building plannable representations with mixed reality},
  year      = {2020},
  address   = {Las Vegas, NV, USA},
  month     = oct,
  pages     = {11146--11153},
  publisher = {IEEE},
  abstract  = {We propose Action-Oriented Semantic Maps (AOSMs), a representation that enables a robot to acquire object manipulation behaviors and semantic information about the environment from a human teacher with a Mixed Reality Head-Mounted Display (MR-HMD). AOSMs are a representation that captures both: a) high-level object manipulation actions in an object class's local frame, and b) semantic representations of objects in the robot's global map that are grounded for navigation. Humans can use a MR-HMD to teach the agent the information necessary for planning object manipulation and navigation actions by interacting with virtual 3D meshes overlaid on the physical workspace. We demonstrate that our system enables users to quickly and accurately teach a robot the knowledge required to autonomously plan and execute three household tasks: picking up a bottle and throwing it in the trash, closing a sink faucet, and flipping a light switch off.},
  doi       = {10.1109/IROS45743.2020.9341627},
  file      = {:FILES/2020 - Rosen2020 - Building plannable representations with mixed reality.pdf:PDF},
  groups    = {representation},
  issn      = {2153-0866},
  keywords  = {Three-dimensional displays;Navigation;Semantics;Mixed reality;Virtual reality;Switches;Task analysis},
  url       = {https://ieeexplore.ieee.org/document/9341627},
}

@InProceedings{Jiang2019,
  author    = {Jiang, Yuqian and Walker, Nick and Hart, Justin and Stone, Peter},
  booktitle = {Proceedings of the 29th International Conference on Automated Planning and Scheduling},
  title     = {Open-world reasoning for service robots},
  year      = {2019},
  editor    = {J. Benton and Nir Lipovetzky and Eva Onaindia and David E. Smith and Siddharth Srivastava},
  month     = jul,
  pages     = {725--733},
  volume    = {29},
  abstract  = {A service robot accepting verbal commands from a human operator is likely to encounter requests that reference objects not currently represented in its knowledge base. In domestic or office settings, the construction of a complete knowledge base would be cumbersome and unlikely to succeed in most real-world deployments. The world that such a robot operates in is thus “open” in the sense that some objects that it must act on in the real world are not described in its internal representation. However, when an operator gives a command referencing an object that the robot has not yet observed (and thus not incorporated into its knowledge base), we can think of the object as being hypothetical to the robot. This paper presents a novel method for closing the robot’s world model for planning purposes by introducing hypothetical objects into the robot’s knowledge base, reasoning about these hypothetical objects, and acting on these hypotheses in the real world. We use our implementation of this method on a domestic service robot as an illustrative demonstration to explore how it works in practice.},
  file      = {:FILES/2019 - Jiang2019 - Open-world reasoning for service robots.pdf:PDF},
  groups    = {reasoning},
  url       = {https://ojs.aaai.org//index.php/ICAPS/article/view/3541},
}

@InProceedings{Yang2020,
  author    = {Guang {Yang} and Shuoyu {Wang} and Junyou {Yang} and Pei {Shi}},
  booktitle = {2020 IEEE International Conference on Mechatronics and Automation (ICMA)},
  title     = {Desire-driven reasoning considering status-based knowledge description for personal care robots},
  year      = {2020},
  address   = {Beijing, China},
  month     = oct,
  pages     = {1883--1888},
  publisher = {IEEE},
  abstract  = {One option to face the aging society and caring force shortage is to develop intelligent robots capable of caring for people while no one is available. This paper investigates how specific commands (e.g. serve a cup of water) can be reasoned from abstracted desires (e.g., thirst) while caring for bedridden individuals with robots. The key to solving the problem is a status-based knowledge description, which is expendable considering complex and large quantify of available household operations and items. Based on such a description, a reasoning system is presented to identify suitable actions given an abstracted need. Finally, we evaluate the reasoning system with our personal care robot KUT-PCR in a real household domain.},
  doi       = {10.1109/ICMA49215.2020.9233588},
  file      = {:FILES/2020 - Yang2020 - Desire-driven reasoning considering status-based knowledge description for personal care robots.pdf:PDF},
  groups    = {reasoning},
  issn      = {2152-744X},
  keywords  = {Mechatronics;Automation;Conferences;Force;Cognition;Intelligent robots;Faces;knowledge description;reasoning;personal care},
  url       = {https://ieeexplore.ieee.org/document/9233588},
}

@Article{Savage2019,
  author     = {Jesus Savage and David A. Rosenblueth and Mauricio Matamoros and Marco Negrete and Luis Contreras and Julio Cruz and Reynaldo Martell and Hugo Estrada and Hiroyuki Okada},
  journal    = {Robotics and Autonomous Systems},
  title      = {Semantic reasoning in service robots using expert systems},
  year       = {2019},
  issn       = {0921-8890},
  pages      = {77--92},
  volume     = {114},
  abstract   = {This paper presents the semantic-reasoning module of VIRBOT, our proposed architecture for service robots. We show that by combining symbolic AI with digital-signal processing techniques this module achieves competitive performance. Our system translates a voice command into an unambiguous representation that helps an inference engine, built around an expert system, to perform action and motion planning. First, in the natural-language interpretation process, the system generates two outputs: (1) conceptual dependence, expressing the linguistic meaning of the statement, and (2) verbal confirmation, a paraphrase in natural language that is repeated to the user to confirm that the command has been correctly understood. Then, a conceptual-dependency interpreter extracts semantic role structures from the input sentence and looks for such structures in a set of known interpretation patterns. We evaluate this approach in a series of skill-specific semantic-reasoning experiments. Finally, we demonstrate our system in the general-purpose service robot test of the RoboCup-at-Home international competition, where incomplete information is given to a robot and the robot must recognize and request the missing information, and we compare our results with a series of baselines from the competition where our proposal performed best.},
  comment    = {Cui2021:"use a conceptual-dependency [13] interpreter extracts semantic role structures from the input sentence and planning with the open-source expert system CLIPS"},
  doi        = {10.1016/j.robot.2019.01.007},
  file       = {:FILES/2019 - Savage2019 - Semantic reasoning in service robots using expert systems.pdf:PDF},
  groups     = {reasoning, task understanding},
  keywords   = {Service robots, Semantic reasoning, Knowledge representation, read},
  printed    = {Y},
  readstatus = {read},
  url        = {https://www.sciencedirect.com/science/article/pii/S0921889018302501},
}

@InProceedings{Baxter2020,
  author    = {Baxter, Paul and Del Duchetto, Francesco and Hanheide, Marc},
  booktitle = {Educational Robotics in the Context of the Maker Movement},
  title     = {Engaging learners in dialogue interactivity development for mobile robots},
  year      = {2020},
  address   = {Cham},
  editor    = {Moro, Michele and Alimisis, Dimitris and Iocchi, Luca},
  pages     = {147--160},
  publisher = {Springer International Publishing},
  abstract  = {The use of robots in educational and STEM engagement activities is widespread. In this paper we describe a system developed for engaging learners with the design of dialogue-based interactivity for mobile robots. With an emphasis on a web-based solution that is grounded in both a real robot system and a real application domain -- a museum guide robot -- our intent is to enhance the benefits to both driving research through potential user-group engagement, and enhancing motivation by providing a real application context for the learners involved. The proposed system is designed to be highly scalable to both many simultaneous users and to users of different age groups, and specifically enables direct deployment of implemented systems onto both real and simulated robots. Our observations from preliminary events, involving both children and adults, support the view that the system is both usable and successful in supporting engagement with the dialogue interactivity problem presented to the participants, with indications that this engagement can persist over an extended period of time.},
  doi       = {10.1007/978-3-030-18141-3_12},
  file      = {:FILES/2020 - Baxter2020 - Engaging learners in dialogue interactivity development for mobile robots.pdf:PDF},
  groups    = {human robot interaction},
  isbn      = {978-3-030-18141-3},
  keywords  = {Mobile robots, DialogFlow, Museum guide, Public engagement, Dialogue interactivity},
  url       = {https://link.springer.com/chapter/10.1007/978-3-030-18141-3_12},
}

@Misc{Gomez2019a,
  author        = {Rocio Gomez and Mohan Sridharan and Heather Riley},
  title         = {Towards a theory of intentions for human-robot collaboration},
  year          = {2019},
  abstract      = {The architecture described in this paper encodes a theory of intentions based on the the key principles of non-procrastination, persistence, and automatically limiting reasoning to relevant knowledge and observations. The architecture reasons with transition diagrams of any given domain at two different resolutions, with the fine-resolution description defined as a refinement of, and hence tightly-coupled to, a coarse-resolution description. Non-monotonic logical reasoning with the coarse-resolution description computes an activity (i.e., plan) comprising abstract actions for any given goal. Each abstract action is implemented as a sequence of concrete actions by automatically zooming to and reasoning with the part of the fine-resolution transition diagram relevant to the current coarse-resolution transition and the goal. Each concrete action in this sequence is executed using probabilistic models of the uncertainty in sensing and actuation, and the corresponding fine-resolution outcomes are used to infer coarse-resolution observations that are added to the coarse-resolution history. The architecture's capabilities are evaluated in the context of a simulated robot assisting humans in an office domain, on a physical robot (Baxter) manipulating tabletop objects, and on a wheeled robot (Turtlebot) moving objects to particular places or people. The experimental results indicate improvements in reliability and computational efficiency compared with an architecture that does not include the theory of intentions, and an architecture that does not include zooming for fine-resolution reasoning.},
  archiveprefix = {arXiv},
  eprint        = {1907.13275},
  file          = {:FILES/2019 - Gomez2019a - Towards a theory of intentions for human-robot collaboration.pdf:PDF},
  groups        = {human robot interaction},
  primaryclass  = {cs.AI},
}

@InProceedings{Fischer2018,
  author    = {Lydia Fischer and Stephan Hasler and Joerg Deigmoeller and Thomas Schnuerer and Michael Redert and Ulrike Pluntke and Katrin Nagel and Chris Senzel and Joern Ploennigs and Andreas Richter and Julian Eggert},
  booktitle = {Proceedings of the 11th Cognitive Robotics Workshop 2018 co-located with 16th International Conference on Principles of Knowledge Representation and Reasoning (KR 2018)},
  title     = {Which tool to use? {Grounded} reasoning in everyday environments with assistant robots},
  year      = {2018},
  address   = {Tempe, AZ, USA},
  month     = oct,
  pages     = {3--10},
  file      = {:FILES/2018 - Fischer2018 - Which tool to use {Grounded} reasoning in everyday environments with assistant robots.pdf:PDF},
  groups    = {reasoning},
  url       = {http://ceur-ws.org/Vol-2325/},
}

@InProceedings{Sridharan2016a,
  author    = {Mohan Sridharan and Michael Gelfond},
  booktitle = {Proceedings of the Workshop on Knowledge-based Techniques for Problem Solving and Reasoning co-located with 25th International Joint Conference on Artificial Intelligence (IJCAI 2016)},
  title     = {Using knowledge representation and reasoning tools in the design of robots},
  year      = {2016},
  address   = {New York City, USA},
  month     = jul,
  file      = {:FILES/2016 - Sridharan2016a - Using knowledge representation and reasoning tools in the design of robots.pdf:PDF},
  groups    = {reasoning},
  url       = {http://ceur-ws.org/Vol-1648/},
}

@Article{Lee2018a,
  author     = {Lee, Seokjun and Kim, Incheol},
  journal    = {Sensors},
  title      = {A robotic context query-processing framework based on spatio-temporal context ontology},
  year       = {2018},
  issn       = {1424-8220},
  number     = {10},
  pages      = {3336},
  volume     = {18},
  abstract   = {Service robots operating in indoor environments should recognize dynamic changes from sensors, such as RGB-depth (RGB-D) cameras, and recall the past context. Therefore, we propose a context query-processing framework, comprising spatio-temporal robotic context query language (ST-RCQL) and a spatio-temporal robotic context query-processing system (ST-RCQP), for service robots. We designed them based on spatio-temporal context ontology. ST-RCQL can query not only the current context knowledge, but also the past. In addition, ST-RCQL includes a variety of time operators and time constants; thus, queries can be written very efficiently. The ST-RCQP is a query-processing system equipped with a perception handler, working memory, and backward reasoner for real-time query-processing. Moreover, ST-RCQP accelerates query-processing speed by building a spatio-temporal index in the working memory, where percepts are stored. Through various qualitative and quantitative experiments, we demonstrate the high efficiency and performance of the proposed context query-processing framework.},
  comment    = {本文设计了一种context query 语言和processing system，可以根据service robot实时感知的数据进行推理，},
  doi        = {10.3390/s18103336},
  file       = {:FILES/2018 - Lee2018a - A robotic context query-processing framework based on spatio-temporal context ontology.pdf:PDF},
  groups     = {reasoning},
  readstatus = {skimmed},
  url        = {https://www.mdpi.com/1424-8220/18/10/3336},
}

@InProceedings{Iocchi2016,
  author    = {Iocchi, L. and Jeanpierre, L. and L\'{a}zaro, M. T. and Mouaddib, A.-I.},
  booktitle = {Proceedings of the 26th International Conference on International Conference on Automated Planning and Scheduling (ICAPS'16)},
  title     = {A practical framework for robust decision-theoretic planning and execution for service robots},
  year      = {2016},
  address   = {London, UK},
  month     = jun,
  pages     = {486--494},
  publisher = {AAAI Press},
  abstract  = {The deployment of robots in populated environments is recently gaining more interest because of increased maturity and capability of this technology. In this context, sophisticated planning techniques are required because there is a need of increasing the complexity of the tasks that the robot can accomplish. In particular, there is a large emphasis on service robots, i.e., robots that can satisfy several user needs.In this paper, we present a practical framework based on a decision-theoretic formalism for generation and execution of robust plans for service robots. The proposed framework has been implemented and succesfully tested on service robots interacting with non-expert users in public environments, facing many sources of uncertainty and failures in task execution.},
  file      = {:FILES/2016 - Iocchi2016 - A practical framework for robust decision-theoretic planning and execution for service robots.pdf:PDF},
  groups    = {task planning},
  isbn      = {1577357574},
  url       = {https://www.aaai.org/ocs/index.php/ICAPS/ICAPS16/},
}

@Article{Ramoly2018,
  author   = {N. Ramoly and A. Bouzeghoub and B. Finance},
  journal  = {IRBM},
  title    = {A framework for service robots in smart home: {An} efficient solution for domestic healthcare},
  year     = {2018},
  issn     = {1959-0318},
  note     = {JETSAN},
  number   = {6},
  pages    = {413--420},
  volume   = {39},
  abstract = {Purpose
As the elder population grows, the need for domestic healthcare is on the rise. Both robotics and smart environments, including smart homes, provide a promising solution to monitor, interact and keep company to users. However, in real case scenarios, sensors data are not perfect and the environment changes over time, leading to erroneous understanding of the context and inappropriate responses. The purpose of this work is to tackle those challenges in order to improve the autonomy and efficiency of robots in smart environments.
Methods
The problematic was structured into three steps: (1) perception, (2) cognition and (3) action. We proposed and evaluated a software framework that covers the challenges of each step. It includes respectively: (1) a context acquisition method that supports and models the uncertainty of data by using complex event processing, fuzzy logic and ontologies; (2) an activity recognition system that combines vision, context knowledge and semantic reasoning; (3) a dynamic hierarchical task planner that alternates planning and execution. For each step, the framework was evaluated through simulations and/or experiments using a robot and a smart room.
Results
The quality of the perception was assessed by measuring the efficiency of a cognition process using the acquired context knowledge. An uncertain environment was simulated, and results show our framework to enable a gain of 10\% of correctness for an activity recognition process. The cognition part of the framework was evaluated by observing several persons performing activities. It achieved an overall 90\% correct recognition, yet, such result questions the relevance of our approach. Finally, the action step was confronted a simulated scenario with various levels of dynamism. Our task planner appeared to reduce, by up to 23\%, the number of tasks required to reach a goal in a dynamic environment.
Conclusion
Our framework provides software tools that make robots and smart environments more relevant in real housings. By supporting the uncertainty of context data and the dynamism of the environment, robots and smart environments can achieve more effectively their purposes in domestic healthcare applications.},
  doi      = {10.1016/j.irbm.2018.10.010},
  file     = {:FILES/2018 - Ramoly2018 - A framework for service robots in smart home- {An} efficient solution for domestic healthcare.pdf:PDF},
  groups   = {robots},
  keywords = {Service robots, Smart home, Healthcare, Task planner, Context acquisition, Ontology, Activity recognition},
  url      = {https://www.sciencedirect.com/science/article/pii/S1959031818302793},
}

@Article{Zhang2019b,
  author   = {Zhang, Kailong and Fei, Chao and Xie, Baorong and Wang, Yujia and Gong, Zheng and Xie, Chenyu and Nguyen, Thi Mai Trang and Yao, Yuan and Miao, Kejian},
  journal  = {Applied Sciences},
  title    = {Multi-constraint optimized planning of tasks on virtualized-service pool for mission-oriented swarm intelligent systems},
  year     = {2019},
  issn     = {2076-3417},
  number   = {15},
  pages    = {3010},
  volume   = {9},
  abstract = {With the emergence of swarm intelligent systems, especially the swarming of aircraft and ground vehicles, cooperation in multiple dimensions has becoming one of the great challenges. How to dynamically schedule the resources within a swarm intelligent system and optimize the execution of tasks are all vital aspects for such systems. Focusing on this topic, in this paper, one new task planning mechanism with multiple constraints is proposed to solve such dynamic programming problems. Concretely, several fundamental models, covering three-level task models and resource-service pool models, are put forward and defined first. Considering the limitations of swarm systems running within complicated cyber-physical space, multi-dimension constraints for tasks scheduling and execution are further modeled and established. On this basis, we mapped this planning problem to an optimization searching problem, and then proposed a Genetic-Algorithm-based mechanism. All these works have been verified with simulated cooperation scenes. Experimental results show that this new mechanism is efficient to solve such resource-related and mission-oriented cooperation problems in complicated environments.},
  doi      = {10.3390/app9153010},
  file     = {:FILES/2019 -Zhang2019b - Multi-Constraint Optimized Planning of Tasks on Virtualized-Service Pool for Mission-Oriented Swarm Intelligent Systems.pdf:PDF},
  groups   = {task planning},
  url      = {https://www.mdpi.com/2076-3417/9/15/3010},
}

@Article{Meadows2016,
  author   = {Meadows, Ben and Sridharan, Mohan and Colaco, Zenon},
  journal  = {Robotics},
  title    = {Towards an explanation generation system for robots: {Analysis} and recommendations},
  year     = {2016},
  issn     = {2218-6581},
  number   = {4},
  pages    = {21},
  volume   = {5},
  abstract = {A fundamental challenge in robotics is to reason with incomplete domain knowledge to explain unexpected observations and partial descriptions extracted from sensor observations. Existing explanation generation systems draw on ideas that can be mapped to a multidimensional space of system characteristics, defined by distinctions, such as how they represent knowledge and if and how they reason with heuristic guidance. Instances in this multidimensional space corresponding to existing systems do not support all of the desired explanation generation capabilities for robots. We seek to address this limitation by thoroughly understanding the range of explanation generation capabilities and the interplay between the distinctions that characterize them. Towards this objective, this paper first specifies three fundamental distinctions that can be used to characterize many existing explanation generation systems. We explore and understand the effects of these distinctions by comparing the capabilities of two systems that differ substantially along these axes, using execution scenarios involving a robot waiter assisting in seating people and delivering orders in a restaurant. The second part of the paper uses this study to argue that the desired explanation generation capabilities corresponding to these three distinctions can mostly be achieved by exploiting the complementary strengths of the two systems that were explored. This is followed by a discussion of the capabilities related to other major distinctions to provide detailed recommendations for developing an explanation generation system for robots.},
  comment  = {本文是利用observations and commonsense knowledge to reaon the possible causes of an unexpected scenario, i.e., to generate explanation},
  doi      = {10.3390/robotics5040021},
  file     = {:FILES/2016 - Meadows2016 - Towards an Explanation Generation System for Robots- Analysis and Recommendations.pdf:PDF},
  groups   = {explanation},
  url      = {https://www.mdpi.com/2218-6581/5/4/21},
}

@InProceedings{Dianov2016,
  author    = {I. {Dianov} and K. {Ramírez-Amaro} and P. {Lanillos} and E. {Dean-Leon} and F. {Bergner} and G. {Cheng}},
  booktitle = {2016 IEEE-RAS 16th International Conference on Humanoid Robots (Humanoids)},
  title     = {Extracting general task structures to accelerate the learning of new tasks},
  year      = {2016},
  address   = {Cancun, Mexico},
  month     = nov,
  pages     = {802--807},
  publisher = {IEEE},
  abstract  = {Teaching a robot new tasks through kinesthetic demonstrations can be a long and complicated process. For example, a human has to demonstrate a new “pick and place” task each time the object or the target location has changed. However, obtaining the abstract representation of such task can significantly reduce the learning time as the human only has to teach the necessary parameters required for the successful execution, e.g. the location of an object. In this work, we present a framework which allows to extract general task structures which together with the obtained knowledge can improve and accelerate the teaching of new tasks. Additionally, our framework exploits the semantic similarities between task parameters in order to infer the possible structure of unknown tasks. Our proposed method utilises symbolic representations of tasks combined with an ontology which makes it applicable to different environments in various domains. We analysed our framework in an orange sorting scenario and a cleaning scenario to demonstrate that it allows reducing the time required for teaching from 136.3 to 53 seconds (61.12\%) and from 48.7 to 21 seconds (56.87\%) respectively compared to learning only by kinesthetic demonstrations.},
  doi       = {10.1109/HUMANOIDS.2016.7803365},
  file      = {:FILES/2016 - Dianov2016 - Extracting general task structures to accelerate the learning of new tasks.pdf:PDF},
  groups    = {representation},
  issn      = {2164-0580},
  keywords  = {Robots;Ontologies;Acceleration;Education;Hidden Markov models;Inference algorithms;Semantics},
  url       = {https://ieeexplore.ieee.org/document/7803365},
}

@InProceedings{Scalise2017,
  author     = {Scalise, Rosario and Rosenthal, Stephanie and Srinivasa, Siddhartha},
  booktitle  = {Proceedings of the Companion of the 2017 ACM/IEEE International Conference on Human-Robot Interaction (HRI'17)},
  title      = {Natural language explanations in human-collaborative systems},
  year       = {2017},
  address    = {New York, NY, USA},
  month      = mar,
  pages      = {377--378},
  publisher  = {Association for Computing Machinery},
  comment    = {本文提出了一种four-step approach to generate natural language explanation of the robot's behavior, i.e., 
1. grounding language and environment so that the robot and human share a similar vocabulary.
2. evaluating the user comprehension. 基于inverse RL to predict the robot's optimization function, and compare it with the robot's actual function.
3. determining the explanation method. 目前大部分研究讨论的是what the robot did,可以扩展到why it chose the actions. 
4. generating NL.

本文是一种框架性的讨论，没有涉及具体的技术，只提出了一种解决思路。},
  doi        = {10.1145/3029798.3034809},
  file       = {:FILES/2017 - Scalise2017 - Natural Language Explanations in Human-Collaborative Systems.pdf:PDF},
  groups     = {task understanding, explanation},
  isbn       = {9781450348850},
  keywords   = {natural language, explanation, human-robot collaboration},
  printed    = {Y},
  readstatus = {read},
  url        = {https://doi.org/10.1145/3029798.3034809},
}

@InProceedings{Zhang2017a,
  author    = {Yu {Zhang} and Sarath {Sreedharan} and Anagha {Kulkarni} and Tathagata {Chakraborti} and Hankz H. {Zhuo} and Subbarao {Kambhampati}},
  booktitle = {2017 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Plan explicability and predictability for robot task planning},
  year      = {2017},
  address   = {Singapore},
  month     = may,
  pages     = {1313--1320},
  publisher = {IEEE},
  abstract  = {Intelligent robots and machines are becoming pervasive in human populated environments. A desirable capability of these agents is to respond to goal-oriented commands by autonomously constructing task plans. However, such autonomy can add significant cognitive load and potentially introduce safety risks to humans when agents behave in unexpected ways. Hence, for such agents to be helpful, one important requirement is for them to synthesize plans that can be easily understood by humans. While there exists previous work that studied socially acceptable robots that interact with humans in “natural ways”, and work that investigated legible motion planning, there is no general solution for high level task planning. To address this issue, we introduce the notions of plan explicability and predictability. To compute these measures, first, we postulate that humans understand agent plans by associating abstract tasks with agent actions, which can be considered as a labeling process. We learn the labeling scheme of humans for agent plans from training examples using conditional random fields (CRFs). Then, we use the learned model to label a new plan to compute its explicability and predictability. These measures can be used by agents to proactively choose or directly synthesize plans that are more explicable and predictable to humans. We provide evaluations on a synthetic domain and with a physical robot to demonstrate the effectiveness of our approach.},
  doi       = {10.1109/ICRA.2017.7989155},
  file      = {:FILES/2017 - Zhang2017a - Plan explicability and predictability for robot task planning.pdf:PDF},
  groups    = {task planning},
  keywords  = {Planning;Robots;Labeling;Computational modeling;Training;Predictive models},
  url       = {https://ieeexplore.ieee.org/document/7989155},
}

@InProceedings{Chen2016,
  author    = {Chen, Kai and Yang, Fangkai and Chen, Xiaoping},
  booktitle = {Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI)},
  title     = {Planning with task-oriented knowledge acquisition for a service robot},
  year      = {2016},
  address   = {New York, New York, USA},
  month     = jul,
  pages     = {812--818},
  publisher = {AAAI Press},
  abstract  = {We propose a framework for a service robot to behave intelligently in domains that contain incomplete information, underspecified goals and dynamic change. Human robot interaction (HRI), sensing actions and physical actions are uniformly formalized in action language BC. An answer set solver is called to generate plans that guide the robot to acquire task-oriented knowledge and execute actions to achieve its goal, including interacting with human to gather information and sensing the environment to help motion planning. By continuously interpreting and grounding useful sensing information, robot is able to use contingent knowledge to adapt to unexpected changes and faults. We evaluate the approach on service robot  Ke-Jia  that serves drink to guests, a testing benchmark for general-purpose service robot proposed by RoboCup@Home competition.},
  comment   = {Cui2021: 前期工作：kejia acquire task-oriented knowledge by interacting with the user and sensing the environment. collects task-oriented information by combining HRI with planning. any environment change will trigger a re-plan},
  file      = {:FILES/2016 - Chen2016 - Planning with task-oriented knowledge acquisition for a service robot.pdf:PDF},
  groups    = {representation, task understanding},
  isbn      = {9781577357704},
  url       = {https://www.ijcai.org/proceedings/2016/},
}

@Article{Lyu2019,
  author    = {Lyu, Daoming and Yang, Fangkai and Liu, Bo and Gustafson, Steven},
  journal   = {Electronic Proceedings in Theoretical Computer Science},
  title     = {A human-centered data-driven planner-actor-critic architecture via logic programming},
  year      = {2019},
  issn      = {2075-2180},
  month     = sep,
  pages     = {182--195},
  volume    = {306},
  doi       = {10.4204/eptcs.306.23},
  file      = {:FILES/2019 - Lyu2019 - A human-centered data-driven planner-actor-critic architecture via logic programming.pdf:PDF},
  groups    = {task planning},
  publisher = {Open Publishing Association},
  url       = {https://arxiv.org/abs/1909.09209v1},
}

@Article{Pineda2018,
  author    = {Pineda, Luis A. and Rodr\'{i}guez, Arturo and Fuentes, Gibr\'{a}n and Hernández, No\'{e} and Reyes, Mauricio and Rasc\'{o}n, Caleb and Cruz, Ricardo and V\'{e}lez, Ivette and Ortega, Hernando},
  journal   = {Journal of Intelligent \& Fuzzy Systems},
  title     = {Opportunistic inference and emotion in service robots},
  year      = {2018},
  issn      = {1875-8967},
  number    = {5},
  pages     = {3301--3311},
  volume    = {34},
  abstract  = {In this paper a strategy for incorporating a flexible and reliable high-level inference module in service robots is presented. This module is a part of the robot’s cognitive architecture which coordinates perception, inference and action within the robot’s communication and interaction cycle. The present approach relies on an explicit representation of the structure of the task performed by the robot. There are three kinds of inferences that the robot can use opportunistically along the task: (1) diagnosis, (2) decision making and (3) planning; each kind can be used in specific situations of the task structure or performed in arbitrary situations with recovery purposes when there is an interaction failure. In this latter case the three kinds of inference are performed sequentially in what we call the daily-life inference cycle . The inference cycle allows the incorporation of basic emotions in the robot’s behavior. A case study incorporating these functionalities in the robot Golem-III is presented. The paper is concluded with a reflection on the opportunistic use of inference schemes to support flexible and robust behavior, including the expression of emotions, in service robots.},
  comment   = {本文讲的是facial expression，是service robot展现出emotional behavior.},
  doi       = {10.3233/JIFS-169512},
  file      = {:FILES/2018 - Pineda2018 - Opportunistic inference and emotion in service robots.pdf:PDF},
  groups    = {robots},
  keywords  = {Inference in service robots, robust behavior in service robots, robotics cognitive architecture, the Golem-III robot},
  publisher = {IOS Press},
  url       = {https://content.iospress.com/articles/journal-of-intelligent-and-fuzzy-systems/ifs169512},
}

@Article{Eiband2019,
  author   = {T. {Eiband} and M. {Saveriano} and D. {Lee}},
  journal  = {IEEE Robotics and Automation Letters},
  title    = {Intuitive programming of conditional tasks by demonstration of multiple solutions},
  year     = {2019},
  issn     = {2377-3766},
  month    = oct,
  number   = {4},
  pages    = {4483--4490},
  volume   = {4},
  abstract = {Conditional tasks include a decision on how the robot should react to an observation. This requires to select the appropriate action during execution. For instance, spatial sorting of objects may require different goal positions based on the objects properties, such as weight or geometry. We propose a framework that allows a user to demonstrate conditional tasks including recovery behaviors for expected situations. In our framework, human demonstrations define the required actions for task completion, which we term solutions. Each specific solution accounts for different conditions which may arise during execution. We exploit a clustering scheme to assign multiple demonstrations to a specific solution, which is then encoded in a probabilistic model. At runtime, our approach monitors the execution of the current solution using measured robot pose, external wrench, and grasp status. Deviations from the expected state are then classified as anomalies. This triggers the execution of an alternative solution, appropriately selected from the pool of demonstrated actions. Experiments on a real robot show the capability of the proposed approach to detect anomalies online and switch to an appropriate solution that fulfills the task.},
  doi      = {10.1109/LRA.2019.2935381},
  file     = {:FILES/2019 - Eiband2019 - Intuitive programming of conditional tasks by demonstration of multiple solutions.pdf:PDF},
  groups   = {representation},
  keywords = {Task analysis;Robot sensing systems;Monitoring;Force;Time series analysis;Switches;Learning from demonstration;failure detection and recovery;learning and adaptive systems},
  url      = {https://ieeexplore.ieee.org/document/8798604},
}

@Article{Loncomilla2017,
  author  = {Patricio Loncomilla and Javier {Ruiz-del-Solar} and Marcelo {Saavedra A.}},
  journal = {Journal of Intelligent \& Robotic Systems},
  title   = {A {Bayesian} based methodology for indirect object search},
  year    = {2017},
  month   = oct,
  pages   = {45--63},
  volume  = {90},
  doi     = {10.1007/s10846-017-0643-1},
  file    = {:FILES/2017 - Loncomilla2017 - A {Bayesian} based methodology for indirect object search.pdf:PDF},
  groups  = {sensing system},
  url     = {https://link.springer.com/article/10.1007/s10846-017-0643-1},
}

@Article{Kim2019,
  author     = {Mingu Kim and Il Hong Suh},
  journal    = {Intelligent Service Robotics},
  title      = {Active object search in an unknown large-scale environment using commonsense knowledge and spatial relations},
  year       = {2019},
  pages      = {371-380},
  volume     = {12},
  comment    = {本文是针对大范围未知环境下，根据环境的空间信息和常识信息等，规划合理路径，以实现searching object的目标。重点在于对路径规划，以及基于SLAM的环境感知和位置推理等。},
  doi        = {10.1007/s11370-019-00288-5},
  file       = {:FILES/2019 - Kim2019 - Active object search in an unknown large-scale environment using commonsense knowledge and spatial relations.pdf:PDF},
  groups     = {path planning},
  readstatus = {skimmed},
  url        = {https://link.springer.com/article/10.1007/s11370-019-00288-5},
}
﻿

@Misc{Li2021a,
  author        = {Tao Li and Lei Tan and Qinghua Tao and Yipeng Liu and Xiaolin Huang},
  title         = {Train deep neural networks in {40-D} subspaces},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2103.11154},
  file          = {:FILES/2021 - Li2021a - Train deep neural networks in {40-D} subspaces.pdf:PDF},
  groups        = {Neural Network},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2103.11154v1},
}

@Book{Brynie2009,
  author    = {Brynie, Faith Hickman},
  publisher = {American Management Association},
  title     = {Brain sense: {The} science of senses and how we process the world around us},
  year      = {2009},
  address   = {Broadway, New York, NY, US},
  isbn      = {9780814413265},
  month     = sep,
  groups    = {for aire},
}

@InCollection{Bull2014,
  author    = {David R. Bull},
  booktitle = {Communicating Pictures},
  publisher = {Academic Press},
  title     = {The human visual system},
  year      = {2014},
  address   = {Oxford},
  chapter   = {2},
  editor    = {David R. Bull},
  isbn      = {978-0-12-405906-1},
  pages     = {17--61},
  abstract  = {This chapter is intended to provide the reader with a basic understanding of the human visual system (HVS) and, where possible, to relate its characteristics to visual redundancy and ultimately to a means of compressing image and video signals. It first considers the physical architecture of the HVS and the constraints it imposes on the way we see the world. It then reviews perceptual aspects of vision related to brightness, contrast, texture, color, and motion, indicating the physical limits of key visual parameters. Visual masking is a key component in perception-based compression, and the chapter ends by looking at how certain spatio-temporal visual features can be masked by certain types of content.},
  doi       = {10.1016/B978-0-12-405906-1.00002-7},
  groups    = {for aire},
  keywords  = {The human eye, Human visual system (HVS), Visual cortex, Visual acuity, Color processing, Spatial processing, Contrast sensitivity, Visual perception, Eye movements, Visual masking},
  url       = {https://www.sciencedirect.com/science/article/pii/B9780124059061000027},
}

@InCollection{Juang2006,
  author    = {{Biing-Hwang} Juang and Lawrence R. Rabiner},
  booktitle = {Encyclopedia of Language \& Linguistics (Second Edition)},
  publisher = {Elsevier},
  title     = {Speech recognition, automatic: {History}},
  year      = {2006},
  address   = {Oxford},
  edition   = {Second Edition},
  editor    = {Keith Brown},
  isbn      = {978-0-08-044854-1},
  pages     = {806--819},
  abstract  = {Designing a machine that mimics human behavior, particularly the capability of speaking naturally and responding properly to spoken language, has intrigued engineers and scientists for centuries. Since the 1930s, when Homer Dudley of Bell Laboratories proposed a system model for speech analysis and synthesis (Dudley, 1939; Dudley et al., 1939), the problem of automatic speech recognition has been approached progressively, from a simple machine that responds to a small set of sounds to a sophisticated system that responds to fluently spoken natural language. Based on major advances in statistical modeling of speech in the 1980s, automatic speech recognition systems today find widespread application in tasks that require a human-machine interface. Examples are automatic call processing in the telephone network and query-based information systems that provide updated travel information, stock price quotations, weather reports, etc. In this article we review some major highlights in the research and development of automatic speech recognition during the last few decades to provide a technological perspective and an appreciation of the fundamental progress that has been made in this important area of information and communication technology.},
  doi       = {10.1016/B0-08-044854-2/00906-8},
  file      = {:FILES/2006 - Juang2006 - Speech recognition, automatic- {History}.pdf:PDF},
  groups    = {ASR},
  keywords  = {acoustic modeling, automatic transcription, dialog systems, finite state network, hidden Markov models, keyword spotting, language modeling, neural networks, office automation, pattern recognition, spectral analysis, Speech recognition, speech understanding, statistical modeling, time normalization},
  url       = {https://www.sciencedirect.com/science/article/pii/B0080448542009068},
}

@Article{Huang2014b,
  author    = {Huang, Xuedong and Baker, James and Reddy, Raj},
  journal   = {Communications of the ACM},
  title     = {A historical perspective of speech recognition},
  year      = {2014},
  issn      = {0001-0782},
  month     = jan,
  number    = {1},
  pages     = {94--103},
  volume    = {57},
  abstract  = {With the introduction of Apple's Siri and similar voice search services from Google and Microsoft, it is natural to wonder why it has taken so long for voice recognition technology to advance to this level. Also, we wonder, when can we expect to hear a more human-level performance? In 1976, one of the authors (Reddy) wrote a comprehensive review of the state of the art of voice recognition at that time. A non-expert in the field may benefit from reading the original article.34 Here, we provide our collective historical perspective on the advances in the field of speech recognition. Given the space limitations, this article will not attempt a comprehensive technical review, but limit the scope to discussing the missing science of speech recognition 40 years ago and what advances seem to have contributed to overcoming some of the most thorny problems.},
  address   = {New York, NY, USA},
  doi       = {10.1145/2500887},
  file      = {:FILES/2014 - Huang2014b - A historical perspective of speech recognition.pdf:PDF},
  groups    = {ASR},
  publisher = {Association for Computing Machinery},
  url       = {https://dl.acm.org/doi/10.1145/2500887},
}

@Article{Hochreiter1997,
  author   = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  journal  = {Neural Computation},
  title    = {Long short-term memory},
  year     = {1997},
  issn     = {0899-7667},
  month    = nov,
  number   = {8},
  pages    = {1735--1780},
  volume   = {9},
  abstract = {{Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.}},
  doi      = {10.1162/neco.1997.9.8.1735},
  file     = {:FILES/1997 - Hochreiter1997 - Long short-term memory.pdf:PDF},
  groups   = {ASR, structure},
  url      = {https://direct.mit.edu/neco/article/9/8/1735/6109/Long-Short-Term-Memory},
}

@Article{Schmidhuber2015,
  author   = {J\"{u}rgen Schmidhuber},
  journal  = {Neural Networks},
  title    = {Deep learning in neural networks: {An} overview},
  year     = {2015},
  issn     = {0893-6080},
  month    = jan,
  pages    = {85--117},
  volume   = {61},
  abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
  doi      = {10.1016/j.neunet.2014.09.003},
  file     = {:FILES/2015 - Schmidhuber2015 - Deep learning in neural networks- {An} overview.pdf:PDF},
  groups   = {ASR, Neural Network, machine learning},
  keywords = {Deep learning, Supervised learning, Unsupervised learning, Reinforcement learning, Evolutionary computation},
  url      = {https://www.sciencedirect.com/science/article/pii/S0893608014002135},
}

@InProceedings{Fernandez2007,
  author    = {Fern{\'a}ndez, Santiago and Graves, Alex and Schmidhuber, J{\"u}rgen},
  booktitle = {Artificial Neural Networks -- ICANN 2007},
  title     = {An application of recurrent neural networks to discriminative keyword spotting},
  year      = {2007},
  address   = {Berlin, Heidelberg},
  editor    = {de S{\'a}, Joaquim Marques and Alexandre, Lu{\'i}s A. and Duch, W{\l}odzis{\l}aw and Mandic, Danilo},
  pages     = {220--229},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {The goal of keyword spotting is to detect the presence of specific spoken words in unconstrained speech. The majority of keyword spotting systems are based on generative hidden Markov models and lack discriminative capabilities. However, discriminative keyword spotting systems are currently based on frame-level posterior probabilities of sub-word units. This paper presents a discriminative keyword spotting system based on recurrent neural networks only, that uses information from long time spans to estimate word-level posterior probabilities. In a keyword spotting task on a large database of unconstrained speech the system achieved a keyword spotting accuracy of 84.5{\\%}.},
  doi       = {10.1007/978-3-540-74695-9_23},
  file      = {:FILES/2007 - Fernandez2007 - An application of recurrent neural networks to discriminative keyword spotting.pdf:PDF},
  groups    = {ASR},
  isbn      = {978-3-540-74695-9},
  url       = {https://link.springer.com/chapter/10.1007/978-3-540-74695-9_23},
}

@Article{Perico2021,
  author     = {D. H. Perico and P. E. Santos and R. A. C. Bianchi},
  journal    = {Spatial Cognition \& Computation},
  title      = {Guided navigation from multiple viewpoints using qualitative spatial reasoning},
  year       = {2021},
  number     = {2},
  pages      = {143--172},
  volume     = {21},
  abstract   = {Navigation is an essential ability for mobile agents to be completely autonomous and able to perform complex actions. However, the problem of navigation for agents with limited (or no) perception of the world, or devoid of a fully defined motion model, has received little attention from research in AI and Robotics. One way to tackle this problem is to use guided navigation, in which other autonomous agents, endowed with perception, can combine their distinct viewpoints to infer the localization and the appropriate commands to guide a sensory deprived agent through a particular path. Due to the limited knowledge about the physical and perceptual characteristics of the guided agent, this task should be conducted on a level of abstraction allowing the use of a generic motion model, and high-level commands, that can be applied by any type of autonomous agents, including humans. The main task considered in this work is, given a group of autonomous agents perceiving their common environment with their independent, egocentric and local vision sensors, the development and evaluation of algorithms capable of producing a set of high-level commands (involving qualitative directions: e.g. move left, go straight ahead) capable of guiding a sensory deprived robot to a goal location. In order to accomplish this, the present paper assumes relations from the qualitative spatial reasoning formalism called StarVars, whose inference method is also used to build a model of the domain. This paper presents two qualitative-probabilistic algorithms for guided navigation using a particle filter and qualitative spatial relations. In the first algorithm, the particle filter is run upon a qualitative representation of the domain, whereas the second algorithm transforms the numerical output of a standard particle filter into qualitative relations to guide a sensory deprived robot. The proposed methods were evaluated with experiments carried out on a 2D humanoid robot simulator. A proof of concept executing the algorithms on a group of real humanoid robots is also presented. The results obtained demonstrate the success of the guided navigation models proposed in this work.},
  comment    = {这篇文章讲的是定性分析下达给机器人的命令，在understanding的基础上加深了一步，文中有一些关于task understanding的文章引用。具体内容如下：
1. 假设环境中存在多个agent, 其中部分agent有环境感知系统，而其他agent没有，所要实现的目标是利用前者作为后者的eye，来实现后者到导航，已达到指定位置
2. 所利用的方法是particle filter，其基本思想是利用随机搜索，找到guided agent的最可行路径
3. 搜索具有随机性，是一种启发式搜索算法，本文提出了两种变种
4. 最终的决策是方向性指令，即left, right, ...},
  doi        = {10.1080/13875868.2020.1857386},
  file       = {:FILES/2021 - Perico2021 - Guided navigation from multiple viewpoints using qualitative spatial reasoning.pdf:PDF},
  groups     = {path planning},
  priority   = {prio2},
  publisher  = {Taylor \& Francis},
  readstatus = {skimmed},
  url        = {https://www.tandfonline.com/doi/full/10.1080/13875868.2020.1857386},
}

@Article{Hinton2012,
  author     = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E. and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N. and Kingsbury, Brian},
  journal    = {IEEE Signal Processing Magazine},
  title      = {Deep neural networks for acoustic modeling in speech recognition: {The} shared views of four research groups},
  year       = {2012},
  issn       = {1558-0792},
  month      = nov,
  note       = {survey paper},
  number     = {6},
  pages      = {82--97},
  volume     = {29},
  abstract   = {Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition.},
  comment    = {文献总结未写},
  doi        = {10.1109/MSP.2012.2205597},
  file       = {:FILES/2012 - Hinton2012 - Deep neural networks for acoustic modeling in speech recognition- {The} shared views of four research groups.pdf:PDF},
  groups     = {ASR},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/6296526},
}

@InProceedings{Deng2013,
  author     = {Deng, Li and Hinton, Geoffrey and Kingsbury, Brian},
  booktitle  = {2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
  title      = {New types of deep neural network learning for speech recognition and related applications: {An} overview},
  year       = {2013},
  address    = {Vancouver, BC, Canada},
  month      = may,
  note       = {survey paper (2012-2013 after Hinton2012)},
  pages      = {8599--8603},
  publisher  = {IEEE},
  abstract   = {In this paper, we provide an overview of the invited and contributed papers presented at the special session at ICASSP-2013, entitled “New Types of Deep Neural Network Learning for Speech Recognition and Related Applications,” as organized by the authors. We also describe the historical context in which acoustic models based on deep neural networks have been developed. The technical overview of the papers presented in our special session is organized into five ways of improving deep learning methods: (1) better optimization; (2) better types of neural activation function and better network architectures; (3) better ways to determine the myriad hyper-parameters of deep neural networks; (4) more appropriate ways to preprocess speech for deep neural networks; and (5) ways of leveraging multiple languages or dialects that are more easily achieved with deep neural networks than with Gaussian mixture models.},
  doi        = {10.1109/ICASSP.2013.6639344},
  file       = {:FILES/2013 - Deng2013 - New types of deep neural network learning for speech recognition and related applications- {An} overview.pdf:PDF},
  groups     = {ASR},
  issn       = {2379-190X},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/6639344},
}

@Article{Morgan1993,
  author   = {Morgan, Nelson and Bourlard, Herv\'{e} and Renals, Steve and Cohen, Michael and Franco, Horacio},
  journal  = {International Journal of Pattern Recognition and Artificial Intelligence},
  title    = {Hybrid neural network/hidden {Markov} model systems for continuous speech recognition},
  year     = {1993},
  number   = {04},
  pages    = {899--916},
  volume   = {07},
  abstract = {MultiLayer Perceptrons (MLP) are an effective family of algorithms for the smooth estimation of highly-dimensioned probability density functions that are useful in continuous speech recognition. Hidden Markov Models (HMM) provide a structure for the mapping of a temporal sequence of acoustic vectors to a generating sequence of states. For HMMs that are independent of phonetic context, the MLP approaches have consistently provided significant improvements (once we learned how to use them). Recently, these results have been extended to context-dependent models. In this paper, after having reviewed the basic principles of our hybrid HMM/MLP approach, we describe a series of experiments with continuous speech recognition. The hybrid methods directly trade off computational complexity for reduced requirements of memory and memory bandwidth. Results are presented on the widely used Resource Management speech database that is distributed by the National Institute of Standards and Technology. These results demonstrate performance that is at least as good as any other reported continuous speech recognition system (for this task).},
  doi      = {10.1142/S0218001493000455},
  file     = {:FILES/1993 - Morgan1993 - Hybrid neural network-hidden {Markov} model systems for continuous speech recognition.pdf:PDF},
  groups   = {ASR},
  url      = {https://www.worldscientific.com/doi/abs/10.1142/S0218001493000455},
}

@InProceedings{Robinson1992,
  author    = {Robinson, Tony},
  booktitle = {1992 IEEE International Conference on Acoustics, Speech, and Signal Processing},
  title     = {A real-time recurrent error propagation network word recognition system},
  year      = {1992},
  address   = {San Francisco, CA, USA},
  month     = mar,
  pages     = {617--620},
  publisher = {IEEE},
  volume    = {1},
  abstract  = {A hybrid system using a connectionist model and a Markov model for the DARPA Resource Management task of large-vocabulary multiple-speaker continuous speech recognition is presented. The connectionist model uses internal feedback for context modeling and provides phone state occupancy probabilities for a simple context independent Markov model. The system has been implemented in real-time on a workstation supported by a DSP board. The use of context-independent phone models leads to the possibility of time-domain pruning and computationally efficient durational modeling, both of which are reported.<>},
  doi       = {10.1109/ICASSP.1992.225833},
  file      = {:FILES/1992 - Robinson1992 - A real-time recurrent error propagation network word recognition system.pdf:PDF},
  groups    = {ASR},
  issn      = {1520-6149},
  url       = {https://ieeexplore.ieee.org/document/225833},
}

@Article{Waibel1989,
  author   = {Waibel, Alexander and Hanazawa, Toshiyuki and Hinton, Geoffery and Shikano, Kiyohiro and Lang, Kevin J.},
  journal  = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  title    = {Phoneme recognition using time-delay neural networks},
  year     = {1989},
  issn     = {0096-3518},
  month    = mar,
  number   = {3},
  pages    = {328--339},
  volume   = {37},
  abstract = {The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: (1) using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation; and (2) the time-delay arrangement enables the network to discover acoustic-phonetic features and the temporal relationships between them independently of position in time and therefore not blurred by temporal shifts in the input. As a recognition task, the speaker-dependent recognition of the phonemes B, D, and G in varying phonetic contexts was chosen. For comparison, several discrete hidden Markov models (HMM) were trained to perform the same task. Performance evaluation over 1946 testing tokens from three speakers showed that the TDNN achieves a recognition rate of 98.5\% correct while the rate obtained by the best of the HMMs was only 93.7\%.<>},
  doi      = {10.1109/29.21701},
  file     = {:FILES/1989 - Waibel1989 - Phoneme recognition using time-delay neural networks.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/21701},
}

@Article{Baker2009,
  author     = {Baker, Janet M. and Deng, Li and Glass, James and Khudanpur, Sanjeev and Lee, Chin-hui and Morgan, Nelson and {O'Shaughnessy}, Douglas},
  journal    = {IEEE Signal Processing Magazine},
  title      = {Developments and directions in speech recognition and understanding, {Part} 1},
  year       = {2009},
  issn       = {1558-0792},
  month      = may,
  number     = {3},
  pages      = {75--80},
  volume     = {26},
  abstract   = {To advance research, it is important to identify promising future research directions, especially those that have not been adequately pursued or funded in the past. The working group producing this article was charged to elicit from the human language technology (HLT) community a set of well-considered directions or rich areas for future research that could lead to major paradigm shifts in the field of automatic speech recognition (ASR) and understanding. ASR has been an area of great interest and activity to the signal processing and HLT communities over the past several decades. As a first step, this group reviewed major developments in the field and the circumstances that led to their success and then focused on areas it deemed especially fertile for future research. Part 1 of this article will focus on historically significant developments in the ASR area, including several major research efforts that were guided by different funding agencies, and suggest general areas in which to focus research.},
  comment    = {这篇文章是非常笼统的描述了一下ASR中的关键技术要点，重点说明了在多个应用场景下的应用前景以及所需要面临的挑战。},
  doi        = {10.1109/MSP.2009.932166},
  file       = {:FILES/2009 - Baker2009 - Developments and directions in speech recognition and understanding, {Part} 1.pdf:PDF},
  groups     = {ASR},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/4815544},
}

@PhdThesis{Bengio1991,
  author  = {Bengio, Yoshua},
  school  = {McGill University},
  title   = {Artificial neural networks and their application to sequence recognition},
  year    = {1991},
  address = {Montr\'{e}al, Canada},
  month   = jun,
  file    = {:FILES/1991 - Bengio1991 - Artificial Neural Networks and their Application to Speech-Sequence Recognition.pdf:PDF},
  groups  = {ASR},
}

@InProceedings{Graves2014,
  author    = {Alex Graves and Navdeep Jaitly},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning},
  title     = {Towards end-to-end speech recognition with recurrent neural networks},
  year      = {2014},
  address   = {Bejing, China},
  editor    = {Eric P. Xing and Tony Jebara},
  month     = jun,
  number    = {2},
  pages     = {1764--1772},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {32},
  abstract  = {This paper presents a speech recognition system that directly transcribes audio data with text, without requiring an intermediate phonetic representation. The system is based on a combination of the deep bidirectional LSTM recurrent neural network architecture and the Connectionist Temporal Classification objective function. A modification to the objective function is introduced that trains the network to minimise the expectation of an arbitrary transcription loss function. This allows a direct optimisation of the word error rate, even in the absence of a lexicon or language model. The system achieves a word error rate of 27.3\% on the Wall Street Journal corpus with no prior linguistic information, 21.9\% with only a lexicon of allowed words, and 8.2\% with a trigram language model. Combining the network with a baseline system further reduces the error rate to 6.7\%.},
  file      = {:FILES/2014 - Graves2014 - Towards end-to-end speech recognition with recurrent neural networks.pdf:PDF},
  groups    = {ASR},
  url       = {http://proceedings.mlr.press/v32/graves14.html},
}

@Article{Deng1994,
  author   = {L. Deng and K. Hassanein and M. Elmasry},
  journal  = {Neural Networks},
  title    = {Analysis of the correlation structure for a neural predictive model with application to speech recognition},
  year     = {1994},
  issn     = {0893-6080},
  number   = {2},
  pages    = {331--339},
  volume   = {7},
  abstract = {A speech recognizer is developed using a layered feedforward neural network to implement speech-frame prediction. A Markov chain is used to control changes in the network's weight parameters. We postulate that speech recognition accuracy is closely linked to the capability of the predictive model in representing long-term temporal correlations in speech data. Analytical expressions are obtained for the correlation functions for various types of predictive models (linear, compressively nonlinear, and jointly linear and compressively nonlinear) to determine the faithfulness of the models to the actual speech data. Analytical results, computer simulations, and speech recognition experiments suggest that when compressive nonlinear prediction and linear prediction are jointly performed within the same layer of the neural network, the model is better at capturing long-term data correlations and consequently improving speech recognition performance.},
  doi      = {https://doi.org/10.1016/0893-6080(94)90027-2},
  file     = {:FILES/1994 - Deng1994 - Analysis of the correlation structure for a neural predictive model with application to speech recognition.pdf:PDF},
  groups   = {ASR},
  keywords = {Temporal correlations, Joint linear/nonlinear prediction, Multilayer perceptron, HMM},
  url      = {https://www.sciencedirect.com/science/article/pii/0893608094900272},
}

@Misc{Amodei2015,
  author        = {Dario Amodei and Rishita Anubhai and Eric Battenberg and Carl Case and Jared Casper and Bryan Catanzaro and Jingdong Chen and Mike Chrzanowski and Adam Coates and Greg Diamos and Erich Elsen and Jesse Engel and Linxi Fan and Christopher Fougner and Tony Han and Awni Hannun and Billy Jun and Patrick LeGresley and Libby Lin and Sharan Narang and Andrew Ng and Sherjil Ozair and Ryan Prenger and Jonathan Raiman and Sanjeev Satheesh and David Seetapun and Shubho Sengupta and Yi Wang and Zhiqian Wang and Chong Wang and Bo Xiao and Dani Yogatama and Jun Zhan and Zhenyao Zhu},
  title         = {Deep speech 2: {End-to-end} speech recognition in {English} and {Mandarin}},
  year          = {2015},
  archiveprefix = {arXiv},
  eprint        = {1512.02595},
  file          = {:FILES/2015 - Amodei2015 - Deep speech 2- {End-to-end} speech recognition in {English} and {Mandarin}.pdf:PDF},
  groups        = {ASR},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1512.02595},
}

@Misc{Assael2016,
  author        = {Yannis M. Assael and Brendan Shillingford and Shimon Whiteson and Nando de Freitas},
  title         = {{LipNet}: {End-to-end} sentence-level lipreading},
  year          = {2016},
  archiveprefix = {arXiv},
  eprint        = {1611.01599},
  file          = {:FILES/2016 - Assael2016 - {LipNet}- {End-to-end} sentence-level lipreading.pdf:PDF},
  groups        = {lipreading},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1611.01599v2},
}

@Misc{Shillingford2018,
  author        = {Brendan Shillingford and Yannis Assael and Matthew W. Hoffman and Thomas Paine and Cían Hughes and Utsav Prabhu and Hank Liao and Hasim Sak and Kanishka Rao and Lorrayne Bennett and Marie Mulville and Ben Coppin and Ben Laurie and Andrew Senior and Nando de Freitas},
  title         = {Large-scale visual speech recognition},
  year          = {2018},
  archiveprefix = {arXiv},
  eprint        = {1807.05162},
  file          = {:FILES/2018 - Shillingford2018 - Large-scale visual speech recognition.pdf:PDF},
  groups        = {lipreading},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1807.05162v3},
}

@InProceedings{Chan2016,
  author    = {Chan, William and Jaitly, Navdeep and Le, Quoc and Vinyals, Oriol},
  booktitle = {2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Listen, attend and spell: {A} neural network for large vocabulary conversational speech recognition},
  year      = {2016},
  address   = {Shanghai, China},
  month     = mar,
  pages     = {4960--4964},
  publisher = {IEEE},
  abstract  = {We present Listen, Attend and Spell (LAS), a neural speech recognizer that transcribes speech utterances directly to characters without pronunciation models, HMMs or other components of traditional speech recognizers. In LAS, the neural network architecture subsumes the acoustic, pronunciation and language models making it not only an end-to-end trained system but an end-to-end model. In contrast to DNN-HMM, CTC and most other models, LAS makes no independence assumptions about the probability distribution of the output character sequences given the acoustic sequence. Our system has two components: a listener and a speller. The listener is a pyramidal recurrent network encoder that accepts filter bank spectra as inputs. The speller is an attention-based recurrent network decoder that emits each character conditioned on all previous characters, and the entire acoustic sequence. On a Google voice search task, LAS achieves a WER of 14.1\% without a dictionary or an external language model and 10.3\% with language model rescoring over the top 32 beams. In comparison, the state-of-the-art CLDNN-HMM model achieves a WER of 8.0\% on the same set.},
  doi       = {10.1109/ICASSP.2016.7472621},
  file      = {:FILES/2016 - Chan2016 - Listen, attend and spell- {A} neural network for large vocabulary conversational speech recognition.pdf:PDF},
  groups    = {ASR},
  issn      = {2379-190X},
  url       = {https://ieeexplore.ieee.org/document/7472621},
}

@InProceedings{Bahdanau2016,
  author    = {Bahdanau, Dzmitry and Chorowski, Jan and Serdyuk, Dmitriy and Brakel, Philémon and Bengio, Yoshua},
  booktitle = {2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {End-to-end attention-based large vocabulary speech recognition},
  year      = {2016},
  address   = {Shanghai, China},
  month     = mar,
  pages     = {4945--4949},
  publisher = {IEEE},
  abstract  = {Many state-of-the-art Large Vocabulary Continuous Speech Recognition (LVCSR) Systems are hybrids of neural networks and Hidden Markov Models (HMMs). Recently, more direct end-to-end methods have been investigated, in which neural architectures were trained to model sequences of characters [1,2]. To our knowledge, all these approaches relied on Connectionist Temporal Classification [3] modules. We investigate an alternative method for sequence modelling based on an attention mechanism that allows a Recurrent Neural Network (RNN) to learn alignments between sequences of input frames and output labels. We show how this setup can be applied to LVCSR by integrating the decoding RNN with an n-gram language model and by speeding up its operation by constraining selections made by the attention mechanism and by reducing the source sequence lengths by pooling information over time. Recognition accuracies similar to other HMM-free RNN-based approaches are reported for the Wall Street Journal corpus.},
  doi       = {10.1109/ICASSP.2016.7472618},
  file      = {:FILES/2016 - Bahdanau2016 - End-to-end attention-based large vocabulary speech recognition.pdf:PDF},
  groups    = {ASR},
  issn      = {2379-190X},
  url       = {https://ieeexplore.ieee.org/document/7472618},
}

@InProceedings{Chung2017,
  author    = {Chung, Joon Son and Senior, Andrew and Vinyals, Oriol and Zisserman, Andrew},
  booktitle = {2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Lip reading sentences in the wild},
  year      = {2017},
  address   = {Honolulu, HI, USA},
  month     = jul,
  pages     = {3444--3453},
  publisher = {IEEE},
  abstract  = {The goal of this work is to recognise phrases and sentences being spoken by a talking face, with or without the audio. Unlike previous works that have focussed on recognising a limited number of words or phrases, we tackle lip reading as an open-world problem - unconstrained natural language sentences, and in the wild videos. Our key contributions are: (1) a `Watch, Listen, Attend and Spell' (WLAS) network that learns to transcribe videos of mouth motion to characters; (2) a curriculum learning strategy to accelerate training and to reduce overfitting; (3) a `Lip Reading Sentences' (LRS) dataset for visual speech recognition, consisting of over 100,000 natural sentences from British television. The WLAS model trained on the LRS dataset surpasses the performance of all previous work on standard lip reading benchmark datasets, often by a significant margin. This lip reading performance beats a professional lip reader on videos from BBC television, and we also demonstrate that if audio is available, then visual information helps to improve speech recognition performance.},
  doi       = {10.1109/CVPR.2017.367},
  file      = {:FILES/2017 - Chung2017 - Lip reading sentences in the wild.pdf:PDF},
  groups    = {lipreading},
  issn      = {1063-6919},
  url       = {https://ieeexplore.ieee.org/document/8099850},
}

@InProceedings{Chan2017,
  author    = {William Chan and Yu Zhang and Quoc Le and Navdeep Jaitly},
  booktitle = {Proceedings of 5th International Conference on Learning Representations (ICLR)},
  title     = {Latent sequence decompositions},
  year      = {2017},
  address   = {Toulon, France},
  month     = apr,
  pages     = {1--12},
  abstract  = {Sequence-to-sequence models rely on a fixed decomposition of the target sequences into a sequence of tokens that may be words, word-pieces or characters. The choice of these tokens and the decomposition of the target sequences into a sequence of tokens is often static, and independent of the input, output data domains. This can potentially lead to a sub-optimal choice of token dictionaries, as the decomposition is not informed by the particular problem being solved. In this paper we present Latent Sequence Decompositions (LSD), a framework in which the decomposition of sequences into constituent tokens is learnt during the training of the model. The decomposition depends both on the input sequence and on the output sequence. In LSD, during training, the model samples decompositions incrementally, from left to right by locally sampling between valid extensions. We experiment with the Wall Street Journal speech recognition task. Our LSD model achieves 12.9\% WER compared to a character baseline of 14.8\% WER. When combined with a convolutional network on the encoder, we achieve a WER of 9.6\%.},
  file      = {:FILES/2017 - Chan2017 - Latent sequence decompositions.pdf:PDF},
  groups    = {ASR},
  keywords  = {Speech, Applications, Natural language processing, Deep learning},
}

@Misc{Deng2014,
  author   = {Deng, Li},
  month    = sep,
  note     = {Keynote at Interspeech},
  title    = {Achievements and challenges of deep learning - {From} speech analysis and recognition to language and multimodal processing},
  year     = {2014},
  abstract = {Artificial neural networks have been around for over half a century and their applications to speech processing have been almost as long, yet it was not until year 2010 that their real impact had been made by a deep form of such networks, built upon part of the earlier work on (shallow) neural nets and (deep) graphical models developed by both speech and machine learning communities. This keynote will first reflect on the path to this transformative success, sparked by speech analysis using deep learning methods on spectrogram-like raw features and then progressing rapidly to speech recognition with increasingly larger vocabularies and scale. The role of well-timed academic-industrial collaboration will be highlighted, so will be the advances of big data, big compute, and the seamless integration between the application-domain knowledge of speech and general principles of deep learning. Then, an overview will be given on sweeping achievements of deep learning in speech recognition since its initial success in 2010 (as well as in image recognition and computer vision since 2012). Such achievements have resulted in across-the-board, industry-wide deployment of deep learning. The final part of the talk will look ahead towards stimulating new challenges of deep learning --- making intelligent machines capable of not only hearing (speech) and seeing (vision), but also of thinking with a “mind”; i.e. reasoning and inference over complex, hierarchical relationships and knowledge sources that comprise a vast number of entities and semantic concepts in the real world based in part on multi-sensory data from the user. To this end, language and multimodal processing --- joint exploitation and learning from text, speech/audio, and image/video --- is evolving into a new frontier of deep learning, beginning to be embraced by a mixture of research communities including speech and spoken language processing, natural language processing, computer vision, machine learning, information retrieval, cognitive science, artificial intelligence, and data/knowledge management. A review of recent published studies will be provided on deep learning applied to selected language and multimodal processing tasks, with a trace back to the relevant early connectionist modeling and neural network literature and with future directions in this new exciting deep learning frontier discussed and analyzed.},
  groups   = {ASR},
  url      = {https://www.superlectures.com/interspeech2014/achievements-and-challenges-of-deep-learning-from-speech-analysis-and-recognition-to-language-and-multimodal-processing},
}

@Book{Bourlard1994,
  author    = {Herv\'{e} A. Bourlard and Nelson Morgan},
  publisher = {Springer},
  title     = {Connectionist speech recognition: {A} hybrid approach},
  year      = {1994},
  isbn      = {978-1-4613-6409-2},
  series    = {The Springer International Series in Engineering and Computer Science},
  abstract  = {Connectionist Speech Recognition: A Hybrid Approach describes the theory and implementation of a method to incorporate neural network approaches into state of the art continuous speech recognition systems based on hidden Markov models (HMMs) to improve their performance. In this framework, neural networks (and in particular, multilayer perceptrons or MLPs) have been restricted to well-defined subtasks of the whole system, i.e. HMM emission probability estimation and feature extraction.
The book describes a successful five-year international collaboration between the authors. The lessons learned form a case study that demonstrates how hybrid systems can be developed to combine neural networks with more traditional statistical approaches. The book illustrates both the advantages and limitations of neural networks in the framework of a statistical systems.
Using standard databases and comparison with some conventional approaches, it is shown that MLP probability estimation can improve recognition performance. Other approaches are discussed, though there is no such unequivocal experimental result for these methods.
Connectionist Speech Recognition is of use to anyone intending to use neural networks for speech recognition or within the framework provided by an existing successful statistical approach. This includes research and development groups working in the field of speech recognition, both with standard and neural network approaches, as well as other pattern recognition and/or neural network researchers. The book is also suitable as a text for advanced courses on neural networks or speech processing.},
  comment   = {from cite{Hinton2012}: using artificial 
neural networks with a single layer of nonlinear hidden units 
to predict HMM states from windows of acoustic coefficients},
  doi       = {10.1007/978-1-4615-3210-1},
  file      = {:FILES/1994 - Bourlard1994 - Connectionist speech recognition- {A} hybrid approach.pdf:PDF},
  groups    = {ASR},
  url       = {https://link.springer.com/book/10.1007/978-1-4615-3210-1},
}

@Article{纪2020,
  author  = {纪, 守领 and 杜, 天宇 and 邓, 水光 and 程, 鹏 and 时, 杰 and 杨, 珉 and 李, 博},
  journal = {计算机学报},
  title   = {深度学习模型鲁棒性研究综述},
  year    = {2020},
  file    = {:FILES/2020 - 纪2020 - 深度学习模型鲁棒性研究综述.pdf:PDF},
  groups  = {robustness},
}

@Article{Li2020b,
  author     = {Li, Ruizhi and Wang, Xiaofei and Mallidi, Sri Harish and Watanabe, Shinji and Hori, Takaaki and Hermansky, Hynek},
  journal    = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title      = {Multi-stream end-to-end speech recognition},
  year       = {2020},
  issn       = {2329-9304},
  pages      = {646--655},
  volume     = {28},
  abstract   = {Attention-based methods and Connectionist Temporal Classification (CTC) network have been promising research directions for end-to-end (E2E) Automatic Speech Recognition (ASR). The joint CTC/Attention model has achieved great success by utilizing both architectures during multi-task training and joint decoding. In this article, we present a multi-stream framework based on joint CTC/Attention E2E ASR with parallel streams represented by separate encoders aiming to capture diverse information. On top of the regular attention networks, the Hierarchical Attention Network (HAN) is introduced to steer the decoder toward the most informative encoders. A separate CTC network is assigned to each stream to force monotonic alignments. Two representative framework have been proposed and discussed, which are Multi-Encoder Multi-Resolution (MEM-Res) framework and Multi-Encoder Multi-Array (MEM-Array) framework, respectively. In MEM-Res framework, two heterogeneous encoders with different architectures, temporal resolutions and separate CTC networks work in parallel to extract complementary information from same acoustics. Experiments are conducted on Wall Street Journal (WSJ) and CHiME-4, resulting in relative Word Error Rate (WER) reduction of 18.0-32.1\% and the best WER of 3.6\% in the WSJ eval92 test set. The MEM-Array framework aims at improving the far-field ASR robustness using multiple microphone arrays which are activated by separate encoders. Compared with the best single-array results, the proposed framework has achieved relative WER reduction of 3.7\% and 9.7\% in AMI and DIRHA multi-array corpora, respectively, which also outperforms conventional fusion strategies.},
  doi        = {10.1109/TASLP.2019.2959721},
  file       = {:FILES/2020 - Li2020b - Multi-stream end-to-end speech recognition.pdf:PDF},
  groups     = {ASR},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/document/8932598},
}

@Article{Juang1991,
  author    = {{Biing-Hwang} Juang and Lawrence R. Rabiner},
  journal   = {Technometrics},
  title     = {Hidden {Markov} models for speech recognition},
  year      = {1991},
  number    = {3},
  pages     = {251--272},
  volume    = {33},
  abstract  = {The use of hidden Markov models for speech recognition has become predominant in the last several years, as evidenced by the number of published papers and talks at major speech conferences. The reasons this method has become so popular are the inherent statistical (mathematically precise) framework; the ease and availability of training algorithms for cstimating the parameters of the models from finite training sets of speech data; the flexibility of the resulting recognition system in which one can easily change the size, type, or architecture of the models to suit particular words, sounds, and so forth; and the ease of implementation of the overall recognition system. In this expository article, we address the role of statistical methods in this powerful technology as applied to speech recognition and discuss a range of theoretical and practical issues that are as yet unsolved in terms of their importance and their effect on performance for different system implementations.},
  doi       = {10.1080/00401706.1991.10484833},
  file      = {:FILES/1991 - Juang1991 - Hidden {Markov} models for speech recognition.pdf:PDF},
  groups    = {ASR},
  publisher = {Taylor \& Francis},
  url       = {https://www.tandfonline.com/doi/abs/10.1080/00401706.1991.10484833},
}

@Article{Shneiderman2000,
  author    = {Shneiderman, Ben},
  journal   = {Communications of the ACM},
  title     = {The limits of speech recognition},
  year      = {2000},
  issn      = {0001-0782},
  month     = sep,
  number    = {9},
  pages     = {63-–65},
  volume    = {43},
  doi       = {10.1145/348941.348990},
  file      = {:FILES/2000 - Shneiderman2000 - The limits of speech recognition.pdf:PDF},
  groups    = {ASR},
  publisher = {Association for Computing Machinery},
  url       = {https://dl.acm.org/doi/10.1145/348941.348990},
}

@InProceedings{Caglayan2019,
  author    = {Caglayan, Ozan and Sanabria, Ramon and Palaskar, Shruti and Barraul, Lo\"{i}c and Metze, Florian},
  booktitle = {2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Multimodal grounding for sequence-to-sequence speech recognition},
  year      = {2019},
  address   = {Brighton, UK},
  month     = may,
  pages     = {8648--8652},
  publisher = {IEEE},
  abstract  = {Humans are capable of processing speech by making use of multiple sensory modalities. For example, the environment where a conversation takes place generally provides semantic and/or acoustic context that helps us to resolve ambiguities or to recall named entities. Motivated by this, there have been many works studying the integration of visual information into the speech recognition pipeline. Specifically, in our previous work, we propose a multistep visual adaptive training approach which improves the accuracy of an audio-based Automatic Speech Recognition (ASR) system. This approach, however, is not end-to-end as it requires fine-tuning the whole model with an adaptation layer. In this paper, we propose novel end-to-end multimodal ASR systems and compare them to the adaptive approach by using a range of visual representations obtained from state-of-the-art convolutional neural networks. We show that adaptive training is effective for S2S models leading to an absolute improvement of 1.4\% in word error rate. As for the end-to-end systems, although they perform better than baseline, the improvements are slightly less than adaptive training, 0.8 absolute WER reduction in single-best models. Using ensemble decoding, end-to-end models reach a WER of 15\% which is the lowest score among all systems.},
  doi       = {10.1109/ICASSP.2019.8682750},
  file      = {:FILES/2019 - Caglayan2019 - Multimodal grounding for sequence-to-sequence speech recognition.pdf:PDF},
  groups    = {multi-modal},
  issn      = {2379-190X},
  url       = {https://ieeexplore.ieee.org/document/8682750},
}

@Book{Benesty2008,
  author    = {Jacob Benesty and M. Mohan Sondhi and Yiteng Huang},
  publisher = {Springer-Verlag Berlin Heidelberg},
  title     = {Springer handbook of speech recognition},
  year      = {2008},
  isbn      = {978-3-540-49125-5},
  file      = {:FILES/2008 - Benesty2008 - Springer handbook of speech recognition.pdf:PDF},
  groups    = {ASR},
}

@InProceedings{Graves2006,
  author    = {Graves, Alex and Fern\'{a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J\"{u}rgen},
  booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
  title     = {Connectionist temporal classification: {Labelling} unsegmented sequence data with recurrent neural networks},
  year      = {2006},
  address   = {New York, NY, USA},
  pages     = {369--376},
  publisher = {Association for Computing Machinery},
  series    = {ICML '06},
  abstract  = {Many real-world sequence learning tasks require the prediction of sequences of labels from noisy, unsegmented input data. In speech recognition, for example, an acoustic signal is transcribed into words or sub-word units. Recurrent neural networks (RNNs) are powerful sequence learners that would seem well suited to such tasks. However, because they require pre-segmented training data, and post-processing to transform their outputs into label sequences, their applicability has so far been limited. This paper presents a novel method for training RNNs to label unsegmented sequences directly, thereby solving both problems. An experiment on the TIMIT speech corpus demonstrates its advantages over both a baseline HMM and a hybrid HMM-RNN.},
  doi       = {10.1145/1143844.1143891},
  file      = {:FILES/2006 - Graves2006 - Connectionist temporal classification- {Labelling} unsegmented sequence data with recurrent neural networks.pdf:PDF},
  groups    = {ASR},
  isbn      = {1595933832},
  location  = {Pittsburgh, Pennsylvania, USA},
  url       = {https://dl.acm.org/doi/10.1145/1143844.1143891},
}

@InProceedings{Chorowski2015,
  author    = {Chorowski, Jan K. and Bahdanau, Dzmitry and Serdyuk, Dmitriy and Cho, Kyunghyun and Bengio, Yoshua},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Attention-based models for speech recognition},
  year      = {2015},
  editor    = {C. Cortes and N. Lawrence and D. Lee and M. Sugiyama and R. Garnett},
  pages     = {1--9},
  publisher = {Curran Associates, Inc.},
  volume    = {28},
  file      = {:FILES/2015 - Chorowski2015 - Attention-based models for speech recognition.pdf:PDF},
  groups    = {ASR},
  url       = {https://proceedings.neurips.cc/paper/2015/file/1068c6e4c8051cfd4e9ea8072e3189e2-Paper.pdf},
}

@InProceedings{Graves2012,
  author    = {Alex Graves},
  booktitle = {Proceedings of the International Conference of Machine Learning (ICML) 2012 Workshop on Representation Learning},
  title     = {Sequence transduction with recurrent neural networks},
  year      = {2012},
  address   = {Edinburgh, Scotland, UK},
  month     = jul,
  pages     = {1--8},
  publisher = {International Machine Learning Society},
  file      = {:FILES/2012 - Graves2012 - Sequence transduction with recurrent neural networks.pdf:PDF},
  groups    = {ASR},
}

@InProceedings{Graves2013,
  author    = {Graves, Alex and Mohamed, Abdel-rahman and Hinton, Geoffrey},
  booktitle = {2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
  title     = {Speech recognition with deep recurrent neural networks},
  year      = {2013},
  address   = {Vancouver, BC, Canada},
  month     = may,
  pages     = {6645--6649},
  publisher = {IEEE},
  abstract  = {Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7\% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score.},
  doi       = {10.1109/ICASSP.2013.6638947},
  file      = {:FILES/2013 - Graves2013 - Speech recognition with deep recurrent neural networks.pdf:PDF},
  groups    = {ASR},
  issn      = {2379-190X},
  url       = {https://ieeexplore.ieee.org/document/6638947},
}

@InProceedings{Luong2015,
  author    = {Luong, Thang and Pham, Hieu and Manning, Christopher D.},
  booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  title     = {Effective approaches to attention-based neural machine translation},
  year      = {2015},
  address   = {Lisbon, Portugal},
  month     = sep,
  pages     = {1412--1421},
  publisher = {Association for Computational Linguistics},
  comment   = {to improve the monotonic property of attention based ASR method.},
  doi       = {10.18653/v1/D15-1166},
  file      = {:FILES/2015 - Luong2015 - Effective approaches to attention-based neural machine translation.pdf:PDF},
  groups    = {ASR},
  url       = {https://www.aclweb.org/anthology/D15-1166},
}

@InProceedings{Chiu2017,
  author    = {Chiu, Chung-Cheng and Raffel, Colin},
  booktitle = {Proceedings of the 6th International Conference on Learning Representations (ICLR)},
  title     = {Monotonic chunkwise attention},
  year      = {2017},
  address   = {Vancouver, BC, Canada},
  month     = dec,
  pages     = {1--16},
  file      = {:FILES/2017 - Chiu2017 - Monotonic chunkwise attention.pdf:PDF},
  groups    = {ASR},
  url       = {https://iclr.cc/Conferences/2018/Schedule?showEvent=211},
}

@InProceedings{Kim2017,
  author    = {Kim, Suyoun and Hori, Takaaki and Watanabe, Shinji},
  booktitle = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Joint {CTC-attention} based end-to-end speech recognition using multi-task learning},
  year      = {2017},
  address   = {New Orleans, LA, USA},
  month     = mar,
  pages     = {4835--4839},
  publisher = {IEEE},
  abstract  = {Recently, there has been an increasing interest in end-to-end speech recognition that directly transcribes speech to text without any predefined alignments. One approach is the attention-based encoder-decoder framework that learns a mapping between variable-length input and output sequences in one step using a purely data-driven method. The attention model has often been shown to improve the performance over another end-to-end approach, the Connectionist Temporal Classification (CTC), mainly because it explicitly uses the history of the target character without any conditional independence assumptions. However, we observed that the performance of the attention has shown poor results in noisy condition and is hard to learn in the initial training stage with long input sequences. This is because the attention model is too flexible to predict proper alignments in such cases due to the lack of left-to-right constraints as used in CTC. This paper presents a novel method for end-to-end speech recognition to improve robustness and achieve fast convergence by using a joint CTC-attention model within the multi-task learning framework, thereby mitigating the alignment issue. An experiment on the WSJ and CHiME-4 tasks demonstrates its advantages over both the CTC and attention-based encoder-decoder baselines, showing 5.4-14.6\% relative improvements in Character Error Rate (CER).},
  doi       = {10.1109/ICASSP.2017.7953075},
  groups    = {ASR},
  issn      = {2379-190X},
  url       = {https://ieeexplore.ieee.org/document/7953075},
}

@Article{Watanabe2017,
  author   = {Watanabe, Shinji and Hori, Takaaki and Kim, Suyoun and Hershey, John R. and Hayashi, Tomoki},
  journal  = {IEEE Journal of Selected Topics in Signal Processing},
  title    = {Hybrid {CTC/attention} architecture for end-to-end speech recognition},
  year     = {2017},
  issn     = {1941-0484},
  month    = dec,
  number   = {8},
  pages    = {1240--1253},
  volume   = {11},
  abstract = {Conventional automatic speech recognition (ASR) based on a hidden Markov model (HMM)/deep neural network (DNN) is a very complicated system consisting of various modules such as acoustic, lexicon, and language models. It also requires linguistic resources, such as a pronunciation dictionary, tokenization, and phonetic context-dependency trees. On the other hand, end-to-end ASR has become a popular alternative to greatly simplify the model-building process of conventional ASR systems by representing complicated modules with a single deep network architecture, and by replacing the use of linguistic resources with a data-driven learning method. There are two major types of end-to-end architectures for ASR; attention-based methods use an attention mechanism to perform alignment between acoustic frames and recognized symbols, and connectionist temporal classification (CTC) uses Markov assumptions to efficiently solve sequential problems by dynamic programming. This paper proposes hybrid CTC/attention end-to-end ASR, which effectively utilizes the advantages of both architectures in training and decoding. During training, we employ the multiobjective learning framework to improve robustness and achieve fast convergence. During decoding, we perform joint decoding by combining both attention-based and CTC scores in a one-pass beam search algorithm to further eliminate irregular alignments. Experiments with English (WSJ and CHiME-4) tasks demonstrate the effectiveness of the proposed multiobjective learning over both the CTC and attention-based encoder-decoder baselines. Moreover, the proposed method is applied to two large-scale ASR benchmarks (spontaneous Japanese and Mandarin Chinese), and exhibits performance that is comparable to conventional DNN/HMM ASR systems based on the advantages of both multiobjective learning and joint decoding without linguistic resources.},
  doi      = {10.1109/JSTSP.2017.2763455},
  file     = {:FILES/2017 - Watanabe2017 - Hybrid {CTC-attention} architecture for end-to-end speech recognition.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/8068205},
}

@InProceedings{Hori2017,
  author    = {Takaaki Hori and Shinji Watanabe and Yu Zhang and William Chan},
  booktitle = {Proceedings of INTERSPEECH 2017},
  title     = {Advances in joint {CTC-attention} based end-to-end speech recognition with a deep {CNN} encoder and {RNN-LM}},
  year      = {2017},
  address   = {Stockholm, Sweden},
  month     = aug,
  pages     = {949--953},
  publisher = {ISCA},
  doi       = {10.21437/Interspeech.2017-1296},
  file      = {:FILES/2017 - Hori2017 - Advances in joint {CTC-attention} based end-to-end speech recognition with a deep {CNN} encoder and {RNN-LM}.pdf:PDF},
  groups    = {ASR},
  url       = {https://m.isca-speech.org/archive/Interspeech_2017/abstracts/1296.html},
}

@Article{Chuang2021,
  author     = {Chuang, {Shun-Po} and Liu, Alexander H. and Sung, {Tzu-Wei} and Lee, Hung-yi},
  journal    = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title      = {Improving automatic speech recognition and speech translation via word embedding prediction},
  year       = {2021},
  issn       = {2329-9304},
  pages      = {93--105},
  volume     = {29},
  abstract   = {In this article, we target speech translation (ST). We propose lightweight approaches that generally improve either ASR or end-to-end ST models. We leverage continuous representations of words, known as word embeddings, to improve ASR in cascaded systems as well as end-to-end ST models. The benefit of using word embedding is that word embedding can be obtained easily by training on pure textual data, which alleviates data scarcity issue. Also, word embedding provides additional contextual information to speech models. We motivate to distill the knowledge from word embedding into speech models. In ASR, we use word embeddings as a regularizer to reduce the WER, and further propose a novel decoding method to fuse the semantic relations among words for further improvement. In the end-to-end ST model, we propose leveraging word embeddings as an intermediate representation to enhance translation performance. Our analysis shows that it is possible to map speech signals to semantic space, which motivates future work on applying the proposed methods in spoken language processing tasks.},
  comment    = {将semantic word embedding 引入ASR和speech translation两个领域，以增强语义信息，并降低对large dataset的依赖。},
  doi        = {10.1109/TASLP.2020.3037543},
  file       = {:FILES/2021 - Chuang2021 - Improving automatic speech recognition and speech translation via word embedding prediction.pdf:PDF},
  groups     = {ASR},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/document/9257188},
}

@Article{Chai2021,
  author     = {Chai, Li and Du, Jun and Liu, Qing-Feng and Lee, Chin-Hui},
  journal    = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title      = {A cross-entropy-guided measure {(CEGM)} for assessing speech recognition performance and optimizing {DNN-based} speech enhancement},
  year       = {2021},
  issn       = {2329-9304},
  pages      = {106--117},
  volume     = {29},
  abstract   = {A new cross-entropy-guided measure (CEGM) is proposed to indirectly assess accuracies of automatic speech recognition (ASR) of degraded speech with a speech enhancement front-end and without directly performing ASR experiments. The proposed CEGM is calculated in three steps, namely: (1) a low-level representations via feature extraction, (2) a high-level nonlinear mapping using an acoustic model, and (3) a final CEGM calculation between the high-level representations of clean and enhanced speech. Specifically, state posterior probabilities from outputs of conventional hybrid acoustic model of the target ASR system are adopted as the high-level representations and a cross-entropy criterion is used to calculate the CEGM. Due to CEGM's differentiability, it can also be used to replace the conventional minimum mean squared error (MMSE) criterion as an objective function for deep neural network (DNN)-based speech enhancement. Therefore, the front-end enhancement model can be optimized towards improving the accuracies of the back-end ASR system. Experiments on single-channel CHiME-4 Challenge show that CEGM yields consistently the highest correlations with word error rate (WER) which is often costly to calculate, and achieves the most accurate assessment of ASR performance when compared to the perceptual evaluation metrics commonly used for assessing speech enhancement performance. Furthermore, CEGM-optimized speech enhancement could effectively reduce the WER on the CHiME-4 real test set when compared to unprocessed noisy speech and enhanced speech obtained with MMSE-optimized enhancement for ASR systems with fixed multi-condition acoustic models in various deep architectures.},
  comment    = {关于 robust SR提出一种优化目标.},
  doi        = {10.1109/TASLP.2020.3036783},
  file       = {:FILES/2021 - Chai2021 - A Cross-Entropy-Guided Measure (CEGM) for Assessing Speech Recognition Performance and Optimizing DNN-Based Speech Enhancement.pdf:PDF},
  groups     = {speech enhancement},
  owner      = {National Taiwan University},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/document/9258383},
}

@Article{Fan2021,
  author     = {Fan, Cunhang and Yi, Jiangyan and Tao, Jianhua and Tian, Zhengkun and Liu, Bin and Wen, Zhengqi},
  journal    = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title      = {Gated recurrent fusion with joint training framework for robust end-to-end speech recognition},
  year       = {2021},
  issn       = {2329-9304},
  pages      = {198--209},
  volume     = {29},
  abstract   = {The joint training framework for speech enhancement and recognition methods have obtained quite good performances for robust end-to-end automatic speech recognition (ASR). However, these methods only utilize the enhanced feature as the input of the speech recognition component, which are affected by the speech distortion problem. In order to address this problem, this paper proposes a gated recurrent fusion (GRF) method with joint training framework for robust end-to-end ASR. The GRF algorithm is used to dynamically combine the noisy and enhanced features. Therefore, the GRF can not only remove the noise signals from the enhanced features, but also learn the raw fine structures from the noisy features so that it can alleviate the speech distortion. The proposed method consists of speech enhancement, GRF and speech recognition. Firstly, the mask based speech enhancement network is applied to enhance the input speech. Secondly, the GRF is applied to address the speech distortion problem. Thirdly, to improve the performance of ASR, the state-of-the-art speech transformer algorithm is used as the speech recognition component. Finally, the joint training framework is utilized to optimize these three components, simultaneously. Our experiments are conducted on an open-source Mandarin speech corpus called AISHELL-1. Experimental results show that the proposed method achieves the relative character error rate (CER) reduction of 10.04\% over the conventional joint enhancement and transformer method only using the enhanced features. Especially for the low signal-to-noise ratio (0 dB), our proposed method can achieves better performances with 12.67\% CER reduction, which suggests the potential of our proposed method.},
  comment    = {本文也是讨论speech enhancement,其中framework包含三部分，1. 用mask based speech enhancement network来增强input speech，2. 提出新的gated recurrent fusion (CRF) model 来解决speech distortion problem，3. 利用现有的speech transformer algorithm来speech recognition。},
  doi        = {10.1109/TASLP.2020.3039600},
  file       = {:FILES/2021 - Fan2021 - Gated Recurrent Fusion With Joint Training Framework for Robust End-to-End Speech Recognition.pdf:PDF},
  groups     = {speech enhancement},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/document/9265262},
}

@Article{Cho2021,
  author   = {Cho, Byung Joon and Park, Hyung-Min},
  journal  = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title    = {Convolutional maximum-likelihood distortionless response beamforming with steering vector estimation for robust speech recognition},
  year     = {2021},
  issn     = {2329-9304},
  pages    = {1352--1367},
  volume   = {29},
  abstract = {Beamforming has been one of the most successful approaches using multi-microphones for robust speech recognition. Although a beamforming method, called the “maximum-likelihood distortionless response (MLDR)” beamformer, was recently presented to achieve promising performance, it requires an accurate steering vector for a target speaker in advance like many kinds of beamformers. In this paper, we present a method for steering vector estimation (SVE) by replacing the noise spatial covariance matrix estimate with a normalized version of the variance-weighted spatial covariance matrix estimate for the observed noisy speech signal obtained by the iterative update rule in the MLDR beamforming framework. In addition, an MLDR beamforming method without a steering vector for a target speaker given in advance is presented where the SVE and the beamforming are alternately repeated. Furthermore, an online algorithm based on recursive least squares (RLS) is derived to cope with various practical applications including time-varying situations, and the power method is introduced for further efficient online processing. We also present batch and online convolutional MLDR beamforming with SVE for simultaneous beamforming and dereverberation where the weighted prediction error (WPE) dereverberation and the MLDR beamforming with the SVE were jointly optimized based on the maximum-likelihood estimation (MLE) for a zero-mean complex Gaussian signal with time-varying variances. Moreover, input signals masked by a neural network (NN) for estimating target speech or noise components can be used to further improve the presented beamformers. Experimental results on the CHiME-4 and REVERB challenge datasets demonstrate the effectiveness of the presented methods.},
  comment  = {本文讲的是beamforming的降低复杂度的算法,应该是对模型参数进行修正,从而实现robust SR in noisy environment.},
  doi      = {10.1109/TASLP.2021.3067202},
  file     = {:FILES/2021 - Cho2021 - Convolutional Maximum-Likelihood Distortionless Response Beamforming With Steering Vector Estimation for Robust Speech Recognition.pdf:PDF},
  groups   = {speech enhancement},
  url      = {https://ieeexplore.ieee.org/document/9381713},
}

@Article{Hu2021,
  author     = {Hu, Shoukang and Xie, Xurong and Liu, Shansong and Yu, Jianwei and Ye, Zi and Geng, Mengzhe and Liu, Xunying and Meng, Helen},
  journal    = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title      = {{Bayesian} learning of {LF-MMI} trained time delay neural networks for speech recognition},
  year       = {2021},
  issn       = {2329-9304},
  pages      = {1514--1529},
  volume     = {29},
  abstract   = {Discriminative training techniques define state-of-the-art performance for automatic speech recognition systems. However, they are inherently prone to overfitting, leading to poor generalization performance when using limited training data. In order to address this issue, this paper presents a full Bayesian framework to account for model uncertainty in sequence discriminative training of factored TDNN acoustic models. Several Bayesian learning based TDNN variant systems are proposed to model the uncertainty over weight parameters and choices of hidden activation functions, or the hidden layer outputs. Efficient variational inference approaches using as few as one single parameter sample ensure their computational cost in both training and evaluation time comparable to that of the baseline TDNN systems. Statistically significant word error rate (WER) reductions of 0.4\%–1.8\% absolute (5\%-11\% relative) were obtained over a state-of-the-art 900 h speed perturbed Switchboard corpus trained baseline LF-MMI factored TDNN system using multiple regularization methods including F-smoothing, L2 norm penalty, natural gradient, model averaging and dropout, in addition to i-Vector plus learning hidden unit contribution (LHUC) based speaker adaptation and RNNLM rescoring. The efficacy of the proposed Bayesian techniques is further demonstrated in a comparison against the state-of-the-art performance obtained on the same task using the most recent hybrid and end-to-end systems reported in the literature. Consistent performance improvements were also obtained on a 450-h HKUST conversational Mandarin telephone speech recognition task. On a third cross domain adaptation task requiring rapidly porting a 1000-h LibriSpeech data trained system to a small DementiaBank elderly speech corpus, the proposed Bayesian TDNN LF-MMI systems outperformed the baseline system using direct weight fine-tuning by up to 2.5\% absolute WER reduction.},
  comment    = {本文讨论了基于TDNN的ASR系统,提出了多种模型,以实现对model uncertainty和网络参数配置的应对,如activation function的选择, weight parameter, size of training data等.并说明了算法复杂度并未提升.},
  doi        = {10.1109/TASLP.2021.3069080},
  file       = {:FILES/2021 - Hu2021 - {Bayesian} learning of {LF-MMI} trained time delay neural networks for speech recognition.pdf:PDF},
  groups     = {ASR},
  keywords   = {skimmed},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/document/9387600},
}

@Article{Wu2021,
  author   = {Wu, Linzhi and Zhang, Meishan},
  journal  = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title    = {Deep graph-based character-level chinese dependency parsing},
  year     = {2021},
  issn     = {2329-9304},
  pages    = {1329--1339},
  volume   = {29},
  abstract = {Character-level Chinese dependency parsing has been a concern of several studies that naturally handle word segmentation, POS (Part of Speech) tagging and dependency parsing jointly in an end-to-end way. Previous work mostly concentrates on a transition-based framework for this task because of its easy adaption, which is extremely important when feature representation relies heavily on the decoding strategy, particularly under the traditional statistical setting. Recently, on the one hand, sophisticated deep neural networks and deep contextualized word representations have greatly weakened the dependence between feature representation and decoding. On the other hand, (first-order) graph-based models, especially the biaffine parsers, are straightforward for dependency parsing, and meanwhile they can yield competitive parsing performance. In this paper, we make a comprehensive investigation of the deep graph-based character-level dependency parsing for Chinese. We start from an extension of a standard graph-based biaffine parser, and then exploit Chinese BERT as well as our improved encoders based on transformers to enhance the character-level dependency parsing model. We conduct a series of experiments on the Chinese benchmark datasets, showing the performances of various graph-based character-level models and analyzing the advantages of the character-level dependency parsing under the deep neural setting.},
  doi      = {10.1109/TASLP.2021.3067212},
  file     = {:FILES/2021 - Wu2021 - Deep graph-based character-level chinese dependency parsing.pdf:PDF},
  groups   = {dependency parsing},
  url      = {https://ieeexplore.ieee.org/document/9381612},
}

@Article{Lian2021,
  author   = {Lian, Zheng and Liu, Bin and Tao, Jianhua},
  journal  = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title    = {{CTNet}: {Conversational} transformer network for emotion recognition},
  year     = {2021},
  issn     = {2329-9304},
  pages    = {985--1000},
  volume   = {29},
  abstract = {Emotion recognition in conversation is a crucial topic for its widespread applications in the field of human-computer interactions. Unlike vanilla emotion recognition of individual utterances, conversational emotion recognition requires modeling both context-sensitive and speaker-sensitive dependencies. Despite the promising results of recent works, they generally do not leverage advanced fusion techniques to generate the multimodal representations of an utterance. In this way, they have limitations in modeling the intra-modal and cross-modal interactions. In order to address these problems, we propose a multimodal learning framework for conversational emotion recognition, called conversational transformer network (CTNet). Specifically, we propose to use the transformer-based structure to model intra-modal and cross-modal interactions among multimodal features. Meanwhile, we utilize word-level lexical features and segment-level acoustic features as the inputs, thus enabling us to capture temporal information in the utterance. Additionally, to model context-sensitive and speaker-sensitive dependencies, we propose to use the multihead attention based bi-directional GRU component and speaker embeddings. Experimental results on the IEMOCAP and MELD datasets demonstrate the effectiveness of the proposed method. Our method shows an absolute 2.1~6.2\% performance improvement on weighted average F1 over state-of-the-art strategies.},
  doi      = {10.1109/TASLP.2021.3049898},
  file     = {:FILES/2021 - Lian2021 - CTNet- Conversational Transformer Network for emotion recognition.pdf:PDF},
  groups   = {emotion recognition},
  url      = {https://ieeexplore.ieee.org/document/9316758},
}

@Article{Niermann2021,
  author   = {Niermann, Markus and Vary, Peter},
  journal  = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title    = {Listening enhancement in noisy environments: {Solutions} in time and frequency domain},
  year     = {2021},
  issn     = {2329-9304},
  pages    = {699--709},
  volume   = {29},
  abstract = {The intelligibility of speech from a telephone or a public address system is often affected by acoustical background noise in the near-end listening environment. Speech intelligibility and listening effort can be improved by adaptive pre-processing of the loudspeaker signal. This is called Near-End Listening Enhancement (NELE). The speech spectrum is dynamically modified, taking the acoustical background noise at the near-end into account. In this paper, two opposite NELE strategies with either Noise-Masking-Proportional Shaping or Noise-Masking-Inverse Shaping are proposed which are appropriate for different noise characteristics. Both strategies are formulated in closed form in the frequency domain. They do not require to optimize an intelligibility measure but use explicitly the masking threshold. Motivated by the frequency domain approach, a simpler time domain solution is derived which is based on linear prediction techniques and does not need the masking calculations. The proposed NELE solutions outperform state-of-the-art in terms of computational complexity, memory requirement, continuous processor load, and latency.},
  doi      = {10.1109/TASLP.2020.3047234},
  file     = {:FILES/2021 - Niermann2021 - Listening Enhancement in Noisy Environments- Solutions in Time and Frequency Domain.pdf:PDF},
  groups   = {speech enhancement},
  url      = {https://ieeexplore.ieee.org/document/9306894},
}

@Article{Sari2021,
  author   = {Sari, Leda and Hasegawa-Johnson, Mark and Thomas, Samuel},
  journal  = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title    = {Auxiliary networks for joint speaker adaptation and speaker change detection},
  year     = {2021},
  issn     = {2329-9304},
  pages    = {324--333},
  volume   = {29},
  abstract = {Speaker adaptation and speaker change detection have both been studied extensively to improve automatic speech recognition (ASR). In many cases, these two problems are investigated separately: speaker change detection is implemented first to obtain single-speaker regions, and speaker adaptation is then performed using the derived speaker segments for improved ASR. However, in an online setting, we want to achieve both goals in a single pass. In this study, we propose a neural network architecture that learns a speaker embedding from which it can perform both speaker adaptation for ASR and speaker change detection. The proposed speaker embedding is computed using self-attention based on an auxiliary network attached to a main ASR network. ASR adaptation is then performed by subtracting, from the main network activations, a segment dependent affine transformation of the learned speaker embedding. In experiments on a broadcast news dataset and the Switchboard conversational dataset, we test our system on utterances with a change point in them and show that the proposed method achieves significantly better performance as compared to the unadapted main network (10-14\% relative reduction in word error rate (WER)). The proposed architecture also outperforms three different speaker segmentation methods followed by ASR (around 10\% relative reduction in WER).},
  doi      = {10.1109/TASLP.2020.3040626},
  file     = {:FILES/2021 - Sari2021 - Auxiliary networks for joint speaker Adaptation and Speaker Change Detection.pdf:PDF},
  groups   = {speaker detection},
  url      = {https://ieeexplore.ieee.org/document/9271936},
}

@Article{Lee2021,
  author   = {Lee, Ching-Hua and Rao, Bhaskar D. and Garudadri, Harinath},
  journal  = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  title    = {Proportionate adaptive filtering algorithms derived using an iterative reweighting framework},
  year     = {2021},
  issn     = {2329-9304},
  pages    = {171--186},
  volume   = {29},
  abstract = {In this paper, based on sparsity-promoting regularization techniques from the sparse signal recovery (SSR) area, least mean square (LMS)-type sparse adaptive filtering algorithms are derived. The approach mimics the iterative reweighted ℓ2 and ℓ1 SSR methods that majorize the regularized objective function during the optimization process. We show that introducing the majorizers leads to the same algorithm as simply using the gradient update of the regularized objective function, as is done in existing approaches. Different from the past works, the reweighting formulation naturally leads to an affine scaling transformation (AST) strategy, which effectively introduces a diagonal weighting on the gradient, giving rise to new algorithms that demonstrate improved convergence properties. Interestingly, setting the regularization coefficient to zero in the proposed AST-based framework leads to the Sparsity-promoting LMS (SLMS) and Sparsity-promoting Normalized LMS (SNLMS) algorithms, which exploit but do not strictly enforce the sparsity of the system response if it already exists. The SLMS and SNLMS realize proportionate adaptation for convergence speedup should sparsity be present in the underlying system response. In this manner, we develop a new way for rigorously deriving a large class of proportionate algorithms, and also explain why they are useful in applications where the underlying systems admit certain sparsity, e.g., in acoustic echo and feedback cancellation.},
  doi      = {10.1109/TASLP.2020.3038526},
  file     = {:FILES/2021 - Lee2021 - Proportionate adaptive filtering algorithms derived using an iterative reweighting framework.pdf:PDF},
  groups   = {applications},
  url      = {https://ieeexplore.ieee.org/document/9261941},
}

@Article{Song2021,
  author   = {Chenguang Song and Nianwen Ning and Yunlei Zhang and Bin Wu},
  journal  = {Information Processing \& Management},
  title    = {A multimodal fake news detection model based on crossmodal attention residual and multichannel convolutional neural networks},
  year     = {2021},
  issn     = {0306-4573},
  number   = {1},
  pages    = {102437},
  volume   = {58},
  abstract = {In recent years, social media has increasingly become one of the popular ways for people to consume news. As proliferation of fake news on social media has the negative impacts on individuals and society, automatic fake news detection has been explored by different research communities for combating fake news. With the development of multimedia technology, there is a phenomenon that cannot be ignored is that more and more social media news contains information with different modalities, e.g., texts, pictures and videos. The multiple information modalities show more evidence of the happening of news events and present new opportunities to detect features in fake news. First, for multimodal fake news detection task, it is a challenge of keeping the unique properties for each modality while fusing the relevant information between different modalities. Second, for some news, the information fusion between different modalities may produce the noise information which affects model’s performance. Unfortunately, existing methods fail to handle these challenges. To address these problems, we propose a multimodal fake news detection framework based on Crossmodal Attention Residual and Multichannel convolutional neural Networks (CARMN). The Crossmodal Attention Residual Network (CARN) can selectively extract the relevant information related to a target modality from another source modality while maintaining the unique information of the target modality. The Multichannel Convolutional neural Network (MCN) can mitigate the influence of noise information which may be generated by crossmodal fusion component by extracting textual feature representation from original and fused textual information simultaneously. We conduct extensive experiments on four real-world datasets and demonstrate that the proposed model outperforms the state-of-the-art methods and learns more discriminable feature representations.},
  doi      = {10.1016/j.ipm.2020.102437},
  file     = {:FILES/2021 - Song2021 - A multimodal fake news detection model based on crossmodal attention residual and multichannel convolutional neural networks.pdf:PDF},
  groups   = {fake news detection},
  keywords = {Fake news detection, Crossmodal attention, Residual network, Convolutional neural network},
  url      = {https://www.sciencedirect.com/science/article/pii/S0306457320309304},
}

@InProceedings{Zaib2021,
  author    = {Zaib, Munazza and Tran, Dai Hoang and Sagar, Subhash and Mahmood, Adnan and Zhang, Wei E. and Sheng, Quan Z.},
  booktitle = {Parallel Architectures, Algorithms and Programming},
  title     = {{BERT-CoQAC}: {BERT-based} conversational question answering in context},
  year      = {2021},
  address   = {Singapore},
  editor    = {Ning, Li and Chau, Vincent and Lau, Francis},
  pages     = {47--57},
  publisher = {Springer Singapore},
  abstract  = {As one promising way to inquire about any particular information through a dialog with the bot, question answering dialog systems have gained increasing research interests recently. Designing interactive QA systems has always been a challenging task in natural language processing and used as a benchmark to evaluate machine's ability of natural language understanding. However, such systems often struggle when the question answering is carried out in multiple turns by the users to seek more information based on what they have already learned, thus, giving rise to another complicated form called Conversational Question Answering (CQA). CQA systems are often criticized for not understanding or utilizing the previous context of the conversation when answering the questions. To address the research gap, in this paper, we explore how to integrate the conversational history into the neural machine comprehension system. On one hand, we introduce a framework based on publicly available pre-trained language model called BERT for incorporating history turns into the system. On the other hand, we propose a history selection mechanism that selects the turns that are relevant and contributes the most to answer the current question. Experimentation results revealed that our framework is comparable in performance with the state-of-the-art models on the QuAC (http://quac.ai/) leader board. We also conduct a number of experiments to show the side effects of using entire context information which brings unnecessary information and noise signals resulting in a decline in the model's performance.},
  doi       = {10.1007/978-981-16-0010-4_5},
  file      = {:FILES/2021 - Zaib2021 - BERT-CoQAC- BERT-Based Conversational Question Answering in Context.pdf:PDF},
  groups    = {question answering},
  isbn      = {978-981-16-0010-4},
  url       = {https://link.springer.com/chapter/10.1007/978-981-16-0010-4_5},
}

@Article{Peng2018,
  author    = {Peng, Xue Bin and Kanazawa, Angjoo and Malik, Jitendra and Abbeel, Pieter and Levine, Sergey},
  journal   = {ACM Trans. Graph.},
  title     = {{SFV}: {Reinforcement} learning of physical skills from videos},
  year      = {2018},
  issn      = {0730-0301},
  month     = dec,
  number    = {6},
  pages     = {178},
  volume    = {37},
  abstract  = {Data-driven character animation based on motion capture can produce highly naturalistic behaviors and, when combined with physics simulation, can provide for natural procedural responses to physical perturbations, environmental changes, and morphological discrepancies. Motion capture remains the most popular source of motion data, but collecting mocap data typically requires heavily instrumented environments and actors. In this paper, we propose a method that enables physically simulated characters to learn skills from videos (SFV). Our approach, based on deep pose estimation and deep reinforcement learning, allows data-driven animation to leverage the abundance of publicly available video clips from the web, such as those from YouTube. This has the potential to enable fast and easy design of character controllers simply by querying for video recordings of the desired behavior. The resulting controllers are robust to perturbations, can be adapted to new settings, can perform basic object interactions, and can be retargeted to new morphologies via reinforcement learning. We further demonstrate that our method can predict potential human motions from still images, by forward simulation of learned controllers initialized from the observed pose. Our framework is able to learn a broad range of dynamic skills, including locomotion, acrobatics, and martial arts. (Video1)},
  address   = {New York, NY, USA},
  doi       = {10.1145/3272127.3275014},
  file      = {:FILES/2018 - Peng2018 - {SFV}- {Reinforcement} learning of physical skills from videos.pdf:PDF},
  groups    = {learn from video},
  keywords  = {motion reconstruction, computer vision, video imitation, reinforcement learning, physics-based character animation},
  publisher = {Association for Computing Machinery},
  url       = {https://dl.acm.org/doi/10.1145/3272127.3275014},
}

@InBook{Medaglia2003,
  author    = {Medaglia, Andr{\'e}s L.},
  chapter   = {10},
  pages     = {163--189},
  publisher = {Springer US},
  title     = {An evolutionary algorithm for project selection problems based on stochastic multiobjective linearly constrained optimization},
  year      = {2003},
  address   = {Boston, MA},
  isbn      = {978-1-4615-0280-7},
  abstract  = {This chapter presents a new algorithm that solves a class of project selection problems with uncertain objectives, partial funding, interdependencies in the objectives, and constraints with a linear structure. In general, this class of project selection problems can be modeled as a stochastic multiobjective linearly constrained program (SMOLCP). The SMOLCP can be solved with the stochastic parameter space investigation method (PSI) presented in Chapter 8. The proposed algorithm is based on multiobjective evolutionary optimization and concepts from linear programming. The algorithm presents the decision maker with a high-quality, evenly distributed, and size-controlled approximation of the true efficient frontier. The method compares favorably to the stochastic PSI in terms of quantity and quality of the generated nondominated solutions and in computational efficiency. The algorithm is also able to solve satisfactorily project selection problems modeled as multiobjective linear programs and multiobjective nonlinear programs with linear constraints. The evolutionary algorithm has been designed to scale well to large instances and to become part of a decision support system.},
  booktitle = {Models {\&} Methods for Project Selection: Concepts from Management Science, Finance and Information Technology},
  doi       = {10.1007/978-1-4615-0280-7_10},
  file      = {:FILES/2003 - Medaglia2003 - An Evolutionary Algorithm for Project Selection Problems Based on Stochastic Multiobjective Linearly Constrained Optimization.pdf:PDF},
  groups    = {Evolutionary Algorithms},
  url       = {https://link.springer.com/chapter/10.1007/978-1-4615-0280-7_10},
}

@Article{Pandharipande2014,
  author   = {Shekhar L. Pandharipande and Aarti R. Deshmukh and Rohit P. Kalnake},
  journal  = {International Journal of Computer Applications},
  title    = {Genetic algorithm for constrained optimization with stepwise approach in search interval selection of variables},
  year     = {2014},
  month    = feb,
  number   = {11},
  pages    = {43--52},
  volume   = {87},
  abstract = {Genetic algorithms are evolutionary algorithms that are well suited in searching global solution to varied nature of optimization problems. The inspirations in developing GA are derived from working principle of natural genetics. The operators such as reproduction, crossover \& mutation are employed similar to natural genetics. These steps involved elements of probability that make search for optimal solution random making GA stochastic \& nondeterministic. There are several initiatives made by researcher in improving the search direction \& making it more definitive. Present work aims at suggesting a novel stepwise approach in search interval selection of variables using Genetic algorithm. Three non-linear optimization problems are selected for numerical experimentation with comparative studies of respective solution using conventional methods and GA techniques with \& without stepwise approach. Test run are conducted with constant GA parameters and the best function values for five consecutive run are tabulated. Corresponding values of variables decide the search interval selection criteria for step 1. Five elite-GA run are conducted for step 1 for newly defined search interval of variables. The corresponding values of the variables obtained as in step 1 decide the search interval selection for step 2. Number of steps continues till no further improvement in the function values is obtained. Based on the result of the present work it can be concluded that the optimal values obtained for all the three test problems evaluated using the stepwise approach are better than those obtained using GA without stepwise approach \& conventional techniques. The present work is demonstrative \& it is felt necessary to substantiate the claim by extending this stepwise search interval approach of GA in selection of variables to other problems of optimization.},
  doi      = {10.5120/15256-4017},
  file     = {:FILES/2014 - Pandharipande2014 - Genetic Algorithm for Constrained Optimization with Stepwise Approach in Search Interval Selection of Variables.pdf:PDF},
  groups   = {genetic algorithms},
  url      = {https://www.ijcaonline.org/archives/volume87/number11/15256-4017},
}

@Article{Tee2009,
  author   = {Keng Peng Tee and Shuzhi Sam Ge and Eng Hock Tay},
  journal  = {Automatica},
  title    = {Barrier {Lyapunov} functions for the control of output-constrained nonlinear systems},
  year     = {2009},
  issn     = {0005-1098},
  number   = {4},
  pages    = {918--927},
  volume   = {45},
  abstract = {In this paper, we present control designs for single-input single-output (SISO) nonlinear systems in strict feedback form with an output constraint. To prevent constraint violation, we employ a Barrier Lyapunov Function, which grows to infinity when its arguments approach some limits. By ensuring boundedness of the Barrier Lyapunov Function in the closed loop, we ensure that those limits are not transgressed. Besides the nominal case where full knowledge of the plant is available, we also tackle scenarios wherein parametric uncertainties are present. Asymptotic tracking is achieved without violation of the constraint, and all closed loop signals remain bounded, under a mild condition on the initial output. Furthermore, we explore the use of an Asymmetric Barrier Lyapunov Function as a generalized approach that relaxes the requirements on the initial conditions. We also compare our control with one that is based on a Quadratic Lyapunov Function, and we show that our control requires less restrictive initial conditions. A numerical example is provided to illustrate the performance of the proposed control.},
  doi      = {10.1016/j.automatica.2008.11.017},
  file     = {:FILES/2009 - Tee2009 - Barrier Lyapunov Functions for the control of output-constrained nonlinear systems.pdf:PDF},
  groups   = {control},
  keywords = {Barrier function, Constraints, Adaptive control, Backstepping, Lyapunov methods},
  url      = {https://www.sciencedirect.com/science/article/pii/S0005109808005608},
}

@Article{Sperber2019,
  author   = {Sperber, Matthias and Neubig, Graham and Niehues, Jan and Waibel, Alex},
  journal  = {Transactions of the Association for Computational Linguistics},
  title    = {Attention-passing models for robust and data-efficient end-to-end speech translation},
  year     = {2019},
  issn     = {2307-387X},
  month    = jun,
  pages    = {313--325},
  volume   = {7},
  abstract = {{Speech translation has traditionally been approached through cascaded models consisting of a speech recognizer trained on a corpus of transcribed speech, and a machine translation system trained on parallel texts. Several recent works have shown the feasibility of collapsing the cascade into a single, direct model that can be trained in an end-to-end fashion on a corpus of translated speech. However, experiments are inconclusive on whether the cascade or the direct model is stronger, and have only been conducted under the unrealistic assumption that both are trained on equal amounts of data, ignoring other available speech recognition and machine translation corpora.In this paper, we demonstrate that direct speech translation models require more data to perform well than cascaded models, and although they allow including auxiliary data through multi-task training, they are poor at exploiting such data, putting them at a severe disadvantage. As a remedy, we propose the use of end- to-end trainable models with two attention mechanisms, the first establishing source speech to source text alignments, the second modeling source to target text alignment. We show that such models naturally decompose into multi-task–trainable recognition and translation tasks and propose an attention-passing technique that alleviates error propagation issues in a previous formulation of a model with two attention stages. Our proposed model outperforms all examined baselines and is able to exploit auxiliary training data much more effectively than direct attentional models.}},
  comment  = {multitasking E2E model, which requires less training dataset.},
  doi      = {10.1162/tacl_a_00270},
  file     = {:FILES/2019 - Sperber2019 - Attention-Passing Models for Robust and Data-Efficient End-to-End speech translation.pdf:PDF},
  groups   = {ASR},
  url      = {https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00270/43517/Attention-Passing-Models-for-Robust-and-Data},
}

@InProceedings{Sperber2020,
  author    = {Sperber, Matthias and Paulik, Matthias},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  title     = {Speech translation and the end-to-end promise: {Taking} stock of where we are},
  year      = {2020},
  month     = jul,
  note      = {survey paper},
  pages     = {7409--7421},
  publisher = {Association for Computational Linguistics},
  abstract  = {Over its three decade history, speech translation has experienced several shifts in its primary research themes; moving from loosely coupled cascades of speech recognition and machine translation, to exploring questions of tight coupling, and finally to end-to-end models that have recently attracted much attention. This paper provides a brief survey of these developments, along with a discussion of the main challenges of traditional approaches which stem from committing to intermediate representations from the speech recognizer, and from training cascaded models separately towards different objectives. Recent end-to-end modeling techniques promise a principled way of overcoming these issues by allowing joint training of all model components and removing the need for explicit intermediate representations. However, a closer look reveals that many end-to-end models fall short of solving these issues, due to compromises made to address data scarcity. This paper provides a unifying categorization and nomenclature that covers both traditional and recent approaches and that may help researchers by highlighting both trade-offs and open research questions.},
  comment   = {本文是关于speech translation的综述文章，


multitasking E2E model, which requires less training dataset.},
  doi       = {10.18653/v1/2020.acl-main.661},
  file      = {:FILES/2020 - Sperber2020 - Speech Translation and the End-to-End Promise- Taking Stock of Where We Are.pdf:PDF},
  groups    = {speech translation},
  owner     = {Apple},
  url       = {https://www.aclweb.org/anthology/2020.acl-main.661},
}

@InProceedings{Anastasopoulos2018,
  author    = {Anastasopoulos, Antonios and Chiang, David},
  booktitle = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  title     = {Tied multitask learning for neural speech translation},
  year      = {2018},
  address   = {New Orleans, Louisiana},
  month     = jun,
  pages     = {82--91},
  publisher = {Association for Computational Linguistics},
  volume    = {1},
  abstract  = {We explore multitask models for neural translation of speech, augmenting them in order to reflect two intuitive notions. First, we introduce a model where the second task decoder receives information from the decoder of the first task, since higher-level intermediate representations should provide useful information. Second, we apply regularization that encourages transitivity and invertibility. We show that the application of these notions on jointly trained models improves performance on the tasks of low-resource speech transcription and translation. It also leads to better performance when using attention information for word discovery over unsegmented input.},
  doi       = {10.18653/v1/N18-1008},
  file      = {:FILES/2018 - Anastasopoulos2018 - Tied Multitask Learning for Neural Speech Translation.pdf:PDF},
  groups    = {ASR},
  url       = {https://www.aclweb.org/anthology/N18-1008},
}

@InProceedings{Dalmia2018,
  author    = {Dalmia, Siddharth and Sanabria, Ramon and Metze, Florian and Black, Alan W.},
  booktitle = {2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Sequence-based multi-lingual low resource speech recognition},
  year      = {2018},
  address   = {Calgary, AB, Canada},
  month     = apr,
  pages     = {4909--4913},
  publisher = {IEEE},
  abstract  = {Techniques for multi-lingual and cross-lingual speech recognition can help in low resource scenarios, to bootstrap systems and enable analysis of new languages and domains. End-to-end approaches, in particular sequence-based techniques, are attractive because of their simplicity and elegance. While it is possible to integrate traditional multi-lingual bottleneck feature extractors as front-ends, we show that end-to-end multi-lingual training of sequence models is effective on context independent models trained using Connectionist Temporal Classification (CTC) loss. We show that our model improves performance on Babel languages by over 6\% absolute in terms of word/phoneme error rate when compared to mono-lingual systems built in the same setting for these languages. We also show that the trained model can be adapted cross-lingually to an unseen language using just 25\% of the target data. We show that training on multiple languages is important for very low resource cross-lingual target scenarios, but not for multi-lingual testing scenarios. Here, it appears beneficial to include large well prepared datasets.},
  doi       = {10.1109/ICASSP.2018.8461802},
  file      = {:FILES/2018 - Dalmia2018 - Sequence-based multi-lingual low resource speech recognition.pdf:PDF},
  groups    = {ASR},
  issn      = {2379-190X},
  url       = {https://ieeexplore.ieee.org/document/8461802},
}

@InProceedings{Audhkhasi2018,
  author    = {Audhkhasi, Kartik and Kingsbury, Brian and Ramabhadran, Bhuvana and Saon, George and Picheny, Michael},
  booktitle = {Proceedings of 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Building competitive direct acoustics-to-word models for {English} conversational speech recognition},
  year      = {2018},
  pages     = {4759--4763},
  publisher = {IEEE},
  comment   = {acoustic word embedding with ASR},
  doi       = {10.1109/icassp.2018.8461935},
  file      = {:FILES/2018 - Audhkhasi2018 - Building competitive direct acoustics-to-word models for {English} conversational speech recognition.pdf:PDF},
  groups    = {ASR},
}

@InProceedings{Chorowski2017,
  author    = {Jan Chorowski and Navdeep Jaitly},
  booktitle = {Proceedings of INTERSPEECH 2017},
  title     = {Towards better decoding and language model integration in sequence to sequence models},
  year      = {2017},
  address   = {Stockholm, Sweden},
  month     = aug,
  pages     = {523--527},
  publisher = {ISCA},
  comment   = {use pure text data to train E2E ASR},
  doi       = {10.21437/Interspeech.2017-343},
  file      = {:FILES/2017 - Chorowski2017 - Towards better decoding and language model integration in sequence to sequence models.PDF:PDF},
  groups    = {ASR},
  url       = {http://dx.doi.org/10.21437/Interspeech.2017-343},
}

@InProceedings{Liu2019c,
  author    = {Liu, Alexander H. and Lee, Hung-yi and Lee, Lin-shan},
  booktitle = {Proceedings of 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Adversarial training of end-to-end speech recognition using a criticizing language model},
  year      = {2019},
  address   = {Brighton, UK},
  month     = may,
  pages     = {6176--6180},
  publisher = {IEEE},
  abstract  = {In this paper we proposed a novel Adversarial Training (AT) approach for end-to-end speech recognition using a Criticizing Language Model (CLM). In this way the CLM and the automatic speech recognition (ASR) model can challenge and learn from each other iteratively to improve the performance. Since the CLM only takes the text as input, huge quantities of unpaired text data can be utilized in this approach within end-to-end training. Moreover, AT can be applied to any end-to-end ASR model using any deep-learning-based language modeling frameworks, and compatible with any existing end-to-end decoding method. Initial results with an example experimental setup demonstrated the proposed approach is able to gain consistent improvements efficiently from auxiliary text data under different scenarios.},
  comment   = {integrate an adversial learning model into ASR to reduce its requirement for large training dataset.},
  doi       = {10.1109/ICASSP.2019.8683602},
  file      = {:FILES/2019 - Liu2019c - Adversarial Training of End-to-end Speech Recognition Using a Criticizing Language Model.pdf:PDF},
  groups    = {ASR},
  issn      = {2379-190X},
  url       = {https://ieeexplore.ieee.org/document/8683602},
}

@InProceedings{Baskar2019,
  author    = {Murali Karthick Baskar and Shinji Watanabe and Ramon Astudillo and Takaaki Hori and Luk\'{a}\v{s} Burget and Jan \v{C}ernock\'{y}},
  booktitle = {Proceedings of INTERSPEECH 2019},
  title     = {Semi-supervised sequence-to-sequence {ASR} using unpaired speech and text},
  year      = {2019},
  address   = {Graz, Austria},
  month     = sep,
  pages     = {3790--3794},
  publisher = {ISCA},
  abstract  = {before training ASR, first train a speech to text model, so that it can yield pseudo paired speech-text data.},
  doi       = {10.21437/Interspeech.2019-3167},
  file      = {:FILES/2019 - Baskar2019 - Semi-Supervised Sequence-to-Sequence ASR Using Unpaired Speech and Text.pdf:PDF},
  groups    = {ASR},
  url       = {https://www.isca-speech.org/archive/Interspeech_2019/abstracts/3167.html},
}

@Misc{Ruder2017,
  author        = {Sebastian Ruder},
  note          = {survey paper},
  title         = {An overview of multi-task learning in deep neural networks},
  year          = {2017},
  archiveprefix = {arXiv},
  comment       = {it is about multitask learning in NLP, SR, and some other fields.},
  eprint        = {1706.05098},
  file          = {:FILES/2017 - Ruder2017 - An Overview of Multi-Task Learning in Deep Neural Networks.pdf:PDF;:FILES/notes/Ruder2017.docx:Word 2007+},
  groups        = {ASR, machine learning},
  primaryclass  = {cs.LG},
  readstatus    = {read},
  url           = {https://arxiv.org/abs/1706.05098},
}

@Article{Robinson1994,
  author   = {Robinson, Anthony J.},
  journal  = {IEEE Transactions on Neural Networks},
  title    = {An application of recurrent nets to phone probability estimation},
  year     = {1994},
  issn     = {1941-0093},
  month    = mar,
  number   = {2},
  pages    = {298--305},
  volume   = {5},
  abstract = {This paper presents an application of recurrent networks for phone probability estimation in large vocabulary speech recognition. The need for efficient exploitation of context information is discussed; a role for which the recurrent net appears suitable. An overview of early developments of recurrent nets for phone recognition is given along with the more recent improvements that include their integration with Markov models. Recognition results are presented for the DARPA TIMIT and Resource Management tasks, and it is concluded that recurrent nets are competitive with traditional means for performing phone probability estimation.<>},
  comment  = {pioneer work of using RNN for acoustic model in SR},
  doi      = {10.1109/72.279192},
  file     = {:FILES/1994 - Robinson1994 - An application of recurrent nets to phone probability estimation.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/279192},
}

@InProceedings{Mikolov2010,
  author    = {Mikolov, Tom\'{a}\v{s} and Karafi\'{a}t, Martin and Burget, Luk\'{a}\v{s} and \v{C}ernock\'{y}, Jan and Khudanpur, Sanjeev},
  booktitle = {Proceedings of INTERSPEECH 2010},
  title     = {Recurrent neural network based language model},
  year      = {2010},
  address   = {Chiba, Japan},
  month     = sep,
  pages     = {1045--1048},
  publisher = {ISCA},
  groups    = {ASR},
  url       = {https://isca-speech.org/archive/interspeech_2010/i10_1045.html},
}

@Article{Lang1990,
  author   = {Kevin J. Lang and Alex H. Waibel and Geoffrey E. Hinton},
  journal  = {Neural Networks},
  title    = {A time-delay neural network architecture for isolated word recognition},
  year     = {1990},
  issn     = {0893-6080},
  number   = {1},
  pages    = {23--43},
  volume   = {3},
  abstract = {A translation-invariant back-propagation network is described that performs better than a sophisticated continuous acoustic parameter hidden Markov model on a noisy, 100-speaker confusable vocabulary isolated word recognition task. The network's replicated architecture permits it to extract precise information from unaligned training patterns selected by a naive segmentation rule.},
  comment  = {first apply CNN on acoustic modeling,但没有引起重视},
  doi      = {10.1016/0893-6080(90)90044-L},
  file     = {:FILES/1990 - Lang1990 - A time-delay neural network architecture for isolated word recognition.pdf:PDF},
  groups   = {ASR},
  keywords = {Isolated word recognition, Network architecture, Constrained links, Time delays, Multiresolution learning, Multispeaker speech recognition, Neural networks},
  url      = {https://www.sciencedirect.com/science/article/pii/089360809090044L},
}

@InProceedings{AbdelHamid2012,
  author    = {{Abdel-Hamid}, Ossama and Mohamed, {Abdel-rahman} and Jiang, Hui and Penn, Gerald},
  booktitle = {2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Applying convolutional neural networks concepts to hybrid {NN-HMM} model for speech recognition},
  year      = {2012},
  address   = {Kyoto, Japan},
  month     = mar,
  pages     = {4277--4280},
  abstract  = {Convolutional Neural Networks (CNN) have showed success in achieving translation invariance for many image processing tasks. The success is largely attributed to the use of local filtering and max-pooling in the CNN architecture. In this paper, we propose to apply CNN to speech recognition within the framework of hybrid NN-HMM model. We propose to use local filtering and max-pooling in frequency domain to normalize speaker variance to achieve higher multi-speaker speech recognition performance. In our method, a pair of local filtering layer and max-pooling layer is added at the lowest end of neural network (NN) to normalize spectral variations of speech signals. In our experiments, the proposed CNN architecture is evaluated in a speaker independent speech recognition task using the standard TIMIT data sets. Experimental results show that the proposed CNN method can achieve over 10% relative error reduction in the core TIMIT test sets when comparing with a regular NN using the same number of hidden layers and weights. Our results also show that the best result of the proposed CNN model is better than previously published results on the same TIMIT test sets that use a pre-trained deep NN model.},
  comment   = {CNN with convolutional across frequency is much effective for TIMIT testsets.},
  doi       = {10.1109/ICASSP.2012.6288864},
  file      = {:FILES/2012 - AbdelHamid2012 - Applying Convolutional Neural Networks concepts to hybrid NN-HMM model for speech recognition.pdf:PDF},
  groups    = {ASR},
  issn      = {2379-190X},
  url       = {https://ieeexplore.ieee.org/document/6288864},
}

@InProceedings{Deng2013a,
  author    = {Deng, Li and Li, Jinyu and Huang, Jui-Ting and Yao, Kaisheng and Yu, Dong and Seide, Frank and Seltzer, Michael and Zweig, Geoff and He, Xiaodong and Williams, Jason and Gong, Yifan and Acero, Alex},
  booktitle = {2013 IEEE International Conference on Acoustics, Speech and Signal Processing},
  title     = {Recent advances in deep learning for speech research at {Microsoft}},
  year      = {2013},
  address   = {Vancouver, BC, Canada},
  month     = may,
  pages     = {8604--8608},
  publisher = {IEEE},
  abstract  = {Deep learning is becoming a mainstream technology for speech recognition at industrial scale. In this paper, we provide an overview of the work by Microsoft speech researchers since 2009 in this area, focusing on more recent advances which shed light to the basic capabilities and limitations of the current deep learning technology. We organize this overview along the feature-domain and model-domain dimensions according to the conventional approach to analyzing speech systems. Selected experimental results, including speech recognition and related applications such as spoken dialogue and language modeling, are presented to demonstrate and analyze the strengths and weaknesses of the techniques described in the paper. Potential improvement of these techniques and future research directions are discussed.},
  comment   = {shows that designing the convolution and pooling layers to 
properly trade-off between invariance to the vocal tract length and 
discrimination among speech sounds together with the “dropout” 
technique of regularization [27] leads to much better TIMIT phone 
recognition accuracy.},
  doi       = {10.1109/ICASSP.2013.6639345},
  file      = {:FILES/2013 - Deng2013a - Recent advances in deep learning for speech research at Microsoft.pdf:PDF},
  groups    = {ASR},
  issn      = {2379-190X},
  url       = {https://ieeexplore.ieee.org/document/6639345},
}

@InProceedings{Rosenberg2019,
  author    = {Rosenberg, Andrew and Zhang, Yu and Ramabhadran, Bhuvana and Jia, Ye and Moreno, Pedro and Wu, Yonghui and Wu, Zelin},
  booktitle = {2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  title     = {Speech recognition with augmented synthesized speech},
  year      = {2019},
  address   = {Singapore},
  month     = dec,
  pages     = {996--1002},
  publisher = {IEEE},
  abstract  = {Recent success of the Tacotron speech synthesis architecture and its variants in producing natural sounding multi-speaker synthesized speech has raised the exciting possibility of replacing expensive, manually transcribed, domain-specific, human speech that is used to train speech recognizers. The multi-speaker speech synthesis architecture can learn latent embedding spaces of prosody, speaker and style variations derived from input acoustic representations thereby allowing for manipulation of the synthesized speech. In this paper, we evaluate the feasibility of enhancing speech recognition performance using speech synthesis using two corpora from different domains. We explore algorithms to provide the necessary acoustic and lexical diversity needed for robust speech recognition. Finally, we demonstrate the feasibility of this approach as a data augmentation strategy for domain-transfer. We find that improvements to speech recognition performance is achievable by augmenting training data with synthesized material. However, there remains a substantial gap in performance between recognizers trained on human speech those trained on synthesized speech.},
  doi       = {10.1109/ASRU46091.2019.9003990},
  file      = {:FILES/2019 - Rosenberg2019 - Speech Recognition with Augmented Synthesized Speech.pdf:PDF},
  groups    = {ASR},
  url       = {https://ieeexplore.ieee.org/document/9003990},
}

@InProceedings{Lu2020,
  author    = {Liang Lu and Changliang Liu and Jinyu Li and Yifan Gong},
  booktitle = {Proceedings of INTERSPEECH 2020},
  title     = {Exploring transformers for large-scale speech recognition},
  year      = {2020},
  address   = {Shanghai, China},
  month     = oct,
  pages     = {5041--5045},
  publisher = {ISCA},
  doi       = {10.21437/Interspeech.2020-2638},
  file      = {:FILES/2020 - Lu2020 - {Exploring Transformers for Large-Scale Speech Recognition}.pdf:PDF},
  groups    = {ASR},
  url       = {https://www.isca-speech.org/archive/Interspeech_2020/abstracts/2638.html},
}

@InProceedings{Sainath2019,
  author    = {Tara N. Sainath and Ruoming Pang and David Rybach and Yanzhang He and Rohit Prabhavalkar and Wei Li and Mirk\'{o} Visontai and Qiao Liang and Trevor Strohman and Yonghui Wu and Ian McGraw and Chung-Cheng Chiu},
  booktitle = {Proceedings of INTERSPEECH 2019},
  title     = {Two-pass end-to-end speech recognition},
  year      = {2019},
  address   = {Graz, Austria},
  month     = sep,
  pages     = {2773--2777},
  publisher = {ISCA},
  doi       = {10.21437/Interspeech.2019-1341},
  file      = {:FILES/2019 - Sainath2019 - Two-pass end-to-end speech recognition.pdf:PDF},
  groups    = {ASR},
  url       = {https://www.isca-speech.org/archive/Interspeech_2019/abstracts/1341.html},
}

@InProceedings{Petridis2018,
  author    = {Petridis, Stavros and Stafylakis, Themos and Ma, Pingehuan and Cai, Feipeng and Tzimiropoulos, Georgios and Pantic, Maja},
  booktitle = {2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {End-to-end audiovisual speech recognition},
  year      = {2018},
  address   = {Calgary, AB, Canada},
  month     = apr,
  pages     = {6548--6552},
  publisher = {IEEE},
  abstract  = {Several end-to-end deep learning approaches have been recently presented which extract either audio or visual features from the input images or audio signals and perform speech recognition. However, research on end-to-end audiovisual models is very limited. In this work, we present an end-to-end audiovisual model based on residual networks and Bidirectional Gated Recurrent Units (BGRUs). To the best of our knowledge, this is the first audiovisual fusion model which simultaneously learns to extract features directly from the image pixels and audio waveforms and performs within-context word recognition on a large publicly available dataset (LRW). The model consists of two streams, one for each modality, which extract features directly from mouth regions and raw waveforms. The temporal dynamics in each stream/modality are modeled by a 2-layer BGRU and the fusion of multiple streams/modalities takes place via another 2-layer BGRU. A slight improvement in the classification rate over an end-to-end audio-only and MFCC-based model is reported in clean audio conditions and low levels of noise. In presence of high levels of noise, the end-to-end audiovisual model significantly outperforms both audio-only models.},
  doi       = {10.1109/ICASSP.2018.8461326},
  file      = {:FILES/2018 - Petridis2018 - End-to-End Audiovisual Speech Recognition.pdf:PDF},
  groups    = {ASR},
  issn      = {2379-190X},
  url       = {https://ieeexplore.ieee.org/document/8461326},
}

@InProceedings{Wang2019d,
  author    = {Wang, Senmao and Zhou, Pan and Chen, Wei and Jia, Jia and Xie, Lei},
  booktitle = {2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)},
  title     = {Exploring {RNN-transducer} for {Chinese} speech recognition},
  year      = {2019},
  address   = {Lanzhou, China},
  month     = nov,
  pages     = {1364--1369},
  publisher = {IEEE},
  abstract  = {End-to-end approaches have drawn much attention recently for significantly simplifying the construction of an automatic speech recognition (ASR) system. RNN transducer (RNN-T) is one of the popular end- to-end methods. Previous studies have shown that RNN-T is difficult to train and a very complex training process is needed for a reasonable performance. In this paper, we explore RNN-T for a Chinese large vocabulary continuous speech recognition (LVCSR) task and aim to simplify the training process while maintaining performance. First, a new strategy of learning rate decay is proposed to accelerate the model convergence. Second, we find that adding convolutional layers at the beginning of the network and using ordered data can discard the pre-training process of the encoder without loss of performance. Besides, we design experiments to find a balance among the usage of GPU memory, training circle and model performance. Finally, we achieve 16.9% character error rate (CER) on our test set, which is 2% absolute improvement from a strong BLSTM CE system with language model trained on the same text corpus.},
  doi       = {10.1109/APSIPAASC47483.2019.9023133},
  file      = {:FILES/2019 - Wang2019d - Exploring RNN-Transducer for Chinese speech recognition.pdf:PDF},
  groups    = {ASR},
  issn      = {2640-0103},
  url       = {https://ieeexplore.ieee.org/document/9023133},
}

@InProceedings{Xu2020a,
  author    = {Xu, Bo and Lu, Cheng and Guo, Yandong and Wang, Jacob},
  booktitle = {2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Discriminative multi-modality speech recognition},
  year      = {2020},
  address   = {Seattle, WA, USA},
  month     = jun,
  pages     = {14421--14430},
  publisher = {IEEE},
  abstract  = {Vision is often used as a complementary modality for audio speech recognition (ASR), especially in the noisy environment where performance of solo audio modality significantly deteriorates. After combining visual modality, ASR is upgraded to the multi-modality speech recognition (MSR). In this paper, we propose a two-stage speech recognition model. In the first stage, the target voice is separated from background noises with help from the corresponding visual information of lip movements, making the model `listen' clearly. At the second stage, the audio modality combines visual modality again to better understand the speech by a MSR sub-network, further improving the recognition rate. There are some other key contributions: we introduce a pseudo-3D residual convolution (P3D)-based visual front-end to extract more discriminative features; we upgrade the temporal convolution block from 1D ResNet with the temporal convolutional network (TCN), which is more suitable for the temporal tasks; the MSR sub-network is built on the top of Element-wise-Attention Gated Recurrent Unit (EleAtt-GRU), which is more effective than Transformer in long sequences. We conducted extensive experiments on the LRS3-TED and the LRW datasets. Our two-stage model (audio enhanced multi-modality speech recognition, AE-MSR) consistently achieves the state-of-the-art performance by a significant margin, which demonstrates the necessity and effectiveness of AE-MSR.},
  doi       = {10.1109/CVPR42600.2020.01444},
  file      = {:FILES/2020 - Xu2020a - Discriminative Multi-Modality Speech Recognition.pdf:PDF},
  groups    = {ASR},
  issn      = {2575-7075},
  url       = {https://ieeexplore.ieee.org/document/9156852},
}

@Article{Dudley1940,
  author     = {Dudley, Homer},
  journal    = {The Bell System Technical Journal},
  title      = {The carrier nature of speech},
  year       = {1940},
  issn       = {0005-8580},
  month      = oct,
  number     = {4},
  pages      = {495--515},
  volume     = {19},
  abstract   = {Speech synthesizing is here discussed in the terminology of carrier circuits. The speaker is pictured as a sort of radio broadcast transmitter with the message to be sent out originating in the studio of the talker's brain and manifesting itself in muscular wave motions in the vocal tract. Although these motions contain the message, they are inaudible because they occur at syllabic rates. An audible sound is needed to pass the message into the listener's ear. This is provided by the carrier in the form of a group of higher frequency waves in the audible range set up by oscillatory action at the vocal cords or elsewhere in the vocal tract. These carrier waves either in their generation or their transmission are modulated by the message waves to form the speech waves. As the speech waves contain the message information on an audible carrier they are adapted to broadcast reception by receiving sets in the form of listeners' ears. The message is then recovered by the listeners' minds.},
  comment    = {这篇文章是从人发出声音的原理中（大脑、声带、口腔等多器官协同运动）学习，发展出一种声音合成电路，从而发出carrier of speech which contains the information,而本文没有涉及声音处理的过程。},
  doi        = {10.1002/j.1538-7305.1940.tb00843.x},
  file       = {:FILES/1940 - Dudley1940 - The carrier nature of speech.pdf:PDF},
  groups     = {ASR},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/document/6768033},
}

@Article{Elias1955,
  author   = {Elias, Peter},
  journal  = {IRE Transactions on Information Theory},
  title    = {Predictive coding--{Parter I}},
  year     = {1955},
  issn     = {2168-2712},
  month    = mar,
  number   = {1},
  pages    = {16--24},
  volume   = {1},
  abstract = {Predictive coding is a procedure for transmitting messages which are sequences of magnitudes. In this coding method, the transmitter and the receiver store past message terms, and from them estimate the value of the next message term. The transmitter transmits, not the message term, but the difference between it and its predicted value. At the receiver this error term is added to the receiver prediction to reproduce the message term. This procedure is defined and messages, prediction, entropy, and ideal coding are discussed to provide a basis for Part II, which will give the mathematical criterion for the best predictor for use in the predictive coding of particular messages, will give examples of such messages, and will show that the error term which is transmitted in predictive coding may always be coded efficiently.},
  comment  = {first proposal of LPC},
  doi      = {10.1109/TIT.1955.1055126},
  file     = {:FILES/1955 - Elias1955 - Predictive coding--{Parter I}.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/1055126?arnumber=1055126},
}

@Article{Elias1955a,
  author   = {Elias, Peter},
  journal  = {IRE Transactions on Information Theory},
  title    = {Predictive coding--{Part II}},
  year     = {1955},
  issn     = {2168-2712},
  month    = {March},
  number   = {1},
  pages    = {24-33},
  volume   = {1},
  abstract = {In Part I predictive coding was defined and messages, prediction, entropy, and ideal coding were discussed. In the present paper the criterion to be used for predictors for the purpose of predictive coding is defined: that predictor is optimum in the information theory (IT) sense which minimizes the entropy of the average error-term distribution. Ordered averages of distributions are defined and it is shown that if a predictor gives an ordered average error term distribution it will be a best IT predictor. Special classes of messages are considered for which a best IT predictor can easily be found, and some examples are given. The error terms which are transmitted in predictive coding are treated as if they were statistically independent. If this is indeed the case, or a good approximation, then it is still necessary to show that sequences of message terms which are statistically independent may always be coded efficiently, without impractically large memory requirements, in order to show that predictive coding may be practical and efficient in such cases. This is done in the final section of this paper.},
  comment  = {first proposal of LPC},
  doi      = {10.1109/TIT.1955.1055116},
  file     = {:FILES/1955 - Elias1955a - Predictive coding--{Part II}.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/1055116},
}

@Article{Atal1970,
  author   = {Atal, B. S. and Schroeder, M. R.},
  journal  = {The Bell System Technical Journal},
  title    = {Adaptive predictive coding of speech signals},
  year     = {1970},
  issn     = {0005-8580},
  month    = oct,
  number   = {8},
  pages    = {1973--1986},
  volume   = {49},
  abstract = {We describe in this paper a method for efficient encoding of speech signals, based on predictive coding. In this coding method, both the transmitter and the receiver estimate the signal's current value by linear prediction on the previously transmitted signal. The difference between this estimate and the true value of the signal is quantized, coded and transmitted to the receiver. At the receiver, the decoded difference signal is added to the predicted signal to reproduce the input speech signal. Because of the nonstationary nature of the speech signals, an adaptive linear predictor is used, which is readjusted periodically to minimize the mean-square error between the predicted and the true value of the signals. The predictive coding system was simulated on a digital computer. The predictor parameters, comprising one delay and nine other coefficients related to the signal spectrum, were readjusted every 5 milliseconds. The speech signal was sampled at a rate of 6.67 kHz, and the difference signal was quantized by a two-level quantizer with variable step size. Subjective comparisons with speech from a logarithmic PCM encoder (log-PCM) indicate that the quality of the synthesized speech signal from the predictive coding system is approximately equal to that of log-PCM speech encoded at 6 bits/sample. Preliminary studies suggest that the binary difference signal and the predictor parameters together can be transmitted at approximately 10 kilobits/second which is several times less than the bit rate required for log-PCM encoding with comparable speech quality.},
  doi      = {10.1002/j.1538-7305.1970.tb04297.x},
  file     = {:FILES/1970 - Atal1970 - Adaptive predictive coding of speech signals.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/6769531},
}

@Article{Rabiner1989,
  author   = {Rabiner, Lawrebce R.},
  journal  = {Proceedings of the IEEE},
  title    = {A tutorial on hidden {Markov} models and selected applications in speech recognition},
  year     = {1989},
  issn     = {1558-2256},
  month    = feb,
  number   = {2},
  pages    = {257--286},
  volume   = {77},
  abstract = {This tutorial provides an overview of the basic theory of hidden Markov models (HMMs) as originated by L.E. Baum and T. Petrie (1966) and gives practical details on methods of implementation of the theory along with a description of selected applications of the theory to distinct problems in speech recognition. Results from a number of original sources are combined to provide a single source of acquiring the background required to pursue further this area of research. The author first reviews the theory of discrete Markov chains and shows how the concept of hidden states, where the observation is a probabilistic function of the state, can be used effectively. The theory is illustrated with two simple examples, namely coin-tossing, and the classic balls-in-urns system. Three fundamental problems of HMMs are noted and several practical techniques for solving these problems are given. The various types of HMMs that have been studied, including ergodic as well as left-right models, are described.<>},
  doi      = {10.1109/5.18626},
  file     = {:FILES/1989 - Rabiner1989 - A tutorial on hidden {Markov} models and selected applications in speech recognition.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/18626},
}

@Article{Fletcher1922,
  author     = {Fletcher, Harvey},
  journal    = {The Bell System Technical Journal},
  title      = {The nature of speech and its interpretation},
  year       = {1922},
  issn       = {0005-8580},
  month      = jul,
  number     = {1},
  pages      = {129--144},
  volume     = {1},
  abstract   = {VARIOUS phases of this subject have received serious study by phoneticians, otologists, and physicists. On account of its universal interest, it has received attention from men in many branches of science. In spite of the large amount of time devoted to the subject, the progress in understanding its fundamental aspects has been rather slow. At the present time the physical properties which differentiate the various fundamental speech sounds are understood in only a very fragmentary way. Some very interesting and painstaking work has been done on the physical analysis of vowel sounds, but the results to date are far from conclusive. Although several theories have been advanced to explain the way in which the ear interprets sound waves, they are still in the controversial stage.},
  comment    = {本文主要探索了speech and hearing之间的关系，即声音发送和接收信号的性质对接收端对信息理解的影响，如强度、频率等。},
  doi        = {10.1002/j.1538-7305.1922.tb00384.x},
  file       = {:FILES/1922 - Fletcher1922 - The nature of speech and its interpretation.pdf:PDF},
  groups     = {ASR},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/document/6773299},
}

@Article{Vintsyuk1968,
  author  = {Vintsyuk, T. K.},
  journal = {Cybernetics},
  title   = {Speech discrimination by dynamic programming},
  year    = {1968},
  issn    = {1573-8337},
  month   = jan,
  number  = {1},
  pages   = {52--57},
  volume  = {4},
  comment = {proposal of DTW},
  doi     = {10.1007/BF01074755},
  file    = {:FILES/1968 - Vintsyuk1968 - Speech discrimination by dynamic programming.pdf:PDF},
  groups  = {ASR},
  url     = {https://link.springer.com/article/10.1007/BF01074755},
}

@Article{Linde1980,
  author   = {Linde, Yoseph and Buzo, Andres and Gray, Robert M.},
  journal  = {IEEE Transactions on Communications},
  title    = {An algorithm for vector quantizer design},
  year     = {1980},
  issn     = {1558-0857},
  month    = jan,
  number   = {1},
  pages    = {84--95},
  volume   = {28},
  abstract = {An efficient and intuitive algorithm is presented for the design of vector quantizers based either on a known probabilistic model or on a long training sequence of data. The basic properties of the algorithm are discussed and demonstrated by examples. Quite general distortion measures and long blocklengths are allowed, as exemplified by the design of parameter vector quantizers of ten-dimensional vectors arising in Linear Predictive Coded (LPC) speech compression with a complicated distortion measure arising in LPC analysis that does not depend only on the error vector.},
  comment  = {proposal of VQ},
  doi      = {10.1109/TCOM.1980.1094577},
  file     = {:FILES/1980 - Linde1980 - An algorithm for vector quantizer design.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/1094577},
}

@Article{Rabiner1979,
  author   = {Rabiner, Lawrence R. and Levinson, Stephen E. and Rosenberg, Arron E. and Wilpon, Jay G.},
  journal  = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  title    = {Speaker-independent recognition of isolated words using clustering techniques},
  year     = {1979},
  issn     = {0096-3518},
  month    = aug,
  number   = {4},
  pages    = {336--349},
  volume   = {27},
  abstract = {A speaker-independent isolated word recognition system is described which is based on the use of multiple templates for each word in the vocabulary. The word templates are obtained from a statistical clustering analysis of a large database consisting of 100 replications of each word (i.e., once by each of 100 talkers). The recognition system, which accepts telephone quality speech input, is based on an LPC analysis of the unknown word, dynamic time warping of each reference template to the unknown word (using the Itakura LPC distance measure), and the application of a K-nearest neighbor (KNN) decision rule. Results for several test sets of data are presented. They show error rates that are comparable to, or better than, those obtained with speaker-trained isolated word recognition systems.},
  doi      = {10.1109/TASSP.1979.1163259},
  file     = {:FILES/1979 - Rabiner1979 - Speaker-independent recognition of isolated words using clustering techniques.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/1163259},
}

@Article{Itakura1975,
  author   = {Itakura, Fumitada},
  journal  = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  title    = {Minimum prediction residual principle applied to speech recognition},
  year     = {1975},
  issn     = {0096-3518},
  month    = feb,
  number   = {1},
  pages    = {67--72},
  volume   = {23},
  abstract = {A computer system is described in which isolated words, spoken by a designated talker, are recognized through calculation of a minimum prediction residual. A reference pattern for each word to be recognized is stored as a time pattern of linear prediction coefficients (LPC). The total log prediction residual of an input signal is minimized by optimally registering the reference LPC onto the input autocorrelation coefficients using the dynamic programming algorithm (DP). The input signal is recognized as the reference word which produces the minimum prediction residual. A sequential decision procedure is used to reduce the amount of computation in DP. A frequency normalization with respect to the long-time spectral distribution is used to reduce effects of variations in the frequency response of telephone connections. The system has been implemented on a DDP-516 computer for the 200-word recognition experiment. The recognition rate for a designated male talker is 97.3 percent for telephone input, and the recognition time is about 22 times real time.},
  doi      = {10.1109/TASSP.1975.1162641},
  file     = {:FILES/1975 - Itakura1975 - Minimum prediction residual principle applied to speech recognition.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/1162641},
}

@Article{Atal1971,
  author  = {Atal, B. S. and Hanauer, Suzanne L.},
  journal = {The Journal of the Acoustical Society of America},
  title   = {Speech analysis and synthesis by linear prediction of the speech wave},
  year    = {1971},
  number  = {2B},
  pages   = {637--655},
  volume  = {50},
  doi     = {10.1121/1.1912679},
  file    = {:FILES/1971 - Atal1971 - Speech Analysis and Synthesis by Linear Prediction of the Speech Wave.pdf:PDF},
  groups  = {ASR},
  url     = {https://asa.scitation.org/doi/10.1121/1.1912679},
}

@TechReport{Martin1964,
  author      = {Martin, T. and Nelson, A. and Zadell, H.},
  institution = {Air Force Avionics Laboratory},
  title       = {Speech recognition by feature abstraction techniques},
  year        = {1964},
  file        = {:FILES/1964 - Martin1964 - Speech recognition by feature abstraction techniques.pdf:PDF},
  groups      = {ASR},
}

@Article{Reddy1966,
  author  = {Reddy,D. R.},
  journal = {The Journal of the Acoustical Society of America},
  title   = {Approach to Computer Speech Recognition by Direct Analysis of the Speech Wave},
  year    = {1966},
  number  = {5},
  pages   = {1273-1273},
  volume  = {40},
  doi     = {10.1121/1.2143468},
  eprint  = {https://doi.org/10.1121/1.2143468},
  groups  = {ASR},
  url     = {https://doi.org/10.1121/1.2143468},
}

@InBook{Juang2008,
  author     = {{Biing-Hwang} Juang and Lawrence R. Rabiner},
  chapter    = {26},
  pages      = {519--537},
  publisher  = {Springer-Verlag Berlin Heidelberg},
  title      = {Historical perspective of the field of {ASR/NLU}},
  year       = {2008},
  isbn       = {978-3-540-49125-5},
  booktitle  = {Springer handbook of speech recognition},
  file       = {:FILES/2008 - Juang2008 - Historical perspective of the field of {ASRNLU}.pdf:PDF},
  groups     = {ASR},
  readstatus = {read},
}

@Article{Wilpon1990,
  author   = {Wilpon, Jay G. and Rabiner, Lawrence R. and Lee, Chin-Hui and Goldman, E. R.},
  journal  = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  title    = {Automatic recognition of keywords in unconstrained speech using hidden {Markov} models},
  year     = {1990},
  issn     = {0096-3518},
  month    = nov,
  number   = {11},
  pages    = {1870--1878},
  volume   = {38},
  abstract = {The modifications made to a connected word speech recognition algorithm based on hidden Markov models (HMMs) which allow it to recognize words from a predefined vocabulary list spoken in an unconstrained fashion are described. The novelty of this approach is that statistical models of both the actual vocabulary word and the extraneous speech and background are created. An HMM-based connected word recognition system is then used to find the best sequence of background, extraneous speech, and vocabulary word models for matching the actual input. Word recognition accuracy of 99.3% on purely isolated speech (i.e., only vocabulary items and background noise were present), and 95.1% when the vocabulary word was embedded in unconstrained extraneous speech, were obtained for the five word vocabulary using the proposed recognition algorithm.<>},
  doi      = {10.1109/29.103088},
  file     = {:FILES/1990 - Wilpon1990 - Automatic recognition of keywords in unconstrained speech using hidden Markov models.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/103088},
}

@InCollection{Lowerre1990,
  author    = {Bruce Lowerre and Raj Reddy},
  booktitle = {Readings in Speech Recognition},
  publisher = {Morgan Kaufmann},
  title     = {The {HARPY} speech understanding system},
  year      = {1990},
  address   = {San Francisco},
  editor    = {Alex Waibel and {Kai-Fu} Lee},
  isbn      = {978-1-55860-124-6},
  pages     = {576--586},
  doi       = {https://doi.org/10.1016/B978-0-08-051584-7.50053-X},
  file      = {:FILES/1990 - Lowerre1990 - The HARPY speech understanding system.pdf:PDF},
  groups    = {ASR},
  url       = {https://www.sciencedirect.com/science/article/pii/B978008051584750053X},
}

@Article{Rabiner1983,
  author   = {Rabiner, Lawrence R. and Levinson, Stephen E. and Sondhi, Mohan M.},
  journal  = {The Bell System Technical Journal},
  title    = {On the application of vector quantization and hidden {Markov} models to speaker-independent, isolated word recognition},
  year     = {1983},
  issn     = {0005-8580},
  month    = apr,
  number   = {4},
  pages    = {1075--1105},
  volume   = {62},
  abstract = {In this paper we present an approach to speaker-independent, isolated word recognition in which the well-known techniques of vector quantization and hidden Markov modeling are combined with a linear predictive coding analysis front end. This is done in the framework of a standard statistical pattern recognition model. Both the vector quantizer and the hidden Markov models need to be trained for the vocabulary being recognized. Such training results in a distinct hidden Markov model for each word of the vocabulary. Classification consists of computing the probability of generating the test word with each word model and choosing the word model that gives the highest probability. There are several factors, in both the vector quantizer and the hidden Markov modeling, that affect the performance of the overall word recognition system, including the size of the vector quantizer, the structure of the hidden Markov model, the ways of handling insufficient training data, etc. The effects, on recognition accuracy, of many of these factors are discussed in this paper. The entire recognizer (training and testing) has been evaluated on a 10-word digits vocabulary. For training, a set of 100 talkers spoke each of the digits one time. For testing, an independent set of 100 tokens of each of the digits was obtained. The overall recognition accuracy was found to be 96.5 percent for the 100-talker test set. These results are comparable to those obtained in earlier work, using a dynamic time-warping recognition algorithm with multiple templates per digit. It is also shown that the computation and storage requirements of the new recognizer were an order of magnitude less than that required for a conventional pattern recognition system using linear prediction with dynamic time warping.},
  doi      = {10.1002/j.1538-7305.1983.tb03115.x},
  file     = {:FILES/1983 - Rabiner1983 - On the application of vector quantization and hidden Markov models to speaker-independent, isolated word recognition.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/6768245},
}

@Article{Lippmann1989,
  author   = {Lippmann, Richard P.},
  journal  = {Neural Computation},
  title    = {Review of neural networks for speech recognition},
  year     = {1989},
  issn     = {0899-7667},
  month    = mar,
  number   = {1},
  pages    = {1--38},
  volume   = {1},
  abstract = {The performance of current speech recognition systems is far below that of humans. Neural nets offer the potential of providing massive parallelism, adaptation, and new algorithmic approaches to problems in speech recognition. Initial studies have demonstrated that multilayer networks with time delays can provide excellent discrimination between small sets of pre-segmented difficult-to-discriminate words, consonants, and vowels. Performance for these small vocabularies has often exceeded that of more conventional approaches. Physiological front ends have provided improved recognition accuracy in noise and a cochlea filter-bank that could be used in these front ends has been implemented using micro-power analog VLSI techniques. Techniques have been developed to scale networks up in size to handle larger vocabularies, to reduce training time, and to train nets with recurrent connections. Multilayer perceptron classifiers are being integrated into conventional continuous-speech recognizers. Neural net architectures have been developed to perform the computations required by vector quantizers, static pattern classifiers, and the Viterbi decoding algorithm. Further work is necessary for large-vocabulary continuous-speech problems, to develop training algorithms that progressively build internal word models, and to develop compact VLSI neural net hardware.},
  comment  = {NN +SR早期研究},
  doi      = {10.1162/neco.1989.1.1.1},
  file     = {:FILES/1989 - Lippmann1989 - Review of Neural Networks for Speech Recognition.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/6796621},
}

@Article{Juang1992,
  author   = {Juang, {Biing-Hwang}. and Katagiri, Shigeru},
  journal  = {IEEE Transactions on Signal Processing},
  title    = {Discriminative learning for minimum error classification},
  year     = {1992},
  issn     = {1941-0476},
  month    = dec,
  number   = {12},
  pages    = {3043--3054},
  volume   = {40},
  abstract = {A formulation is proposed for minimum-error classification, in which the misclassification probability is to be minimized based on a given set of training samples. A fundamental technique for designing a classifier that approaches the objective of minimum classification error in a more direct manner than traditional methods is given. The method is contrasted with several traditional classifier designs in typical experiments to demonstrate the superiority of the new learning formulation. The method can applied to other classifier structures as well. Experimental results pertaining to a speech recognition task are provided to show the effectiveness of the technique.<>},
  doi      = {10.1109/78.175747},
  file     = {:FILES/1992 - Juang1992 - Discriminative learning for minimum error classification.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/175747},
}

@Article{Juang1997,
  author   = {{Biing-Hwang} Juang and Wu Hou and {Chin-Hui} Lee},
  journal  = {IEEE Transactions on Speech and Audio Processing},
  title    = {Minimum classification error rate methods for speech recognition},
  year     = {1997},
  issn     = {1558-2353},
  month    = may,
  number   = {3},
  pages    = {257--265},
  volume   = {5},
  abstract = {A critical component in the pattern matching approach to speech recognition is the training algorithm, which aims at producing typical (reference) patterns or models for accurate pattern comparison. In this paper, we discuss the issue of speech recognizer training from a broad perspective with root in the classical Bayes decision theory. We differentiate the method of classifier design by way of distribution estimation and the discriminative method of minimizing classification error rate based on the fact that in many realistic applications, such as speech recognition, the real signal distribution form is rarely known precisely. We argue that traditional methods relying on distribution estimation are suboptimal when the assumed distribution form is not the true one, and that "optimality" in distribution estimation does not automatically translate into "optimality" in classifier design. We compare the two different methods in the context of hidden Markov modeling for speech recognition. We show the superiority of the minimum classification error (MCE) method over the distribution estimation method by providing the results of several key speech recognition experiments. In general, the MCE method provides a significant reduction of recognition error rate.},
  doi      = {10.1109/89.568732},
  file     = {:FILES/1997 - Juang1997 - Minimum classification error rate methods for speech recognition.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/568732},
}

@Article{Baker1975,
  author   = {Baker, James K.},
  journal  = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
  title    = {The {DRAGON} system--{An} overview},
  year     = {1975},
  issn     = {0096-3518},
  month    = feb,
  number   = {1},
  pages    = {24--29},
  volume   = {23},
  abstract = {This paper briefly describes the major features of the DRAGON speech understanding system. DRAGON makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech. The model--that of a probabilistic function of a Markov process--is very flexible and leads to features which allow DRAGON to function despite high error rates from individual knowledge sources. Repeated use of a simple abstract model produces a system which is simple in structure, but powerful in capabilities.},
  comment  = {将SR建模为Markov Process},
  doi      = {10.1109/TASSP.1975.1162650},
  file     = {:FILES/1975 - Baker1975 - The DRAGON system--An overview.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/1162650},
}

@Article{Makhoul1973,
  author   = {Makhoul, John},
  journal  = {IEEE Transactions on Audio and Electroacoustics},
  title    = {Spectral analysis of speech by linear prediction},
  year     = {1973},
  issn     = {1558-2582},
  month    = jun,
  number   = {3},
  pages    = {140--148},
  volume   = {21},
  abstract = {The autocorrelation method of linear prediction is formulated in the time, autocorrelation, and spectral domains. The analysis is shown to be that of approximating the short-time signal power spectrum by an all-pole spectrum. The method is compared with other methods of spectral analysis such as analysis-by-synthesis and cepstral smoothing. It is shown that this method can be regarded as another method of analysis-by-synthesis where a number of poles is specified, with the advantages of noniterative computation and an error measure which leads to a better spectral envelope fit for an all-pole spectrum. Compared to spectral analysis by cepstral smoothing in conjunction with the chirp z transform (CZT), this method is expected to give a better spectral envelope fit (for an all-pole spectrum) and to be less sensitive to the effects of high pitch on the spectrum. The normalized minimum error is defined and its possible usefulness as a voicing detector is discussed.},
  comment  = {LPC + SR},
  doi      = {10.1109/TAU.1973.1162470},
  file     = {:FILES/1973 - Spectral analysis of speech by linear prediction.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/1162470},
}

@Article{Baum1972,
  author   = {Lenard E. Baum},
  journal  = {Inequalities},
  title    = {An inequality and associated maximization technique in statistical estimation for probabilistic functions of {Markov} processes},
  year     = {1972},
  pages    = {1--8},
  volume   = {3},
  abstract = {HMM 优化算法Baum-Welch algorithm},
  file     = {:FILES/1972 - Baum1972 - An inequality and associated maximization technique in statistical estimation for probabilistic functions of {Markov} processes.pdf:PDF},
  groups   = {ASR, machine learning},
}

@Article{Mohri1997,
  author  = {Mohri, Mehryar},
  journal = {Computational Linguistics},
  title   = {Finite-state tranducers in language and speech processing},
  year    = {1997},
  number  = {2},
  pages   = {269--311},
  volume  = {23},
  comment = {FSN的搜索算法},
  file    = {:FILES/1997 - Mohri1997 - Finite-state tranducers in language and speech processing.pdf:PDF},
  groups  = {ASR},
}

@Article{Jelinek1976,
  author   = {Jelinek, Frederick},
  journal  = {Proceedings of the IEEE},
  title    = {Continuous speech recognition by statistical methods},
  year     = {1976},
  issn     = {1558-2256},
  month    = apr,
  number   = {4},
  pages    = {532--556},
  volume   = {64},
  abstract = {Statistical methods useful in automatic recognition of continuous speech are described. They concern modeling of a speaker and of an acoustic processor, extraction of the models' statistical parameters and hypothesis search procedures and likelihood computations of linguistic decoding. Experimental results are presented that indicate the power of the methods.},
  comment  = {HMM + SR},
  doi      = {10.1109/PROC.1976.10159},
  file     = {:FILES/1976 - Jelinek1976 - Continuous speech recognition by statistical methods.pdf:PDF},
  groups   = {ASR},
  url      = {https://ieeexplore.ieee.org/document/1454428},
}

@Article{VillamarGomez2021,
  author     = {L. {Villamar G\'{o}mez} and J. Miura},
  journal    = {Robotics and Autonomous Systems},
  title      = {Ontology-based knowledge management with verbal interaction for command interpretation and execution by home service robots},
  year       = {2021},
  issn       = {0921-8890},
  month      = jun,
  pages      = {103763},
  volume     = {140},
  abstract   = {This paper describes a system for service robots that combines ontological knowledge reasoning and human–robot interaction to interpret natural language commands and successfully perform household chores, such as finding and delivering objects. Knowledge and context reasoning is essential for providing more efficient service robots, given their diverse and continuously changing environments. Moreover, since they are in contact with humans, robots require such skills as interaction and language. Therefore, we developed a system with specific modules to manage robots’ knowledge and reasoning, command analysis, decision-making, and talking interaction. The system relies on inference methods and verbal interaction to understand commands and clarify uncertain information. We tested our system inside a simulated environment where the robot receives commands with missing or unclear information. The system’s performance was compared with the average performance of human subjects who completed the same commands in the simulation.},
  comment    = {本文设计的机器人主要面向household service，包括了三个模块：知识库、command analysis, task planning and execution。其中任务理解部分的主要方法如下：
1. 利用Stanford CoreNLP获得文本指令的POS tagging, dependency等，
2. 利用关键字进行搜索，找到对应的task，
3. 针对task中缺失或有多种可能的信息，利用KB或dialog system进行消岐
分析：
1. 机器人可执行的动作有限，共有6种，且每种任务已定义好相关要素、关键字、同义词等信息
2. 任务涉及的要素只包括对象、位置两种
3. 语音生成和SR没有提及工具
4. 定义了问题模板，只能对固定的内容进行提问
5. 文章并未对任务理解过程进行实验验证
6. ontology基于KnowRob},
  doi        = {10.1016/j.robot.2021.103763},
  file       = {:FILES/2021 - VillamarGomez2021 - Ontology-based knowledge management with verbal interaction for command interpretation and execution by home service robots.pdf:PDF},
  groups     = {task understanding, ontology based},
  keywords   = {Knowledge management, Ontology-based, Service robots, Human–robot interaction, read},
  printed    = {Y},
  readstatus = {read},
  url        = {https://www.sciencedirect.com/science/article/pii/S0921889021000488},
}

@InProceedings{Bandara2018,
  author     = {Bandara, H. M. Ravindu T. and Muthugala, M. A. Viraj J. and Jayasekara, A. G. Buddhika P. and Chandima, D. P.},
  booktitle  = {Proceedings of the 2018 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  title      = {Grounding object attributes through interactive discussion for building cognitive maps in service robots},
  year       = {2018},
  address    = {Miyazaki, Japan},
  month      = oct,
  pages      = {3775--3780},
  publisher  = {IEEE},
  abstract   = {Assistive robots are developed to uplift living standards of human being. An assistive robot needs to be friendly, reliable, and understandable in order to be a human like companion. A robot should be able to understand its user effectively and the robot should be able to expand its knowledge based on experience gain from activities or conversations. Therefore the assistive robot should have a memory and a knowledge base regarding objects that it comes across in daily activities. It should be able to process data and understand relationships between attributes of objects to self-understand the need of a user. Therefore this paper propose a method to create an object memory and a knowledge base to understand relations between objects attributes and create a cognitive map to enhance interaction between human and robot which will help to make a robot more human-friendly. Conversation Management Module (CMM), Attribute Analyzing Module (AMM) and Object Knowledge Base (OKB) have been introduced in order to create a cognitive map of objects. Capabilities of the robot have been demonstrated and evaluated from experimental results.},
  comment    = {本文提出了一种知识库的表达形式，主要是对环境中物体的物体进行描述，所利用的信息是物体的属性。主要点：
1. 利用的物体属性有6种，包括颜色、形状等。
2. 物体与属性相关联，物体与物体直接关联（当有相同属性时）
3. cognitive map是可以动态变化的
4. 数据的采集手段是让参与者对物体进行描述，从其所说语句中提取响应描述，再分析，分析方法没有提
5. 机器人可以利用cognitive map进行简单的问答，如问物体的属性等，不涉及机器人动作相关任务
6. 收集双人会话中基于物体属性的问答，extract question (10) and answer (9) patterns。机器人的问答只能在这些固定pattern下实现。
本文没有关于理解部分的说明，所用的工具也没有说，如ASR、SG等},
  doi        = {10.1109/SMC.2018.00639},
  file       = {:FILES/2018 - Bandara2018 - Grounding Object Attributes Through Interactive Discussion for Building Cognitive Maps in Service Robots.pdf:PDF},
  groups     = {spatial relation},
  issn       = {2577-1655},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/8616636},
}

@InProceedings{Angleraud2018,
  author     = {Angleraud, Alexandre and Houbre, Quentin and Kyrki, Ville and Pieters, Roel},
  booktitle  = {Proceedings of 2018 IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},
  title      = {Human-robot interactive learning architecture using ontologies and symbol manipulation},
  year       = {2018},
  address    = {Nanjing, China},
  month      = aug,
  pages      = {384--389},
  publisher  = {IEEE},
  abstract   = {Robotic systems developed for support can provide assistance in various ways. However, regardless of the service provided, the quality of user interaction is key to adoption by the general public. Simple communication difficulties, such as terminological differences, can make or break the acceptance of robots. In this work we take into account these difficulties in communication between a human and a robot. We propose a system that allows to handle unknown concepts through symbol manipulation based on natural language interactions. In addition, ontologies are used as a convenient way to store the knowledge and reason about it. To demonstrate the use of our system, two scenarios are described and tested with a Care-O-Bot 4. The experiments show that confusions and difficulties in communication can effectively be resolved through symbol manipulation.},
  comment    = {本文的主要内容是建立一个framework,以处理unknown concept  on the current knowledge of the robot.
1. 该框架包括4部分, input layer, reasoning layer, action layer, knowledge base
2. KB采用了KnowRob
3. input layer实现的是从speech to formalized concept, i.e., action-object pair,所利用的工具是 Google Recognition Engine(speech to text),
4. 人机对话部分是采用activation keyword,即以固定结构的语句教会机器人新的知识,人机对话的管理(speech recognition module)是利用state machine,
5. 系统执行包括两种模式,一种是下达指令而机器人已知该指令进而执行,其二是未知指令,而机器人从对话中学习到新知识.
主要问题:
1. 只讨论了action,或action-object,未涉及包含更复杂结构的action,因而状态机的设计具有局限性
2. 假设speech-to-text的结果是正确的,且人知道问题的正确答案.
3. 限制了conversation的形式,而不是human-like communication
4. 语音识别模块耗时长
5. 对语音信号的要求高,只适用于单人模式
6. 只涉及conceptual knowledge,并未与环境信息相结合,或与机器人本体的执行相关联.
7. 未知concept与knowledge base中的已知concept之间的相似性是如何度量的?},
  doi        = {10.1109/ROMAN.2018.8525580},
  file       = {:FILES/2018 - Angleraud2018 - Human-Robot Interactive Learning Architecture using Ontologies and Symbol Manipulation.pdf:PDF},
  groups     = {task understanding},
  issn       = {1944-9437},
  keywords   = {read},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/8525580},
}

@InProceedings{Jeon2018,
  author     = {Jeon, Hwawoo and Yang, {Kyon-Mo} and Park, Sungkee and Choi, Jongsuk and Lim, Yoonseob},
  booktitle  = {Proceedings of 2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},
  title      = {An ontology-based home care service robot for persons with dementia},
  year       = {2018},
  address    = {Nanjing, China},
  month      = aug,
  pages      = {540--545},
  publisher  = {IEEE},
  abstract   = {In this paper, we introduce an ontology-based home care service robot that can provide personalized care for people who are in the early stage of dementia. The hardware and software framework encompassed in the proposed service robot was developed to carry out care services in their daily life at home. Specifically, to generate adaptive task plans in diverse caring situation, context reasoner and ontological model of dementia are included. Ontology includes various concepts that are related with the knowledge of caring dementia patient: dementia, dementia symptom, environment of around patient, and situation during patient's daily life. To evaluate if the proposed service robot could provide appropriate care service or not, experimental care scenario for helping a person with dementia take medicine was tried in the lab environment. Although tasks of the robot required for the experiment are rather simple, we have demonstrated that the robot could provide a personalized service that may be beneficial to dementia patient, family members and caregivers. In the future, we will add more care knowledge in the ontology and further develop a variety of care services. Additionally, we are going to test the care service robot in a real environment with actual dementia patient.},
  comment    = {本文的主要工作是设计并实现了一种用以辅助person with dementia的家庭服务机器人，主要内容：
1. 包括本体外形设计、具备视觉感知、语音识别、本体移动的功能，可以实现emergence detectioin, information notification, recommendation, social connection等功能，
2. 软件系统包括knowledge base， task manager, context reasoner, action component等部分
3. KB是基于KnowRob，主要包括person, assessment (疾病及诊断信息等)、event (起床、吃饭、吃药等需病人执行的动作)、environment、common knowledge五种类型及其子类型
4.推理是利用Prolog实现的，
问题：
1. 不具备物体操作能力
2. 能够将病人需要执行的动作进行分解，但是文中未提及complex task in dynamic environment，
3. 系统弱化了goal generation的过程，即是否从语音对话中提取目标任务
4.只面向特定领域，扩展性未知

其他：
文献[16]是基于ontology进行推理，即robot需要为病人执行什么操作，而后基于环境信息执行相关动作。
[15]是提出了一种ontology for persons with dementia},
  doi        = {10.1109/ROMAN.2018.8525668},
  file       = {:FILES/2018 - Jeon2018 - An Ontology-based Home Care Service Robot for Persons with Dementia.pdf:PDF},
  groups     = {robot},
  issn       = {1944-9437},
  printed    = {P},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/8525668},
}

@InProceedings{Kobayashi2011,
  author    = {Kobayashi, Shotaro and Tamagawa, Susumu and Morita, Takeshi and Yamaguchi, Takahira},
  booktitle = {Proceedings of the 6th International Conference on Human-Robot Interaction},
  title     = {Intelligent humanoid robot with {Japanese} {Wikipedia} ontology and robot action ontology},
  year      = {2011},
  address   = {New York, NY, USA},
  pages     = {417--424},
  publisher = {Association for Computing Machinery},
  series    = {HRI '11},
  abstract  = {WioNA (Wikipedia Ontology NAo) is proposed to build much better HRI by integrating four elements: Japanese speech interface, semantic interpretation, Japanese Wikipedia Ontology and Robot Action Ontology. WioNA is implemented on a humanoid robot "Nao". In WioNA, we developed two ontologies: Japanese Wikipedia Ontology and Robot Action Ontology. Japanese Wikipedia Ontology has a large size of concept hierarchy and instance network with many properties from Japanese Wikipedia (semi) automatically. By giving Japanese Wikipedia Ontology to Nao as wisdom, Nao can dialogue with users on many topics of various fields. Robot Action Ontology, in contrast, is built by organizing various performable actions of Nao to control and generate robot actions. Aligning Robot Action Ontology with Japanese Wikipedia Ontology enables Nao to perform related actions to dialogue topics. To show the validities of WioNA, we describe human-robot conversation logs of two case studies whose dialogue topics are sport and rock singer. These case studies show us how HRI goes well in WioNA with these topics.},
  comment   = {ReforgiatoRecupero2020：利用Japanese Wikipedia ontology来支撑机器人与人的交互，可以识别自然语言并关联到相关的动作以完成后续操作。},
  doi       = {10.1145/1957656.1957811},
  file      = {:FILES/2011 - Kobayashi2011 - Intelligent Humanoid Robot with Japanese Wikipedia Ontology and Robot Action Ontology.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781450305617},
  keywords  = {semantic web, japanese wikipedia ontology, dialogue, action, japanese speech interface, robot action ontology},
  location  = {Lausanne, Switzerland},
  url       = {https://dl.acm.org/doi/10.1145/1957656.1957811},
}

@InProceedings{Fukuda2013,
  author    = {Fukuda, Hisato and Mori, Satoshi and Kobayashi, Yoshinori and Kuno, Yoshinori and Kachi, Daisuke},
  booktitle = {Advances in Visual Computing},
  title     = {Object recognition for service robots through verbal interaction based on ontology},
  year      = {2013},
  address   = {Berlin, Heidelberg},
  editor    = {Bebis, George and Boyle, Richard and Parvin, Bahram and Koracin, Darko and Li, Baoxin and Porikli, Fatih and Zordan, Victor and Klosowski, James and Coquillart, Sabine and Luo, Xun and Chen, Min and Gotz, David},
  pages     = {395--406},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {We are developing a helper robot able to fetch objects requested by users. This robot tries to recognize objects through verbal interaction with the user concerning objects that it cannot detect autonomously. Since the robot recognizes objects based on verbal interaction with the user, such a robot must by necessity understand human descriptions of said objects. However, humans describe objects in various ways: they may describe attributes of whole objects, those of parts, or those viewable from a certain direction. Moreover, they may use the same descriptions to describe a range of different objects. In this paper, we propose an ontological framework for interactive object recognition to deal with such varied human descriptions. In particular, we consider human descriptions about object attributes, and develop an interactive object recognition system based on this ontology.},
  comment   = {ReforgiatoRecupero2020：developed a helper robot able to pick objects requested by users, recognizing objects based on verbal interaction. They proposed an ontological framework for interactive object recognition which had to deal with text in open domain},
  doi       = {10.1007/978-3-642-41914-0_39},
  file      = {:FILES/2013 - Fukuda2013 - Object Recognition for Service Robots through Verbal Interaction Based on Ontology.pdf:PDF},
  groups    = {task understanding},
  isbn      = {978-3-642-41914-0},
  url       = {https://link.springer.com/chapter/10.1007/978-3-642-41914-0_39},
}

@Article{Markievicz2015,
  author     = {Irena Markievicz and Jurgita Kapo\v{c}i\={u}tė-Dzikienė and Minija Tamo\v{s}i\={u}naitė and Daiva Vitkutė-Ad\v{z}gauskienė},
  journal    = {Information Technology and Control},
  title      = {Action classification in action ontology building using robot-specific texts},
  year       = {2015},
  issn       = {1392-124X},
  month      = jun,
  note       = {usepackage{newunicodechar}newunicodechar{ė}{.{e}}},
  number     = {2},
  pages      = {155--164},
  volume     = {44},
  comment    = {ReforgiatoRecupero2020： ACAT项目的一部分，基于WordNet ontology，构建了action和object之间的层次关系，提出了一种action environment的概念。利用有监督学习方法实现action的分类（基于自然语言）

本文侧重于研究instruction completion问题，通过adding action specific info that is not explicitly given in NL instructions.应该是将NL instruction分类为某一action category，从而利用预设的action ontology得到其中的properties等信息，但是本文只做了action classification的工作，内容补全的工作没有做。
1.determining the action category for action verbs based on the context surrounding the verb using SVM (implemented in WEKA and solved by SMO);
2.NL instructions from Web 用Stanford NLP来处理
3.输入数据是documents without verbs, 首先对document进行vectorize， each document has only one label. Window size is 200 to both sides of the verb. Features 包括 document level character n-gram, lexical bow, lemmas, stems, Morphological pos, etc共26种. 
4.结论：
(1)a context on the right of the verb should be more informative,
(2)The optimal window size is relatively small
(3)English language does not benefit from lemmatization or stemming},
  doi        = {10.5755/j01.itc.44.2.7322},
  file       = {:FILES/2015 - Markievicz2015 - Action Classification in Action Ontology Building Using Robot-Specific Texts.pdf:PDF},
  groups     = {task understanding},
  printed    = {Y},
  readstatus = {read},
  url        = {https://itc.ktu.lt/index.php/ITC/article/view/7322},
}

@Article{Taylor2015,
  author   = {Julia M. Taylor},
  journal  = {Procedia Computer Science},
  title    = {Mapping human understanding to robotic perception},
  year     = {2015},
  issn     = {1877-0509},
  note     = {Survey paper, The 10th International Conference on Future Networks and Communications (FNC 2015) / The 12th International Conference on Mobile Systems and Pervasive Computing (MobiSPC 2015) Affiliated Workshops},
  pages    = {514--519},
  volume   = {56},
  abstract = {Humans are excellent at adapting their knowledge to various situations and adjusting their communication accordingly. Thus, a person who knows a great deal about a subject can still talk about it to a child, albeit in a much more simplified form. What is of interest here is whether a robot can do the reverse: in other words, can it adjust a limited knowledge that it receives from its sensors to a more complicated knowledge of the world that it doesn’t sense, but knows only abstractly? In other words, what kind of mapping is possible to adapt sensory knowledge to a more expressive knowledge of the world (or, in some cases, less expressive). When DARwin sees a red ball, does it really know that it is a ball? Can the fact that the object is moving in certain manner be leveraged for understanding that it is a ball? Similarly, when a robot or agent has access to a very specific domain, what has to happen to relate this knowledge to a more general domain? What kind of information has to be transferred and what can be omitted? The paper will review previous research in ontology mapping and alignment and, based on the existing research, propose some of the solutions.},
  doi      = {10.1016/j.procs.2015.07.244},
  file     = {:FILES/2015 - Taylor2015 - Mapping human understanding to robotic perception.pdf:PDF},
  groups   = {task understanding},
  keywords = {robotic ontology, ontology matching, granulation manipulation},
  url      = {https://www.sciencedirect.com/science/article/pii/S1877050915017251},
}

@TechReport{VitkuteAdzgauskiene2015,
  author  = {Daiva {Vitkute-Adzgauskiene} and Jurgita Kapociute and IrenaMarkievicz and Tomas Krilavicius and Minija Tamosiunaite and Florentin W\"{o}rg\"{o}tter},
  title   = {Action ontology and object categories},
  year    = {2015},
  month   = sep,
  note    = {ACTA Project: Learning and Execution of Action Categories},
  number  = {D1.3},
  comment = {ReforgiatoRecupero2020： ACAT项目的一部分，基于WordNet ontology，构建了action和object之间的层次关系，提出了一种action environment的概念。},
  file    = {:FILES/2015 - VitkuteAdzgauskiene2015 - Action ontology and object categories.pdf:PDF},
  groups  = {representation},
  url     = {https://acat-project.eu/index298c.html?page=download},
}

@MastersThesis{吴2013,
  author  = {志华 吴},
  school  = {华南理工大学},
  title   = {机器人任务理解与软件自组装方法研究},
  year    = {2013},
  address = {广州, 广东, 中国},
  month   = nov,
  file    = {:FILES/2013 - 吴2013 - 机器人任务理解与软件自组装方法研究_吴志华.caj:caj},
  groups  = {task understanding},
  url     = {https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201401&filename=1014151649.nh&v=Ssxdab3qOYGzh10%mmd2BpgN%mmd2FDoEfqZ8890IvotcCZIlla2yowwj0Cwc7tNb4UrirhZnU},
}

@InProceedings{Branavan2009,
  author       = {Branavan, Satchuthananthavale R. K. and Chen, Harr and Zettlemoyer, Luke S. and Barzilay, Regina},
  booktitle    = {Proceedings of Joint Conference of the Meeting of the ACL \& the International Joint Conference on Natural Language Processing of the AFNLP},
  title        = {Reinforcement learning for mapping instructions to actions},
  year         = {2009},
  organization = {Association for Computational Linguistics},
  pages        = {82--90},
  file         = {:FILES/2009 - Branavan2009 - Reinforcement learning for mapping instructions to actions.pdf:PDF},
  groups       = {task understanding},
}

@InProceedings{Stock2015,
  author    = {Stock, Sebastian and Mansouri, Masoumeh and Pecora, Federico and Hertzberg, Joachim},
  booktitle = {Proceedings of the 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Online task merging with a hierarchical hybrid task planner for mobile service robots},
  year      = {2015},
  address   = {Hamburg, Germany},
  month     = sep,
  pages     = {6459--6464},
  publisher = {IEEE},
  abstract  = {Plan-based robot control has to consider a multitude of aspects of tasks at once, such as task dependency, time, space, and resource usage. Hybrid planning is a strategy for treating them jointly. However, by incorporating all these aspects into a hybrid planner, its search space is huge by construction. This paper introduces the planner CHIMP, which is based on meta-CSP planning to represent the hybrid plan space and uses hierarchical planning as the strategy for cutting efficiently through this space. The paper makes two contributions: First, it describes how HTN planning is integrated into meta-CSP reasoning leading to a planner that can reason about different forms of knowledge and that is fast enough to be used on a robot. Second, it demonstrates CHIMP's task merging capabilities, i.e., the unification of different tasks from different plan parts, resulting in plans that are more efficient to execute. It also allows to merge new tasks online into a plan that is being executed. This is demonstrated on a PR2 robot.},
  comment   = {本文是关于知识推理的，利用多源数据，如task dependency, time, space, resource usage等。提出了一种hierarchical hybrid planner，具有online capability},
  doi       = {10.1109/IROS.2015.7354300},
  file      = {:FILES/2015 - Stock2015 - Online task merging with a hierarchical hybrid task planner for mobile service robots.pdf:PDF},
  groups    = {task planning},
  url       = {https://ieeexplore.ieee.org/document/7354300},
}

@Article{Liu2019d,
  author     = {Rui Liu and Xiaoli Zhang},
  journal    = {International Journal of Advanced Robotic Systems},
  title      = {A review of methodologies for natural-language-facilitated human–robot cooperation},
  year       = {2019},
  month      = jun,
  number     = {3},
  pages      = {1--17},
  volume     = {16},
  abstract   = {Natural-language-facilitated human–robot cooperation refers to using natural language to facilitate interactive information sharing and task executions with a common goal constraint between robots and humans. Recently, natural-language-facilitated human–robot cooperation research has received increasing attention. Typical natural-language-facilitated human–robot cooperation scenarios include robotic daily assistance, robotic health caregiving, intelligent manufacturing, autonomous navigation, and robot social accompany. However, a thorough review, which can reveal latest methodologies of using natural language to facilitate human–robot cooperation, is missing. In this review, we comprehensively investigated natural-language-facilitated human–robot cooperation methodologies, by summarizing natural-language-facilitated human–robot cooperation research as three aspects (natural language instruction understanding, natural language-based execution plan generation, knowledge-world mapping). We also made in-depth analysis on theoretical methods, applications, and model advantages and disadvantages. Based on our paper review and perspective, future directions of natural-language-facilitated human–robot cooperation research were discussed.},
  comment    = {统计了相关文献数量随年份变化趋势。
本文的叙述手法并未着眼于具体的技术及细节，而是从三个方面整体分析当前研究成果的特点，从分类的角度来对参考文献进行了分类讨论，并分析了各类算法的特点。看完文章之后，只能对各种方法的发展水平和方法特点有一定的认识，而并未深入到具体的技术细节和特点。
【见笔记】},
  doi        = {10.1177/1729881419851402},
  file       = {:FILES/2019 - Liu2019d - A review of methodologies for natural-language-facilitated human–robot cooperation.pdf:PDF},
  groups     = {task understanding},
  printed    = {Y},
  priority   = {prio1},
  readstatus = {read},
  url        = {https://journals.sagepub.com/doi/10.1177/1729881419851402},
}

@Article{Mavridis2015,
  author     = {Nikolaos Mavridis},
  journal    = {Robotics and Autonomous Systems},
  title      = {A review of verbal and non-verbal human–robot interactive communication},
  year       = {2015},
  issn       = {0921-8890},
  pages      = {22--35},
  volume     = {63},
  abstract   = {In this paper, an overview of human–robot interactive communication is presented, covering verbal as well as non-verbal aspects. Following a historical introduction, and motivation towards fluid human–robot communication, ten desiderata are proposed, which provide an organizational axis both of recent as well as of future research on human–robot communication. Then, the ten desiderata are examined in detail, culminating in a unifying discussion, and a forward-looking conclusion.},
  comment    = {本文是一篇综述文章，主要介绍了人机交互过程中利用verbal and non-verbal information的发展现状，所要解决的问题和未来发展趋势，没有涉及具体的技术。},
  doi        = {10.1016/j.robot.2014.09.031},
  file       = {:FILES/2015 - Mavridis2015 - A review of verbal and non-verbal human–robot interactive communication.pdf:PDF},
  groups     = {task understanding},
  keywords   = {Verbal, Non-verbal, Human–robot interaction, Human–robot communication, Survey},
  readstatus = {skimmed},
  url        = {https://www.sciencedirect.com/science/article/pii/S0921889014002164},
}

@Article{Muthugala2018,
  author     = {Muthugala, M. A. Viraj J. and Jayasekara, A. G. Buddhika P.},
  journal    = {IEEE Access},
  title      = {A review of service robots coping with uncertain information in natural language instructions},
  year       = {2018},
  issn       = {2169-3536},
  pages      = {12913--12928},
  volume     = {6},
  abstract   = {Intelligent service robots are currently being developed to cater to demands in emerging areas of robotic applications, ranging from entertainment to health care. These service robots are intended to be operated by nonexpert users, and their service tasks involve direct interaction between these robots and their human users. Thus, human-friendly interactive features are generally preferred for such service robots. Humans prefer to use voice instructions, responses, and suggestions to convey ideas to their peers. However, information conveyed through natural language communication is imprecise because it tends to contain uncertain/qualitative information instead of precise quantitative information. Therefore, the ability to cope with uncertain information in natural language instructions is mandatory for human-friendly service robots. This paper presents a review of service robots and systems that can cope with uncertain information in natural language instructions. The available literature has been investigated and analyzed to identify the limitations of the existing methods and possible improvements. The identified limitations and possible improvements are presented as the outcomes of the review.},
  comment    = {refer to handwritten note \#75
本文提到了一些service robot的定义、应用领域的相关文献；
本文主要解决的是机器人在接收语音指令时，通常包含一些uncertain terms，如close, far, near等模糊词语，如何对这些描述进行quantitization是本文的研究重点，本文对文献中常用的方法进行了综述。
1. 文献中常用这些词语来描述spatial information, such as distance to objects, object sizes, object properties, speed of movement, etc.还可考虑time , direction of objects, event counts, possessing tasks, etc.
2. 常用方法是fuzzy neural network, fuzzy logic, fuzzy naive baysian, etc, 可尝试使用Bayesian network, finitie state intention machine等
3. 通常只利用了linguistic commands, 以及perception of the environment using overhead cameras，可以尝试更多模态的信息，如facial expressions, hand gestures, etc.
4. 所感知的环境信息不够全面。

Zhang2019a:friendly human-computer natural language interaction systems should have a certain degree of reasoning ability to deal with missing or incomplete natural language instructions
{Kartmann2020}:"verbal modifiers, which are words that affect the quantitative meaning of a spatial relation in an imprecise manner. A comprehensive analysis of uncertain information in natural language instructions for robotic applications is provided"},
  doi        = {10.1109/ACCESS.2018.2808369},
  file       = {:FILES/2018 - Muthugala2018 - A Review of Service Robots Coping With Uncertain Information in Natural Language Instructions.pdf:PDF},
  groups     = {task understanding, spatial relation},
  printed    = {Y},
  priority   = {prio2},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/8298518},
}

@InProceedings{Tversky1999,
  author    = {Tversky, Barbara and Lee, Paul U.},
  booktitle = {Spatial Information Theory. Cognitive and Computational Foundations of Geographic Information Science},
  title     = {Pictorial and verbal tools for conveying routes},
  year      = {1999},
  address   = {Berlin, Heidelberg},
  editor    = {Freksa, Christian and Mark, David M.},
  pages     = {51--64},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Traditionally, depictions and descriptions have been seen as complementary; depictions have been preferred to convey iconic or metaphorically iconic information whereas descriptions have been preferred for abstract information. Both are external representations designed to complement human memory and information processing. We have found the same underlying structure and semantics for route maps and route directions. Here we find that limited schematic map and direction toolkits are sufficient for constructing directions, supporting the possibility of automatic translation between them.},
  doi       = {10.1007/3-540-48384-5_4},
  file      = {:FILES/1999 - Tversky1999 - Pictorial and Verbal Tools for Conveying Routes.pdf:PDF},
  groups    = {task understanding},
  isbn      = {978-3-540-48384-7},
  url       = {https://link.springer.com/chapter/10.1007/3-540-48384-5_4},
}

@Article{Nikolaidis2018,
  author     = {Nikolaidis, Stefanos and Kwon, Minae and Forlizzi, Jodi and Srinivasa, Siddhartha},
  journal    = {ACM Transactions on Human-Robot Interaction},
  title      = {Planning with verbal communication for human-robot collaboration},
  year       = {2018},
  month      = nov,
  number     = {3},
  pages      = {22:1--21},
  volume     = {7},
  abstract   = {Human collaborators coordinate effectively their actions through both verbal and non-verbal communication. We believe that the the same should hold for human-robot teams. We propose a formalism that enables a robot to decide optimally between taking a physical action toward task completion and issuing an utterance to the human teammate. We focus on two types of utterances: verbal commands, where the robot asks the human to take a physical action, and state-conveying actions, where the robot informs the human about its internal state, which captures the information that the robot uses in its decision making. Human subject experiments show that enabling the robot to issue verbal commands is the most effective form of communicating objectives, while retaining user trust in the robot. Communicating information about the robot’s state should be done judiciously, since many participants questioned the truthfulness of the robot statements when the robot did not provide sufficient explanation about its actions.},
  address    = {New York, NY, USA},
  comment    = {本文主要是解决人机合作完成任务的问题，其相较于已有文献的改进是在机器人做决策的时候，加入了verbal communication，从而提高人对机器人某些动作或决策的信任度，从而更好的完成人机协作任务（如一起搬桌子）。
1. 采用了mixed observability Markov decision process来建立人机混合系统的模型，其中包括状态、人/机器人的动作，以及机器人所采取的verbal commands (ask human to do some actions) and state-conveying actions (why it should be done in the robot's way). 
2. action set是manually defined},
  doi        = {10.1145/3203305},
  file       = {:FILES/2018 - Nikolaidis2018 - Planning with Verbal Communication for Human-Robot Collaboration.pdf:PDF},
  groups     = {human robot interaction},
  keywords   = {verbal communication, planning under uncertainty, Human-robot collaboration, partially observable Markov decision process},
  publisher  = {Association for Computing Machinery},
  readstatus = {skimmed},
  url        = {https://dl.acm.org/doi/10.1145/3203305},
}

@InProceedings{SuarezBonilla2019,
  author     = {Su\'{a}rez Bonilla, F\'{e}lix and Ruiz Ugalde, Federico},
  booktitle  = {Proceedings of the 2019 Third IEEE International Conference on Robotic Computing (IRC)},
  title      = {Automatic translation of {Spanish} natural language commands to control robot comands based on {LSTM} neural network},
  year       = {2019},
  address    = {Naples, Italy},
  month      = feb,
  pages      = {125--131},
  publisher  = {IEEE},
  abstract   = {In this paper, we propose a high level layer able to translate motion commands in natural spanish language to a formal intermediate representation called Robot Control Language (RCL). The layer was built by using the seq2seq TensorFlow library, with a single forward LSTM for encoder and decoder respectively. We were able to achieve a 4.3e-08 loss employing a manually generated corpus in Spanish.},
  comment    = {本文提出了一种端到端的机器人语音控制方法，即将NL command翻译成robot control language,建立了自然语言与运动控制指令的一对一关系。主要方法：
1. 模型采用的是sequence2sequence model with LSTM mechanism as the encoder and decoder,
2. the input is the natural language command, output is the RCL command
3. 只实现了7种指令，分别对应了7种RCL commands
4. 需要对输入输出进行word embedding，均利用genism library
5. 监督学习，
5. LSTM的主要优缺点，利用attention等，是否合理断句等，没有利用语言学特征
作为一种neural machine translatioin (NMT)问题

 proposed an end-to-end task understanding framework which accepts textual commands in Spanish and outputs the corresponding robot control language expressions. The framework treats the task understanding problem as a neural machine translation problem. The framework works as follows. First, the textual commands are represented via the pre-trained word2vec model \cite{}, and the vectorized commands are passed to the sequence-to-sequence model with an LSTM encoder and decoder, and produces the robot control language directly. In their experiments, the framework can handle seven types of commands for navigation, such as ``Doble a la izquierda'' (turn left), ``Salga de la habitaci\'{o}n'' (leave the room).  It compares different implementations of the framework, including the simple configuration of basic LSTM encoder and decoder, the configuration with a LSTM decoder with the attention mechanism \cite{Vaswani2017}, the configuration with bidirectional encoder, etc. The framework does not consider the grounding of concepts in the commands or the extendibility to other commands beyond the manually defined corpus.},
  doi        = {10.1109/IRC.2019.00026},
  file       = {:FILES/2019 - SuarezBonilla2019 - Automatic Translation of Spanish Natural Language Commands to Control Robot Comands Based on LSTM Neural Network.pdf:PDF},
  groups     = {task understanding},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/8675641},
}

@Article{Tellex2011a,
  author  = {Stefanie Tellex and Thomas Kollar and Steven Dickerson and Matthew R. Walter and Ashis Gopal Banerjee and Seth Teller and Nicholas Roy},
  journal = {AI Magazine},
  title   = {Approaching the symbol grounding problem with probabilistic graphical models},
  year    = {2011},
  number  = {4},
  pages   = {64--76},
  volume  = {32},
  comment = {Bastianelli2016: Statistical graphical models for mapping between words and entities in env. grounding. beam search.同时利用了linguistic and perceptual info，但是没有modify wrongly generated syntactic info.},
  doi     = {10.1609/aimag.v32i4.2384},
  file    = {:FILES/2011 - Tellex2011a - Approaching the Symbol Grounding Problem with Probabilistic Graphical Models.pdf:PDF},
  groups  = {task understanding},
  url     = {https://ojs.aaai.org/index.php/aimagazine/article/view/2384},
}

@InProceedings{Sugiura2007,
  author    = {Sugiura, Komei and Iwahashi, Naoto},
  booktitle = {Proceedings of the 2007 Workshop on Multimodal Interfaces in Semantic Interaction},
  title     = {Learning object-manipulation verbs for human-robot communication},
  year      = {2007},
  address   = {New York, NY, USA},
  month     = nov,
  pages     = {32--38},
  publisher = {Association for Computing Machinery},
  series    = {WMISI '07},
  abstract  = {This paper proposes a machine learning method for mapping object-manipulation verbs with sensory inputs and motor outputs that are grounded in the real world. The method learns motion concepts demonstrated by a user and generates a sequence of motions, using reference-point-dependent probability models. Four components, needed to learn objectmanipulation verbs, are estimated from camera images; (1) a trajector and landmark, which are the objects of transitive verbs; (2) a reference point; (3) an intrinsic coordinate system; and (4) parameters of the motion's probabilistic model. The motion concepts are learned using hidden Markov models (HMMs). In the motion generation phase, our method then combines HMMs to generate trajectories to accomplish goal-oriented tasks. Results from simulation experiments in which our method generates motion by combining learned motion primitives are shown.},
  comment   = {基于视觉的action learning，即通过学习人的操作轨迹以及NL commands，利用概率模型建立verb与轨迹的mapping},
  doi       = {10.1145/1330572.1330577},
  file      = {:FILES/2007 - Sugiura2007 - Learning object-manipulation verbs for human-robot communication.pdf:PDF},
  groups    = {task understanding, 知识生成},
  isbn      = {9781595938695},
  keywords  = {HMM, human-robot interaction, motion generation},
  location  = {Nagoya, Japan},
  url       = {https://dl.acm.org/doi/abs/10.1145/1330572.1330577},
}

@InBook{Wermter2005,
  author    = {Wermter, Stefan and Weber, Cornelius and Elshaw, Mark and Gallese, Vittorio and Pulverm{\"u}ller, Friedemann},
  editor    = {Wermter, Stefan and Palm, G{\"u}nther and Elshaw, Mark},
  pages     = {162--181},
  publisher = {Springer Berlin Heidelberg},
  title     = {Grounding neural robot language in action},
  year      = {2005},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-540-31896-5},
  abstract  = {In this paper we describe two models for neural grounding of robotic language processing in actions. These models are inspired by concepts of the mirror neuron system in order to produce learning by imitation by combining high-level vision, language and motor command inputs. The models learn to perform and recognise three behaviours, `go', `pick' and `lift'. The first single-layer model uses an adapted Helmholtz machine wake-sleep algorithm to act like a Kohonen self-organising network that receives all inputs into a single layer. In contrast, the second, hierarchical model has two layers. In the lower level hidden layer the Helmholtz machine wake-sleep algorithm is used to learn the relationship between action and vision, while the upper layer uses the Kohonen self-organising approach to combine the output of the lower hidden layer and the language input.},
  booktitle = {Biomimetic Neural Learning for Intelligent Robots: Intelligent Systems, Cognitive Robotics, and Neuroscience},
  doi       = {10.1007/11521082_10},
  file      = {:FILES/2005 - Wermter2005 - Grounding Neural Robot Language in Action.pdf:PDF},
  groups    = {task understanding},
  url       = {https://link.springer.com/chapter/10.1007/11521082_10},
}

@InProceedings{Alam2017,
  author     = {Alam, Mehreen and ul Hussain, Sibt},
  booktitle  = {Proceedings of the 2017 International Multi-topic Conference (INMIC)},
  title      = {Sequence to sequence networks for {Roman-Urdu} to {Urdu} transliteration},
  year       = {2017},
  address    = {Lahore, Pakistan},
  month      = nov,
  pages      = {1--7},
  publisher  = {IEEE},
  abstract   = {Neural Machine Translation models have replaced the conventional phrase based statistical translation methods since the former takes a generic, scalable, data-driven approach rather than relying on manual, hand-crafted features. The neural machine translation system is based on one neural network that is composed of two parts, one that is responsible for input language sentence and other part that handles the desired output language sentence. This model based on encoder-decoder architecture also takes as input the distributed representations of the source language which enriches the learnt dependencies and gives a warm start to the network. In this work, we transform Roman-Urdu to Urdu transliteration into sequence to sequence learning problem. To this end, we make the following contributions. We create the first ever parallel corpora of Roman-Urdu to Urdu, create the first ever distributed representation of Roman-Urdu and present the first neural machine translation model that transliterates text from Roman-Urdu to Urdu language. Our model has achieved the state-of-the-art results using BLEU as the evaluation metric. Precisely, our model is able to correctly predict sentences up to length 10 while achieving BLEU score of 48.6 on the test set. We are hopeful that our model and our results shall serve as the baseline for further work in the domain of neural machine translation for Roman-Urdu to Urdu using distributed representation.},
  comment    = {roman urdu transliteration to urdu类似于英文单词的片假名到英文单词的翻译。
本文采用的方法是multilayer LSTN encoder decoder model，利用了paralelle corpus,本文只考虑了具有相同长度的两种语言对应的句子，不适用于一对多，或多对一的translation.所使用的工具是Tensorflow seq2seq library},
  doi        = {10.1109/INMIC.2017.8289449},
  file       = {:FILES/2017 - Alam2017 - Sequence to sequence networks for Roman-Urdu to Urdu transliteration.pdf:PDF},
  groups     = {speech translation, machine translation},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/8289449},
}

@InProceedings{Kahuttanaseth2018,
  author     = {Kahuttanaseth, Wittawin and Dressler, Alexander and Netramai, Chayakorn},
  booktitle  = {Proceedings of the 2018 5th International Conference on Business and Industrial Research (ICBIR)},
  title      = {Commanding mobile robot movement based on natural language processing with {RNN} encoder­-decoder},
  year       = {2018},
  address    = {Bangkok, Thailand},
  month      = may,
  pages      = {161--166},
  publisher  = {IEEE},
  abstract   = {This work utilizes the potential of NLP and machine learning for the challenging task of human-machine communication. A task of robot movement is selected as the context of the research work where the goal is to create a software system that receives natural language input movement command from human and produces the set of precise trajectory information for the robot to perform. The proposed system consists of Pre-processing function, Command classification, Parameter classification, Post-processing function where RNN Encoder-Decoder is used for the implementation of the classification process. The system was trained using a dataset of 1,600 unique entries. The experiment results show that the average accuracy in case of single movement command is 79.23% whereas the average accuracy in case of multiple command in one sentence is 73.65%.},
  comment    = {handwritten note \#76
1. 本文是将文本指令翻译成机器人可以识别的指令
2. 指令只与机器人运动有关，如运动方向、速度等，共6中
3. 指令有限,无法判定oov，
4.将指令视为一个分类问题，用RNN encoder-decoder来实现，并未体现该模型的优势，

{SuarezBonilla2019}:use RNN + LSTM for TU. implemented in Python and Tensorflow. accuracy 79.25},
  doi        = {10.1109/ICBIR.2018.8391185},
  file       = {:FILES/2018 - Kahuttanaseth2018 - Commanding mobile robot movement based on natural language processing with RNN encoder­decoder.pdf:PDF},
  groups     = {task understanding},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/8391185},
}

@InProceedings{Putra2015,
  author     = {Putra, Karisma Trinanda and Purwanto, Djoko and Mardiyanto, Ronny},
  booktitle  = {Proceedings of the 2015 International Conference on Electrical Engineering and Informatics (ICEEI)},
  title      = {Indonesian natural voice command for robotic applications},
  year       = {2015},
  address    = {Denpasar, Indonesia},
  month      = aug,
  pages      = {638--643},
  publisher  = {IEEE},
  abstract   = {Human-machine interaction has been growing with the discovery of artificial intelligence technology. The development of human-machine interaction leads to a more natural interaction. In daily interactions, human uses speech, more dominant than the other way such as gestures and eye contact. Speech is the vocalized form of human communication which is closely related to language system. The problem is meaning, ambiguity, and the language that is not according to the rules of syntax, causing the command translation become more complex. To understand the meaning of the voice command, it is necessary to know the semantic and syntactic structure of sentences. An artificial intelligence technology that can understand Indonesian voice commands for robotic applications will be developed in this research. The purpose of this research is to translate voice command into the robots action, to generate human-machine interaction more natural. The voice command will be extracted using bark-frequency cepstral coefficients. Cepstral identified into words using neural networks. Words in a complete sentences will be processed using natural language processing so that, the meaning and appropriate action from the given command can be executed. Speech recognition experiments with 28 sets of speech signal obtain 82 % accuracy, while natural language processing experiments obtain 93 % accuracy with 50 sets of learning data.},
  comment    = {本文是将voice command转化为machine language,其中分为ASR和NLP,后者是利用了VSM和RNN来分别表示words, phrases以及识别句子-短语-词语的层次关系,decoder将识别结果转化为machine language,但是本文并未指出decoder的形式,也没有说明action language 的形式.},
  doi        = {10.1109/ICEEI.2015.7352577},
  file       = {:FILES/2015 - Putra2015 - Indonesian natural voice command for robotic applications.pdf:PDF},
  groups     = {task understanding},
  issn       = {2155-6830},
  keywords   = {read},
  printed    = {Y},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/7352577},
}

@InProceedings{Yamazaki2010,
  author    = {Yamazaki, Kimitoshi and Watanabe, Yoshiaki and Nagahama, Kotaro and Okada, Kei and Inaba, Masayuki},
  booktitle = {Proceedings of the 2010 IEEE International Conference on Robotics and Biomimetics},
  title     = {Recognition and manipulation integration for a daily assistive robot working on kitchen environments},
  year      = {2010},
  address   = {Tianjin, China},
  month     = dec,
  pages     = {196--201},
  publisher = {IEEE},
  abstract  = {This paper describes a system integration of a daily assistive robot. Several tasks on cooking are focused on, recognition and manipulation functions are developed and integrated. It is often the case that kitchen tools and foods have less distinctive texture on its surface, and kitchen environments which are made of reflective materials are susceptible to the effect of illumination. From these fact, recognition functions are implemented with a basic policy which composes simple image features. On the other hand, tasks on kitchen often include relatively complicate dual arm manipulation. In such case it is effective in generating a robot pose by considering several manipulators at the same time. Experiments doing several cooking tasks with handling daily tools showed the effectiveness of our system.},
  doi       = {10.1109/ROBIO.2010.5723326},
  file      = {:FILES/2010 - Yamazaki2010 - Recognition and manipulation integration for a daily assistive robot working on kitchen environments.pdf:PDF},
  groups    = {task understanding},
  url       = {https://ieeexplore.ieee.org/abstract/document/5723326},
}

@InProceedings{Thenmozhi2017,
  author     = {Thenmozhi, D. and Seshathiri, R. and Revanth, K. and Ruban, B.},
  booktitle  = {Proceedings of the 2017 International Conference on Computer, Communication and Signal Processing (ICCCSP)},
  title      = {Robotic simulation using natural language commands},
  year       = {2017},
  address    = {Chennai, India},
  month      = jan,
  pages      = {1--4},
  publisher  = {IEEE},
  abstract   = {Robots are inevitable these days, so naive users should not find difficult to interact with robots. Since robots understand only RCL (Robot command language), we need a system which converts natural language commands into RCL. We use a semantic parser to address this problem of converting natural language commands to RCL that can be readily implemented in a robot execution system. Our system gets the natural language command from the user and converts it into RCL using tagging approach. This tagging operation is implemented using a trainer, which uses Hidden Markov Model approach. Using this tagged command the Parser builds the RCL. Then the RCL is converted to configurations which is the co-ordinates of the objects in a given spatial context. The validation of these configurations is performed using robotic simulator. We have used an annotated dataset to compare and evaluate our approach. Despite the fixed domain, the task is challenging as correctly parsing commands requires understanding spatial context.},
  comment    = {HMM！！！本文是为了解决在某些情况下visual interaction system is not available时，利用speech进行interaction的问题，将NL sentences转录成Robot command language (RCL)。
1. 文献：【1】利用question-answer pair without annotated logical forms来设计问答系统的parser；【2】将NL问题翻译成formal queries；【3】to spatial command using PCFG;【4】semantic parser of robot spatial command;【5】利用CCG parser；【6】基于grammatical and lexical rules;【7】 CCG；【8】KRISP parser and SVM
本文内容如下：
1. 输入是NL texts, 输出是RCL；首先tokenization，而后feed into trainer
2. trainer需要事先定义command set \& annotation set,前者用于determine the token's labels, such as color, type, event, etc. 后者用于识别commands，同时，可以chunker模块可以得到commands's probability of occurances. --- 上述过程总结为利用HMM模型，预测每个词的label，其中两个集合是training dataset,对新句子，则利用viberti algorithm来决定概率最大的路径，得到相应的label。并结合这些label组合二得到RCL
3. 将RCL作为输入，feed into simulator，},
  doi        = {10.1109/ICCCSP.2017.7959814},
  file       = {:FILES/2017 - Thenmozhi2017 - Robotic simulation using natural language commands.pdf:PDF},
  groups     = {task understanding},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/7959814},
}

@InCollection{Matuszek2013,
  author     = {Matuszek, Cynthia and Herbst, Evan and Zettlemoyer, Luke and Fox, Dieter},
  booktitle  = {Experimental Robotics: The 13th International Symposium on Experimental Robotics},
  publisher  = {Springer International Publishing},
  title      = {Learning to parse natural language commands to a robot control system},
  year       = {2013},
  address    = {Heidelberg},
  editor     = {Desai, Jaydev P. and Dudek, Gregory and Khatib, Oussama and Kumar, Vijay},
  isbn       = {978-3-319-00065-7},
  pages      = {403--415},
  abstract   = {As robots become more ubiquitous and capable of performing complex tasks, the importance of enabling untrained users to interact with them has increased. In response, unconstrained natural-language interaction with robots has emerged as a significant research area. We discuss the problem of parsing natural language commands to actions and control structures that can be readily implemented in a robot execution system. Our approach learns a parser based on example pairs of English commands and corresponding control language expressions. We evaluate this approach in the context of following route instructions through an indoor environment, and demonstrate that our system can learn to translate English commands into sequences of desired actions, while correctly capturing the semantic intent of statements involving complex control structures. The procedural nature of our formal representation allows a robot to interpret route instructions online while moving through a previously unknown environment.},
  comment    = {Bastianelli2016: probabilistic CCG is used to map instructions to executable commands about navigation. using log linear model and specified robot language
Liu2016d: Natural language (NL) communication is natural for that even the non-expert user without any prior training could interface with the machine
Whitney2016: batch interpretation
Boularias2015: following verbal route instructions
Hemachandra2015: learn a parser 以把NL instr映射为plan
Howard2014a: NL in route direction following
Duvallet2016: Natural language has proven to be effective for commanding robots to follow route directions. used a parser that maps language directly to plans.没有利用NL instruction中包含的信息来reason uncertainty and infer environment representation.
{SuarezBonilla2019}:Robot Control Language (RCL), this is a motion  oriented language made of route instructions through an indoor  environment containing objects and landmarks


proposed a high level robot control language based on the logic theory, which can describe various tasks, ranging from motions to perception.
提出了一种将NL翻译为logic based RCL的过程，后者是execution system independent。基于的parsing模型是extention of UBL model, which is based on probabilistic CCG. 优势在于对自然语言中的noise鲁棒，有助于grounding效率，可利用（NL，RCL）数据对和log-linear model来训练模型参数，给予了lexical and semantic features.},
  doi        = {10.1007/978-3-319-00065-7_28},
  file       = {:FILES/2013 - Matuszek2013 - Learning to Parse Natural Language Commands to a Robot Control System.pdf:PDF},
  groups     = {task understanding},
  readstatus = {read},
  url        = {https://link.springer.com/chapter/10.1007/978-3-319-00065-7_28},
}

@Article{Takano2015,
  author     = {Wataru Takano and Yoshihiko Nakamura},
  journal    = {Robotics and Autonomous Systems},
  title      = {Action database for categorizing and inferring human poses from video sequences},
  year       = {2015},
  issn       = {0921-8890},
  month      = aug,
  pages      = {116--125},
  volume     = {70},
  abstract   = {One of the difficulties in automated recognition of human activities is classifying a video into a specific action class by selecting among a large number of human actions. Technology for understanding complex and varied human actions is necessary for automated surveillance, sports training, computer games, and human–robot interactions. The difficulty of classification comes from a dearth of datasets of human actions that are manually categorized and suitable for use as training data for designing action classifiers. A marker-based motion capture system enables precise measurement of human actions for the purpose of analysis. This type of capture system has several drawbacks, however; in particular, marker-based systems are expensive, intrusive, and complex to use. Despite this, the intensive use of a motion capture system can provide large datasets of human actions, and the datasets can be used to facilitate handling the variety of actions to be classified. Large datasets of human actions measured by motion capture systems are expected to be suitable for use in classifying video segments into the correct human action category, selecting from among a large number of action categories, and for inferring human postures from video. This paper proposes a new concept for a database of human whole body actions and an application to understanding human actions from video. The database contains action configurations, such as positions of body parts, pose descriptors from silhouette images, a stochastic model encoding each sequence of the pose descriptors, and a regression model for predicting the configuration from the pose descriptor. The action configurations are recorded in advance of use by measuring many human actions with a marker-based motion capture system, and silhouette images are created from these configurations. We tested the action database on action classification tasks and human body posture inference tasks. The experimental results show that the action database is suitable for use in both action classification and posture inference.},
  comment    = {本文提供了一个database，并介绍了其构造方法，用于实现基于视频的人体动作分类。基本数据是data from marker-based motion capture system (including derived joint angles, ),image features (represented as HMM nodes). action classification model是基于概率模型的，或者说是mixture gaussian model},
  doi        = {10.1016/j.robot.2015.03.001},
  file       = {:FILES/2015 - Takano2015 - Action database for categorizing and inferring human poses from video sequences.pdf:PDF},
  groups     = {body gesture},
  keywords   = {Action database, Action classification, Hidden Markov model, Gaussian process regression},
  readstatus = {skimmed},
  url        = {https://www.sciencedirect.com/science/article/pii/S092188901500038X},
}

@Article{Liu2016c,
  author     = {Liu, Rui and Zhang, Xiaoli},
  journal    = {IEEE Transactions on Cognitive and Developmental Systems},
  title      = {Understanding human behaviors with an object functional role perspective for robotics},
  year       = {2016},
  issn       = {2379-8939},
  month      = jun,
  number     = {2},
  pages      = {115--127},
  volume     = {8},
  abstract   = {Intelligent robotic assistance requires a robot to accurately understand human behavior. Many researchers have explored human-object interactions to decode behavior-related information. However, current methods only model probabilistic correlations between objects and activities. Their applications are usually limited to fixed environments and fixed sets of activities. They are unable to deal with variability in the real environments due to the lack of the human-like cognitive reasoning process. To address this urgent problem, we developed an Object Functional Role Perspective method to endow a robot with comprehensive behavior understanding. Instead of using specific objects to identify an activity, our role-based method models the human cognitive process during task performing by analyzing object selection and object interaction. Then activity-related information, such as activity feasibility, likely plan, and urgent need of an activity, is inferred in order to improve a robot's cognition level for comprehensive behavior understanding. Through a large amount of human behavior observations, this cognitive knowledge is constructed using a Markov random field (MRF) model. Experiments were performed in both real-life scenarios and lab scenarios to evaluate the method's usefulness. The results demonstrated flexibility and effectiveness of the role-based method for human behavior understanding under variability.},
  comment    = {capture human motion via visual system
Liu2016d: capture objects

基于环境中的物体来理解human behavior,或这说是事件的理解？},
  doi        = {10.1109/TAMD.2015.2504919},
  file       = {:FILES/2016 - Liu2016c - Understanding Human Behaviors with an Object Functional Role Perspective for Robotics.pdf:PDF},
  groups     = {task understanding, representation, 知识生成, action classification},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/abstract/document/7345551},
}

@InProceedings{Kim2013,
  author    = {Kim, Sangwook and Jung, Jehan and Kavuri, Swathi and Lee, Minho},
  booktitle = {Neural Information Processing},
  title     = {Intention estimation and recommendation system based on attention sharing},
  year      = {2013},
  address   = {Berlin, Heidelberg},
  editor    = {Lee, Minho and Hirose, Akira and Hou, Zeng-Guang and Kil, Rhee Man},
  pages     = {395--402},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {In human-agent interactions, attention sharing plays a key role in understanding other's intention without explicit verbal explanation. Deep learning algorithms are recently used to model these interactions in a complex real world environment. In this paper we propose a deep learning based intention estimation and recommendation system by understanding humans attention based on their gestures. Action-object affordances are modeled using stacked auto-encoder, which represents the relationships between actions and objects. Intention estimation and object recommendation system according to human intention is implemented based on an affordance model. Experimental result demonstrates meaningful intention estimation and recommendation performance in the real-world scenarios.},
  comment   = {基于视觉系统的人体位姿估计},
  doi       = {10.1007/978-3-642-42054-2_49},
  file      = {:FILES/2013 - Kim2013 - Intention Estimation and Recommendation System Based on Attention Sharing.pdf:PDF},
  groups    = {from visual},
  isbn      = {978-3-642-42054-2},
  url       = {https://link.springer.com/chapter/10.1007/978-3-642-42054-2_49},
}

@Article{Krueger2008,
  author   = {J. Kr\"{u}ger and D. Surdilovic},
  journal  = {CIRP Annals},
  title    = {Robust control of force-coupled human–robot-interaction in assembly processes},
  year     = {2008},
  issn     = {0007-8506},
  number   = {1},
  pages    = {41--44},
  volume   = {57},
  abstract = {Flexibility and changeability of assembly processes require a close interlinkage between the worker and the automated assembly system. The interaction between human and robot improves complex assembly processes, particularly when a robot can be guided by a worker and the robot provides power assistance to the worker. The close physical contact and the direct coupling of forces of human and robot necessitate a stable and robust interaction control. This paper describes a framework developed for a robustly stable control design for interactive robots serving as intelligent assist systems for flexible and highly adaptable assembly.},
  doi      = {10.1016/j.cirp.2008.03.005},
  file     = {:FILES/2008 - Krueger2008 - Robust control of force-coupled human–robot-interaction in assembly processes.pdf:PDF},
  groups   = {from tactile},
  keywords = {Co-operative Assembly, Robot, Man–machine system},
  url      = {https://www.sciencedirect.com/science/article/pii/S0007850608000073},
}

@Article{Iwata2005,
  author   = {Iwata, Hiroyasu and Sugano, Shigeki},
  journal  = {IEEE Transactions on Industrial Electronics},
  title    = {Human-robot-contact-state identification based on tactile recognition},
  year     = {2005},
  issn     = {1557-9948},
  month    = dec,
  number   = {6},
  pages    = {1468--1477},
  volume   = {52},
  abstract = {In this paper, we propose a method for designing an identification system for human-robot contact states based on tactile recognition. The following ideas are incorporated: experimentation for human-robot contact, verbalization of contact states, extraction of characteristic parameters from acquired tactile information, quantification of the recipient's tactile recognition incorporating its redundancy (identification confusability among contact states), evaluation of the identification confusability with a new criterion, and identification of contact states based on the received tactile stimulation. The proposed method allows a robot to quantify tactile recognition of a human (recipient) touched by other people (touch initiator), in which the verbal response by the recipient is matched with tactile stimulation acquired during physical contact utilizing a tactile interface. In addition, the method enables a robot that comes into contact with a human to identify contact states nearly similar to that of the recipient, based on the features of the received tactile stimulation. At this point, the reproduction of the identification confusability of the recipient's tactile recognition is also accomplished by using a neural network called modified counterpropagation (MCP). Once a tactile stimulation is induced on the robot body, the probability of corresponding contact states is calculated and outputted by the system, based on the degree of similarity of the characteristics between the newly received and previously stored tactile stimulation. Experimental results indicate that the constructed system allows a successful quantification of the recipient's contact-state recognition incorporating the identification confusability and the accomplishment of a high level of accuracy in contact-state identification. These results confirm that the proposed method is useful for identifying human-robot contact states based on tactile recognition.},
  doi      = {10.1109/TIE.2005.858739},
  file     = {:FILES/2005 - Iwata2005 - Human-robot-contact-state identification based on tactile recognition.pdf:PDF},
  groups   = {from tactile},
  url      = {https://ieeexplore.ieee.org/abstract/document/1546362},
}

@Article{Waldherr2000,
  author   = {Waldherr, Stefan and Romero, Roseli and Thrun, Sebastian},
  journal  = {Autonomous Robots},
  title    = {A gesture based interface for human-robot interaction},
  year     = {2000},
  issn     = {1573-7527},
  month    = sep,
  number   = {2},
  pages    = {151--173},
  volume   = {9},
  abstract = {Service robotics is currently a highly active research area in robotics, with enormous societal potential. Since service robots directly interact with people, finding “natural” and easy-to-use user interfaces is of fundamental importance. While past work has predominately focussed on issues such as navigation and manipulation, relatively few robotic systems are equipped with flexible user interfaces that permit controlling the robot by “natural” means. This paper describes a gesture interface for the control of a mobile robot equipped with a manipulator. The interface uses a camera to track a person and recognize gestures involving arm motion. A fast, adaptive tracking algorithm enables the robot to track and follow a person reliably through office environments with changing lighting conditions. Two alternative methods for gesture recognition are compared: a template based approach and a neural network approach. Both are combined with the Viterbi algorithm for the recognition of gestures defined through arm motion (in addition to static arm poses). Results are reported in the context of an interactive clean-up task, where a person guides the robot to specific locations that need to be cleaned and instructs the robot to pick up trash.},
  doi      = {10.1023/A:1008918401478},
  file     = {:FILES/2000 - Waldherr2000 - A Gesture Based Interface for Human-Robot Interaction.pdf:PDF},
  groups   = {from visual},
  url      = {https://link.springer.com/article/10.1023/A:1008918401478},
}

@Article{Argall2009,
  author   = {Brenna D. Argall and Sonia Chernova and Manuela Veloso and Brett Browning},
  journal  = {Robotics and Autonomous Systems},
  title    = {A survey of robot learning from demonstration},
  year     = {2009},
  issn     = {0921-8890},
  month    = may,
  number   = {5},
  pages    = {469--483},
  volume   = {57},
  abstract = {We present a comprehensive survey of robot Learning from Demonstration (LfD), a technique that develops policies from example state to action mappings. We introduce the LfD design choices in terms of demonstrator, problem space, policy derivation and performance, and contribute the foundations for a structure in which to categorize LfD research. Specifically, we analyze and categorize the multiple ways in which examples are gathered, ranging from teleoperation to imitation, as well as the various techniques for policy derivation, including matching functions, dynamics models and plans. To conclude we discuss LfD limitations and related promising areas for future research.},
  doi      = {10.1016/j.robot.2008.10.024},
  file     = {:FILES/2009 - Argall2009 - A survey of robot learning from demonstration.pdf:PDF},
  groups   = {task understanding},
  keywords = {Learning from demonstration, Robotics, Machine learning, Autonomous systems},
  url      = {https://www.sciencedirect.com/science/article/pii/S0921889008001772},
}

@Article{Rautaray2015,
  author   = {Rautaray, Siddharth S. and Agrawal, Anupam},
  journal  = {Artificial Intelligence Review},
  title    = {Vision based hand gesture recognition for human computer interaction: {A} survey},
  year     = {2015},
  issn     = {1573-7462},
  month    = jan,
  number   = {1},
  pages    = {1--54},
  volume   = {43},
  abstract = {As computers become more pervasive in society, facilitating natural human-computer interaction (HCI) will have a positive impact on their use. Hence, there has been growing interest in the development of new approaches and technologies for bridging the human-computer barrier. The ultimate aim is to bring HCI to a regime where interactions with computers will be as natural as an interaction between humans, and to this end, incorporating gestures in HCI is an important research area. Gestures have long been considered as an interaction technique that can potentially deliver more natural, creative and intuitive methods for communicating with our computers. This paper provides an analysis of comparative surveys done in this area. The use of hand gestures as a natural interface serves as a motivating force for research in gesture taxonomies, its representations and recognition techniques, software platforms and frameworks which is discussed briefly in this paper. It focuses on the three main phases of hand gesture recognition i.e. detection, tracking and recognition. Different application which employs hand gestures for efficient interaction has been discussed under core and advanced application domains. This paper also provides an analysis of existing literature related to gesture recognition systems for human computer interaction by categorizing it under different key parameters. It further discusses the advances that are needed to further improvise the present hand gesture recognition systems for future perspective that can be widely used for efficient human computer interaction. The main goal of this survey is to provide researchers in the field of gesture based HCI with a summary of progress achieved to date and to help identify areas where further research is needed.},
  comment  = {Liu2016d: human body pose.只能expert使用


survey,介绍了contact based and vision based hand gesture techniques, softwares, applications, etc.},
  doi      = {10.1007/s10462-012-9356-9},
  file     = {:FILES/2015 - Rautaray2015 - Vision based hand gesture recognition for human computer interaction- a survey.pdf:PDF},
  groups   = {hand gesture},
  url      = {https://link.springer.com/article/10.1007%2Fs10462-012-9356-9},
}

@Article{Argall2010,
  author   = {Brenna D. Argall and Aude G. Billard},
  journal  = {Robotics and Autonomous Systems},
  title    = {A survey of tactile human-robot interactions},
  year     = {2010},
  issn     = {0921-8890},
  month    = oct,
  number   = {10},
  pages    = {1159--1176},
  volume   = {58},
  abstract = {Robots come into physical contact with humans in both experimental and operational settings. Many potential factors motivate the detection of human contact, ranging from safe robot operation around humans, to robot behaviors that depend on human guidance. This article presents a review of current research within the field of Tactile Human–Robot Interactions (Tactile HRI), where physical contact from a human is detected by a robot during the execution or development of robot behaviors. Approaches are presented from two viewpoints: the types of physical interactions that occur between the human and robot, and the types of sensors used to detect these interactions. We contribute a structure for the categorization of Tactile HRI research within each viewpoint. Tactile sensing techniques are grouped into three categories, according to what covers the sensors: (i) a hard shell, (ii) a flexible substrate or (iii) no covering. Three categories of physical HRI likewise are identified, consisting of contact that (i) interferes with robot behavior execution, (ii) contributes to behavior execution and (iii) contributes to behavior development. We populate each category with the current literature, and furthermore identify the state-of-the-art within categories and promising areas for future research.},
  doi      = {10.1016/j.robot.2010.07.002},
  file     = {:FILES/2010 - Argall2010 - A survey of Tactile Human–Robot Interactions.pdf:PDF},
  groups   = {from tactile},
  keywords = {Human–Robot Interaction (HRI), Tactile sensing, Physical human–robot contact},
  url      = {https://www.sciencedirect.com/science/article/pii/S0921889010001375},
}

@InProceedings{Bethel2007,
  author    = {Bethel, Cindy L. and Salomon, Kristen and Murphy, Robin R. and Burke, Jennifer L.},
  booktitle = {The 16th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},
  title     = {Survey of psychophysiology measurements applied to human-robot interaction},
  year      = {2007},
  address   = {Jeju, Korea (South)},
  month     = aug,
  pages     = {732--737},
  publisher = {IEEE},
  abstract  = {This paper reviews the literature related to the use of psychophysiology measures in human-robot interaction (HRI) studies in an effort to address the fundamental question of appropriate metrics and methodologies for evaluating HRI research, especially affect. It identifies four main methods of evaluation in HRI studies: (1) self-report measures, (2) behavioral measures, (3) psychophysiology measures, and (4) task performance. However, the paper also shows that using only one of these measures for evaluation is insufficient to provide a complete evaluation and interpretation of the interactions between a robot and the human with which it is interacting. In addition, the paper describes exemplar HRI studies which use psychophysiological measures; these implementations fall into three categories: detection and/or identification of specific emotions of participants from physiological signals, evaluation of participants' responses to a robot through physiological signals, and development and implementation of real-time control and modification of robot behaviors using physiological signals. Two open research questions on psychophysiological metrics were identified as a result of this review.},
  comment   = {measurements of HRI methods},
  doi       = {10.1109/ROMAN.2007.4415182},
  file      = {:FILES/2007 - Bethel2007 - Survey of psychophysiology measurements applied to human-robot interaction.pdf:PDF},
  groups    = {human robot interaction},
  issn      = {1944-9437},
  url       = {https://ieeexplore.ieee.org/abstract/document/4415182},
}

@InProceedings{Huang2010a,
  author    = {Huang, Albert S. and Tellex, Stefanie and Bachrach, Abraham and Kollar, Thomas and Roy, Deb and Roy, Nicholas},
  booktitle = {Proceedings of the 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Natural language command of an autonomous micro-air vehicle},
  year      = {2010},
  address   = {Taipei, Taiwan},
  month     = oct,
  pages     = {2663--2669},
  publisher = {IEEE},
  abstract  = {Natural language is a flexible and intuitive modality for conveying directions and commands to a robot but presents a number of computational challenges. Diverse words and phrases must be mapped into structures that the robot can understand, and elements in those structures must be grounded in an uncertain environment. In this paper we present a micro-air vehicle (MAV) capable of following natural language directions through a previously mapped and labeled environment. We extend our previous work in understanding 2D natural language directions to three dimensions, accommodating new verb modifiers such as go up and go down, and commands such as turn around and face the windows. We demonstrate the robot following directions created by a human for another human, and interactively executing commands in the context of surveillance and search and rescue in confined spaces. In an informal study, 71% of the paths computed from directions given by one user terminated within 10 m of the desired destination.},
  comment   = {navigation via NL commands
Zhang2019a:keyword matching method uses domain dictionary to parses instructions, and the matching results are used as trigger conditions of the frame template
{Anderson2018}：operating in visually restricted environments requiring limited perception},
  doi       = {10.1109/IROS.2010.5650910},
  file      = {:FILES/2010 - Huang2010a - Natural language command of an autonomous micro-air vehicle.pdf:PDF},
  groups    = {task understanding},
  issn      = {2153-0866},
  url       = {https://ieeexplore.ieee.org/document/5650910},
}

@Article{Steels2000,
  author     = {Steels, Luc and Kaplan, Fr\'{e}d\'{e}ric},
  journal    = {Evolution of Communication},
  title      = {{AIBO’s} first words: {The} social learning of language and meaning},
  year       = {2000},
  issn       = {1387-5337},
  month      = jan,
  number     = {1},
  pages      = {3--32},
  volume     = {4},
  abstract   = {This paper explores the hypothesis that language communication in its very first stage is bootstrapped in a social learning process under the strong influence of culture. A concrete framework for social learning has been developed based on the notion of a language game. Autonomous robots have been programmed to behave according to this framework. We show experiments that demonstrate why there has to be a causal role of language on category acquisition; partly by showing that it leads effectively to the bootstrapping of communication and partly by showing that other forms of learning do not generate categories usable in communication or make information assumptions which cannot be satisfied.},
  comment    = {NL commands in social learning and navigation

总的来说,本文是通过实验,建立了framework of social learning,即通过mediator and learner之间的互动来实现语言与concept的映射.文中并没有涉及机器人的动作,而主要讨论了对物体这种概念的学习.没有涉及各种算法细节,而是framework上的讨论.},
  doi        = {10.1075/eoc.4.1.03ste},
  file       = {:FILES/2000 - Steels2000 - AIBO’s first words- The social learning of language and meaning.pdf:PDF},
  groups     = {task understanding, 知识生成},
  keywords   = {skimmed},
  publisher  = {John Benjamins},
  readstatus = {skimmed},
  type       = {Journal Article},
  url        = {https://www.jbe-platform.com/content/journals/10.1075/eoc.4.1.03ste},
}

@InProceedings{Guerin2015,
  author     = {Guerin, Kelleher R. and Lea, Colin and Paxton, Chris and Hager, Gregory D.},
  booktitle  = {Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA)},
  title      = {A framework for end-user instruction of a robot assistant for manufacturing},
  year       = {2015},
  address    = {Seattle, WA, USA},
  month      = may,
  pages      = {6167--6174},
  publisher  = {IEEE},
  abstract   = {Small Manufacturing Entities (SMEs) have not incorporated robotic automation as readily as large companies due to rapidly changing product lines, complex and dexterous tasks, and the high cost of start-up. While recent low-cost robots such as the Universal Robots UR5 and Rethink Robotics Baxter are more economical and feature improved programming interfaces, based on our discussions with manufacturers further incorporation of robots into the manufacturing work flow is limited by the ability of these systems to generalize across tasks and handle environmental variation. Our goal is to create a system designed for small manufacturers that contains a set of capabilities useful for a wide range of tasks, is both powerful and easy to use, allows for perceptually grounded actions, and is able to accumulate, abstract, and reuse plans that have been taught. We present an extension to Behavior Trees that allows for representing the system capabilities of a robot as a set of generalizable operations that are exposed to an end-user for creating task plans. We implement this framework in CoSTAR, the Collaborative System for Task Automation and Recognition, and demonstrate its effectiveness with two case studies. We first perform a complex tool-based object manipulation task in a laboratory setting. We then show the deployment of our system in an SME where we automate a machine tending task that was not possible with current off the shelf robots.},
  comment    = {NL commands for manufacturing

本文设计了CoSTAR System来实现end-user instruction of industrial robots. 该系统包括GUI for users to build robot task plan，which can be re-used in generating other plans manually.这里面没有NL instruction的内容，也没有自主决策的内容。
本文将任务表示为behavior tree,定义了任务的执行顺序、条件等，},
  doi        = {10.1109/ICRA.2015.7140065},
  file       = {:FILES/2015 - Guerin2015 - A framework for end-user instruction of a robot assistant for manufacturing.pdf:PDF},
  groups     = {robots},
  issn       = {1050-4729},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/abstract/document/7140065},
}

@InProceedings{Hsiao2008,
  author    = {Hsiao, Kai-yuh and Vosoughi, Soroush and Tellex, Stefanie and Kubat, Rony and Roy, Deb},
  booktitle = {Proceedings of the 3rd ACM/IEEE International Conference on Human Robot Interaction (HRI)},
  title     = {Object schemas for responsive robotic language use},
  year      = {2008},
  address   = {New York, NY, USA},
  month     = mar,
  pages     = {233--240},
  publisher = {Association for Computing Machinery},
  series    = {HRI '08},
  abstract  = {The use of natural language should be added to a robot system without sacrificing responsiveness to the environment. In this paper, we present a robot that manipulates objects on a tabletop in response to verbal interaction. Reactivity is maintained by using concurrent interaction processes, such as visual trackers and collision detection processes. The interaction processes and their associated data are organized into object schemas, each representing a physical object in the environment, based on the target of each process. The object schemas then serve as discrete structures of coordination between reactivity, planning, and language use, permitting rapid integration of information from multiple sources.},
  comment   = {everyday assistant},
  doi       = {10.1145/1349822.1349853},
  file      = {:FILES/2008 - Hsiao2008 - Object Schemas for Responsive Robotic Language Use.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781605580173},
  keywords  = {behavior-based, robot, language grounding, affordances, object schema},
  location  = {Amsterdam, The Netherlands},
  url       = {https://dl.acm.org/doi/abs/10.1145/1349822.1349853},
}

@InProceedings{Hemachandra2015,
  author     = {Hemachandra, Sachithra and Duvallet, Felix and Howard, Thomas M. and Roy, Nicholas and Stentz, Anthony and Walter, Matthew R.},
  booktitle  = {Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA)},
  title      = {Learning models for following natural language directions in unknown environments},
  year       = {2015},
  address    = {Seattle, WA, USA},
  month      = may,
  pages      = {5608--5615},
  publisher  = {IEEE},
  abstract   = {Natural language offers an intuitive and flexible means for humans to communicate with the robots that we will increasingly work alongside in our homes and workplaces. Recent advancements have given rise to robots that are able to interpret natural language manipulation and navigation commands, but these methods require a prior map of the robot's environment. In this paper, we propose a novel learning framework that enables robots to successfully follow natural language route directions without any previous knowledge of the environment. The algorithm utilizes spatial and semantic information that the human conveys through the command to learn a distribution over the metric and semantic properties of spatially extended environments. Our method uses this distribution in place of the latent world model and interprets the natural language instruction as a distribution over the intended behavior. A novel belief space planner reasons directly over the map and behavior distributions to solve for a policy using imitation learning. We evaluate our framework on a voice-commandable wheelchair. The results demonstrate that by learning and performing inference over a latent environment model, the algorithm is able to successfully follow natural language route directions within novel, extended environments.},
  comment    = {本文的主要内容是提出了一种framework使得机器人可以follow NL route directions within unknown env by exploiting spatial and semantic knowledge explicitly expressed in the commands. 该方法的思想是从NL中提取action、spatial rel between entities in NL，而后建立entity之间空间关系的概率图模型，再利用imitation learning来学习在当前条件下所需执行的action，求解模型是多分类模型。具体的：
1.在给定NL instr + 传感器观测数据+机器人odometry data的情况下，推测其轨迹（条件概率）--unknown env下第二类数据可能不完整，所以引入latent world model, which is conditional dependent on NL instr. 机器人的behavior/action依赖于NL instr + latent world model。而最终机器人的轨迹依赖于上述三个变量。
2.P(latent | NL instr): 对instr进行NLP后，得到其grammatical structure, 然后建模为HDCG，以描述linguistic element与groundings之间的关系，是一种概率图模型，模型参数通过log-linear model训练而得到。利用HDCG模型来推断该概率，即annotations representing knowledge of env inferred from language. annotation包括两部分内容，即object type (文中是room type)和subspaces(文中表示为spatial rel.)-- 具体的推理方法没有细看。
3.P(behavior | latent, NL instr)：infer behaviors based on HDCG model. 主要涉及objects, subspaces, actions, objective, constraints.利用了semantic map and subspaces中的object等，
4.P(trajectory |behavior, latent, NL instr ): imitation learning

上述内容中关于TU的部分是1-3点，即由NL instr到behavior的映射过程，这部分内容的主要思想是利用HDCG表达环境中物体与NL instr的概率分布，从而利用概率图推理方法获得实际的映射关系，其中所利用到的是spatial rel.},
  doi        = {10.1109/ICRA.2015.7139984},
  file       = {:FILES/2015 - Hemachandra2015 - Learning models for following natural language directions in unknown environments.pdf:PDF;:FILES/notes/Hemachandra2015.docx:Word 2007+},
  groups     = {task understanding},
  issn       = {1050-4729},
  printed    = {Y},
  priority   = {prio2},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/7139984},
}

@InProceedings{Dominey2007,
  author    = {Dominey, Peter Ford and Mallet, Anthony and Yoshida, Eiichi},
  booktitle = {Proceedings of 2007 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Progress in programming the {HRP-2} humanoid using spoken language},
  year      = {2007},
  address   = {Rome, Italy},
  month     = apr,
  pages     = {2169--2174},
  publisher = {IEEE},
  abstract  = {The current research analyses and demonstrates how spoken language can be used by human users to communicate with the HRP-2 humanoid to program the robot's behavior in a cooperative task. The task involves the humans and the HRP-2 working together to assemble a piece of furniture. The objectives of the system are to 1) Allow the human to impart knowledge of how to accomplish a cooperative task to the robot, i.e. to program the robot, in the form of a sensory-motor action plan. 2) To do this in a semi-natural and real-time manner using spoken language. In this framework, a system for spoken language programming (SLP) is presented, and experimental results are presented from this prototype system. In Experiment 1, the human programs the robot to assist in assembling a small table. In Experiment 2, the generalization of the system is demonstrated as the user programs the robot to assist in taking the table apart. The SLP is evaluated in terms of the changes in efficiency as revealed by task completion time and number of command operations required to accomplish the tasks with and without SLP. Lessons learned are discussed, along with plans for improving the system, including developing a richer base of robot action and perception predicates that will allow the use of richer language. We thus demonstrate - for the first time - the capability for a human user to tell a humanoid what to do in a cooperative task so that in real time, the robot performs the task, and acquires new skills that significantly facilitate the cooperative human-robot interaction.},
  comment   = {association model},
  doi       = {10.1109/ROBOT.2007.363642},
  file      = {:FILES/2007 - Dominey2007 - Progress in Programming the HRP-2 Humanoid Using Spoken Language.pdf:PDF},
  groups    = {task understanding},
  issn      = {1050-4729},
  url       = {https://ieeexplore.ieee.org/abstract/document/4209406},
}

@InProceedings{House2009,
  author    = {House, Brandi and Malkin, Jonathan and Bilmes, Jeff},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI)},
  title     = {The {VoiceBot}: {A} voice controlled robot arm},
  year      = {2009},
  address   = {New York, NY, USA},
  month     = apr,
  pages     = {183--192},
  publisher = {Association for Computing Machinery},
  abstract  = {We present a system whereby the human voice may specify continuous control signals to manipulate a simulated 2D robotic arm and a real 3D robotic arm. Our goal is to move towards making accessible the manipulation of everyday objects to individuals with motor impairments. Using our system, we performed several studies using control style variants for both the 2D and 3D arms. Results show that it is indeed possible for a user to learn to effectively manipulate real-world objects with a robotic arm using only non-verbal voice as a control mechanism. Our results provide strong evidence that the further development of non-verbal voice controlled robotics and prosthetic limbs will be successful.},
  comment   = {grammar model},
  doi       = {10.1145/1518701.1518731},
  file      = {:FILES/2009 - House2009 - The VoiceBot- A Voice Controlled Robot Arm.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781605582467},
  keywords  = {motor impairment, speech recognition, robotics, voice-based interface},
  location  = {Boston, MA, USA},
  url       = {https://dl.acm.org/doi/abs/10.1145/1518701.1518731},
}

@Article{Bicho2010,
  author   = {Bicho, Estela and Louro, Lu\'{i}s and Erlhagen, Wolfram},
  journal  = {Frontiers in Neurorobotics},
  title    = {Integrating verbal and nonverbal communication in a dynamic neural field architecture for human-robot interaction},
  year     = {2010},
  issn     = {1662-5218},
  month    = may,
  pages    = {5},
  volume   = {4},
  abstract = {How do humans coordinate their intentions, goals and motor behaviors when performing joint action tasks? Recent experimental evidence suggests that resonance processes in the observer's motor system are crucially involved in our ability to understand actions of others’, to infer their goals and even to comprehend their action-related language. In this paper, we present a control architecture for human–robot collaboration that exploits this close perception-action linkage as a means to achieve more natural and efficient communication grounded in sensorimotor experiences. The architecture is formalized by a coupled system of dynamic neural fields representing a distributed network of neural populations that encode in their activation patterns goals, actions and shared task knowledge. We validate the verbal and nonverbal communication skills of the robot in a joint assembly task in which the human–robot team has to construct toy objects from their components. The experiments focus on the robot's capacity to anticipate the user's needs and to detect and communicate unexpected events that may occur during joint task execution.},
  comment  = {grammar model, v+ n 描述action, to align multiple types of sensor data
empirical association model, using the key aspects, such as preconditions or other details of the actions etc.},
  doi      = {10.3389/fnbot.2010.00005},
  file     = {:FILES/2010 - Bicho2010 - Integrating verbal and nonverbal communication in a dynamic neural field architecture for human-robot interaction.pdf:PDF},
  groups   = {task understanding},
  url      = {https://www.frontiersin.org/article/10.3389/fnbot.2010.00005},
}

@InProceedings{Lee2010,
  author    = {Lee, Sungjin and Kim, Changgu and Lee, Jonghoon and Noh, Hyungjong and Lee, Kyusong and Lee, Gary Geunbae},
  booktitle = {2010 IEEE Spoken Language Technology Workshop},
  title     = {Affective effects of speech-enabled robots for language learning},
  year      = {2010},
  address   = {Berkeley, CA, USA},
  month     = dec,
  pages     = {145--150},
  publisher = {IEEE},
  abstract  = {This study introduces the speech and language technologies used in the educational assistant robots that we developed for language learning and exploring the affective effects of robot-assisted language learning (RALL). To achieve this purpose, a course was designed in which students have meaningful interaction with intelligent robots in an immersive environment. A total of 24 elementary students, ranging in age over 9-13, were enrolled in English lessons. Descriptive statistics and pre-test/post-test design were used to investigate the affective effects of RALL approach. The result showed that RALL is promoting and improving students' satisfaction, interest, confidence, and motivation at the significance level of 0.01.},
  comment   = {grammar model, with pattern keyword + POS tagging combination
empirical association model, using the key aspects, such as preconditions or other details of the actions etc.},
  doi       = {10.1109/SLT.2010.5700837},
  file      = {:FILES/2010 - Lee2010 - Affective effects of speech-enabled robots for language learning.pdf:PDF},
  groups    = {task understanding},
  url       = {https://ieeexplore.ieee.org/abstract/document/5700837},
}

@InProceedings{Lee2005,
  author    = {Kang Woo Lee and Hyoung-Rock Kim and Wan Chul Yoon and Young-Sik Yoon and Dong-Soo Kwon},
  booktitle = {Proceedings of 2005 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN)},
  title     = {Designing a human-robot interaction framework for home service robot},
  year      = {2005},
  address   = {Nashville, TN, USA},
  month     = aug,
  pages     = {286--293},
  publisher = {IEEE},
  abstract  = {This paper presents a human-robot interaction framework that outlines a general structure of future home service robots that are expected to assist humans in their home-based daily activities. We describe three interaction modules - multimodal, cognitive, and emotional interaction modules. Each module takes a different role in the process of human robot interaction. The purpose of multi-modal interaction is to make the interaction convenient for the human, the cognitive interaction is for cooperative sharing of tasks, and the emotional interaction is to maintain a close relationship. The general concept for the systematical software integration and the relationships among the three modules are described.},
  comment   = {grammar model, with pattern keyword + POS tagging combination},
  doi       = {10.1109/ROMAN.2005.1513793},
  file      = {:FILES/2005 - Lee2005 - Designing a human-robot interaction framework for home service robot.pdf:PDF},
  groups    = {task understanding},
  issn      = {1944-9437},
  url       = {https://ieeexplore.ieee.org/abstract/document/1513793},
}

@InProceedings{Ovchinnikova2015,
  author    = {Ovchinnikova, Ekaterina and Wachter, Mirko and Wittenbeck, Valerij and Asfour, Tamim},
  booktitle = {Proceedings of the 2015 IEEE-RAS 15th International Conference on Humanoid Robots (Humanoids)},
  title     = {Multi-purpose natural language understanding linked to sensorimotor experience in humanoid robots},
  year      = {2015},
  address   = {Seoul, Korea (South)},
  month     = nov,
  pages     = {365--372},
  publisher = {IEEE},
  abstract  = {Humans have an amazing ability to bootstrap new knowledge. The concept of structural bootstrapping refers to mechanisms relying on prior knowledge, sensorimotor experience, and inference that can be implemented in robotic systems and employed to speed up learning and problem solving in new environments. In this context, the interplay between the symbolic encoding of the sensorimotor information, prior knowledge, planning, and natural language understanding plays a significant role. In this paper, we show how the symbolic descriptions of the world can be generated on the fly from the continuous robot's memory. We also introduce a multi-purpose natural language understanding framework that processes human spoken utterances and generates planner goals as well as symbolic descriptions of the world and human actions. Both components were tested on the humanoid robot ARMAR-III in a scenario requiring planning and plan recognition based on human-robot communication.},
  comment   = {interpreted model},
  doi       = {10.1109/HUMANOIDS.2015.7363576},
  file      = {:FILES/2015 - Ovchinnikova2015 - Multi-purpose natural language understanding linked to sensorimotor experience in humanoid robots.pdf:PDF},
  groups    = {task understanding},
  url       = {https://ieeexplore.ieee.org/abstract/document/7363576},
}

@Article{Dantam2013,
  author   = {Dantam, Neil and Stilman, Mike},
  journal  = {IEEE Transactions on Robotics},
  title    = {The motion grammar: {Analysis} of a linguistic method for robot control},
  year     = {2013},
  issn     = {1941-0468},
  month    = jun,
  number   = {3},
  pages    = {704--718},
  volume   = {29},
  abstract = {We present the Motion Grammar: an approach to represent and verify robot control policies based on context-free grammars. The production rules of the grammar represent a top-down task decomposition of robot behavior. The terminal symbols of this language represent sensor readings that are parsed in real time. Efficient algorithms for context-free parsing guarantee that online parsing is computationally tractable. We analyze verification properties and language constraints of this linguistic modeling approach, show a linguistic basis that unifies several existing methods, and demonstrate effectiveness through experiments on a 14-degree-of-freedom (DOF) manipulator interacting with 32 objects (chess pieces) and an unpredictable human adversary. We provide many of the algorithms discussed as Open Source, permissively licensed software.},
  comment  = {grammar model, v+ n 描述action
Zhang2019a:use context-free grammar models to parse task requests, the reason these grammar models are ineffective in practice may be that such grammar models have difficulty in modeling long-distance dependency phenomena.},
  doi      = {10.1109/TRO.2013.2239553},
  file     = {:FILES/2013 - Dantam2013 - The Motion Grammar- Analysis of a Linguistic Method for Robot Control.pdf:PDF},
  groups   = {task understanding},
  url      = {https://ieeexplore.ieee.org/abstract/document/6457507},
}

@InProceedings{McGuire2002,
  author     = {{McGuire}, P. and Fritsch, J. and Steil, J. J. and Rothling, F. and Fink, G. A. and Wachsmuth, S. and Sagerer, G. and Ritter, H.},
  booktitle  = {Proceedings of the 2002 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title      = {Multi-modal human-machine communication for instructing robot grasping tasks},
  year       = {2002},
  address    = {Lausanne, Switzerland},
  month      = sep,
  pages      = {1082--1088},
  publisher  = {IEEE},
  volume     = {2},
  abstract   = {A major challenge for the realization of intelligent robots is to supply them with cognitive abilities in order to allow ordinary users to program them easily and intuitively. One approach to such programming is teaching work tasks by interactive demonstration. To make this effective and convenient for the user, the machine must be capable of establishing a common focus of attention and be able to use and integrate spoken instructions, visual perception, and non-verbal clues like gestural commands. We report progress in building a hybrid architecture that combines statistical methods, neural networks, and finite state machines into an integrated system for instructing grasping tasks by man-machine interaction. The system combines the GRAVIS-robot for visual attention and gestural instruction with an intelligent interface for speech recognition and linguistic interpretation, and a modality fusion module to allow multi-modal task-oriented man-machine communication with respect to dextrous robot manipulation of objects.},
  comment    = {grammar model, v+ n 描述temporal relation},
  doi        = {10.1109/IRDS.2002.1043875},
  file       = {:FILES/2002 - McGuire2002 - Multi-modal human-machine communication for instructing robot grasping tasks.pdf:PDF},
  groups     = {task understanding, from visual, from tactile, from kinematics},
  priority   = {prio2},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/1043875},
}

@InProceedings{Kollar2013,
  author    = {Kollar, Thomas and Perera, Vittorio and Nardi, Daniele and Veloso, Manuela},
  booktitle = {Proceedings of the 2013 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Learning environmental knowledge from task-based human-robot dialog},
  year      = {2013},
  address   = {Karlsruhe, Germany},
  month     = may,
  pages     = {4304--4309},
  publisher = {IEEE},
  abstract  = {This paper presents an approach for learning environmental knowledge from task-based human-robot dialog. Previous approaches to dialog use domain knowledge to constrain the types of language people are likely to use. In contrast, by introducing a joint probabilistic model over speech, the resulting semantic parse and the mapping from each element of the parse to a physical entity in the building (e.g., grounding), our approach is flexible to the ways that untrained people interact with robots, is robust to speech to text errors and is able to learn referring expressions for physical locations in a map (e.g., to create a semantic map). Our approach has been evaluated by having untrained people interact with a service robot. Starting with an empty semantic map, our approach is able ask 50% fewer questions than a baseline approach, thereby enabling more effective and intuitive human robot dialog.},
  comment   = {theoretical association model, learn from human's experience (high level knowledge)
Lu2016a: Grounding the missing semantic roles with the entities in the context
Perara2015: grounding NL using probabilisitic methods based on KB and semantic frame},
  doi       = {10.1109/ICRA.2013.6631186},
  file      = {:FILES/2013 - Kollar2013 - Learning environmental knowledge from task-based human-robot dialog.pdf:PDF},
  groups    = {task understanding},
  issn      = {1050-4729},
  url       = {https://ieeexplore.ieee.org/abstract/document/6631186},
}

@InProceedings{Fasola2013,
  author    = {Fasola, Juan and Mataric, Maja J.},
  booktitle = {Proceedings of the 2013 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Using semantic fields to model dynamic spatial relations in a robot architecture for natural language instruction of service robots},
  year      = {2013},
  address   = {Tokyo, Japan},
  month     = nov,
  pages     = {143--150},
  publisher = {IEEE},
  abstract  = {We present a methodology for enabling service robots to follow natural language commands from non-expert users, with and without user-specified constraints, with a particular focus on spatial language understanding. As part of our approach, we propose a novel extension to the semantic field model of spatial prepositions that enables the representation of dynamic spatial relations involving paths. The design, system modules, and implementation details of our robot software architecture are presented and the relevance of the proposed methodology to interactive instruction and task modification through the addition of constraints is discussed. The paper concludes with an evaluation of our robot software architecture implemented on a simulated mobile robot operating in both a 2D home environment and in real world environment maps to demonstrate the generalizability and usefulness of our approach in real world applications.},
  comment   = {theoretical association model, learn from commonsense knowledge
Howard2014a: NL in route direction following},
  doi       = {10.1109/IROS.2013.6696345},
  file      = {:FILES/2013 - Fasola2013 - Using semantic fields to model dynamic spatial relations in a robot architecture for natural language instruction of service robots.pdf:PDF},
  groups    = {task understanding},
  issn      = {2153-0866},
  url       = {https://ieeexplore.ieee.org/abstract/document/6696345},
}

@InProceedings{Zender2007,
  author    = {Hendrik Zender and Patric Jensfelt and \'{o}scar Martínez Mozos and Geert-Jan M. Kruijff and Wolfram Burgard},
  booktitle = {Proceedings of the 22nd AAAI Conference on Artificial Intelligence},
  title     = {An integrated robotic system for spatial understanding and situated interaction in indoor environments},
  year      = {2007},
  address   = {Vancouver, British Columbia},
  month     = jul,
  pages     = {1584--1589},
  publisher = {AAAI Press},
  comment   = {grammar model, v+ n 描述temporal relation},
  file      = {:FILES/2007 - Zender2007 - An Integrated Robotic System for Spatial Understanding and Situated Interaction in Indoor Environments.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.aaai.org/Library/AAAI/aaai07contents.php},
}

@Article{Scheutz2011,
  author  = {Matthias Scheutz and Rehj Cantrell and Paul Schermerhorn},
  journal = {AI Magazine},
  title   = {Toward humanlike task-based dialogue processing for human robot interaction},
  year    = {2011},
  month   = dec,
  number  = {4},
  pages   = {77--84},
  volume  = {32},
  comment = {grammar model, v+ n 描述spatial relation},
  doi     = {10.1609/aimag.v32i4.2381},
  file    = {:FILES/2011 - Scheutz2011 - Toward Humanlike Task-Based Dialogue Processing for Human Robot Interaction.pdf:PDF},
  groups  = {task understanding},
  url     = {https://ojs.aaai.org/index.php/aimagazine/article/view/2381},
}

@Misc{Lu2016a,
  author        = {Lu, Dongcai and Wu, Feng and Chen, Xiaoping},
  month         = jun,
  title         = {Understanding user instructions by utilizing open knowledge for service robots},
  year          = {2016},
  archiveprefix = {arXiv},
  comment       = {theoretical association model, learn from commonsense knowledge

基本是{卢栋才2017}的内容.主要解决：如何define semantics of meanings of common verbs, match and recover such semantics in user instructions, handle a large number of instruction, and Generate plans in real-time using open knowledge resource.
1. 可以处理两种user instruction: task-oriented instructions (如serve a meal) + desire-oriented instructions (如I’m thirty)
2. 系统包括：
2.1 Human-robot dialog module
2.2 Processing module： OMICS + FrameNet,将NL instructions表示为基于FrameNet的元语言
2.3 motion planner 
2.4 control module},
  eprint        = {1606.02877},
  file          = {:FILES/2016 - Lu2016a - Understanding User Instructions by Utilizing Open Knowledge for Service Robots.pdf:PDF},
  groups        = {task understanding},
  primaryclass  = {cs.RO},
  printed       = {Y},
  readstatus    = {read},
  url           = {https://arxiv.org/abs/1606.02877},
}

@Article{Jayawardena2007,
  author    = {Chandimal Jayawardena and Keigo Watanabe and Kiyotaka Izumi},
  journal   = {Advanced Robotics},
  title     = {Posture control of robot manipulators with fuzzy voice commands using a fuzzy coach–player system},
  year      = {2007},
  number    = {3-4},
  pages     = {293--328},
  volume    = {21},
  abstract  = {This paper presents a method of controlling robot manipulators with fuzzy voice commands. Recently, there has been some research on controlling robots using information-rich fuzzy voice commands such as 'go little slowly' and learning from such commands. However, the scope of all those works was limited to basic fuzzy voice motion commands. In this paper, we introduce a method of controlling the posture of a manipulator using complex fuzzy voice commands. A complex fuzzy voice command is composed of a set of fuzzy voice joint commands. Complex fuzzy voice commands can be used for complicated maneuvering of a manipulator, while fuzzy voice joint commands affect only a single joint. Once joint commands are learned, any complex command can be learned as a combination of some or all of them, so that, using the learned complex commands, a human user can control the manipulator in a complicated manner with natural language commands. Learning of complex commands is discussed in the framework of fuzzy coach–player model. The proposed idea is demonstrated with a PA-10 redundant manipulator.},
  comment   = {empirical association model, using discrete values of sensors, such as close and open, etc},
  doi       = {10.1163/156855307780131983},
  file      = {:FILES/2007 - Jayawardena2007 - Posture control of robot manipulators with fuzzy voice commands using a fuzzy coach–player system.pdf:PDF},
  groups    = {task understanding},
  publisher = {Taylor \& Francis},
  url       = {https://www.tandfonline.com/doi/abs/10.1163/156855307780131983},
}

@InProceedings{Cantrell2011,
  author    = {Cantrell, Rehj and Schermerhorn, Paul and Scheutz, Matthias},
  booktitle = {Proceedings of 2011 IEEE International Workshop on Robot and Human Interactive Communication (RO-MAN)},
  title     = {Learning actions from human-robot dialogues},
  year      = {2011},
  address   = {Atlanta, GA, USA},
  month     = jul,
  pages     = {125--130},
  publisher = {IEEE},
  abstract  = {Natural language interactions between humans and robots are currently limited by many factors, most notably by the robot's concept representations and action repertoires. We propose a novel algorithm for learning meanings of action verbs through dialogue-based natural language descriptions. This functionality is deeply integrated in the robot's natural language subsystem and allows it to perform the actions associated with the learned verb meanings right away without any additional help or learning trials. We demonstrate the effectiveness of the algorithm in a scenario where a human explains to a robot the meaning of an action verb unknown to the robot and the robot is subsequently able to carry out the instructions involving this verb.},
  comment   = {empirical association model, using the key aspects, such as preconditions or other details of the actions etc.},
  doi       = {10.1109/ROMAN.2011.6005199},
  file      = {:FILES/2011 - Cantrell2011 - Learning actions from human-robot dialogues.pdf:PDF},
  groups    = {task understanding},
  issn      = {1944-9437},
  url       = {https://ieeexplore.ieee.org/abstract/document/6005199},
}

@Article{Zhang2003,
  author   = {Zhang, Jianwei and Knoll, Alois},
  journal  = {IEEE Transactions on Industrial Electronics},
  title    = {A two-arm situated artificial communicator for human-robot cooperative assembly},
  year     = {2003},
  issn     = {1557-9948},
  month    = aug,
  number   = {4},
  pages    = {651--658},
  volume   = {50},
  abstract = {We present the development of a robot system with some cognitive capabilities, as well as experimental results. We focus on two topics: assembly by two hands and understanding human instructions in nonconstrained natural language. These two features distinguish human beings from animals, and are, thus, the means leading to high-level intelligence. A typical application of such a system is a human-robot cooperative assembly. A human communicator sharing a view of the assembly scenario with the robot instructs the latter by speaking to it in the same way that he would communicate with a child whose common-sense knowledge is limited. His instructions can be underspecified, incomplete, and/or context dependent. After introducing the general purpose of our research project, we present the hardware and software components of our robots needed for interactive assembly tasks. We then discuss the control architecture of the robot system with two stationary robot arms by describing the functionalities of perception, instruction understanding, and execution. To show how our robot learns from humans, the implementations of a layered learning methodology, memory, and monitoring functions are introduced. Finally, we outline a list of future research topics related to the enhancement of such systems.},
  comment  = {empirical association model, using discrete values of sensors, such as close and open, etc
difficulty: human social behavior understanding and mimicking},
  doi      = {10.1109/TIE.2003.814767},
  file     = {:FILES/2003 - Zhang2003 - A two-arm situated artificial communicator for human-robot cooperative assembly.pdf:PDF},
  groups   = {task understanding},
  url      = {https://ieeexplore.ieee.org/abstract/document/1215467},
}

@InProceedings{Fong2012,
  author    = {Terrence Fong and Illah Nourbakhsh and Clayton Kunz and Lorenzo Fluckiger and John Schreiner and Robert Ambrose and Robert Burridge and Reid Simmons and Laura Hiatt and Alan Schultz and J. Gregory Trafton and Magda Bugajska and Jean Scholtz},
  booktitle = {Proceedings of Space 2005},
  title     = {The peer-to-peer human-robot interaction project},
  year      = {2012},
  address   = {Long Beach, California, USA},
  month     = aug,
  pages     = {1--11},
  publisher = {AIAA},
  comment   = {empirical association model, using the knowledge of the environment where the human locates and which he/she sensors},
  doi       = {10.2514/6.2005-6750},
  file      = {:FILES/2012 - Fong2012 - The Peer-to-Peer Human-Robot Interaction Project.pdf:PDF},
  groups    = {task understanding},
  url       = {https://arc.aiaa.org/doi/abs/10.2514/6.2005-6750},
}

@Article{Rybski2008,
  author   = {Rybski, Paul E. and Stolarz, Jeremy and Yoon, Kevin and Veloso, Manuela},
  journal  = {Intelligent Service Robotics},
  title    = {Using dialog and human observations to dictate tasks to a learning robot assistant},
  year     = {2008},
  issn     = {1861-2784},
  number   = {2},
  pages    = {159--167},
  volume   = {1},
  abstract = {Robot assistants need to interact with people in a natural way in order to be accepted into people’s day-to-day lives. We have been researching robot assistants with capabilities that include visually tracking humans in the environment, identifying the context in which humans carry out their activities, understanding spoken language (with a fixed vocabulary), participating in spoken dialogs to resolve ambiguities, and learning task procedures. In this paper, we describe a robot task learning algorithm in which the human explicitly and interactively instructs a series of steps to the robot through spoken language. The training algorithm fuses the robot’s perception of the human with the understood speech data, maps the spoken language to robotic actions, and follows the human to gather the action applicability state information. The robot represents the acquired task as a conditional procedure and engages the human in a spoken-language dialog to fill in information that the human may have omitted.},
  comment  = {empirical association model, using the knowledge of the environment where the human locates and which he/she sensors},
  doi      = {10.1007/s11370-008-0016-5},
  file     = {:FILES/2008 - Rybski2008 - Using dialog and human observations to dictate tasks to a learning robot assistant.pdf:PDF},
  groups   = {task understanding},
  url      = {https://link.springer.com/article/10.1007/s11370-008-0016-5},
}

@InProceedings{Liu2016d,
  author     = {Liu, Rui and Webb, Jeremy and Zhang, Xiaoli},
  booktitle  = {Proceedings of the ASME 2016 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference (IDETC/CIE 2016)},
  title      = {Natural-language-instructed industrial task execution},
  year       = {2016},
  address    = {Charlotte, North Carolina},
  month      = aug,
  pages      = {1--7},
  publisher  = {The Americal Society of Mechanical Engineers},
  volume     = {1B},
  abstract   = {{To effectively cooperate with a human, advanced manufacturing machines are expected to execute the industrial tasks according to human natural language (NL) instructions. However, NL instructions are not explicit enough to be understood and are not complete enough to be executed, leading to incorrected executions or even execution failure. To address these problems for better execution performance, we developed a Natural-Language-Instructed Task Execution (NL-Exe) method. In NL-Exe, semantic analysis is adopted to extract task-related knowledge, based on what human NL instructions are accurately understood. In addition, logic modeling is conducted to search the missing execution-related specifications, with which incomplete human instructions are repaired. By orally instructing a humanoid robot Baxter to perform industrial tasks “drill a hole” and “clean a spot”, we proved that NL-Exe could enable an advanced manufacturing machine to accurately understand human instructions, improving machine’s performance in industrial task execution.}},
  comment    = {empirical association model, using the key aspects, such as preconditions or other details of the actions etc.
Liu2016e: activity related situation knowledge is learned from human demonstration in a one way manner.

本文提出了一种natural language instructed task execution (NL-Exe) method来讲自然语言指令翻译成机器人可执行的任务，包括三部分
1. semantic analysis: 利用SR技术将语音信号翻译成text，利用NLP方法得到其words, PoS tags, dependencies, etc,而后word normalization, structure analysis, goal matching (利用特征keywords, pos tags, dependencies来与KB中事先定义的goal进行匹配，计算相似度，从而识别出what to do)
2.  knowledge world mapping: 将NL中的machine execution specification (MES，包括goal, precondition, action, tool, location, requirement) 与形式化表达的任务参数进行一一对应，所利用的方法文中没说，也应该是基于语义分析结果和特定规则的
3. executable plan generation,包括missing sub-goal generation (本文未讨论) + missing MES generation. 目标是将NL生成可执行的指令序列，方法是backward-chaining logic method【31】, 基于first logic

总结：
1. 本文是单纯利用NL，考虑了环境和action的因素，作为precondition，但是并没有结合感知系统来真正的感知环境
2. knowledge base是first order logic集合，需要人为制定，目前的任务数较少，扩展性差
3. 不能处理指令中的oov，},
  doi        = {10.1115/DETC2016-60063},
  file       = {:FILES/2016 - Liu2016d - Natural-Language-Instructed Industrial Task Execution.pdf:PDF},
  groups     = {task understanding},
  printed    = {Y},
  priority   = {prio2},
  readstatus = {read},
  url        = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings/IDETC-CIE2016/50084/V01BT02A043/258091},
}

@InProceedings{Walter2013,
  author     = {Walter, Matthew R. and Hemachandra, Sachithra Madhaw and Homberg, Bianca S. and Tellex, Stefanie and Teller, Seth},
  booktitle  = {Proceedings of the 2013 Robotics: Science and Systems IX Conference},
  title      = {Learning semantic maps from natural language descriptions},
  year       = {2013},
  address    = {Berlin, Germany},
  month      = jun,
  publisher  = {Robotics: Science and Systems},
  comment    = {用多模态数据来纠正语义
Liu2016d: use logic relation for task execution. <action + object> pattern for generalization
Boularias2015:Navigation based on G3, incorporates odometry and path constraints in grounding
Hemachandra2015:interpret natural language expressions that convey environment knowledge,利用NL来学习world model  ，只对机器人observe的环境有用, modified semantic map used in 本文
Howard2014a: NL in map building
Hemachandra2014:前期工作：Guided tour中，利用NL utterances + sensor data 来获取environment description，即a joint distribution over a semantic graph。 Attributes of env包括names fro regions, properties of areas outside of the sensor range等typical sensor 不能感知到的信息。利用semantic knowledge to influence the semantic graph.
Duvallet2016: using the robot’s sensor observations to update its representation of the world. integrate language descriptions to improve the representation but do not extend the maps based on natural language.  combinatorial number of candidate topologies. The labels might be uncertain


与Hemachandra2014的内容基本相同，主要是没有考虑sensor data from camera。},
  file       = {:FILES/2013 - Walter2013 - Learning Semantic Maps from Natural Language Descriptions.pdf:PDF;:FILES/notes/Walter2013.docx:Word 2007+},
  groups     = {task understanding},
  printed    = {Y},
  readstatus = {skimmed},
  url        = {https://dspace.mit.edu/handle/1721.1/87051},
}

@InProceedings{Brenner2007,
  author    = {Michael Brenner and Nick Hawes and John Kelleher and Jeremy Wyatt},
  booktitle = {Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI)},
  title     = {Mediating between qualitative and quantitative representations for task-orientated human-robot interaction},
  year      = {2007},
  address   = {Hyderabad, India},
  month     = jan,
  pages     = {2072--2077},
  publisher = {AAAI Press},
  abstract  = {In human-robot interaction (HRI) it is essential that the robot interprets and reacts to a human's utterances in a manner that reflects their intended meaning. In this paper we present a collection of novel techniques that allow a robot to interpret and execute spoken commands describing manipulation goals involving qualitative spatial constraints (e.g. "put the red ball near the blue cube"). The resulting implemented system integrates computer vision, potential field models of spatial relationships, and action planning to mediate between the continuous real world, and discrete, qualitative representations used for symbolic reasoning.},
  comment   = {empirical association model, using ambiguous words or phrases to describe the sensor values, such as slowly, etc.},
  file      = {:FILES/2007 - Brenner2007 - Mediating between Qualitative and Quantitative Representations for Task-Orientated Human-Robot Interaction.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.ijcai.org/proceedings/2007},
}

@InProceedings{Bastianelli2016,
  author     = {Emanuele Bastianelli and Danilo Croce and Andrea Vanzo and Roberto Basili and Daniele Nardi},
  booktitle  = {Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI)},
  title      = {A discriminative approach to grounded spoken language understanding in interactive robotics},
  year       = {2016},
  address    = {New York, New York, USA},
  month      = jul,
  pages      = {2747--2753},
  publisher  = {AAAI Press},
  comment    = {VillamarGomez2021 : "use  discriminative learning and distributional semantics to extend [39]. Spoken language understanding is achieved using linguistic data
and perceptual knowledge. Although this approach deals with ambiguous sentence structures, it does not consider situations where knowledge is missing in the semantic map, and neither creates any spoken interaction other than upon receiving
the initial command."
Thomason2019:




用多模态数据来纠正语义

本文主要内容是利用spoken NL + percepted env knowledge来建立action。
{卢栋才2017}的主要内容与本文方法类似：
1. 基于FrameNet
2. 主要流程：<sentence>--<words>--<features>--<labels>
3. 包括三个步骤，即action detection, argument identification, argumentation classification。第一个过程是利用semantic map + sentence + platform model来识别sentence所对应的frame；第二个过程是识别句子中的子句以及meaning carrier word，第三个过程是预测句子中各frame element的role label。
4.三个过程都用的是structured SVM, 状态分别是frame label, BIEO tags, role label, 观测分别为words, words, 子句span。
5. 对环境的感知在第二个过程中发挥作用，是作为一种特征。
6.grounding要实现的是建立环境感知到物体的描述--框架元素的语义描述之间的对应关系，所利用的方法是lexicalized distance function, 该度量基于semantic vector + phonetic similarity，并利用所预设的empirical threshold (relating to spatial distance)来判定是否存在映射关系。
7. 本文可以处理未知词，其实就是在grounding中利用了distributional model of lexical semantics + phonetic similarity (文献中方法)，且grounding中未利用物体的属性},
  file       = {:FILES/2016 - Bastianelli2016 - A Discriminative Approach to Grounded Spoken Language Understanding in Interactive Robotics.pdf:PDF},
  groups     = {task understanding},
  priority   = {prio1},
  readstatus = {read},
  url        = {https://www.ijcai.org/Abstract/16/390},
}

@InProceedings{Thomason2015,
  author     = {Jesse Thomason and Shiqi Zhang and Raymond Mooney and Peter Stone},
  booktitle  = {Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)},
  title      = {Learning to interpret natural language commands through human-robot dialog},
  year       = {2015},
  address    = {Buenos Aires, Argentina},
  month      = jul,
  publisher  = {AAAI Press},
  comment    = {多模态数据纠正语义
Bastianelli2016: weighted CCG parses utterances into lambda calculus expressions for querying KB about env.具有学习新知识的能力，可以处理unknown words through dialog
Cui2021: collects information from user during natural language processing (NLP) representing HRI actions using planning actions.
Zhang2019a:Introducing a user clarification mechanism to enable robots to acquire the missing key information through dialogue and inquiry
Savage2019: use the University of Washington Semantic Parsing Framework to map natural language sentences to a λ- calculus representation.
Thomason2019: 利用clarification dialog来增强semantic parsing,物体识别,记录过程中的utterance-denotation pair来重新训练模型.},
  file       = {:FILES/2015 - Thomason2015 - Learning to interpret natural language commands through human-robot dialog.pdf:PDF},
  groups     = {task understanding},
  printed    = {Y},
  readstatus = {skimmed},
  url        = {https://www.ijcai.org/proceedings/2015},
}

@InProceedings{Bischoff2002,
  author    = {Bischoff, Rainer and Graefe, Volker},
  booktitle = {Proceedings. 11th IEEE International Workshop on Robot and Human Interactive Communication},
  title     = {Dependable multimodal communication and interaction with robotic assistants},
  year      = {2002},
  address   = {Berlin, Germany},
  month     = sep,
  pages     = {300--305},
  abstract  = {To advance research in the field of multimodal human-robot communication we designed and built the humanoid robot Hermes. Equipped with an omnidirectional undercarriage and two manipulator arms it combines visual, kinesthetic, tactile, and auditory sensing with natural spoken language input and output and body expressions for natural communication and interaction with humans. Hermes was successfully tested in an extended six-month experiment in a museum where only naive users interacted with the robot. They chatted with Hermes in several languages and requested various services. Multimodal communication and an understanding of the current situation by the robot turned out to be the key to success.},
  doi       = {10.1109/ROMAN.2002.1045639},
  file      = {:FILES/2002 - Bischoff2002 - Dependable multimodal communication and interaction with robotic assistants.pdf:PDF},
  groups    = {from tactile},
  url       = {https://ieeexplore.ieee.org/abstract/document/1045639},
}

@Article{Breazeal2002,
  author   = {Breazeal, Cynthia and Aryananda, Lijin},
  journal  = {Autonomous Robots},
  title    = {Recognition of affective communicative intent in robot-directed speech},
  year     = {2002},
  issn     = {1573-7527},
  number   = {1},
  pages    = {83--104},
  volume   = {12},
  abstract = {Human speech provides a natural and intuitive interface for both communicating with humanoid robots as well as for teaching them. In general, the acoustic pattern of speech contains three kinds of information: who the speaker is, what the speaker said, and how the speaker said it. This paper focuses on the question of recognizing affective communicative intent in robot-directed speech without looking into the linguistic content. We present an approach for recognizing four distinct prosodic patterns that communicate praise, prohibition, attention, and comfort to preverbal infants. These communicative intents are well matched to teaching a robot since praise, prohibition, and directing the robot's attention to relevant aspects of a task, could be used by a human instructor to intuitively facilitate the robot's learning process. We integrate this perceptual ability into our robot's “emotion” system, thereby allowing a human to directly manipulate the robot's affective state. This has a powerful organizing influence on the robot's behavior, and will ultimately be used to socially communicate affective reinforcement. Communicative efficacy has been tested with people very familiar with the robot as well as with naïve subjects.},
  comment  = {facial expression},
  doi      = {10.1023/A:1013215010749},
  file     = {:FILES/2002 - Breazeal2002 - Recognition of Affective Communicative Intent in Robot-Directed Speech.pdf:PDF},
  groups   = {from visual},
  refid    = {Breazeal2002},
  url      = {https://link.springer.com/article/10.1023/A:1013215010749},
}

@InProceedings{Connell2012,
  author    = {Connell, Jonathan and Marcheret, Etienne and Pankanti, Sharath and Kudoh, Michiharu and Nishiyama, Risa},
  booktitle = {Artificial General Intelligence},
  title     = {An extensible language interfacefor robot manipulation},
  year      = {2012},
  address   = {Berlin, Heidelberg},
  editor    = {Bach, Joscha and Goertzel, Ben and Ikl{\'e}, Matthew},
  pages     = {21--30},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {This paper describes our Extensible Language Interface (ELI) for robots. The system is intended to interpret far-field speech commands in order to perform fetch-and-carry tasks, potentially for use in an eldercare context. By ``extensible'' we mean that the robot is able to learn new nouns and verbs by simple interaction with its user. An associated video [1] illustrates the range of phenomena handled by our implemented real-time system.},
  comment   = {hand pose},
  doi       = {10.1007/978-3-642-35506-6_3},
  file      = {:FILES/2012 - Connell2012 - An extensible language Interfacefor Robot Manipulation.pdf:PDF},
  groups    = {from visual},
  isbn      = {978-3-642-35506-6},
  url       = {https://link.springer.com/chapter/10.1007/978-3-642-35506-6_3},
}

@InProceedings{Stiefelhagen2004,
  author    = {Stiefelhagen, R. and Fugen, C. and Gieselmann, R. and Holzapfel, H. and Nickel, K. and Waibel, A.},
  booktitle = {Proceedings of the 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Natural human-robot interaction using speech, head pose and gestures},
  year      = {2004},
  address   = {Sendai, Japan},
  month     = sep,
  pages     = {2422--2427},
  publisher = {IEEE},
  volume    = {3},
  abstract  = {In this paper we present our ongoing work in building technologies for natural multimodal human-robot interaction. We present our systems for spontaneous speech recognition, multimodal dialogue processing and visual perception of a user, which includes the recognition of pointing gestures as well as the recognition of a person's head orientation. Each of the components is described in the paper and experimental results are presented. In order to demonstrate and measure the usefulness of such technologies for human-robot interaction, all components have been integrated on a mobile robot platform and have been used for real-time human-robot interaction in a kitchen scenario.},
  comment   = {head orientation
NLC面临的困难：humanlike cooperation},
  doi       = {10.1109/IROS.2004.1389771},
  file      = {:FILES/2004 - Stiefelhagen2004 - Natural human-robot interaction using speech, head pose and gestures.pdf:PDF},
  groups    = {from visual, task understanding},
  url       = {https://ieeexplore.ieee.org/abstract/document/1389771},
}

@InProceedings{Ghidary2001,
  author     = {Ghidary, Saeed Shiry and Nakata, Yasushi and Saito, Hiroshi and Hattori, Motofumi and Takamori, Toshi},
  booktitle  = {Proceedings of the 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title      = {Multi-modal human robot interaction for map generation},
  year       = {2001},
  address    = {Maui, HI, USA},
  month      = oct,
  pages      = {2246--2251},
  publisher  = {IEEE},
  volume     = {4},
  abstract   = {Describes an interface for multi modal human robot interaction, which enables people to introduce a newcomer robot to different attributes of objects and places in the room through speech commands and hand gestures. The robot makes an environment map of the room based on knowledge learned through communication with human and uses this map for navigation. The developed system consists of several sections including: natural language processing, posture recognition, object localization and map generation. This system uses a combination of multiple sources of information and model matching to detect and track a human hand so that the user can point toward an object of interest and guide the robot to go near to it or locate that object's position in the room. The position of objects in the room is located by a monocular camera vision and depth from focus method.},
  comment    = {NLC面临的困难：complex instruction understanding
Perara2015: use NL for mapping of unknown environments


1.本文enables human to introduce objects in his relatively unstructured room to the robot through verbal statements and teach object’s position by hand gestures and linguistic description。 从而利用知识构建环境地图以用于导航任务。
2. 设定了predefined command set,只能处理sentences with simple structure。
2.1 command category: motional commands (如go, stop, turn left等), direct and indirect localization statement (传递place或物体位置信息，前者通过手势+语言描述，后者通过语言描述), object modifier (传递place或物体信息，基于语言), fuzzy commands （用于导航，如a little bit,基于模糊函数和历史记录）, knowledge base query and update.
2.2 文中并未说明internal representation of motional actions，
3. 基于finite state machine的任务决策。指令被中断后停止执行。
4. 对话系统实现的功能包括：令机器人移动，介绍object or location（名称、size, spatial rel），或查询知识
5. 利用geometric map表示room env. attributed topological map表示characterstics of learned objects and pathways
6. each command has a speech component, which defines the action, and a gesture modifier (optional), providing complementary information},
  doi        = {10.1109/IROS.2001.976404},
  file       = {:FILES/2001 - Ghidary2001 - Multi-modal human robot interaction for map generation.pdf:PDF},
  groups     = {task understanding, from visual, 知识生成, spatial relation},
  printed    = {Y},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/976404},
}

@InProceedings{Levinson2003,
  author    = {Levinson, Stephen and Zhu, Weiyu and Li, Danfeng and Squire, Kevin and Lin, Ruei-sung and Kleffner, Matthew and {McClain}, Matthew and Lee, Johnny},
  booktitle = {Proceedings of the 2003 International Joint Conference on Neural Networks},
  title     = {Automatic language acquisition by an autonomous robot},
  year      = {2003},
  address   = {Portland, OR, USA},
  month     = jul,
  pages     = {2716--2721},
  publisher = {IEEE},
  volume    = {4},
  abstract  = {There is no such thing as a disembodied mind. We posit that cognitive development can only occur through interaction with the physical world. To this end, we are developing a robotic platform for the purpose of studying cognition. We suggest that the central component of cognition is a memory which is primarily associative, one where learning occurs as the correlation of events from diverse inputs. We also posit that human-like cognition requires a well-integrated sensory-motor system, to provide these diverse inputs. As implemented in our robot, this system includes binaural hearing, stereo vision, tactile sense, and basic proprioceptive control. On top of these abilities, we are implementing and studying various models of processing, learning and decision making. Our goal is to produce a robot that will learn to carry out simple tasks in response to natural language requests. The robot's understanding of language will be learned concurrently with its other cognitive abilities. We have already developed a robust system and conducted a number or experiments on the way to this goal, some details of which appear in this paper. This is a first progress report of what we believe will be a long term project with significant implications.},
  comment   = {HMM, 多模态},
  doi       = {10.1109/IJCNN.2003.1223997},
  file      = {:FILES/2003 - Levinson2003 - Automatic language acquisition by an autonomous robot.pdf:PDF},
  groups    = {task understanding},
  issn      = {1098-7576},
  url       = {https://ieeexplore.ieee.org/abstract/document/1223997},
}

@Article{Kruijff2007,
  author   = {Geert-Jan M. Kruijff and Hendrik Zender and Patric Jensfelt and Henrik I. Christensen},
  journal  = {International Journal of Advanced Robotic Systems},
  title    = {Situated dialogue and spatial organization: {What}, where… and why?},
  year     = {2007},
  month    = mar,
  number   = {1},
  pages    = {16},
  volume   = {4},
  abstract = {The paper presents an HRI architecture for human-augmented mapping, which has been implemented and tested on an autonomous mobile robotic platform. Through interaction with a human, the robot can augment its autonomously acquired metric map with qualitative information about locations and objects in the environment. The system implements various interaction strategies observed in independently performed Wizard-of-Oz studies. The paper discusses an ontology-based approach to multi-layered conceptual spatial mapping that provides a common ground for human-robot dialogue. This is achieved by combining acquired knowledge with innate conceptual commonsense knowledge in order to infer new knowledge. The architecture bridges the gap between the rich semantic representations of the meaning expressed by verbal utterances on the one hand and the robot's internal sensor-based world representation on the other. It is thus possible to establish references to spatial areas in a situated dialogue between a human and a robot about their environment. The resulting conceptual descriptions represent qualitative knowledge about locations in the environment that can serve as a basis for achieving a notion of situational awareness.},
  comment  = {多模态
Bastianelli2016:  parse transcriptions obtained through ASR using contextual categorial grammars
Perara2015: use NL for mapping of unknown environments},
  doi      = {10.5772/5701},
  file     = {:FILES/2007 - Kruijff2007 - Situated Dialogue and Spatial Organization- What, Where… and Why.pdf:PDF},
  groups   = {task understanding},
  url      = {https://journals.sagepub.com/doi/full/10.5772/5701},
}

@InProceedings{Shimizu2009,
  author    = {Shimizu, Nobuyuki and Haas, Andrew},
  booktitle = {Proceedings of the 21st International Jont Conference on Artifical Intelligence (IJCAI)},
  title     = {Learning to follow navigational route instructions},
  year      = {2009},
  address   = {San Francisco, CA, USA},
  pages     = {1488--1493},
  publisher = {Morgan Kaufmann Publishers Inc.},
  abstract  = {We have developed a simulation model that accepts instructions in unconstrained natural language, and then guides a robot to the correct destination. The instructions are segmented on the basis of the actions to be taken, and each segment is labeled with the required action. This flat formulation reduces the problem to a sequential labeling task, to which machine learning methods are applied. We propose an innovative machine learning method for explicitly modeling the actions described in instructions and integrating learning and inference about the physical environment. We obtained a corpus of 840 route instructions that experimenters verified as follow-able, given by people in building navigation situations. Using the four-fold cross validation, our experiments showed that the simulated robot reached the correct destination 88% of the time.},
  comment   = {多模态，bayesian network
Ji2016: Understanding natural language command},
  file      = {:FILES/2009 - Shimizu2009 - Learning to Follow Navigational Route Instructions.pdf:PDF},
  groups    = {task understanding},
  location  = {Pasadena, California, USA},
  url       = {https://www.ijcai.org/proceedings/2009},
}

@InProceedings{Gemignani2015,
  author    = {Gemignani, Guglielmo and Veloso, Manuela and Nardi, Daniele},
  booktitle = {RoboCup 2015: Robot World Cup XIX},
  title     = {Language-based sensing descriptors for robot object grounding},
  year      = {2015},
  editor    = {Almeida, Luis and Ji, Jianmin and Steinbauer, Gerald and Luke, Sean},
  pages     = {3--15},
  publisher = {Springer International Publishing},
  volume    = {9513},
  abstract  = {In this work, we consider an autonomous robot that is required to understand commands given by a human through natural language. Specifically, we assume that this robot is provided with an internal representation of the environment. However, such a representation is unknown to the user. In this context, we address the problem of allowing a human to understand the robot internal representation through dialog. To this end, we introduce the concept of sensing descriptors. Such representations are used by the robot to recognize unknown object properties in the given commands and warn the user about them. Additionally, we show how these properties can be learned over time by leveraging past interactions in order to enhance the grounding capabilities of the robot.},
  comment   = {多模态，bayesian network},
  file      = {:FILES/2015 - Gemignani2015 - Language-Based Sensing Descriptors for Robot Object Grounding.pdf:PDF},
  groups    = {task understanding},
  isbn      = {978-3-319-29339-4},
  url       = {https://link.springer.com/chapter/10.1007/978-3-319-29339-4_1},
}

@Article{Takano2015a,
  author   = {Takano, Wataru},
  journal  = {ROBOMECH Journal},
  title    = {Learning motion primitives and annotative texts from crowd-sourcing},
  year     = {2015},
  issn     = {2197-4225},
  number   = {1},
  pages    = {1--9},
  volume   = {2},
  abstract = {Humanoidrobots are expected to be integrated into daily life, where a large variety of human actions and language expressions are observed. They need to learn the referential relations between the actions and language, and to understand the actions in the form of language in order to communicate with human partners or to make inference using language. Intensive research on imitation learning of human motions has been performed for the robots that can recognize human activity and synthesize human-like motions, and this research is subsequently extended to integration of motions and language. This research aims at developing robots that understand human actions in the form of natural language. One difficulty comes from handling a large variety of words or sentences used in daily life because it is too time-consuming for researchers to annotate human actions in various expressions. Recent development of information and communication technology gives an efficient process of crowd-sourcing where many users are available to complete a lot of simple tasks. This paper proposes a novel concept of collecting a large training dataset of motions and their descriptive sentences, and of developing an intelligent framework learning relations between the motions and sentences. This framework enables humanoid robots to understand human actions in various forms of sentences. We tested it on recognition of human daily full-body motions, and demonstrated the validity of it.},
  comment  = {hmm},
  doi      = {10.1186/s40648-014-0022-7},
  file     = {:FILES/2015 - Takano2015a - Learning motion primitives and annotative texts from crowd-sourcing.pdf:PDF},
  groups   = {task understanding},
  url      = {https://robomechjournal.springeropen.com/articles/10.1186/s40648-014-0022-7},
}

@InProceedings{Oliveira2012,
  author    = {Oliveira, Jo\~{a}o Lobato and Ince, Gökhan and Nakamura, Keisuke and Nakadai, Kazuhiro and Okuno, Hiroshi G. and Reis, Luis Paulo and Gouyon, Fabien},
  booktitle = {Proceedings of the 21st IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},
  title     = {An active audition framework for auditory-driven {HRI}: {Application} to interactive robot dancing},
  year      = {2012},
  address   = {Paris, France},
  month     = sep,
  pages     = {1078--1085},
  publisher = {IEEE},
  abstract  = {In this paper we propose a general active audition framework for auditory-driven Human-Robot Interaction (HRI). The proposed framework simultaneously processes speech and music on-the-fly, integrates perceptual models for robot audition, and supports verbal and non-verbal interactive communication by means of (pro)active behaviors. To ensure a reliable interaction, on top of the framework a behavior decision mechanism based on active audition policies the robot's actions according to the reliability of the acoustic signals for auditory processing. To validate the framework's application to general auditory-driven HRI, we propose the implementation of an interactive robot dancing system. This system integrates three preprocessing robot audition modules: sound source localization, sound source separation, and ego noise suppression; two modules for auditory perception: live audio beat tracking and automatic speech recognition; and multi-modal behaviors for verbal and non-verbal interaction: music-driven dancing and speech-driven dialoguing. To fully assess the system, we set up experimental and interactive real-world scenarios with highly dynamic acoustic conditions, and defined a set of evaluation criteria. The experimental tests revealed accurate and robust beat tracking and speech recognition, and convincing dance beat-synchrony. The interactive sessions confirmed the fundamental role of the behavior decision mechanism for actively maintaining a robust and natural human-robot interaction.},
  comment   = {多模态，hmm},
  doi       = {10.1109/ROMAN.2012.6343892},
  file      = {:FILES/2012 - Oliveira2012 - An active audition framework for auditory-driven HRI- Application to interactive robot dancing.pdf:PDF},
  groups    = {task understanding},
  issn      = {1944-9437},
  url       = {https://ieeexplore.ieee.org/abstract/document/6343892},
}

@InProceedings{Lu2017a,
  author     = {Lu, Dongcai and Zhang, Shiqi and Stone, Peter and Chen, Xiaoping},
  booktitle  = {Proceedings of the 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title      = {Leveraging commonsense reasoning and multimodal perception for robot spoken dialog systems},
  year       = {2017},
  address    = {Vancouver, BC, Canada},
  month      = sep,
  pages      = {6582--6588},
  publisher  = {IEEE},
  abstract   = {Probabilistic graphical models, such as partially observable Markov decision processes (POMDPs), have been used in stochastic spoken dialog systems to handle the inherent uncertainty in speech recognition and language understanding. Such dialog systems suffer from the fact that only a relatively small number of domain variables are allowed in the model, so as to ensure the generation of good-quality dialog policies. At the same time, the non-language perception modalities on robots, such as vision-based facial expression recognition and Lidar-based distance detection, can hardly be integrated into this process. In this paper, we use a probabilistic commonsense reasoner to “guide” our POMDP-based dialog manager, and present a principled, multimodal dialog management (MDM) framework that allows the robot's dialog belief state to be seamlessly updated by both observations of human spoken language, and exogenous events such as the change of human facial expressions. The MDM approach has been implemented and evaluated both in simulation and on a real mobile robot using guidance tasks.},
  comment    = {重点不在于对话系统，在于利用多模态知识对人的理解，从而用于决策（导览）。

本文提出了一种principled multimodal dialogue management (MDM) framework,从而使机器人能够根据exogenous evenet+spoken language来做决策。
1. 感知系统：visual system for facial/age/emotion recognition (现成的工具); speech recognitioin system(现成工具); dialogue system (未说明）
2. MDM包括两部分，其一是commonsense reasoner,其二是task oriented probablistic planner
2.1 commonsense reasoner包括了一系列logical and probablistic rules, 表示为causal Bayesian network,其中节点分为两类，一类是endogenous variables(内因变量，如展览内容的特征，本文定义了三种），一类是exogenous(外因变量，如人的表情、是否跟随等，本文定义了三种)；后者依赖于前者，前者内部可互相依赖
2.2 planner是基于对POMDP的改进，增加了event reasoner（基于P-log实现）,可用于识别exogenous variables的变化，并利用预设规则来对belief state进行修正。
3. 从其实验中看，对话系统应该是预定了问题的模板，而人需要回答“是/否”即可
4. 对比方法是CORPP(cite{Zhang2015})，也是本文的基础
5. 结论：当speech recognition 不可靠时，多模态感知可提高准确性

不足：
1. 状态少，若特征增多，计算性能？基于Rule的推理，复杂时怎么办？规则的制定需要人的参与？！ 对话系统可实现自由交流？常识知识具有领域特异性，且不是真正的常识知识。

文献包括：POMDP原理、ASP、P-log、emotion/face recognition、curse of history, causal BN},
  doi        = {10.1109/IROS.2017.8206570},
  file       = {:FILES/2017 - Lu2017a - Leveraging commonsense reasoning and multimodal perception for robot spoken dialog systems.pdf:PDF},
  groups     = {task understanding},
  issn       = {2153-0866},
  printed    = {Y},
  priority   = {prio2},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/8206570},
}

@InProceedings{Allen2005,
  author     = {Allen, Jared and Duong, Quang and Thompson, Craig},
  booktitle  = {Proceedings of the 2005 International Conference on Integration of Knowledge Intensive Multi-Agent Systems},
  title      = {Natural language service for controlling robots and other agents},
  year       = {2005},
  address    = {Waltham, MA, USA},
  month      = apr,
  pages      = {592--595},
  publisher  = {IEEE},
  abstract   = {The Everything is Alive (EiA) agent system architecture is modular and scalable. It uses the E2 platform, a derivative of the Eclipse core platform, to dynamically add or remove plugin capabilities that have XML or WSDL interfaces. This paper describes two capabilities that can be modularly added to EiA agents. The capabilities described include a robot command capability that customizes an agent to operate as a robot controller and a menu-based natural language interface (MBNLI) capability that provides a human-level interface for commanding a robot.},
  comment    = {多模态，一阶逻辑

本文提出了一种机器人框架，everything is alive (EiA) agent system,即IoT思想的体现，其中包括an agent platform (E2) and some E2 plugin capabilities. 人对agent下达指令的方式是通过menu-based NL interface,事先定义了grammar，包括动作以及要素，需要在interface上全部填充完整，才可将指令翻译为DTD并转译WSDL下达给机器人执行。可执行动作包括navigatioin and manipulation with grippers.
1. 本文关注于两个plugin，即robot controller capability  that allows third parties to command, query, and control a robot.以及A menu-based natural language interface capability provides a way for humans to communicate to smart devices。
2. EiA与agent之间的command format是XML格式based on document type definition (DTD),利用JavaWSDL将其Transformed into Web Service Description Language (WSDL) document,which encodes information about classes, methods, and  method arguments, corresponding to ARIA methods
3.The ActivMedia Robotics Interface for Applications(ARIA) is client-side software that provides a higher level  object-oriented API for management of the robot servers.  ARIA can be used in different ways, ranging from direct  command-and-control of the robot to development of  intelligent actions or robot behaviors. Some of the most common commands used in ARIA include move, set heading (turn), stop, lift and lower the robot's gripper, etc
4. 人机几乎采用了menu-based NL interface，通过select from a series of menus to build up sentences as queries or commands.这些sentence会被翻译成agent-specific target language, 如（light: turn on）(robot: move - forward - for two seconds) (Robot:- if - you - enter - a room,- ask - the light - to turn - on). Each menu will be implemented as a list  of possible command elements},
  doi        = {10.1109/KIMAS.2005.1427150},
  file       = {:FILES/2005 - Allen2005 - Natural language service for controlling robots and other agents.pdf:PDF},
  groups     = {task understanding},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/1427150},
}

@Article{Salvi2012,
  author   = {Salvi, Giampiero and Montesano, Luis and Bernardino, Alexandre and Santos-Victor, Jos\'{e}},
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  title    = {Language bootstrapping: {Learning} word meanings from perception–action association},
  year     = {2012},
  issn     = {1941-0492},
  month    = jun,
  number   = {3},
  pages    = {660--671},
  volume   = {42},
  abstract = {We address the problem of bootstrapping language acquisition for an artificial system similarly to what is observed in experiments with human infants. Our method works by associating meanings to words in manipulation tasks, as a robot interacts with objects and listens to verbal descriptions of the interactions. The model is based on an affordance network, i.e., a mapping between robot actions, robot perceptions, and the perceived effects of these actions upon objects. We extend the affordance model to incorporate spoken words, which allows us to ground the verbal symbols to the execution of actions and the perception of the environment. The model takes verbal descriptions of a task as the input and uses temporal co-occurrence to create links between speech utterances and the involved objects, actions, and effects. We show that the robot is able form useful word-to-meaning associations, even without considering grammatical structure in the learning process and in the presence of recognition errors. These word-to-meaning associations are embedded in the robot's own understanding of its actions. Thus, they can be directly used to instruct the robot to perform tasks and also allow to incorporate context in the speech recognition task. We believe that the encouraging results with our approach may afford robots with a capacity to acquire language descriptors in their operation's environment as well as to shed some light as to how this challenging process develops with human infants.},
  comment  = {naive Bayesian model},
  doi      = {10.1109/TSMCB.2011.2172420},
  file     = {:FILES/2012 - Salvi2012 - Language Bootstrapping- Learning Word Meanings From Perception–Action Association.pdf:PDF},
  groups   = {task understanding},
  url      = {https://ieeexplore.ieee.org/abstract/document/6082460},
}

@InProceedings{Liu2015,
  author     = {Liu, Rui and Zhang, Xiaoli and Webb, Jeremy and Li, Songpo},
  booktitle  = {Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA)},
  title      = {Context-specific intention awareness through web query in robotic caregiving},
  year       = {2015},
  address    = {Seattle, WA, USA},
  month      = may,
  pages      = {1962--1967},
  publisher  = {IEEE},
  abstract   = {To provide the elderly with appropriate and timely caregiving in activities of daily life (ADL), it is desired for robots to have the capability of intention awareness (IA). Different from existing context-specific intention awareness (CSIA) approaches which are based on a limited and passive knowledge database, our approach, named `WebIA', adopts a novel web query approach to establish a vast and active knowledge database for robots to perform CSIA. In our method, robots are endowed with comprehensive commonsense knowledge towards the correlations of the surrounding environment and human intentions. WebIA enables robots to effectively infer intentions in both trained familiar and untrained new situations. By performing several experiments, we evaluated two aspects of the WebIA approach: the effectiveness of IA in familiar situations and the self-learning ability in new situations.},
  comment    = {概率模型，activity and environment， NB algorithm
Liu2016d:NL instructions for industrial tasks

1.围绕context specific intention awareness.展开
2.应用场景是面向react to elderly’s personal need in activities of daily living
3.提出了WebIA方法，主要过程如下：
(1)利用工具（CamFind）来识别环境中的物体，并与KB中数据匹配，
(2)若物体不在KB中，则在（WikiHow）中获取object-related affordance knowledge，从而判断其可能对应的intention
(3)Query the Web来计算relevant intention-context correlations with (correlation strength),所用方法是Naive Bayesian Network algorithm
4.Intention可以类比为动作，context feature包括环境状态和物体，如hot day, cup等。
5.Self learning mechanism: 同义词，如glass/mug,作为同一个concept，而未知物体通过web query来实现
6.本文的方法部署到了humanoid NAO robot上，来实现infer cup-related human intentions。 实验结果与questionair相对比。},
  doi        = {10.1109/ICRA.2015.7139455},
  file       = {:FILES/2015 - Liu2015 - Context-specific intention awareness through web query in robotic caregiving.pdf:PDF},
  groups     = {task understanding},
  issn       = {1050-4729},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/7139455},
}

@Article{Bos2009,
  author   = {Johan Bos},
  journal  = {Journal of Applied Logic},
  title    = {Applying automated deduction to natural language understanding},
  year     = {2009},
  issn     = {1570-8683},
  month    = mar,
  note     = {Special Issue: Empirically Successful Computerized Reasoning},
  number   = {1},
  pages    = {100--112},
  volume   = {7},
  abstract = {Very few natural language understanding applications employ methods from automated deduction. This is mainly because (i) a high level of interdisciplinary knowledge is required, (ii) there is a huge gap between formal semantic theory and practical implementation, and (iii) statistical rather than symbolic approaches dominate the current trends in natural language processing. Moreover, abduction rather than deduction is generally viewed as a promising way to apply reasoning in natural language understanding. We describe three applications where we show how first-order theorem proving and finite model construction can efficiently be employed in language understanding. The first is a text understanding system building semantic representations of texts, developed in the late 1990s. Theorem provers are here used to signal inconsistent interpretations and to check whether new contributions to the discourse are informative or not. This application shows that it is feasible to use general-purpose theorem provers for first-order logic, and that it pays off to use a battery of different inference engines as in practice they complement each other in terms of performance. The second application is a spoken-dialogue interface to a mobile robot and an automated home. We use the first-order theorem prover spass for checking inconsistencies and newness of information, but the inference tasks are complemented with the finite model builder mace used in parallel to the prover. The model builder is used to check for satisfiability of the input; in addition, the produced finite and minimal models are used to determine the actions that the robot or automated house has to execute. When the semantic representation of the dialogue as well as the number of objects in the context are kept fairly small, response times are acceptable to human users. The third demonstration of successful use of first-order inference engines comes from the task of recognising entailment between two (short) texts. We run a robust parser producing semantic representations for both texts, and use the theorem prover vampire to check whether one text entails the other. For many examples it is hard to compute the appropriate background knowledge in order to produce a proof, and the model builders mace and paradox are used to estimate the likelihood of an entailment.},
  comment  = {多模态 一阶逻辑},
  doi      = {10.1016/j.jal.2007.07.008},
  file     = {:FILES/2009 - Bos2009 - Applying automated deduction to natural language understanding.pdf:PDF},
  groups   = {task understanding},
  keywords = {Automated reasoning, Natural language understanding, First-order logic, Theorem proving, Model building},
  url      = {https://www.sciencedirect.com/science/article/pii/S1570868307000651},
}

@Article{Liu2018,
  author     = {Rui Liu and Xiaoli Zhang},
  journal    = {Knowledge-Based Systems},
  title      = {Generating machine-executable plans from end-user's natural-language instructions},
  year       = {2018},
  issn       = {0950-7051},
  month      = jan,
  pages      = {15--26},
  volume     = {140},
  abstract   = {It is critical for advanced manufacturing machines to autonomously execute a task by following an end-user's natural language (NL) instructions. However, NL instructions are usually ambiguous and abstract so that the machines may misunderstand and incorrectly execute the task. To address this NL-based human-machine communication problem and enable the machines to appropriately execute tasks by following the end-user's NL instructions, we developed a Machine-Executable-Plan-Generation (exePlan) method. The exePlan method conducts task-centered semantic analysis to extract task-related information from ambiguous NL instructions. In addition, the method specifies machine execution parameters to generate a machine-executable plan by interpreting abstract NL instructions. To evaluate the exePlan method, an industrial robot Baxter was instructed by NL to perform three types of industrial tasks {“drill a hole”, “clean a spot”, “install a screw”}. The experiment results proved that the exePlan method was effective in generating machine-executable plans from the end-user's NL instructions. Such a method has the promise to endow a machine with the ability of NL-instructed task execution.},
  comment    = {本文是讨论机器人在接收人的NL instruction之后，利用所提出的exePlan method进行任务理解和决策的过程，主要内容如下：
1. 分为instruction disambiguation, instruction interpretation, plan executability assessment三个部分。
2. ID部分讨论的是将speech instruction 转化为文本形式（现有工具【48】），并利用stanford CoreNLP进行解析，并将所得到的linguistic feature映射到task centered features (即形式化表达，包括keyword、pos、dependencies、prev task等要素），其中keyword的识别是利用SVM做多分类问题（3种可执行任务）
3. II包括两个内容，其一是对其中的MES parameter进行识别，其二是将sub-goal \& transitions作为节点，构建MLN，并利用SSVM学习其中weights，在实际执行过程中通过搜索sum of weights最大来确定execution plan
4. PEA是对execution plan是否feasible进行检查，主要是其中的MES parameter是否满足条件，通过对周围环境的感知来确定，不行的话就重新调用II来进行参数补全。
5. 主要问题是对speech、text的处理都是利用通用方法，缺少对特定场景的适应性调整，任务类型少，存在大量的人工参与，实时性差、缺少知识推理、MES parameter补全的方法不明确、若出现异常没有响应的应对机制（如keyword分类错误等）、Task centered feature的描述不够充分},
  doi        = {10.1016/j.knosys.2017.10.023},
  file       = {:FILES/2018 - Liu2018 - Generating machine-executable plans from end-user's natural-language instructions.pdf:PDF},
  groups     = {task understanding},
  keywords   = {Semantic analysis, Machine-executable plan, Natural language instruction, Advanced manufacturing machine},
  printed    = {Y},
  priority   = {prio2},
  readstatus = {read},
  url        = {https://www.sciencedirect.com/science/article/pii/S0950705117304926},
}

@InProceedings{Boril2006,
  author    = {Hynek Boril and Petr Fousek and Petr},
  booktitle = {Proceedings of INTERSPEECH 2006},
  title     = {Data-driven design of front-end filter bank for {Lombard} speech recognition},
  year      = {2006},
  address   = {Pittsburgh, PA, USA},
  month     = sep,
  pages     = {381--384},
  publisher = {ISCA},
  abstract  = {Adverse environments not only corrupt speech signal by additive and convolutional noises, which can be successfully addressed by a number of suppression algorithms, but also affect the way how speech is produced. Speech production variations introduced by a speaker in reaction to a noisy background (Lombard effect) may result in a severe degradation of automatic speech recognition. This paper contributes to the solution of Lombard speech recognition issue by providing a robust filter bank for use in front-ends. It is shown that cepstral features derived from the proposed filter bank significantly outperform conventional cepstral features.},
  file      = {:FILES/2006 - Boril2006 - Data-driven design of front-end filter bank for {Lombard} speech recognition.pdf:PDF},
  groups    = {ASR},
  url       = {https://isca-speech.org/archive/interspeech_2006/i06_1803.html},
}

@Article{Nam2020,
  author     = {Nam, Changjoo and Lee, Seokjun and Lee, Jeongho and Cheong, Sang Hun and Kim, Dong Hwan and Kim, Changhwan and Kim, Incheol and Park, Sung-Kee},
  journal    = {IEEE Access},
  title      = {A software architecture for service robots manipulating objects in human environment},
  year       = {2020},
  issn       = {2169-3536},
  pages      = {117900--117920},
  volume     = {8},
  abstract   = {This paper presents a software architecture for robots providing manipulation services autonomously in human environments. In an unstructured human environment, a service robot often needs to perform tasks even without human intervention and prior knowledge about tasks and environments. For autonomous execution of tasks, varied processes are necessary such as perceiving environments, representing knowledge, reasoning with the knowledge, and planning for task and motion. While developing each of the processes is important, integrating them into a working system for deployment is also important as a robotic system can bring tangible outcomes when it works in real world. However, such an architecture has been rarely realized in the literature owing to the difficulties of a full integration, deployment, understanding high-level goals without human interventions. In this work, we suggest a software architecture that integrates the components necessary to perform tasks by a real robot without human intervention. We show our architecture composed of deep learning based perception, symbolic reasoning, AI task planning, and geometric motion planning. We implement a deep neural network that produces information about the environment, which are then stored in a knowledge base. We implement a reasoner that processes the knowledge to use the result for task planning. We show our implementation of the symbolic task planner that generates a sequence of motion predicates. We implement an interface that computes geometric information necessary for motion planning to execute the symbolic task plans. We describe the deployment of the architecture through the result of lab tests and a public demonstration. The architecture is developed based on Robot Operating System (ROS) so compatible with any robot that is capable of object manipulation and mobile navigation running in ROS. We deploy the architecture to two different robot platforms to show the compatibility.},
  comment    = {本文可以归结为self-motivated task understanding with human's intervention，提出了一种架构，包含了perception, knowledge representation, reasoning, task planning and motion planning 等模块},
  doi        = {10.1109/ACCESS.2020.3003991},
  file       = {:FILES/2020 - Nam2020 - A Software Architecture for Service Robots Manipulating Objects in Human Environments.pdf:PDF},
  groups     = {self-motivated},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/document/9122008},
}

@InProceedings{Rosenthal2010,
  author    = {Rosenthal, Stephanie and Biswas, Joydeep and Veloso, Manuela},
  booktitle = {Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems:},
  title     = {An effective personal mobile robot agent through symbiotic human-robot interaction},
  year      = {2010},
  address   = {Richland, SC},
  month     = may,
  pages     = {915--922},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  series    = {AAMAS '10},
  abstract  = {Several researchers, present authors included, envision personal mobile robot agents that can assist humans in their daily tasks. Despite many advances in robotics, such mobile robot agents still face many limitations in their perception, cognition, and action capabilities. In this work, we propose a symbiotic interaction between robot agents and humans to overcome the robot limitations while allowing robots to also help humans. We introduce a visitor's companion robot agent, as a natural task for such symbiotic interaction. The visitor lacks knowledge of the environment but can easily open a door or read a door label, while the mobile robot with no arms cannot open a door and may be confused about its exact location, but can plan paths well through the building and can provide useful relevant information to the visitor. We present this visitor companion task in detail with an enumeration and formalization of the actions of the robot agent in its interaction with the human. We briefly describe the wifi-based robot localization algorithm and show results of the different levels of human help to the robot during its navigation. We then test the value of robot help to the visitor during the task to understand the relationship tradeoffs. Our work has been fully implemented in a mobile robot agent, CoBot, which has successfully navigated for several hours and continues to navigate in our indoor environment.},
  comment   = {liu2018: Non-expert users without prior programming training could command a machine to perform their desired tasks
Xie2015:Get human’s knowledge through dialog},
  file      = {:FILES/2010 - Rosenthal2010 - An Effective Personal Mobile Robot Agent through Symbiotic Human-Robot Interaction.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9780982657119},
  keywords  = {human-robot/agent interaction},
  location  = {Toronto, Canada},
  url       = {https://dl.acm.org/doi/abs/10.5555/1838206.1838329},
}

@TechReport{Tellex2012,
  author      = {Stefanie Tellex and Pratiksha Thaker and Robin Deits and Dimitar Simeonov and Thomas Kollar and Nicholas Roy},
  institution = {Massachusetts Institute of Technology},
  title       = {A probabilistic approach for enabling robots to acquire information from human partners using language},
  year        = {2012},
  comment     = {liu2018: structured instructions to control a machine with object finding or placing, such as “go to someplace”, “drop something”, etc.},
  file        = {:FILES/2012 - Tellex2012 - A Probabilistic Approach for Enabling Robots to Acquire Information From Human Partners Using Language.pdf:PDF},
  groups      = {task understanding},
  url         = {https://people.csail.mit.edu/stefie10/publications/tellex11b.pdf},
}

@InProceedings{Gemignani2015a,
  author    = {Gemignani, Guglielmo and Bastianelli, Emanuele and Nardi, Daniele},
  booktitle = {Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems},
  title     = {Teaching robots parametrized executable plans through spoken interaction},
  year      = {2015},
  address   = {Richland, SC},
  month     = may,
  pages     = {851--859},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  series    = {AAMAS '15},
  abstract  = {While operating in domestic environments, robots will necessarily face difficulties not envisioned by their developers at programming time. Moreover, the tasks to be performed by a robot will often have to be specialized and/or adapted to the needs of specific users and specific environments. Hence, learning how to operate by interacting with the user seems a key enabling feature to support the introduction of robots in everyday environments.In this paper we contribute a novel approach for learning, through the interaction with the user, task descriptions that are defined as a combination of primitive actions. The proposed approach makes a significant step forward by making task descriptions parametric with respect to domain specific semantic categories. Moreover, by mapping the task representation into a task representation language, we are able to express complex execution paradigms and to revise the learned tasks in a high-level fashion. The approach is evaluated in multiple practical applications with a service robot.},
  comment   = {liu2018: (8)structured instructions to control a machine with object finding or placing, such as “go to someplace”, “drop something”, etc. human's instruction is abstract},
  file      = {:FILES/2015 - Gemignani2015a - Teaching Robots Parametrized Executable Plans Through Spoken Interaction.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781450334136},
  keywords  = {communication and teamwork, robot planning and plan execution, human-robot interaction},
  location  = {Istanbul, Turkey},
  numpages  = {9},
  url       = {https://dl.acm.org/doi/abs/10.5555/2772879.2773262},
}

@InProceedings{Williams2015,
  author    = {Tom Williams and Gordon Briggs and Bradley Oosterveld and Matthias Scheutz},
  booktitle = {Proceedings of the 29th AAAI Conference on Artificial Intelligence},
  title     = {Going beyond literal command-based instructions: {Extending} robotic natural language interaction capabilities},
  year      = {2015},
  address   = {Austin, Texas, USA},
  month     = feb,
  pages     = {1387--1393},
  publisher = {AAAI Press},
  volume    = {29},
  abstract  = {The ultimate goal of human natural language interaction is to communicate intentions. However, these intentions are often not directly derivable from the semantics of an utterance (e.g., when linguistic modulations are employed to convey polite-ness, respect, and social standing). Robotic architectures withsimple command-based natural language capabilities are thus not equipped to handle more liberal, yet natural uses of linguistic communicative exchanges. In this paper, we propose novel mechanisms for inferring in-tentions from utterances and generating clarification requests that will allow robots to cope with a much wider range of task-based natural language interactions. We demonstrate the potential of these inference algorithms for natural human-robot interactions by running them as part of an integrated cognitive robotic architecture on a mobile robot in a dialogue-based instruction task.},
  comment   = {liu2018: a reasonable and flexible knowledge structure, which is implicitly embedded in NL descriptions to guide correct task execution, is difficult to extract;},
  file      = {:FILES/2015 - Williams2015 - Going Beyond Literal Command-Based Instructions- Extending Robotic Natural Language Interaction Capabilities.pdf:PDF},
  groups    = {task understanding},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/9377},
}

@Article{Liu2016e,
  author     = {Rui Liu and Xiaoli Zhang},
  journal    = {Knowledge-Based Systems},
  title      = {Context-specific grounding of web natural descriptions to human-centered situations},
  year       = {2016},
  issn       = {0950-7051},
  month      = nov,
  pages      = {1--16},
  volume     = {111},
  abstract   = {Human-centered situation, which describes the surrounding world of a person, indicates his undergoing activities. Understanding of human-centered situations helps an assistive robot with its decision making. Existing methods, such as learning from human demonstration, are economically expensive, time-consuming, and have limited scalability. To address this problem, we developed a web-to-situation (W2S) method with which web natural descriptions are grounded into human-centered situations in a context-specific manner. By comparing the learned knowledge from the web and the survey, we proved that W2S is effective in extracting reliable knowledge in an efficient and low-cost manner. By implementing the W2S-retrieved knowledge in 60 web-collected situations and 60 real life situations, we proved that W2S is effective in situation understanding. Given that the web contains huge amounts of information, W2S is expected to effectively scale up a robot's knowledge.},
  comment    = {liu2018: a reasonable and flexible knowledge structure, which is implicitly embedded in NL descriptions to guide correct task execution, is difficult to extract; semi-supervised SVM模型

本文主要处理的问题是understanding human-centered situations，即根据人所处的环境信息，得到相应的situation。这里有些类似于map objects to actions，从Fig. 5中看，其输入是obj，输出是action（或人正在做什么）。或者可以用于learn actions from video or dimenstration. 提出了web-to-situation (W2S) method:
1. 利用object来搜索text description online in conceptNet5.得到concepts with special types like {isA, usedFor, RelatedTo, ...}
2. word normalization: 生成同义词的树状结构based on WordNet (synsets and definition) and conceptNet5 (isA relation)
3. potential activity generation:利用concepts，构造object-related semantic ontologies, including object layer, hidden layer, situation layer。其中中间层表示了object与situation建立联系所需的其他concept. 对这些concept计算semantic similarity,从而实现concept merging，所利用该的信息包括verb similarity, norm similarity, pos等多种feature，是文献中方法的适应性改进。
4.利用<generated potential situation, object>在WikiHow中进行检索，得到text description of situation
5. tokenization: use NLTK for NLP with a list of sentences, words with PoS tags. They use a combined Ngram tagger consisting of unigram, bigram, trigram, and WordNet tagger. 具有记忆能力
6. Word Normalization: 基于WordNet，对动词时态等进行归一化
7. syntax analysis: 基于Stanford CoreNLP, 得到其syntax tree
8. topic relevance analysis: 基于 potential activity generation中所利用的feature进行semantic similarity computation，得到the relevance between each article and situation
9. objects and environmental context extraction: 用来提取与human-centered situation有关的human, env context and objects. 主要思路是计算各entity's involvement degree based on surrounding sentence context.方法是基于semi-supervised classification,来给各word进行label,kernel是naive Bayesian function. 
10. object-contex relation detection: 通过统计object and context在one description中共现情况.
11. Situation representation: as a hierarchical structure with the situation (output layer), object layer (intra connections), and context layer (intra connections), where connections between sequential layers exist. MRF model

situation model是计算每个object对应situation的likelihood的,其中涉及到参数权重的确定,所利用的方法是SSVM模型,表达为QP问题进行求解.},
  doi        = {10.1016/j.knosys.2016.07.037},
  file       = {:FILES/2016 - Liu2016e - Context-Specific grounding of web natural descriptions to human-centered situations.pdf:PDF},
  groups     = {task understanding},
  keywords   = {Assistive robot, Decision making, Human-centered situation, Web information retrieval, Environmental context, read},
  priority   = {prio1},
  readstatus = {read},
  url        = {https://www.sciencedirect.com/science/article/pii/S0950705116302532},
}

@InProceedings{Forbes2015,
  author    = {Forbes, Maxwell and Rao, Rajesh P. N. and Zettlemoyer, Luke and Cakmak, Maya},
  booktitle = {2015 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Robot programming by demonstration with situated spatial language understanding},
  year      = {2015},
  address   = {Seattle, WA, USA},
  month     = may,
  pages     = {2014--2020},
  publisher = {IEEE},
  abstract  = {Robot Programming by Demonstration (PbD) allows users to program a robot by demonstrating the desired behavior. Providing these demonstrations typically involves moving the robot through a sequence of states, often by physically manipulating it. This requires users to be co-located with the robot and have the physical ability to manipulate it. In this paper, we present a natural language based interface for PbD that removes these requirements and enables hands-free programming. We focus on programming object manipulation actions-our key insight is that such actions can be decomposed into known types of manipulator movements that are naturally described using spatial language; e.g., object reference expressions and prepositions. Our method takes a natural language command and the current world state to infer the intended movement command and its parametrization. We implement this method on a two-armed mobile manipulator and demonstrate the different types of manipulation actions that can be programmed with it. We compare it to a kinesthetic PbD interface and we demonstrate our method's ability to deal with incomplete language.},
  comment   = {liu2018: 利用spatial informaiton来grounding
Liu2016d: use action and environmental constraints for quatitative analysis to generate action plan,包括object size and posotions},
  doi       = {10.1109/ICRA.2015.7139462},
  file      = {:FILES/2015 - Forbes2015 - Robot Programming by Demonstration with situated spatial language understanding.pdf:PDF},
  groups    = {task understanding},
  issn      = {1050-4729},
  url       = {https://ieeexplore.ieee.org/document/7139462},
}

@InProceedings{Duvallet2013,
  author    = {Duvallet, Felix and Kollar, Thomas and Stentz, Anthony},
  booktitle = {Proceedings of the 2013 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Imitation learning for natural language direction following through unknown environments},
  year      = {2013},
  address   = {Karlsruhe, Germany},
  month     = may,
  pages     = {1047--1053},
  publisher = {IEEE},
  abstract  = {The use of spoken instructions in human-robot teams holds the promise of enabling untrained users to effectively control complex robotic systems in a natural and intuitive way. Providing robots with the capability to understand natural language directions would enable effortless coordination in human robot teams that operate in non-specialized unknown environments. However, natural language direction following through unknown environments requires understanding the meaning of language, using a partial semantic world model to generate actions in the world, and reasoning about the environment and landmarks that have not yet been detected. We address the problem of robots following natural language directions through complex unknown environments. By exploiting the structure of spatial language, we can frame direction following as a problem of sequential decision making under uncertainty. We learn a policy which predicts a sequence of actions that follow the directions by exploring the environment and discovering landmarks, backtracking when necessary, and explicitly declaring when it has reached the destination. We use imitation learning to train the policy, using demonstrations of people following directions. By training explicitly in unknown environments, we can generalize to situations that have not been encountered previously.},
  comment   = {liu2018: grounding entities with environment info; probabilistic graphical models to generate task plan
Liu2016d: NL is procedure concise
Duvallet2016: trained a policy that reasons about uncertainty and can backtrack when needed. 没有利用NL instruction中包含的信息来reason uncertainty and infer environment representation.},
  doi       = {10.1109/ICRA.2013.6630702},
  file      = {:FILES/2013 - Duvallet2013 - Imitation learning for natural language direction following through unknown environments.pdf:PDF},
  groups    = {task understanding},
  issn      = {1050-4729},
  url       = {https://ieeexplore.ieee.org/document/6630702},
}

@InBook{Kollar2014,
  author    = {Kollar, Thomas and Tellex, Stefanie and Roy, Deb and Roy, Nicholas},
  editor    = {Khatib, Oussama and Kumar, Vijay and Sukhatme, Gaurav},
  pages     = {31--47},
  publisher = {Springer Berlin Heidelberg},
  title     = {Grounding verbs of motion in natural language commands to robots},
  year      = {2014},
  address   = {Berlin, Heidelberg},
  isbn      = {978-3-642-28572-1},
  abstract  = {To be useful teammates to human partners, robots must be able to follow spoken instructions given in natural language. An important class of instructions involve interacting with people, such as ``Follow the person to the kitchen'' or ``Meet the person at the elevators.'' These instructions require that the robot fluidly react to changes in the environment, not simply follow a pre-computed plan. We present an algorithm for understanding natural language commands with three components. First, we create a cost function that scores the language according to how well it matches a candidate plan in the environment, defined as the log-likelihood of the plan given the command. Components of the cost function include novel models for the meanings of motion verbs such as ``follow,'' ``meet,'' and ``avoid,'' as well as spatial relations such as ``to'' and landmark phrases such as ``the kitchen.'' Second, an inference method uses this cost function to perform forward search, finding a plan that matches the natural language command. Third, a high-level controller repeatedly calls the inference method at each timestep to compute a new plan in response to changes in the environment such as the movement of the human partner or other people in the scene. When a command consists of more than a single task, the controller switches to the next task when an earlier one is satisfied. We evaluate our approach on a set of example tasks that require the ability to follow both simple and complex natural language commands.},
  booktitle = {Experimental Robotics: The 12th International Symposium on Experimental Robotics},
  comment   = {liu2018: 利用spatial informaiton来grounding
Liu2016d: use action and environmental constraints for quatitative analysis to generate action plan,包括object size and posotions
Zhang2019a:keyword matching method uses domain dictionary to parses instructions, and the matching results are used as trigger conditions of the frame template},
  doi       = {10.1007/978-3-642-28572-1_3},
  file      = {:FILES/2014 - Kollar2014 - Grounding Verbs of Motion in Natural Language Commands to Robots.pdf:PDF},
  groups    = {task understanding},
  url       = {https://doi.org/10.1007/978-3-642-28572-1_3},
}

@Article{Joachims2009,
  author   = {Joachims, Thorsten and Finley, Thomas and Yu, Chun-Nam John},
  journal  = {Machine Learning},
  title    = {Cutting-plane training of structural {SVMs}},
  year     = {2009},
  issn     = {1573-0565},
  number   = {1},
  pages    = {27--59},
  volume   = {77},
  abstract = {Discriminative training approaches like structural SVMs have shown much promise for building highly complex and accurate models in areas like natural language processing, protein structure prediction, and information retrieval. However, current training algorithms are computationally expensive or intractable on large datasets. To overcome this bottleneck, this paper explores how cutting-plane methods can provide fast training not only for classification SVMs, but also for structural SVMs. We show that for an equivalent “1-slack” reformulation of the linear SVM training problem, our cutting-plane method has time complexity linear in the number of training examples. In particular, the number of iterations does not depend on the number of training examples, and it is linear in the desired precision and the regularization parameter. Furthermore, we present an extensive empirical evaluation of the method applied to binary classification, multi-class classification, HMM sequence tagging, and CFG parsing. The experiments show that the cutting-plane algorithm is broadly applicable and fast in practice. On large datasets, it is typically several orders of magnitude faster than conventional training methods derived from decomposition methods like SVM-light, or conventional cutting-plane methods. Implementations of our methods are available at www.joachims.org.},
  doi      = {10.1007/s10994-009-5108-8},
  file     = {:FILES/2009 - Joachims2009 - Cutting-plane training of structural {SVMs}.pdf:PDF},
  groups   = {SVM},
  url      = {https://link.springer.com/article/10.1007/s10994-009-5108-8},
}

@PhdThesis{Wang2020d,
  author  = {Wang, Shengye},
  school  = {University of California San Diego},
  title   = {Reliability engineering for long-term deployment of autonomous service robots},
  year    = {2020},
  address = {San Diego, California, USA},
  file    = {:FILES/2020 - Wang2020d - Reliability Engineering for Long-term Deployment of Autonomous Service Robots.pdf:PDF},
  groups  = {tour guide robot},
  url     = {https://escholarship.org/uc/item/2gp1k05k},
}

@InProceedings{Thrun1999,
  author    = {Thrun, Sebastian and Bennewitz, Maren and Burgard, Wolfram and Cremers, Armin B. and Dellaert, Frank and Fox, Dieter and H\"{a}hnel, Dirk and Rosenberg, Charles and Roy, Nicholas and Schulte, Jamieson and Schulz, Dirk},
  booktitle = {Proceedings 1999 IEEE International Conference on Robotics and Automation (Cat. No.99CH36288C)},
  title     = {{MINERVA}: {A} second-generation museum tour-guide robot},
  year      = {1999},
  address   = {Detroit, MI, USA},
  month     = may,
  pages     = {1999--2005},
  publisher = {IEEE},
  volume    = {3},
  abstract  = {This paper describes an interactive tour-guide robot, which was successfully exhibited in a Smithsonian museum. During its two weeks of operation, the robot interacted with thousands of people, traversing more than 44 km at speeds of up to 163 cm/sec. Our approach specifically addresses issues such as safe navigation in unmodified and dynamic environments, and short-term human-robot interaction. It uses learning pervasively at all levels of the software architecture.},
  doi       = {10.1109/ROBOT.1999.770401},
  file      = {:FILES/1999 - Thrun1999 - {MINERVA} {A} second-generation museum tour-guide robot.pdf:PDF},
  groups    = {tour guide robot},
  issn      = {1050-4729},
  url       = {https://ieeexplore.ieee.org/abstract/document/770401},
}

@InProceedings{Velentza2019,
  author    = {Velentza, Anna-Maria and Heinke, Dietmar and Wyatt, Jeremy},
  booktitle = {Proceedings of the 2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
  title     = {Human interaction and improving knowledge through collaborative tour guide robots},
  year      = {2019},
  address   = {New Delhi, India},
  month     = oct,
  pages     = {1--7},
  abstract  = {In the coming years tour guide robots will be widely used in museums and exhibitions. Therefore, it is important to identify how these new museum guides can optimally interact with visitors. In this paper, we introduce the idea of two collaborative tour guide robots. We have been inspired by evidence from cognitive studies stating that people remember more when they receive information from two different human speakers. Our collaborative tour guides were benchmarked against single robot guides. Our study initially proved, through real-world experiments, previous proposals stating that the personality of the robot affects the human learning process; our results demonstrate that people remember significantly more information when they are guided by a cheerful robot than when their guide is a serious one. Moreover, another important outcome of our study is that our visitors tend to like more our collaborative robots, than any referenced single robot, as demonstrated by the higher scores in the aesthetic-related questions. Hence our results suggest that a cheerful robot is more suitable for learning purposes while two robots are more suitable for entertainment purposes.},
  doi       = {10.1109/RO-MAN46459.2019.8956372},
  file      = {:FILES/2019 - Velentza2019 - Human Interaction and Improving Knowledge through Collaborative Tour Guide Robots.pdf:PDF},
  groups    = {tour guide robot},
  issn      = {1944-9437},
  url       = {https://ieeexplore.ieee.org/abstract/document/8956372},
}

@InProceedings{Duchetto2019,
  author    = {Duchetto, Francesco Del and Baxter, Paul and Hanheide, Marc},
  booktitle = {Proceedings of the 2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)},
  title     = {Lindsey the tour guide robot - usage patterns in a museum long-term deployment},
  year      = {2019},
  address   = {New Delhi, India},
  month     = oct,
  pages     = {1--8},
  abstract  = {The long-term deployment of autonomous robots co-located with humans in real-world scenarios remains a challenging problem. In this paper, we present the “Lindsey” tour guide robot system in which we attempt to increase the social capability of current state-of-the-art robotic technologies. The robot is currently deployed at a museum displaying local archaeology where it is providing guided tours and information to visitors. The robot is operating autonomously daily, navigating around the museum and engaging with the public, with on-site assistance from roboticists only in cases of hardware/software malfunctions. In a deployment lasting seven months up to now, it has travelled nearly 300km and has delivered more than 2300 guided tours. First, we describe the robot framework and the management interfaces implemented. We then analyse the data collected up to now with the goal of understanding and modelling the visitors' behavior in terms of their engagement with the technology. These data suggest that while short-term engagement is readily gained, continued engagement with the robot tour guide is likely to require more refined and robust socially interactive behaviours. The deployed system presents us with an opportunity to empirically address these issues.},
  doi       = {10.1109/RO-MAN46459.2019.8956329},
  file      = {:FILES/2019 - Duchetto2019 - Lindsey the Tour Guide Robot - Usage Patterns in a Museum Long-Term Deployment.pdf:PDF},
  groups    = {tour guide robot},
  issn      = {1944-9437},
  url       = {https://ieeexplore.ieee.org/abstract/document/8956329},
}

@InProceedings{Whitney2016,
  author     = {Whitney, David and Eldon, Miles and Oberlin, John and Tellex, Stefanie},
  booktitle  = {Proceedings of the 2016 IEEE International Conference on Robotics and Automation (ICRA)},
  title      = {Interpreting multimodal referring expressions in real time},
  year       = {2016},
  address    = {Stockholm, Sweden},
  month      = may,
  pages      = {3331--3338},
  publisher  = {IEEE},
  abstract   = {Humans communicate about objects using language, gesture, and context, fusing information from multiple modalities over time. Robots need to interpret this communication in order to collaborate with humans on shared tasks. Processing communicative input incrementally has the potential to increase the speed and accuracy of a robot's reaction. It also enables the robot to incorporate the relative timing of words and gestures into the understanding process. To address this problem, we define a multimodal Bayes filter for interpreting a person's referential expressions to objects. Our approach outputs a distribution over the referent object at 14Hz, updating dynamically as it receives new observations of the person's spoken words and gestures. We collected a new dataset of people referring to one of four objects in a tabletop setting and demonstrate that our approach is able to infer the correct object with 90% accuracy. Additionally, we augment and improve our filter in a simulated home kitchen domain by learning contextual knowledge in an unsupervised manner from existing written text, increasing our maximum accuracy to 96%, even with an increase in the number of objects from four to seventy.},
  comment    = {Scalise2017: to ensure humans and robots share the same groundings that map what a robot senses to agreed upon vocabulary while communicating (e.g., [8, 12]).

利用多模态信息infering and grounding objects in env.

本文内容：利用speech + gesture 来infer the object the user is referring to，基本方法是Bayesian filter:
1. 状态是object，观测是gesture +  speech，
2. 通过实验验证trigram model效果最好，
3. 在计算概率的时候，考虑了无意义的gesture、unknown words (do nothing)的影响，原理上没有什么重要创新。
4. SR、NLP等都是成熟工具，并未详细介绍，且基本是co-occurence statistics的方法
5.场景是home kitchen domain with limited number of objects.
6. 模型参数是fine tuned
7. the system updates at 14Hz},
  doi        = {10.1109/ICRA.2016.7487507},
  file       = {:FILES/2016 - Whitney2016 - Interpreting multimodal referring expressions in real time.pdf:PDF},
  groups     = {task understanding},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/7487507},
}

@Article{Paul2018,
  author   = {Rohan Paul and Jacob Arkin and Derya Aksaray and Nicholas Roy and Thomas M. Howard},
  journal  = {The International Journal of Robotics Research},
  title    = {Efficient grounding of abstract spatial concepts for natural language interaction with robot platforms},
  year     = {2018},
  month    = jun,
  number   = {10},
  pages    = {1269--1299},
  volume   = {37},
  abstract = {Our goal is to develop models that allow a robot to efficiently understand or “ground” natural language instructions in the context of its world representation. Contemporary approaches estimate correspondences between language instructions and possible groundings such as objects, regions, and goals for actions that the robot should execute. However, these approaches typically reason in relatively small domains and do not model abstract spatial concepts such as as “rows,” “columns,” or “groups” of objects and, hence, are unable to interpret an instruction such as “pick up the middle block in the row of five blocks.” In this paper, we introduce two new models for efficient natural language understanding of robot instructions. The first model, which we call the adaptive distributed correspondence graph (ADCG), is a probabilistic model for interpreting abstract concepts that require hierarchical reasoning over constituent concrete entities as well as notions of cardinality and ordinality. Abstract grounding variables form a Markov boundary over concrete groundings, effectively de-correlating them from the remaining variables in the graph. This structure reduces the complexity of model training and inference. Inference in the model is posed as an approximate search procedure that orders factor computation such that the estimated probable concrete groundings focus the search for abstract concepts towards likely hypothesis, pruning away improbable portions of the exponentially large space of abstractions. Further, we address the issue of scalability to complex domains and introduce a hierarchical extension to a second model termed the hierarchical adaptive distributed correspondence graph (HADCG). The model utilizes the abstractions in the ADCG but infers a coarse symbolic structure from the utterance and the environment model and then performs fine-grained inference over the reduced graphical model, further improving the efficiency of inference. Empirical evaluation demonstrates accurate grounding of abstract concepts embedded in complex natural language instructions commanding a robotic torso and a mobile robot. Further, the proposed approximate inference method allows significant efficiency gains compared with the baseline, with minimal trade-off in accuracy.},
  comment  = {Scalise2017: to ensure humans and robots share the same groundings that map what a robot senses to agreed upon vocabulary while communicating (e.g., [8, 12]).
{Kartmann2020}:spatial relations are used as a basis to ground abstract spatial concepts such as columns or groups of objects for natural language interaction
partition joint distributioninto concrete and abstract factors},
  doi      = {10.1177/0278364918777627},
  file     = {:FILES/2018 - Paul2018 - Efficient grounding of abstract spatial concepts for natural language interaction with robot platforms.pdf:PDF},
  groups   = {task understanding, spatial relation},
  priority = {prio1},
  url      = {https://journals.sagepub.com/doi/abs/10.1177/0278364918777627},
}

@Article{Young2013,
  author   = {Young, Steve and Ga\v{s}i\'{c}, Milica and Thomson, Blaise and Williams, Jason D.},
  journal  = {Proceedings of the IEEE},
  title    = {{POMDP}-based statistical spoken dialog systems: {A} review},
  year     = {2013},
  issn     = {1558-2256},
  month    = may,
  number   = {5},
  pages    = {1160--1179},
  volume   = {101},
  abstract = {Statistical dialog systems (SDSs) are motivated by the need for a data-driven framework that reduces the cost of laboriously handcrafting complex dialog managers and that provides robustness against the errors created by speech recognizers operating in noisy environments. By including an explicit Bayesian model of uncertainty and by optimizing the policy via a reward-driven process, partially observable Markov decision processes (POMDPs) provide such a framework. However, exact model representation and optimization is computationally intractable. Hence, the practical application of POMDP-based systems requires efficient algorithms and carefully constructed approximations. This review article provides an overview of the current state of the art in the development of POMDP-based spoken dialog systems.},
  comment  = {Lu2017a: POMDP用于dialog management, model uncertainty from language understanding in a continuous space, audio based dialog system},
  doi      = {10.1109/JPROC.2012.2225812},
  file     = {:FILES/2013 - Young2013 - {POMDP}-based Statistical Spoken Dialog Systems- A Review.pdf:PDF},
  groups   = {dialog system, task understanding},
  url      = {https://ieeexplore.ieee.org/document/6407655},
}

@Article{Singh2002,
  author  = {Satinder Singh and Diane Litman and Michael Kearns and Marilyn Walker},
  journal = {Journal of Artificial Intelligence Research},
  title   = {Optimizing dialogue management with reinforcement learning: {Experiments} with the {NJFun} system},
  year    = {2002},
  month   = feb,
  pages   = {105--133},
  volume  = {16},
  comment = {Lu2017a: Dialog system 基于MDP},
  doi     = {10.1613/jair.859},
  file    = {:FILES/2002 - Singh2002 - Optimizing Dialogue Management with Reinforcement Learning- Experiments with the NJFun System.pdf:PDF},
  groups  = {dialog system, task understanding},
  url     = {https://www.jair.org/index.php/jair/article/view/10294},
}

@InProceedings{Roy2000,
  author     = {Roy, Nicholas and Pineau, Joelle and Thrun, Sebastian},
  booktitle  = {Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics},
  title      = {Spoken dialogue management using probabilistic reasoning},
  year       = {2000},
  address    = {Hong Kong, China},
  month      = oct,
  pages      = {93--100},
  publisher  = {Association for Computational Linguistics},
  comment    = {Lu2017a: Dialog system 基于PoMDP用于机器人

本文提出了一种基于POMDP的对话管理系统,其中observation is the NL utterance, state is the intention of human, action is the robot's response (verbal or navigational actions). 其中动作intention的识别是基于SR和关键词,结果分配了belief,本质还是针对每个观测值,预测机器人下一步应采取的动作(confirmation or action).具有HRI.

这部分内容勉强可以作为TU的一部分,但是更适合对话系统.},
  doi        = {10.3115/1075218.1075231},
  file       = {:FILES/2000 - Roy2000 - Spoken Dialogue Management Using Probabilistic Reasoning.pdf:PDF},
  groups     = {dialog system, task understanding},
  keywords   = {read},
  readstatus = {read},
  url        = {https://www.aclweb.org/anthology/P00-1013},
}

@InProceedings{Gopalan2015,
  author    = {Nakul Gopalan and Stefanie Tellex},
  booktitle = {Robotics: Science and Systems 2015: Workshop on Model Learning for Human-Robot Communication},
  title     = {Modeling and solving human-robot collaborative tasks using {POMDPs}},
  year      = {2015},
  file      = {:FILES/2015 - Gopalan2015 - Modeling and Solving Human-Robot Collaborative Tasks Using POMDPs.pdf:PDF},
  groups    = {dialog system, task understanding},
}

@InProceedings{Kollar2010,
  author     = {Kollar, Thomas and Tellex, Stefanie and Roy, Deb and Roy, Nicholas},
  booktitle  = {Proceedings of the 2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  title      = {Toward understanding natural language directions},
  year       = {2010},
  address    = {Osaka, Japan},
  month      = mar,
  pages      = {259--266},
  publisher  = {IEEE},
  abstract   = {Speaking using unconstrained natural language is an intuitive and flexible way for humans to interact with robots. Understanding this kind of linguistic input is challenging because diverse words and phrases must be mapped into structures that the robot can understand, and elements in those structures must be grounded in an uncertain environment. We present a system that follows natural language directions by extracting a sequence of spatial description clauses from the linguistic input and then infers the most probable path through the environment given only information about the environmental geometry and detected visible objects. We use a probabilistic graphical model that factors into three key components. The first component grounds landmark phrases such as ¿the computers¿ in the perceptual frame of the robot by exploiting co-occurrence statistics from a database of tagged images such as Flickr. Second, a spatial reasoning component judges how well spatial relations such as ¿past the computers¿ describe a path. Finally, verb phrases such as ¿turn right¿ are modeled according to the amount of change in orientation in the path. Our system follows 60% of the directions in our corpus to within 15 meters of the true destination, significantly outperforming other approaches.},
  comment    = {Lu2016a: manually create a small set of hand-coded robot actions for primitive tasks though their scalability and generality are limited.
Bastianelli2016: CRF is used to extract spatial information represented as spatial description clauses. infer path to follow in the env.
Whitney2016: batch interpretation
Ji2016: Understanding natural language commands
Boularias2015:Same spatial relation clauses
Hemachandra2015:interpret natural language expressions that provide route direction,需要prior knowledge
Howard2014a: NL in route direction following
Hemachandra2014:Mapping NL to the corresponding referents in the robot’s world model
Walter2013:Symbol grounding problem is in the context of following NL commands
Duvallet2016: Natural language has proven to be effective for commanding robots to follow route directions. Require a complete semantically-labeled environment model that captures the geometry, location, type, and label of objects and regions in the environment. 没有利用NL instruction中包含的信息来reason uncertainty and infer environment representation.
{Anderson2018}：operating in visually restricted environments requiring limited perception},
  doi        = {10.1109/HRI.2010.5453186},
  file       = {:FILES/2010 - Kollar2010 - Toward understanding natural language directions.pdf:PDF;:FILES/notes/Kollar2010.docx:Word 2007+},
  groups     = {task understanding},
  issn       = {2167-2148},
  printed    = {Y},
  priority   = {prio2},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/5453186},
}

@InProceedings{Nyga2012,
  author    = {Nyga, Daniel and Beetz, Michael},
  booktitle = {Proceedings of the 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Everything robots always wanted to know about housework (but were afraid to ask)},
  year      = {2012},
  address   = {Vilamoura-Algarve, Portugal},
  month     = oct,
  pages     = {243--250},
  publisher = {IEEE},
  abstract  = {In this paper we discuss the problem of action-specific knowledge processing, representation and acquisition by autonomous robots performing everyday activities. We report on a thorough analysis of the household domain, which has been performed on a large corpus of natural-language instructions from the Web and underlines the supreme need of action-specific knowledge for robots acting in those environments. We introduce the concept of Probabilistic Robot Action Cores (PRAC) that are well-suited for encoding such knowledge in a probabilistic first-order knowledge base. We additionally show how such a knowledge base can be acquired by natural language and we address the problems of incompleteness, underspecification and ambiguity of naturalistic action specifications and point out how PRAC models can tackle those.},
  comment   = {Lu2016a: manually create a small set of hand-coded robot actions for primitive tasks though their scalability and generality are limited.},
  doi       = {10.1109/IROS.2012.6385923},
  file      = {:FILES/2012 - Nyga2012 - Everything robots always wanted to know about housework (but were afraid to ask).pdf:PDF},
  groups    = {task understanding},
  issn      = {2153-0866},
  url       = {https://ieeexplore.ieee.org/abstract/document/6385923},
}

@InProceedings{Dzifcak2009,
  author    = {Dzifcak, Juraj and Scheutz, Matthias and Baral, Chitta and Schermerhorn, Paul},
  booktitle = {Proceedings of the 2009 IEEE International Conference on Robotics and Automation (IROS)},
  title     = {What to do and how to do it: Translating natural language directives into temporal and dynamic logic representation for goal management and action execution},
  year      = {2009},
  address   = {Kobe, Japan},
  month     = may,
  pages     = {4163--4168},
  publisher = {IEEE},
  abstract  = {Robots that can be given instructions in spoken language need to be able to parse a natural language utterance quickly, determine its meaning, generate a goal representation from it, check whether the new goal conflicts with existing goals, and if acceptable, produce an action sequence to achieve the new goal (ideally being sensitive to the existing goals). In this paper, we describe an integrated robotic architecture that can achieve the above steps by translating natural language instructions incrementally and simultaneously into formal logical goal description and action languages, which can be used both to reason about the achievability of a goal as well as to generate new action scripts to pursue the goal. We demonstrate the implementation of our approach on a robot taking spoken natural language instructions in an office environment.},
  comment   = {Lu2016a: NLU for robots，假设对话的领域已知，且没有考虑动词及semantic role的消岐
Ji2016: NL to generate plans
Boularias2015:Firstorder dynamic logic for grounding goal and action utterances
Walter2013:enabling robots to interpret natural language commands, Symbol grounding problem is in the context of following NL commands
Kollar2010:提出了language understanding system来follow NL commands,但是without using a corpus-based evaluation，从而让untrained users使用该系统},
  doi       = {10.1109/ROBOT.2009.5152776},
  file      = {:FILES/2009 - Dzifcak2009 - What to do and how to do it- Translating natural language directives into temporal and dynamic logic representation for goal management and action execution.pdf:PDF},
  groups    = {task understanding},
  issn      = {1050-4729},
  url       = {https://ieeexplore.ieee.org/abstract/document/5152776},
}

@Article{KressGazit2009,
  author   = {{Kress-Gazit}, Hadas and Fainekos, Georgios E. and Pappas, George J.},
  journal  = {IEEE Transactions on Robotics},
  title    = {Temporal-logic-based reactive mission and motion planning},
  year     = {2009},
  issn     = {1941-0468},
  month    = dec,
  number   = {6},
  pages    = {1370--1381},
  volume   = {25},
  abstract = {This paper provides a framework to automatically generate a hybrid controller that guarantees that the robot can achieve its task when a robot model, a class of admissible environments, and a high-level task or behavior for the robot are provided. The desired task specifications, which are expressed in a fragment of linear temporal logic (LTL), can capture complex robot behaviors such as search and rescue, coverage, and collision avoidance. In addition, our framework explicitly captures sensor specifications that depend on the environment with which the robot is interacting, which results in a novel paradigm for sensor-based temporal-logic-motion planning. As one robot is part of the environment of another robot, our sensor-based framework very naturally captures multirobot specifications in a decentralized manner. Our computational approach is based on first creating discrete controllers satisfying specific LTL formulas. If feasible, the discrete controller is then used to guide the sensor-based composition of continuous controllers, which results in a hybrid controller satisfying the high-level specification but only if the environment is admissible.},
  comment  = {Lu2016a: NLU for robots，假设对话的领域已知，且没有考虑动词及semantic role的消岐},
  doi      = {10.1109/TRO.2009.2030225},
  file     = {:FILES/2009 - KressGazit2009 - Temporal-Logic-Based Reactive Mission and Motion Planning.pdf:PDF},
  groups   = {task understanding},
  url      = {https://ieeexplore.ieee.org/abstract/document/5238617},
}

@InProceedings{Cantrell2010,
  author    = {Cantrell, Rehj and Scheutz, Matthias and Schermerhorn, Paul and Wu, Xuan},
  booktitle = {Proceedings of the 2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  title     = {Robust spoken instruction understanding for {HRI}},
  year      = {2010},
  address   = {Osaka, Japan},
  month     = mar,
  pages     = {275--282},
  publisher = {IEEE},
  abstract  = {Natural human-robot interaction requires different and more robust models of language understanding (NLU) than non-embodied NLU systems. In particular, architectures are required that (1) process language incrementally in order to be able to provide early back channel feedback to human speakers; (2) use pragmatic contexts throughout the understanding process to infer missing information; and (3) handle the underspecified, fragmentary, or otherwise ungrammatical utterances that are common in spontaneous speech. In this paper, we describe our attempts at developing an integrated natural language understanding architecture for HRI, and demonstrate its novel capabilities using challenging data collected in human-human interaction experiments.},
  comment   = {Lu2016a: NLU for robots，假设对话的领域已知，且没有考虑动词及semantic role的消岐},
  doi       = {10.1109/HRI.2010.5453184},
  file      = {:FILES/2010 - Cantrell2010 - Robust spoken instruction understanding for HRI.pdf:PDF},
  groups    = {task understanding},
  issn      = {2167-2148},
  url       = {https://ieeexplore.ieee.org/abstract/document/5453184},
}

@InProceedings{Hemachandra2014,
  author     = {Hemachandra, Sachithra and Walter, Matthew R. and Tellex, Stefanie and Teller, Seth},
  booktitle  = {Proceedings of the 2014 IEEE International Conference on Robotics and Automation (ICRA)},
  title      = {Learning spatial-semantic representations from natural language descriptions and scene classifications},
  year       = {2014},
  address    = {Hong Kong, China},
  month      = may,
  pages      = {2623--2630},
  publisher  = {IEEE},
  abstract   = {We describe a semantic mapping algorithm that learns human-centric environment models by interpreting natural language utterances. Underlying the approach is a coupled metric, topological, and semantic representation of the environment that enables the method to fuse information from natural language descriptions with low-level metric and appearance data. We extend earlier work with a novel formulation that incorporates spatial layout into a topological representation of the environment. We also describe a factor graph formulation of the semantic properties that encodes human-centric concepts such as type and colloquial name for each mapped region. The algorithm infers these properties by combining the user's natural language descriptions with image- and laser-based scene classification. We also propose a mechanism to more effectively ground natural language descriptions of distant regions using semantic cues from other modalities. We describe how the algorithm employs this learned semantic information to propose valid topological hypotheses, leading to more accurate topological and metric maps. We demonstrate that integrating language with other sensor data increases the accuracy of the achieved spatial-semantic representation of the environment.},
  comment    = {Lu2016a:manually create environment driven instructions for grounding user instructions in NL to actions.但是规模小，对机器人硬件有要求（机械臂）
Liu2016d: use logic relation for task execution. <action + object> pattern for generalization
Hemachandra2015:前期工作：interpret natural language expressions that convey environment knowledge,利用NL来学习world model，只对机器人observe的环境有用 ，利用spatial clustering来segment resions


(4)提出了一种构造spatial semantic representation of the environment的framework，结合了natural language, laser sensor data, and visual perceived data。该方法通过构造一个layered structure, i.e., semantic graph with topology, metric, and semantic representation of the environment，并利用joint distribution over semantic graph conditioned on sensor data, odometry, scene appearance observations, and natural language distributions来动态更新semantic map，实现对observation, region的语义信息的识别，从而判断其category and label。利用了多模态信息。
(5)假设了NL中不含uncertainty，且对于环境中observation的可能label或category都已知（同义词），SR过程无错误等。不适用于unknown env
(6)可以处理egocentric and allocentric NL instructions. 后者的correspondence variable由G3 model计算而得到。},
  doi        = {10.1109/ICRA.2014.6907235},
  file       = {:FILES/2014 - Hemachandra2014 - Learning spatial-semantic representations from natural language descriptions and scene classifications.pdf:PDF;:FILES/notes/Hemachandra2014.docx:Word 2007+},
  groups     = {task understanding},
  issn       = {1050-4729},
  printed    = {Y},
  priority   = {prio2},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/6907235},
}

@Article{Lemaignan2012,
  author   = {Lemaignan, S\'{e}verin and Ros, Raquel and Sisbot, E. Akin and Alami, Rachid and Beetz, Michael},
  journal  = {International Journal of Social Robotics},
  title    = {Grounding the interaction: {Anchoring} situated discourse in everyday human-robot interaction},
  year     = {2012},
  issn     = {1875-4805},
  number   = {2},
  pages    = {181--199},
  volume   = {4},
  abstract = {This paper presents how extraction, representation and use of symbolic knowledge from real-world perception and human-robot verbal and non-verbal interaction can actually enable a grounded and shared model of the world that is suitable for later high-level tasks such as dialogue understanding. We show how the anchoring process itself relies on the situated nature of human-robot interactions. We present an integrated approach, including a specialized symbolic knowledge representation system based on Description Logics, and case studies on several robotic platforms that demonstrate these cognitive capabilities.},
  comment  = {Lu2016a: 利用online knowledge},
  doi      = {10.1007/s12369-011-0123-x},
  file     = {:FILES/2012 - Lemaignan2012 - Grounding the Interaction- Anchoring Situated Discourse in Everyday Human-Robot Interaction.pdf:PDF},
  groups   = {task understanding},
  url      = {https://link.springer.com/article/10.1007/s12369-011-0123-x},
}

@Article{Lemaignan2013,
  author   = {Lemaignan, S\'{e}verin},
  journal  = {KI - K\"{u}nstliche Intelligenz},
  title    = {Grounding the interaction: {Knowledge} management for interactive robots},
  year     = {2013},
  issn     = {1610-1987},
  number   = {2},
  pages    = {183--185},
  volume   = {27},
  abstract = {The dissertation tackles the broad question of knowledge representation and manipulation for companion robots. It first builds a taxonomy of the knowledge manipulation skills required by service robots, then proposes a novel active knowledge base that integrates into large cognitive architectures, and finally explores several applications, including natural language grounding.},
  comment  = {Lu2016a: 利用online knowledge},
  doi      = {10.1007/s13218-013-0246-3},
  file     = {:FILES/2013 - Lemaignan2013 - Grounding the Interaction- Knowledge Management for Interactive Robots.pdf:PDF},
  groups   = {task understanding},
  url      = {https://link.springer.com/article/10.1007/s13218-013-0246-3},
}

@InProceedings{Varadarajan2012,
  author    = {Varadarajan, Karthik Mahesh and Vincze, Markus},
  booktitle = {Proceedings of the 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {{AfRob}: {The} affordance network ontology for robots},
  year      = {2012},
  address   = {Vilamoura-Algarve, Portugal},
  month     = oct,
  pages     = {1343--1350},
  publisher = {IEEE},
  abstract  = {AfNet, The Affordance Network is an open affordance computing initiative that provides affordance knowledge ontologies for common household articles in terms of affordance features using surface forms termed as afbits (affordance bits). AfNet currently offers 68 base affordance features (25 structural, 10 material, 33 grasp), providing over 200 object category definitions in terms of 4000 afbits. Symbol grounding algorithms for these affordance features enable recognition of objects in visual (RGB-D) data. While AfNet is built as a generic visual knowledge ontology for recognition, it is well suited for deployment on domestic robots. In this paper, we describe AfRob, an extension of AfNet for robotic applications. AfRob builds upon AfNet by imbibing semantic context and mapping for holistic recognition and manipulation of objects in domestic environments. AfRob also offers modules to enable robots to interact and grasp objects through the generation of grasp affordances. The paper also details the inference mechanisms that adapt AfNet for robots in domestic contexts. Results demonstrate the efficiency of the affordance driven approach to holistic visual processing.},
  comment   = {Lu2016a: Grounding the missing semantic roles with the entities in the context},
  doi       = {10.1109/IROS.2012.6386232},
  file      = {:FILES/2012 - Varadarajan2012 - AfRob- The affordance network ontology for robots.pdf:PDF},
  groups    = {task understanding},
  issn      = {2153-0866},
  url       = {https://ieeexplore.ieee.org/abstract/document/6386232},
}

@InProceedings{Williams2013,
  author    = {Thomas Williams and Rehj Cantrell and Gordon Briggs and Paul Schermerhorn and Matthias Scheutz},
  booktitle = {Proceedings of the 27th AAAI Conference on Artificial Intelligence},
  title     = {Grounding natural language references to unvisited and hypothetical locations},
  year      = {2013},
  address   = {Bellevue, Washington, USA},
  month     = jul,
  pages     = {947--953},
  publisher = {AAAI Press},
  comment   = {Lu2016a: Grounding the missing semantic roles with the entities in the context
Duvallet2016: Use a cognitive architecture to add unvisited locations to a partial map.只reason about topological relationships to unknown places，而没有maintain multiple hypotheses, 并make strong assumptions about the environment limiting the applicability to real robot systems},
  file      = {:FILES/2013 - Williams2013 - Grounding Natural Language References to Unvisited and Hypothetical Locations.pdf:PDF},
  groups    = {task understanding},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/8563},
}

@Article{Tanenhaus1995,
  author     = {Tanenhaus, Michael K. and {Spivey-Knowlton}, Michael J. and Eberhard, Kathleen M. and Sedivy, Julie C.},
  journal    = {Science},
  title      = {Integration of visual and linguistic information in spoken language comprehension},
  year       = {1995},
  issn       = {0036-8075},
  month      = jun,
  number     = {5217},
  pages      = {1632--1634},
  volume     = {268},
  abstract   = {Psycholinguists have commonly assumed that as a spoken linguistic message unfolds over time, it is initially structured by a syntactic processing module that is encapsulated from information provided by other perceptual and cognitive systems. To test the effects of relevant visual context on the rapid mental processes that accompany spoken language comprehension, eye movements were recorded with a head-mounted eye-tracking system while subjects followed instructions to manipulate real objects. Visual context influenced spoken word recognition and mediated syntactic processing, even during the earliest moments of language processing.},
  comment    = {Bastianelli2016:  Robot interactions need thus to be grounded, as meaning must correspond to the physical world and interpretation is strongly interlaced with what is perceived, as pointed out by psycho-linguistic theories


1.本文基于实验的方法，从psycholinguist的角度，讨论了人类在理解语言指令时，mental process in natural context where language has real-world reference. 
2.通过recording eye movements as participants followed instructions to move objects,来monitor the ongoing comprehension process on a millisecond time scale. 
3.结论：through experiments on human understanding NL instructions with linking real-world references by eye movement, they found that in natural contexts, people seek to establish reference with respect to their behavioral goals during the earliest moments of linguistic processing. therefore, assign a central role to encapsulated linguistic subsystems are unlikely to prove fruitful.},
  doi        = {10.1126/science.7777863},
  file       = {:FILES/1995 - Tanenhaus1995 - Integration of visual and linguistic information in spoken language comprehension.pdf:PDF},
  groups     = {task understanding},
  publisher  = {American Association for the Advancement of Science},
  readstatus = {read},
  url        = {https://science.sciencemag.org/content/268/5217/1632},
}

@InProceedings{Bastianelli2014,
  author    = {Bastianelli, Emanuele and Castellucci, Giuseppe and Croce, Danilo and Basili, Roberto and Nardi, Daniele},
  booktitle = {Proceedings of the 21st European Conference on Artificial Intelligence (ECAI)},
  title     = {Effective and robust natural language understanding for human-robot interaction},
  year      = {2014},
  month     = aug,
  pages     = {57--62},
  publisher = {IOS Press},
  volume    = {263},
  abstract  = {Robots are slowly becoming part of everyday life, as they are being marketed for commercial applications (viz. telepresence, cleaning or entertainment). Thus, the ability to interact with non-expert users is becoming a key requirement. Even if user utterances can be efficiently recognized and transcribed by Automatic Speech Recognition systems, several issues arise in translating them into suitable robotic actions. In this paper, we will discuss both approaches providing two existing Natural Language Understanding workflows for Human Robot Interaction. First, we discuss a grammar based approach: it is based on grammars thus recognizing a restricted set of commands. Then, a data driven approach, based on a free-from speech recognizer and a statistical semantic parser, is discussed. The main advantages of both approaches are discussed, also from an engineering perspective, i.e. considering the effort of realizing HRI systems, as well as their reusability and robustness. An empirical evaluation of the proposed approaches is carried out on several datasets, in order to understand performances and identify possible improvements towards the design of NLP components in HRI.},
  comment   = {Bastianelli2016: 将instruction interpretation作为classification problem or sequence labeling task. 在linguistic level},
  doi       = {10.3233/978-1-61499-419-0-57},
  file      = {:FILES/2014 - Bastianelli2014 - Effective and Robust Natural Language Understanding for Human-Robot Interaction.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781614994183},
  url       = {https://ebooks.iospress.nl/publication/36916},
}

@InProceedings{Bastianelli2015,
  author    = {Bastianelli, Emanuele and Croce, Danilo and Basili, Roberto and Nardi, Daniele},
  booktitle = {Proceedings of the AI*IA 2015 Advances in Artificial Intelligence},
  title     = {Using semantic models for robust natural language human robot interaction},
  year      = {2015},
  editor    = {Gavanelli, Marco and Lamma, Evelina and Riguzzi, Fabrizio},
  pages     = {343--356},
  publisher = {Springer International Publishing},
  abstract  = {While robotic platforms are moving from industrial to consumer applications, the need of flexible and intuitive interfaces becomes more critical and the capability of governing the variability of human language a strict requirement. Grounding of lexical expressions, i.e. mapping words of a user utterance to the perceived entities of a robot operational scenario, is particularly critical. Usually, grounding proceeds by learning how to associate objects categorized in discrete classes (e.g. routes or sets of visual patterns) to linguistic expressions. In this work, we discuss how lexical mapping functions that integrate Distributional Semantics representations and phonetic metrics can be adopted to robustly automate the grounding of language expressions into the robotic semantic maps of a house environment. In this way, the pairing between words and objects into a semantic map facilitates the grounding without the need of an explicit categorization. Comparative measures demonstrate the viability of the proposed approach and the achievable robustness, quite crucial in operational robotic settings.},
  comment   = {Bastianelli2016: 提出了基于Distributional Model of Lexical Semantics + phonetic similarity的lexicalized distance measure},
  doi       = {10.1007/978-3-319-24309-2_26},
  file      = {:FILES/2015 - Bastianelli2015 - Using Semantic Models for Robust Natural Language Human Robot Interaction.pdf:PDF},
  groups    = {task understanding},
  isbn      = {978-3-319-24309-2},
  url       = {https://link.springer.com/chapter/10.1007/978-3-319-24309-2_26},
}

@InProceedings{Chen2011a,
  author    = {David Chen and Raymond Mooney},
  booktitle = {Proceedings of the 25th AAAI Conference on Artificial Intelligence},
  title     = {Learning to interpret natural language navigation instructions from observations},
  year      = {2011},
  address   = {San Francisco, California, USA},
  month     = aug,
  pages     = {859--865},
  publisher = {AAAI Press},
  comment   = {Bastianelli2016: linguistic level SLU for robot.  language descriptions are paired with robotic actions, and Statistical Machine Translation is applied
Hemachandra2015: interpret natural language expressions that provide route direction, learn a parser 以把NL instr映射为plan
Howard2014a: NL in route direction following
Hemachandra2014:HRI with NL speech
Walter2013:enabling robots to interpret natural language commands
Duvallet2016: Natural language has proven to be effective for commanding robots to follow route directions. used a parser that maps language directly to plans. 没有利用NL instruction中包含的信息来reason uncertainty and infer environment representation.
{Anderson2018}：natural language navigation, relate natual language to real imagery (labels) as a classification problem，所有object都已知},
  file      = {:FILES/2011 - Chen2011a - Learning to Interpret Natural Language Navigation Instructions from Observations.pdf:PDF},
  groups    = {task understanding, navigation},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/7974},
}

@InProceedings{Kaplan2000,
  author    = {Kaplan, Fr\'{e}d\'{e}ric},
  booktitle = {Proceedings of the 2000 CELE-Twente Workshop on Interacting Agents},
  title     = {Talking {AIBO}: {First} experimentation of verbal interactions with an autonomous four-legged robot},
  year      = {2000},
  pages     = {1--7},
  comment   = {Bastianelli2016: robot is instructed through dialog to acquire lexical references for real objects. 可以处理unknown words related to objects through dialog},
  file      = {:FILES/2000 - Kaplan2000 - Talking {AIBO}- {First} experimentation of verbal interactions with an autonomous four-legged robot.pdf:PDF},
  groups    = {task understanding},
}

@Article{Bos2007,
  author     = {Bos, Johan and Oka, Tetsushi},
  journal    = {Artificial Life and Robotics},
  title      = {A spoken language interface with a mobile robot},
  year       = {2007},
  issn       = {1614-7456},
  month      = jan,
  number     = {1},
  pages      = {42--47},
  volume     = {11},
  abstract   = {We describe a spoken dialogue interface with a mobile robot, which a human can direct to specific locations, ask for information about its status, and supply information about its environment. The robot uses an internal map for navigation, and communicates its current orientation and accessible locations to the dialogue system. In this article, we focus on linguistic and inferential aspects of the human-robot communication process.},
  comment    = {Bastianelli2016: 将SLU与ASR相结合，将semantic attachments + recognition grammar rule作为特征，已得到utterance transcription based on lambda calculus
VillamarGomez2021 : the interpretation of utterances and context information are represented as logical forms.  implements clarification dialog, it does not consider the number of dialogs made before being able to obtain the information needed for the model or the proof.overusing of questions},
  doi        = {10.1007/s10015-006-0397-5},
  file       = {:FILES/2007 - Bos2007 - A spoken language interface with a mobile robot.pdf:PDF},
  groups     = {task understanding},
  readstatus = {skimmed},
  refid      = {Bos2007},
  url        = {https://link.springer.com/article/10.1007/s10015-006-0397-5},
}

@Article{Miller1995,
  author    = {Miller, George A.},
  journal   = {Communications of the ACM},
  title     = {{WordNet}: {A} lexical database for {English}},
  year      = {1995},
  issn      = {0001-0782},
  month     = nov,
  number    = {11},
  pages     = {39--41},
  volume    = {38},
  abstract  = {Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet1 provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets [4].},
  doi       = {10.1145/219717.219748},
  file      = {:FILES/1995 - Miller1995 - WordNet- A Lexical Database for English.pdf:PDF},
  groups    = {knowledge graph},
  publisher = {Association for Computing Machinery},
  url       = {https://dl.acm.org/doi/abs/10.1145/219717.219748},
}

@InProceedings{Baker1998,
  author    = {Baker, Collin F. and Fillmore, Charles J. and Lowe, John B.},
  booktitle = {Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics (ACL) and 17th International Conference on Computational Linguistics (COLING)},
  title     = {The {Berkeley} {FrameNet} project},
  year      = {1998},
  address   = {USA},
  pages     = {86--90},
  publisher = {Association for Computational Linguistics},
  abstract  = {FrameNet is a three-year NSF-supported project in corpus-based computational lexicography, now in its second year (NSF IRI-9618838, "Tools for Lexicon Building"). The project's key features are (a) a commitment to corpus evidence for semantic and syntactic generalizations, and (b) the representation of the valences of its target words (mostly nouns, adjectives, and verbs) in which the semantic portion makes use of frame semantics. The resulting database will contain (a) descriptions of the semantic frames underlying the meanings of the words described, and (b) the valence representation (semantic and syntactic) of several thousand words and phrases, each accompanied by (c) a representative collection of annotated corpus attestations, which jointly exemplify the observed linkings between "frame elements" and their syntactic realizations (e.g. grammatical function, phrase type, and other syntactic traits). This report will present the project's goals and workflow, and information about the computational tools that have been adapted or created in-house for this work.},
  comment   = {framenet},
  doi       = {10.3115/980845.980860},
  file      = {:FILES/1998 - Baker1998 - The Berkeley FrameNet Project.pdf:PDF},
  groups    = {knowledge graph},
  url       = {https://dl.acm.org/doi/abs/10.3115/980845.980860},
}

@InProceedings{Altun2003,
  author    = {Yasemin Altun and Ioannis Tsochantaridis and Thomas Hofmann},
  booktitle = {Proceedings of the 2003 Internation Conference of Machine Learning (ICML)},
  title     = {Hidden Markov Support Vector Machines},
  year      = {2003},
  address   = {Washington, DC, USA},
  month     = aug,
  pages     = {1--8},
  publisher = {AAAI Press},
  abstract  = {This paper presents a novel discriminative learning technique for label sequences based on a combination of the two most successful learning algorithms, Support Vector Machines and Hidden Markov Models which we call Hidden Markov Support Vector Machine. The proposed architecture handles dependencies between neighboring labels using Viterbi decoding. In contrast to standard HMM training, the learning procedure is discriminative and is based on a maximum/soft margin criterion. Compared to previous methods like Conditional Random Fields, Maximum Entropy Markov Models and label sequence boosting, HM-SVMs have a number of advantages. Most notably, it is possible to learn non-linear discriminant functions via kernel functions. At the same time, HM-SVMs share the key advantages with other discriminative methods, in particular the capability to deal with overlapping features. We report experimental evaluations on two tasks, named entity recognition and part-of-speech tagging, that demonstrate the competitiveness of the proposed approach.},
  comment   = {structured SVM},
  file      = {:FILES/2003 - Altun2003 - Hidden Markov Support Vector Machines.pdf:PDF},
  groups    = {SVM},
  url       = {https://www.aaai.org/Library/ICML/2003/icml03-004.php},
}

@InProceedings{Filice2015,
  author    = {Simone Filice and Giuseppe Castellucci and Danilo Croce and Roberto Basili},
  booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACL)},
  title     = {{KeLP}: {A} kernel-basedlearning platform for natural language processing},
  year      = {2015},
  address   = {Beijing, China},
  pages     = {19--24},
  publisher = {The Association for Computer Linguistics},
  comment   = {implementation of structured SVM},
  file      = {:FILES/2015 - Filice2015 - KeLP- a Kernel-based Learning Platform for Natural Language Processing.pdf:PDF},
  groups    = {SVM},
  url       = {https://dblp.org/rec/conf/acl/FiliceCCB15.html},
}

@InProceedings{MacMahon2006,
  author    = {Matt {MacMahon} and Brian Stankiewicz and Benjamin Kuipers},
  booktitle = {Proceedings of the 21st AAAI Conference on Artificial Intelligence},
  title     = {Walk the talk: {Connecting} language, knowledge, and action in route instructions},
  year      = {2006},
  address   = {Boston, Massachusetts, USA},
  month     = jul,
  pages     = {1475--1482},
  publisher = {AAAI Press},
  comment   = {Perera2015: use NL for navigation
Whitney2016: batch interpretation
Boularias2015： following verbal route instructions
Hemachandra2015： interpret natural language expressions that provide route direction, learn a parser 以把NL instr映射为plan
Howard2014a: NL in route direction following
Hemachandra2014:Mapping NL to the corresponding referents in the robot’s world model
Walter2013:Symbol grounding problem is in the context of following NL commands
Kollar2010:represented a clause in a set of directions as a compound action consisting of a simple action (move, turn, verify, and declaregoal), plus a set of pre- and post-conditions. 本文的local search algorithm借鉴了该文献. 比SDC more expressive,但难以从NL中自动抽取信息
Duvallet2016: Natural language has proven to be effective for commanding robots to follow route directions. used a parser that maps language directly to plans.没有利用NL instruction中包含的信息来reason uncertainty and infer environment representation.
{Anderson2018}：operating in visually restricted environments requiring limited perception},
  file      = {:FILES/2006 - MacMahon2006 - Walk the Talk- Connecting Language, Knowledge, and Action in Route Instructions.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.aaai.org/Library/AAAI/2006/aaai06-232.php},
}

@InProceedings{Marge2010,
  author    = {Marge, Matthew and Rudnicky, Alexander I.},
  booktitle = {Proceedings of the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)},
  title     = {Comparing spoken language route instructions for robots across environment representations},
  year      = {2010},
  address   = {Tokyo, Japan},
  month     = sep,
  pages     = {157--164},
  publisher = {Association for Computational Linguistics},
  abstract  = {Spoken language interaction between humans and robots in natural environments will necessarily involve communication about space and distance. The current study examines people's close-range route instructions for robots and how the presentation format (schematic, virtual or natural) and the complexity of the route affect the content of instructions. We find that people have a general preference for providing metric-based instructions. At the same time, presentation format appears to have less impact on the formulation of these instructions. We conclude that understanding of spatial language requires handling both landmark-based and metric-based expressions.},
  comment   = {Perera2015: use NL for navigation},
  file      = {:FILES/2010 - Marge2010 - Comparing spoken language route instructions for robots across environment representations.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781932432855},
  url       = {https://dl.acm.org/doi/abs/10.5555/1944506.1944534},
}

@InProceedings{Zuo2010,
  author    = {Zuo, Xiang and Iwahashi, Naoto and Taguchi, Ryo and Funakoshi, Kotaro and Nakano, Mikio and Matsuda, Shigeki and Sugiura, Komei and Oka, Natsuki},
  booktitle = {Proceedings of the 19th International Symposium in Robot and Human Interactive Communication (RO-MAN)},
  title     = {Detecting robot-directed speech by situated understanding in object manipulation tasks},
  year      = {2010},
  address   = {Viareggio, Italy},
  month     = sep,
  pages     = {608--613},
  publisher = {IEEE},
  abstract  = {In this paper, we propose a novel method for a robot to detect robot-directed speech, that is, to distinguish speech that users speak to a robot from speech that users speak to other people or to themselves. The originality of this work is the introduction of a multimodal semantic confidence (MSC) measure, which is used for domain classification of input speech based on the decision on whether the speech can be interpreted as a feasible action under the current physical situation in an object manipulation task. This measure is calculated by integrating speech, object, and motion confidence with weightings that are optimized by logistic regression. Then we integrate this measure with gaze tracking and conduct experiments under conditions of natural human-robot interaction. Experimental results show that the proposed method achieves a high performance of 94% and 96% in average recall and precision rates, respectively, for robot-directed speech detection.},
  comment   = {Perera2015: NL for manipulating objects},
  doi       = {10.1109/ROMAN.2010.5598729},
  file      = {:FILES/2010 - Zuo2010 - Detecting robot-directed speech by situated understanding in object manipulation tasks.pdf:PDF},
  groups    = {task understanding},
  issn      = {1944-9437},
  url       = {https://ieeexplore.ieee.org/abstract/document/5598729},
}

@Article{Biswas2013,
  author   = {Joydeep Biswas and Manuela M. Veloso},
  journal  = {The International Journal of Robotics Research},
  title    = {Localization and navigation of the {CoBots} over long-term deployments},
  year     = {2013},
  month    = nov,
  number   = {14},
  pages    = {1679--1694},
  volume   = {32},
  abstract = {For the last three years, we have developed and researched multiple collaborative robots, CoBots, which have been autonomously traversing our multi-floor buildings. We pursue the goal of long-term autonomy for indoor service mobile robots as the ability for them to be deployed indefinitely while they perform tasks in an evolving environment. The CoBots include several levels of autonomy, and in this paper we focus on their localization and navigation algorithms. We present the Corrective Gradient Refinement (CGR) algorithm, which refines the proposal distribution of the particle filter used for localization with sensor observations using analytically computed state space derivatives on a vector map. We also present the Fast Sampling Plane Filtering algorithm that extracts planar regions from depth images in real time. These planar regions are then projected onto the 2D vector map of the building, and along with the laser rangefinder observations, used with CGR for localization. For navigation, we present a hierarchical planner, which computes a topological policy using a graph representation of the environment, computes motion commands based on the topological policy, and then modifies the motion commands to side-step perceived obstacles. We started logging the deployments of the CoBots one and a half years ago, and have since collected logs of the CoBots traversing more than 130 km over 1082 deployments and a total run time of 182 h, which we publish as a dataset consisting of more than 10 million laser scans. The logs show that although there have been continuous changes in the environment, the robots are robust to most of them, and there exist only a few locations where changes in the environment cause increased uncertainty in localization.},
  comment  = {Perera2015: in an office-like environment for prolonged periods of time,},
  doi      = {10.1177/0278364913503892},
  file     = {:FILES/2013 - Biswas2013 - Localization and navigation of the CoBots over long-term deployments.pdf:PDF},
  groups   = {task understanding},
  url      = {https://journals.sagepub.com/doi/abs/10.1177/0278364913503892},
}

@Article{Ghidary2002,
  author     = {Ghidary, Saeed Shiry and Nakata, Yasushi and Saito, Hiroshi and Hattori, Motofumi and Takamori, Toshi},
  journal    = {Autonomous Robots},
  title      = {Multi-modal interaction of human and home robot in the context of room map generation},
  year       = {2002},
  issn       = {1573-7527},
  month      = sep,
  number     = {2},
  pages      = {169--184},
  volume     = {13},
  abstract   = {In robotics, the idea of human and robot interaction is receiving a lot of attention lately. In this paper, we describe a multi-modal system for generating a map of the environment through interaction of a human and home robot. This system enables people to teach a newcomer robot different attributes of objects and places in the room through speech commands and hand gestures. The robot learns about size, position, and topological relations between objects, and produces a map of the room based on knowledge learned through communication with the human. The developed system consists of several sections including: natural language processing, posture recognition, object localization and map generation. This system combines multiple sources of information and model matching to detect and track a human hand so that the user can point toward an object of interest and guide the robot to either go near it or to locate that object's position in the room. The positions of objects in the room are located by monocular camera vision and depth from focus method.},
  comment    = {Perera2015: NL for mapping in unknown env

本文是{Ghidary2001}的增强版本。
1. NLP主要用来generate map of environment. 是有监督学习，学习的内容是names + size of places and objects, spatial rel between any two in the env. 
2. 定义了common language, with predefined interaction patterns, 包括4种，即 introducing new object or places, guiding the robot in free space, making requests from the root, and error feedback.
3. 并没有具体说明command的计算机或机器人表示、NL parsing method等细节问题。},
  doi        = {10.1023/A:1019689509522},
  file       = {:FILES/2002 - Ghidary2002 - Multi-Modal Interaction of Human and Home Robot in the Context of Room Map Generation.pdf:PDF},
  groups     = {task understanding},
  readstatus = {read},
  refid      = {Ghidary2002},
  url        = {https://link.springer.com/article/10.1023/A:1019689509522},
}

@InProceedings{Marneffe2006,
  author    = {de Marneffe, Marie-Catherine and {MacCartney}, Bill and Manning, Christopher D.},
  booktitle = {Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC)},
  title     = {Generating typed dependency parses from phrase structure parses},
  year      = {2006},
  address   = {Genoa, Italy},
  month     = may,
  pages     = {449--454},
  publisher = {European Language Resources Association (ELRA)},
  abstract  = {This paper describes a system for extracting typed dependency parses of English sentences from phrase structure parses. In order to capture inherent relations occurring in corpus texts that can be critical in real-world applications, many NP relations are included in the set of grammatical relations used. We provide a comparison of our system with Minipar and the Link parser. The typed dependency extraction facility described here is integrated in the Stanford Parser, available for download.},
  comment   = {typed dependency parsing},
  groups    = {dependency parsing},
  url       = {https://www.aclweb.org/anthology/L06-1260/},
}

@Article{Burgard1999,
  author     = {Wolfram Burgard and Armin B. Cremers and Dieter Fox and Dirk Hähnel and Gerhard Lakemeyer and Dirk Schulz and Walter Steiner and Sebastian Thrun},
  journal    = {Artificial Intelligence},
  title      = {Experiences with an interactive museum tour-guide robot},
  year       = {1999},
  issn       = {0004-3702},
  month      = oct,
  number     = {1},
  pages      = {3--55},
  volume     = {114},
  abstract   = {This article describes the software architecture of an autonomous, interactive tour-guide robot. It presents a modular and distributed software architecture, which integrates localization, mapping, collision avoidance, planning, and various modules concerned with user interaction and Web-based telepresence. At its heart, the software approach relies on probabilistic computation, on-line learning, and any-time algorithms. It enables robots to operate safely, reliably, and at high speeds in highly dynamic environments, and does not require any modifications of the environment to aid the robot's operation. Special emphasis is placed on the design of interactive capabilities that appeal to people's intuition. The interface provides new means for human-robot interaction with crowds of people in public places, and it also provides people all around the world with the ability to establish a “virtual telepresence” using the Web. To illustrate our approach, results are reported obtained in mid-1997, when our robot “RHINO” was deployed for a period of six days in a densely populated museum. The empirical results demonstrate reliable operation in public environments. The robot successfully raised the museum's attendance by more than 50%. In addition, thousands of people all over the world controlled the robot through the Web. We conjecture that these innovations transcend to a much larger range of application domains for service robots.},
  comment    = {提出了一种autonomous interactive tour-guide robot的软件架构，可以实现localization, mapping, collision avoidance, planning, UI, and web-based telepresence  in highly dynamic environments.本文并没有利用NL来实现人机交互,而是按照预定方案完成展点间的导览,人机交互是通过图形界面的按钮(选项)来实现的.

文中说明了museum环境的复杂性,以及所遇到的挑战,能实现的功能是navigate and play explanation.

动作的中间表示:Programs (and plans) in GOLOG are sequences of elemental actions expressed in a logical language using if-then-else rules and recursive procedures.},
  doi        = {10.1016/S0004-3702(99)00070-3},
  file       = {:FILES/1999 - Burgard1999 - Experiences with an interactive museum tour-guide robot.pdf:PDF},
  groups     = {task understanding, robot},
  keywords   = {Mobile robotics, Probabilistic reasoning, Localization, Mapping, Planning, Collision avoidance, Logic, Human robot interaction, Machine learning, Entertainment, read},
  readstatus = {read},
  url        = {https://www.sciencedirect.com/science/article/pii/S0004370299000703},
}

@InProceedings{Liu2014,
  author     = {Liu, Rui and Zhang, Xiaoli and Li, Songpo},
  booktitle  = {Proceedings of the 2014 IEEE International Conference on Mechatronics and Automation (ICMA)},
  title      = {Use context to understand user's implicit intentions in activities of daily living},
  year       = {2014},
  address    = {Tianjin, China},
  month      = aug,
  pages      = {1214--1219},
  publisher  = {IEEE},
  abstract   = {For an assistive robot, accurately understanding the user's intention with minimal user involvement is critical in human-robot interaction. Especially for the elderly in their Activities of Daily Living (ADL), implicit intention recognition using subtle cues could provide them great convenience as well as improving quality of life. Usually user intentions in ADL are closely connected with specific context. For example, the user's intention for a cup on a hot day is likely to be drinking. Therefore, the relation between intention and context should be emphasized. The goal of our research is to effectively infer implicit human intention using the object that the user attends to and its subtle context. The context helps to filter the coarse intentions. Towards this goal, a new context-specific implicit intention recognition (IR) model has been established based on a Bayesian Network (BN) algorithm. Using set of questionnaires, the strongly intention-related context features have been selected and their conditional values for different intentions have been calculated. Then another set of questionnaires were used to verify the model's effectiveness. The results showed the BN based context-specific implicit IR model could help the robot to proactively get a good understanding of a user's implicit intentions with merely subtle context cues.},
  comment    = {Liu2016d:NL instructions for industrial tasks. NL instructions are incomplete，未说明sweep的工具等??(本文未涉及这部分内容，没有涉及NL instruction)

本文是将context features融入intention recognition的早期工作，主要实现了利用context information来进行推理，从而判定human intention，所利用的数据是调查问卷，而没有用到语言、动作等，情境比较单一，不具备泛化能力。
user可以发出的指令是concise and ambiguous，形式可以为vocabulary, a nod or even a gaze to indicate the intention related object.
需要对context feature进行选择，主要过程如下：
1.利用Bayesian network model来描述features 与 intention之间的关系，即context-specific implicit IR model.
2.模型训练是利用问卷调查，two objects (cup + window) in office and home env. Affordance是人为定义的，如cup -- {drink, wash, transfer}等，feature是{hot day, low drinking frequency, cup was used, near sink, in cabinet, medicine taken time}等，利用fuzzy words来描述各特征，并进一步将这些words与real-valued possibility相关联。},
  doi        = {10.1109/ICMA.2014.6885872},
  file       = {:FILES/2014 - Liu2014 - Use context to understand user's implicit intentions in Activities of Daily Living.pdf:PDF;:FILES/notes/Liu2014.docx:Word 2007+},
  groups     = {task understanding},
  issn       = {2152-744X},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/6885872},
}

@Article{Baur2015,
  author    = {Baur, Tobias and Mehlmann, Gregor and Damian, Ionut and Lingenfelser, Florian and Wagner, Johannes and Lugrin, Birgit and Andr\'{e}, Elisabeth and Gebhard, Patrick},
  journal   = {ACM Transactions on Interactive Intelligent Systems},
  title     = {Context-aware automated analysis and annotation of social human--agent interactions},
  year      = {2015},
  issn      = {2160-6455},
  month     = jun,
  number    = {2},
  pages     = {11},
  volume    = {5},
  abstract  = {The outcome of interpersonal interactions depends not only on the contents that we communicate verbally, but also on nonverbal social signals. Because a lack of social skills is a common problem for a significant number of people, serious games and other training environments have recently become the focus of research. In this work, we present NovA (Nonverbal behavior Analyzer), a system that analyzes and facilitates the interpretation of social signals automatically in a bidirectional interaction with a conversational agent. It records data of interactions, detects relevant social cues, and creates descriptive statistics for the recorded data with respect to the agent's behavior and the context of the situation. This enhances the possibilities for researchers to automatically label corpora of human--agent interactions and to give users feedback on strengths and weaknesses of their social behavior.},
  comment   = {Liu2016d: facial expression},
  doi       = {10.1145/2764921},
  file      = {:FILES/2015 - Baur2015 - Context-Aware Automated Analysis and Annotation of Social Human--Agent Interactions.pdf:PDF},
  groups    = {from visual},
  keywords  = {virtual job interviews, serious games, Social cue recognition, interaction design, automated behavior analysis},
  publisher = {Association for Computing Machinery},
  url       = {https://dl.acm.org/doi/abs/10.1145/2764921},
}

@InProceedings{Nikolaidis2015,
  author    = {Nikolaidis, Stefanos and Ramakrishnan, Ramya and Gu, Keren and Shah, Julie},
  booktitle = {Proceeding of the 2015 10th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  title     = {Efficient model learning from joint-action demonstrations for human-robot collaborative tasks},
  year      = {2015},
  address   = {Portland, OR, USA},
  month     = mar,
  pages     = {189--196},
  publisher = {IEEE},
  abstract  = {We present a framework for automatically learning human user models from joint-action demonstrations that enables a robot to compute a robust policy for a collaborative task with a human. First, the demonstrated action sequences are clustered into different human types using an unsupervised learning algorithm. A reward function is then learned for each type through the employment of an inverse reinforcement learning algorithm. The learned model is then incorporated into a mixed-observability Markov decision process (MOMDP) formulation, wherein the human type is a partially observable variable. With this framework, we can infer online the human type of a new user that was not included in the training set, and can compute a policy for the robot that will be aligned to the preference of this user. In a human subject experiment (n=30), participants agreed more strongly that the robot anticipated their actions when working with a robot incorporating the proposed framework (p<;0.01), compared to manually annotating robot actions. In trials where participants faced difficulty annotating the robot actions to complete the task, the proposed framework significantly improved team efficiency (p <;0.01). The robot incorporating the framework was also found to be more responsive to human actions compared to policies computed using a hand-coded reward function by a domain expert (p<;0.01). These results indicate that learning human user models from joint-action demonstrations and encoding them in a MOMDP formalism can support effective teaming in human-robot collaborative tasks.},
  comment   = {Liu2016d: use action sequence to generate robot commands, need experts to use},
  file      = {:FILES/2015 - Nikolaidis2015 - Efficient Model Learning from Joint-Action Demonstrations for Human-Robot Collaborative Tasks.pdf:PDF},
  groups    = {from kinematics},
  issn      = {2167-2121},
  url       = {https://ieeexplore.ieee.org/abstract/document/8520627},
}

@InProceedings{Akgun2012,
  author    = {Akgun, Baris and Cakmak, Maya and Yoo, Jae Wook and Thomaz, Andrea Lockerd},
  booktitle = {Proceedings of the 7th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  title     = {Trajectories and keyframes for kinesthetic teaching: {A} human-robot interaction perspective},
  year      = {2012},
  address   = {New York, NY, USA},
  month     = mar,
  pages     = {391--398},
  publisher = {Association for Computing Machinery},
  abstract  = {Kinesthetic teaching is an approach to providing demonstrations to a robot in Learning from Demonstration whereby a human physically guides a robot to perform a skill. In the common usage of kinesthetic teaching, the robot's trajectory during a demonstration is recorded from start to end. In this paper we consider an alternative, keyframe demonstrations, in which the human provides a sparse set of consecutive keyframes that can be connected to perform the skill. We present a user-study (n=34) comparing the two approaches and highlighting their complementary nature. The study also tests and shows the potential benefits of iterative and adaptive versions of keyframe demonstrations. Finally, we introduce a hybrid method that combines trajectories and keyframes in a single demonstration.},
  comment   = {Liu2016d: use action trajectory to generate robot commands,  Only some simple information patterns are defined, insufficiently describing task-related knowledge such as task procedures and human special requirements},
  doi       = {10.1145/2157689.2157815},
  file      = {:FILES/2012 - Akgun2012 - Trajectories and Keyframes for Kinesthetic Teaching- A Human-Robot Interaction Perspective.pdf:PDF},
  groups    = {from kinematics},
  isbn      = {9781450310635},
  keywords  = {learning from demonstration},
  location  = {Boston, Massachusetts, USA},
  url       = {https://dl.acm.org/doi/10.1145/2157689.2157815},
}

@Article{Wang2013,
  author   = {Zhikun Wang and Katharina M\"{u}lling and Marc Peter Deisenroth and Heni Ben Amor and David Vogt and Bernhard Sch\"{o}lkopf and Jan Peters},
  journal  = {The International Journal of Robotics Research},
  title    = {Probabilistic movement modeling for intention inference in human–robot interaction},
  year     = {2013},
  month    = apr,
  number   = {7},
  pages    = {841--858},
  volume   = {32},
  abstract = {Intention inference can be an essential step toward efficient human–robot interaction. For this purpose, we propose the Intention-Driven Dynamics Model (IDDM) to probabilistically model the generative process of movements that are directed by the intention. The IDDM allows the intention to be inferred from observed movements using Bayes’ theorem. The IDDM simultaneously finds a latent state representation of noisy and high-dimensional observations, and models the intention-driven dynamics in the latent states. As most robotics applications are subject to real-time constraints, we develop an efficient online algorithm that allows for real-time intention inference. Two human–robot interaction scenarios, i.e. target prediction for robot table tennis and action recognition for interactive humanoid robots, are used to evaluate the performance of our inference algorithm. In both intention inference tasks, the proposed algorithm achieves substantial improvements over support vector machines and Gaussian processes.},
  comment  = {Liu2016d: use movement dynamics to generate robot commands,these methods are procedure-complex and time-consuming. Their clue patterns need to be defined for encoding and decoding the task-related information embedded in human instructions},
  doi      = {10.1177/0278364913478447},
  file     = {:FILES/2013 - Wang2013 - Probabilistic movement modeling for intention inference in human–robot interaction.pdf:PDF},
  groups   = {from kinematics},
  url      = {https://journals.sagepub.com/doi/abs/10.1177/0278364913478447},
}

@InProceedings{Kulic2005,
  author    = {Kuli\'{c}, Dana and Croft, Elizabeth},
  booktitle = {Proceedings of the 2005 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Anxiety detection during human-robot interaction},
  year      = {2005},
  address   = {Edmonton, AB, Canada},
  month     = aug,
  pages     = {616--621},
  publisher = {IEEE},
  abstract  = {This paper describes an experiment to determine the feasibility of using physiological signals to determine the human response to robot motions during direct human-robot interaction. A robot manipulator is used to generate common interaction motions, and human subjects are asked to report their response to the motions. The human physiological response is also measured. Motion paths are generated using a classic potential field planner and a safe motion planner, which minimizes the potential collision force along the path. A fuzzy inference engine is developed to estimate the human response based on the physiological measures. Results show that emotional arousal can be detected using physiological signals and the inference engine. Comparison of initial results between the two planners shows that subjects report less anxiety and surprise with the safe planner for high planner speeds.},
  comment   = {Liu2016d: use heart rate to generate robot commands},
  doi       = {10.1109/IROS.2005.1545012},
  file      = {:FILES/2005 - Kulic2005 - Anxiety detection during human-robot interaction.pdf:PDF},
  groups    = {from bio signal},
  issn      = {2153-0866},
}

@Article{Esfahani2011,
  author   = {Esfahani, Ehsan Tarkesh and Sundararajan, V.},
  journal  = {International Journal of Humanoid Robotics},
  title    = {Using brain-computer interfaces to detect human satisfaction in human-robot interaction},
  year     = {2011},
  number   = {01},
  pages    = {87--101},
  volume   = {08},
  abstract = {This article discusses the use of a brain–computer interface (BCI) to obtain emotional feedback from a human in response to the motion of humanoid robots in collaborative environments. The purpose of this study is to detect the human satisfaction level and use it as a feedback for correcting and improving the behavior of the robot to maximize human satisfaction. This article describes experiments and algorithms that use human brains activity collected through BCI in order to estimate the level of satisfaction. Users wear an electroencephalogram (EEG) headset and control the movement of the robot by mental imagination. The robots responds to the mental imagination may not be the same as human mental command and this will affect the emotional satisfaction level. The headset records brain activity from 14 locations on the scalp. Power spectral density of each EEG frequency band and four largest Lyapunov exponents of each EEG signal form the feature vector. The Mann–Whitney–Wilcoxon test is then used to rank all the features. The highest rank features are then selected to train a linear discriminant classifier (LDC) to determine the satisfaction level. Our experimental results show an accuracy of 79.2\% in detecting the human satisfaction level.},
  comment  = {Liu2016d: use electroencephalogram (EEG) pattern to generate robot commands},
  doi      = {10.1142/S0219843611002356},
  file     = {:FILES/2011 - Esfahani2011 - USING BRAIN–COMPUTER INTERFACES TO DETECT HUMAN SATISFACTION IN HUMAN–ROBOT INTERACTION.pdf:PDF},
  groups   = {from bio signal},
  url      = {https://www.worldscientific.com/doi/abs/10.1142/s0219843611002356},
}

@InProceedings{Boularias2015,
  author     = {Boularias, Abdeslam and Duvallet, Felix and Oh, Jean and Stentz, Anthony},
  booktitle  = {Proceedings of the 2015 IEEE International Conference on Robotics and Automation (ICRA)},
  title      = {Grounding spatial relations for outdoor robot navigation},
  year       = {2015},
  address    = {Seattle, WA, USA},
  month      = may,
  pages      = {1976--1982},
  publisher  = {IEEE},
  abstract   = {We propose a language-driven navigation approach for commanding mobile robots in outdoor environments. We consider unknown environments that contain previously unseen objects. The proposed approach aims at making interactions in human-robot teams natural. Robots receive from human teammates commands in natural language, such as “Navigate around the building to the car left of the fire hydrant and near the tree”. A robot needs first to classify its surrounding objects into categories, using images obtained from its sensors. The result of this classification is a map of the environment, where each object is given a list of semantic labels, such as “tree” and “car”, with varying degrees of confidence. Then, the robot needs to ground the nouns in the command. Grounding, the main focus of this paper, is mapping each noun in the command into a physical object in the environment. We use a probabilistic model for interpreting the spatial relations, such as “left of” and “near”. The model is learned from examples provided by humans. For each noun in the command, a distribution on the objects in the environment is computed by combining spatial constraints with a prior given as the semantic classifier's confidence values. The robot needs also to ground the navigation mode specified in the command, such as “navigate quickly” and “navigate covertly”, as a cost map. The cost map is also learned from examples, using Inverse Optimal Control (IOC). The cost map and the grounded goal are used to generate a path for the robot. This approach is evaluated on a robot in a real-world environment. Our experiments clearly show that the proposed approach is efficient for commanding outdoor robots.},
  comment    = {Liu2016d: grounding objects via NL words. Backus-Naur Form (BNF) for representing task

本文解决的是在unknown, semi-structured outdoor env 中language driven navigation，可以对指令中的fuzzy words, spatial relations进行qualitative and quantitative analysis, such as near, quickly, etc, probabilistic approach. Only for navigation mode and spatial relation. 基于imitation learning的path planning，


1.输入虽然是NL，但转化为Tactical Behavior Specifification (TBS, based on the grammar of BNF) , with the spatial relation recognized
2.Perception using 2D camera 并对图像分割得到image of objects
3.Grounding navigation model: 从NL instruction中识别mode，再利用imitation learning得到其cost function的weight（事先），而后生成path.
4.Grounding objects: 利用log-linear model来描述两个object满足给定的spatial relation，其中的feature vector is the spatial features of the objects from the robot’s perspective, i.e., (两个物体质心距离、其质心坐标、质心到原点的夹角正弦余弦值). 需利用给定数据集来学习model parameters.在利用Bayes’ rule等计算各entity in NL mapping to objects的概率 

5.learning cost functions for different navigation modes
6.take into account label uncertainty and path cost in grounding
7.Spatial relation是二元关系，如left, right, front, behind, near, away等，所以只涉及two objects.当句子中存在多个entities时，需要选出两个相关的，若不足怎么办？文章没有讲
8. 只考虑了动词和名词，other constraints 的考虑好像没有，如walk to the left of the building away from car中的away from 


1.Goal: landmark objects
2.Navigation mode: the path constraints with landmark objects. Subjective and explicitly written
3.Understanding spatial language: from NL description to cost function based on cost map. The cost function is linear combination of features: The features describe the shape of the path, the
4.geometry of the landmark, and the relationship between the two. 其中各feature的weight由imitation learning（凸优化，2-norm+max reg）得到。
5.Path planning: given navigation mode, the path is determined by find the minimum cost path under cost function},
  doi        = {10.1109/ICRA.2015.7139457},
  file       = {:FILES/2015 - Boularias2015 - Grounding spatial relations for outdoor robot navigation.pdf:PDF},
  groups     = {task understanding},
  issn       = {1050-4729},
  printed    = {Y},
  priority   = {prio2},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/7139457},
}

@InProceedings{Manning2014,
  author    = {Manning, Christopher and Surdeanu, Mihai and Bauer, John and Finkel, Jenny and Bethard, Steven and McClosky, David},
  booktitle = {Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics (ACL)},
  title     = {The {Stanford} {CoreNLP} natural language processing toolkit},
  year      = {2014},
  address   = {Baltimore, Maryland},
  month     = jun,
  pages     = {55--60},
  publisher = {Association for Computational Linguistics},
  comment   = {Stanford CoreNLP},
  doi       = {10.3115/v1/P14-5010},
  file      = {:FILES/2014 - Manning2014 - The {Stanford} {CoreNLP} natural language processing toolkit.pdf:PDF},
  groups    = {softwares},
  url       = {https://www.aclweb.org/anthology/P14-5010},
}

@Misc{Zhang2017b,
  author  = {Zhang, Anthony},
  title   = {Speech recognition (version 3.8)},
  year    = {2017},
  comment = {Speech Recognition tool},
  groups  = {softwares},
  url     = {https://github.com/Uberi/speech_recognition#readme},
}

@Misc{Mtuk,
  title    = {{Amazon Mechanical Turk}},
  year     = {2021},
  abstract = {Amazon Mechanical Turk (MTurk) is a crowdsourcing marketplace that makes it easier for individuals and businesses to outsource their processes and jobs to a distributed workforce who can perform these tasks virtually.},
  comment  = {TU常用来收集对任务等的描述，如{Whitney2016,allrecipes}},
  groups   = {softwares},
  url      = {https://www.mturk.com/},
}

@Misc{allrecipes,
  title   = {allrecipes},
  year    = {2021},
  comment = {websites with recipes used in {Whitney2016}},
  groups  = {softwares},
  url     = {http://www.allrecipes.com},
}

@Misc{HTML5SR,
  title   = {HTML5 Speech Recognition package in conjunctionwith Google Chrome},
  year    = {2021},
  comment = {{Whitney2016}: used for SR},
  groups  = {softwares},
  url     = {https://github.com/ranacseruet/webspeech},
}

@InProceedings{Kennington2015,
  author    = {Kennington, Casey and Schlangen, David},
  booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing},
  title     = {Simple learning and compositional application of perceptually grounded word meanings for incremental reference resolution},
  year      = {2015},
  address   = {Beijing, China},
  month     = jul,
  pages     = {292--301},
  publisher = {Association for Computational Linguistics},
  comment   = {Whitney2016: 提出一种discriminative model of incremental reference resolution based on logistic regression，缺点在于需要data collection and hand-crafting features},
  doi       = {10.3115/v1/P15-1029},
  file      = {:FILES/2015 - Kennington2015 - Simple Learning and Compositional Application of Perceptually Grounded Word Meanings for Incremental Reference Resolution.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.aclweb.org/anthology/P15-1029},
}

@InProceedings{Funakoshi2012,
  author    = {Funakoshi, Kotaro and Nakano, Mikio and Tokunaga, Takenobu and Iida, Ryu},
  booktitle = {Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)},
  title     = {A unified probabilistic approach to referring expressions},
  year      = {2012},
  address   = {Seoul, South Korea},
  month     = jul,
  pages     = {237--246},
  publisher = {Association for Computational Linguistics},
  comment   = {Whitney2016: use Bayesian network for reference resolution,可以用于多个domain' words,单模态},
  file      = {:FILES/2012 - Funakoshi2012 - A Unified Probabilistic Approach to Referring Expressions.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.aclweb.org/anthology/W12-1633},
}

@InProceedings{Foster2012,
  author    = {Foster, Mary Ellen and Gaschler, Andre and Giuliani, Manuel and Isard, Amy and Pateraki, Maria and Petrick, Ronald P. A.},
  booktitle = {Proceedings of the 14th ACM International Conference on Multimodal Interaction (ICMI)},
  title     = {Two people walk into a bar: {Dynamic} multi-party social interaction with a robot agent},
  year      = {2012},
  address   = {New York, NY, USA},
  month     = oct,
  pages     = {3--10},
  publisher = {Association for Computing Machinery},
  abstract  = {We introduce a humanoid robot bartender that is capable of dealing with multiple customers in a dynamic, multi-party social setting. The robot system incorporates state-of-the-art components for computer vision, linguistic processing, state management, high-level reasoning, and robot control. In a user evaluation, 31 participants interacted with the bartender in a range of social situations. Most customers successfully obtained a drink from the bartender in all scenarios, and the factors that had the greatest impact on subjective satisfaction were task success and dialogue efficiency.},
  comment   = {Whitney2016：robot bar-tender serves drinks based on speech and torso position},
  doi       = {10.1145/2388676.2388680},
  file      = {:FILES/2012 - Foster2012 - Two People Walk into a Bar- Dynamic Multi-Party Social Interaction with a Robot Agent.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781450314671},
  keywords  = {multi-party interaction, social robotics},
  url       = {https://dl.acm.org/doi/10.1145/2388676.2388680},
}

@InProceedings{Bohus2014,
  author    = {Bohus, Dan and Horvitz, Eric},
  booktitle = {Proceedings of the 16th International Conference on Multimodal Interaction (ICMI)},
  title     = {Managing human-robot engagement with forecasts and... Um... hesitations},
  year      = {2014},
  address   = {New York, NY, USA},
  month     = nov,
  pages     = {2--9},
  publisher = {Association for Computing Machinery},
  abstract  = {We explore methods for managing conversational engagement in open-world, physically situated dialog systems. We investigate a self-supervised methodology for constructing forecasting models that aim to anticipate when participants are about to terminate their interactions with a situated system. We study how these models can be leveraged to guide a disengagement policy that uses linguistic hesitation actions, such as filled and non-filled pauses, when uncertainty about the continuation of engagement arises. The hesitations allow for additional time for sensing and inference, and convey the system's uncertainty. We report results from a study of the proposed approach with a directions-giving robot deployed in the wild.},
  comment   = {Whitney2016: direct humans searching for romms in a building with prior knowledge about the location of rooms. With head direction and speech.},
  doi       = {10.1145/2663204.2663241},
  file      = {:FILES/2014 - Bohus2014 - Managing Human-Robot Engagement with Forecasts and... Um... Hesitations.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781450328852},
  keywords  = {hesitation actions, forecasting models, filled pauses, self-supervision, multimodal interaction, engagement, human-robot interaction},
  location  = {Istanbul, Turkey},
  numpages  = {8},
  url       = {https://dl.acm.org/doi/10.1145/2663204.2663241},
}

@InProceedings{Matuszek2014,
  author    = {Cynthia Matuszek and Liefeng Bo and Luke Zettlemoyer and Dieter Fox},
  booktitle = {Proceedings of the 28th AAAI Conference on Artificial Intelligence},
  title     = {Learning from unscripted deictic gesture and language for human-robot interactions},
  year      = {2014},
  address   = {Qu\'{e}bec, Canada},
  month     = jul,
  pages     = {2556--2563},
  publisher = {AAAI Press},
  abstract  = {Whitney2016: use gesture and language to resolve references to tabletop objects. person is close to the objects.},
  comment   = {Howard2014a: NL in object manipulation},
  file      = {:FILES/2014 - Matuszek2014 - Learning from Unscripted Deictic Gesture and Language for Human-Robot Interactions.pdf:PDF},
  groups    = {task understanding},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/9051},
}

@InCollection{MacMillan2004,
  author    = {{MacMillan}, Jean and Entin, Elliot E. and Serfaty, Daniel},
  booktitle = {Team cognition: {Understanding} the factors that drive process and performance},
  publisher = {American Psychological Association},
  title     = {Communication overhead: {The} hidden cost of team cognition},
  year      = {2004},
  address   = {Washington, DC, US},
  editor    = {Eduardo Salas and Stephen M. Fiore},
  pages     = {61--82},
  abstract  = {To function effectively, a team must act as an information-processing unit, maintaining an awareness of the situation or context in which it is functioning and acquiring and using information to act in that situation. This team cognition differs from individual cognition, of course, because each team member acts as an individual information processor. For a team to act in concert to achieve common goals, the team must have shared information about both the situation and the other team members. Team cognition thus requires communication-a process that has no direct analog in individual cognition-in order for the team to build and maintain a shared mental model of the situation. Because communication is essential to team performance, effective team cognition has a communication "overhead" associated with the exchange of information among team members. Communication requires both time and cognitive resources, and, to the extent that communication can be made less necessary or more efficient, team performance can benefit as a result. In this chapter we present a theoretical framework that describes the relationship between team communication behaviors and team performance. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  comment   = {Whitney2016: Cognitive science experiments have shown that highly successful teams rarely make explicit requests from one another and instead infer correct actions as needs arise},
  doi       = {10.1037/10690-004},
  groups    = {interesting articles},
  issn      = {1-59147-103-6 (Hardcover)},
  journal   = {Team cognition: Understanding the factors that drive process and performance.},
  keywords  = {Cognitions, Communication, Group Performance, Teams},
  refid     = {2004-00226-004},
  url       = {https://psycnet.apa.org/record/2004-00226-004},
}

@Article{Clark2004,
  author   = {Herbert H. Clark and Meredyth A. Krych},
  journal  = {Journal of Memory and Language},
  title    = {Speaking while monitoring addressees for understanding},
  year     = {2004},
  issn     = {0749-596X},
  month    = jan,
  number   = {1},
  pages    = {62--81},
  volume   = {50},
  abstract = {Speakers monitor their own speech and, when they discover problems, make repairs. In the proposal examined here, speakers also monitor addressees for understanding and, when necessary, alter their utterances in progress. Addressees cooperate by displaying and signaling their understanding in progress. Pairs of participants were videotaped as a director instructed a builder in assembling 10 Lego models. In one group, directors could see the builders’ workspace; in a second, they could not; in a third, they gave instructions by audiotape. Two partners were much slower when directors could not see the builders’ workspace, and they made many more errors when the instructions were audiotaped. When their workspace was visible, builders communicated with directors by exhibiting, poising, pointing at, placing, and orienting blocks, and by eye gaze, head nods, and head shakes, all timed with precision. Directors often responded by altering their utterances midcourse, also timed with precision.},
  comment  = {Whitney2016: measurement of HRI:  Responding quickly and incorporating the relative timing of speech and gesture is critical for accurate understanding in humanhuman interaction},
  doi      = {10.1016/j.jml.2003.08.004},
  file     = {:FILES/2004 - Clark2004 - Speaking while monitoring addressees for understanding.pdf:PDF},
  groups   = {human robot interaction},
  keywords = {Speaking, Language production, Dialogue, Monitoring, Gestures, Collaboration},
  url      = {https://www.sciencedirect.com/science/article/pii/S0749596X03001098},
}

@InProceedings{Zhang2016,
  author    = {Zhang, Shiqi and Lu, Dongcai and Chen, Xiaoping and Stone, Peter},
  booktitle = {Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI)},
  title     = {Robot {Scavenger} {Hunt}: {A} standardized framework for evaluating intelligent mobile robots},
  year      = {2016},
  address   = {New York, New York, USA},
  month     = jul,
  pages     = {4276--4277},
  publisher = {AAAI Press},
  file      = {:FILES/2016 - Zhang2016 - Robot Scavenger Hunt- A Standardized Framework for Evaluating Intelligent Mobile Robots.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781577357704},
  url       = {https://www.ijcai.org/proceedings/2016/},
}

@InProceedings{Lu2015,
  author    = {Lu, Dongcai and Ji, Jianmin and Chen, Xiaoping and Liu, Jiangchuan},
  booktitle = {Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems (AAMAS)},
  title     = {Filling knowledge gaps in human-robot interaction using rewritten knowledge of common verbs},
  year      = {2015},
  address   = {Richland, SC, USA},
  month     = may,
  pages     = {1667--1668},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  abstract  = {In this paper, we present an approach to representing a core part of the knowledge consists of semantic information of common verbs from semantic dictionaries. We provide a meta-language as the representation framework for the rewritten knowledge of common verbs and their corresponding user tasks. The meta-language is interpreted based on transition systems, which can be realized on various formalizations such as situation calculus, action languages, and answer set planning. We realize the approach based on answer set planning. Moreover, we provide empirical evidence showing that HRI may significantly benefit from the rewritten knowledge and remarkable performance improvement compared to previous work.},
  file      = {:FILES/2015 - Lu2015 - Filling Knowledge Gaps in Human-Robot Interaction Using Rewritten Knowledge of Common Verbs- Extended Abstract.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781450334136},
  keywords  = {human-robot interaction, common verbs, knowledge representation, task planning},
  location  = {Istanbul, Turkey},
  numpages  = {2},
  url       = {https://dl.acm.org/doi/abs/10.5555/2772879.2773376},
}

@InProceedings{Lu2015a,
  author    = {Lu, Dongcai and Chen, Xiaoping},
  booktitle = {RoboCup 2015: Robot World Cup XIX},
  title     = {Towards an architecture combining grounding and planning for human-robot interaction},
  year      = {2015},
  editor    = {Almeida, Luis and Ji, Jianmin and Steinbauer, Gerald and Luke, Sean},
  pages     = {214--225},
  publisher = {Springer International Publishing},
  abstract  = {We consider here the problem of connecting natural language to the physical world for robotic object manipulation. This problem needs to be solved in robotic reasoning systems so that the robot can act in the real world. In this paper, we propose an architecture that combines grounding and planning to enable robots to solve such a problem. The grounding system of the architecture grounds the meaning of a natural language sentence in physical environment perceived by the robot's sensors and generates a knowledge base of the physical environment. Then the planning system utilizes the knowledge base to infer a plan for object manipulation, which can be effectively generated by an Answer Set Programming (ASP) planner. We evaluate the overall architecture on several datasets and a task of RoboCup2014@home (http://www.robocup2014.org/). The results show that the new architecture outperformed some other systems, and yielded acceptable performance in a real-world scenario.},
  file      = {:FILES/2015 - Lu2015a - Towards an architecture combining grounding and planning for human-robot interaction.pdf:PDF},
  groups    = {task understanding},
  isbn      = {978-3-319-29339-4},
  url       = {https://link.springer.com/chapter/10.1007/978-3-319-29339-4_18},
}

@InProceedings{Ji2016,
  author     = {Ji, Jianmin and Fazli, Pooyan and Liu, Song and Pereira, Tiago and Lu, Dongcai and Liu, Jiangchuan and Veloso, Manuela and Chen, Xiaoping},
  booktitle  = {Social Robotics},
  title      = {Help me! {Sharing} of instructions between remote and heterogeneous robots},
  year       = {2016},
  editor     = {Agah, Arvin and Cabibihan, John-John and Howard, Ayanna M. and Salichs, Miguel A. and He, Hongsheng},
  pages      = {786--795},
  publisher  = {Springer International Publishing},
  abstract   = {Service robots frequently face similar tasks. However, they are still not able to share their knowledge efficiently on how to accomplish those tasks. We introduce a new framework, which allows remote and heterogeneous robots to share instructions on the tasks assigned to them. This framework is used to initiate tasks for the robots, to receive or provide instructions on how to accomplish the tasks, and to ground the instructions in the robots' capabilities. We demonstrate the feasibility of the framework with experiments between two geographically distributed robots and analyze the performance of the proposed framework quantitatively.},
  comment    = {本文的主要内容是提出了一种framework以实现remote and heterogeneous robots之间知识共享。主要是其中一个机器人fail to parse the request or generate an executable plan时，通过这个框架来让另一个机器人生成plan，并传递回第一个机器人。主要思路如下
1.NL instruction receive (没说SR工具), parsing (Stanford Parser), reformulate into RCL (没说具体方法，利用了WordNet的synonyms)
2.将环境信息和任务RCL传递给framework，
3.远端robot接收信息，并利用ASP生成plan，或action sequence
4.将指令通过framework传递给第一个robot，并依据其capability进行调整plan

1.利用OMICS生成instruction list，以处理I’m thirsty这种指令
2.很多细节没有说明，主要是motivation不是很清楚，为何要用远端机器人，用服务器不就可以了？利用了什么环境信息？},
  file       = {:FILES/2016 - Ji2016 - Help Me! Sharing of Instructions Between Remote and Heterogeneous Robots.pdf:PDF},
  groups     = {task understanding},
  isbn       = {978-3-319-47437-3},
  printed    = {Y},
  readstatus = {read},
  url        = {https://link.springer.com/chapter/10.1007/978-3-319-47437-3_77},
}

@InProceedings{Rybski2007,
  author    = {Rybski, Paul E. and Yoon, Kevin and Stolarz, Jeremy and Veloso, Manuela M.},
  booktitle = {Proceedings of the ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  title     = {Interactive robot task training through dialog and demonstration},
  year      = {2007},
  address   = {New York, NY, USA},
  month     = mar,
  pages     = {49--56},
  publisher = {Association for Computing Machinery},
  series    = {HRI '07},
  abstract  = {Effective human/robot interfaces which mimic how humans interact with one another could ultimately lead to robots being accepted in a wider domain of applications. We present a framework for interactive task training of a mobile robot where the robot learns how to do various tasks while observing a human. In addition to observation, the robot listens to the human's speech and interprets the speech as behaviors that are required to be executed. This is especially important where individual steps of a given task may have contingencies that have to be dealt with depending on the situation. Finally, the context of the location where the task takes place and the people present factor heavily into the robot's interpretation of how to execute the task. In this paper, we describe the task training framework, describe how environmental context and communicative dialog with the human help the robot learn the task, and illustrate the utility of this approach with several experimental case studies.},
  comment   = {Ji2016: NL to generate plans
Xie2015:     基于spoken commands, observation and imitation的LfD},
  doi       = {10.1145/1228716.1228724},
  file      = {:FILES/2007 - Rybski2007 - Interactive Robot Task Training through Dialog and Demonstration.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781595936172},
  keywords  = {human-robot interaction, learning by demonstration},
  location  = {Arlington, Virginia, USA},
  url       = {https://dl.acm.org/doi/abs/10.1145/1228716.1228724},
}

@Article{Skubic2004,
  author   = {Skubic, Marjorie and Perzanowski, Dennis and Blisard, Samuel and Schultz, Alan and Adams, William and Bugajska, Magda and Brock, Derek},
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  title    = {Spatial language for human-robot dialogs},
  year     = {2004},
  issn     = {1558-2442},
  month    = may,
  number   = {2},
  pages    = {154--167},
  volume   = {34},
  abstract = {In conversation, people often use spatial relationships to describe their environment, e.g., "There is a desk in front of me and a doorway behind it," and to issue directives, e.g., "go around the desk and through the doorway." In our research, we have been investigating the use of spatial relationships to establish a natural communication mechanism between people and robots, in particular, for novice users. In this paper, the work on robot spatial relationships is combined with a multimodal robot interface. We show how linguistic spatial descriptions and other spatial information can be extracted from an evidence grid map and how this information can be used in a natural, human-robot dialog. Examples using spatial language are included for both robot-to-human feedback and also human-to-robot commands. We also discuss some linguistic consequences in the semantic representations of spatial and locative information based on this work.},
  comment  = {Ji2016: NL to generate plans
Hemachandra2014:Mapping NL to the corresponding referents in the robot’s world model
Walter2013: Symbol grounding problem is in the context of following NL commands
Kollar2010:提出了language understanding system来follow NL commands,但是without using a corpus-based evaluation，从而让untrained users使用该系统
{Kartmann2020}:divide directions around the robot into 16 sub-directions to represent utterances such as “mostly in front but somewhat to the left”
{Tellex2006}: [14] developed Coyote, a mobile robot that can understand spatial commands and generate spatial linguistic descriptions of its environment。 it maps language and spatial information gained from sensors.},
  doi      = {10.1109/TSMCC.2004.826273},
  file     = {:FILES/2004 - Skubic2004 - Spatial language for human-robot dialogs.pdf:PDF},
  groups   = {task understanding, spatial relation},
  url      = {https://ieeexplore.ieee.org/abstract/document/1291663},
}

@InProceedings{Allen2007,
  author    = {Allen, James and Chambers, Nathanael and Ferguson, George and Galescu, Lucian and Jung, Hyuckchul and Swift, Mary and Taysom, William},
  booktitle = {Proceedings of the 22nd National Conference on Artificial Intelligence (AAAI)},
  title     = {{PLOW}: {A} collaborative task learning agent},
  year      = {2007},
  address   = {Vancouver, British Columbia, Canada},
  month     = jul,
  pages     = {1514--1519},
  publisher = {AAAI Press},
  abstract  = {To be effective, an agent that collaborates with humans needs to be able to learn new tasks from humans they work with. This paper describes a system that learns executable task models from a single collaborative learning session consisting of demonstration, explanation and dialogue. To accomplish this, the system integrates a range of AI technologies: deep natural language understanding, knowledge representation and reasoning, dialogue systems, planning/agent-based systems and machine learning. A formal evaluation shows the approach has great promise.},
  comment   = {Xie2015: LfD，展示过程中play-by-play description},
  file      = {:FILES/2007 - Allen2007 - PLOW- A Collaborative Task Learning Agent.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781577353232},
  url       = {https://www.aaai.org/Library/AAAI/2007/aaai07-240.php},
}

@Article{Calinon2007,
  author   = {Calinon, Sylvain and Guenter, Florent and Billard, Aude},
  journal  = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  title    = {On learning, representing, and generalizing a task in a humanoid robot},
  year     = {2007},
  issn     = {1941-0492},
  month    = apr,
  number   = {2},
  pages    = {286--298},
  volume   = {37},
  abstract = {We present a programming-by-demonstration framework for generically extracting the relevant features of a given task and for addressing the problem of generalizing the acquired knowledge to different contexts. We validate the architecture through a series of experiments, in which a human demonstrator teaches a humanoid robot simple manipulatory tasks. A probability-based estimation of the relevance is suggested by first projecting the motion data onto a generic latent space using principal component analysis. The resulting signals are encoded using a mixture of Gaussian/Bernoulli distributions (Gaussian mixture model/Bernoulli mixture model). This provides a measure of the spatio-temporal correlations across the different modalities collected from the robot, which can be used to determine a metric of the imitation performance. The trajectories are then generalized using Gaussian mixture regression. Finally, we analytically compute the trajectory which optimizes the imitation metric and use this to generalize the skill to different contexts},
  comment  = {Xie2015: 基于spoken commands, observation and imitation的LfD},
  doi      = {10.1109/TSMCB.2006.886952},
  file     = {:FILES/2007 - Calinon2007 - On Learning, Representing, and Generalizing a Task in a Humanoid Robot.pdf:PDF},
  groups   = {task understanding},
  url      = {https://ieeexplore.ieee.org/abstract/document/4126276},
}

@Article{Mazuel2008,
  author  = {Mazuel, Laurent and Sabouret, Nicolas},
  journal = {Web Intelligence and Agent Systems: An International Journal},
  title   = {Generic command interpretation algorithms for conversational agents},
  year    = {2008},
  number  = {1},
  pages   = {43--57},
  volume  = {6},
  comment = {Xie2015:     提出一种View Design Language表示NL commands, relied on rules to connect words to ontology concepts。基于ontology KB----DL theory},
  doi     = {10.3233/WIA-2008-0129},
  file    = {:FILES/2008 - Mazuel2008 - Generic command interpretation algorithms for conversational agents.pdf:PDF},
  groups  = {task understanding},
  url     = {https://content.iospress.com/articles/web-intelligence-and-agent-systems-an-international-journal/wia129},
}

@Article{Paraiso2005,
  author    = {Paraiso, Emerson Cabrera and Barth\`{e}s, Jean-Paul A.},
  journal   = {Web Intelligence and Agent Systems: An international journal},
  title     = {An intelligent speech interface for personal assistants applied to knowledge management},
  year      = {2005},
  number    = {4},
  pages     = {217--230},
  volume    = {3},
  comment   = {Xie2015: made use of predefined grammar rules to translate natural language into ontology representation.基于ontology KB--DL theory

see {Paraiso2006}},
  groups    = {task understanding},
  timestamp = {20210520},
  url       = {https://content.iospress.com/articles/web-intelligence-and-agent-systems-an-international-journal/wia00072},
}

@Article{Gorostiza2011,
  author   = {Javi F. Gorostiza and Miguel A. Salichs},
  journal  = {Robotics and Autonomous Systems},
  title    = {End-user programming of a social robot by dialog},
  year     = {2011},
  issn     = {0921-8890},
  month    = dec,
  number   = {12},
  pages    = {1102--1114},
  volume   = {59},
  abstract = {One of the main challenges faced by social robots is how to provide intuitive, natural and enjoyable usability for the end-user. In our ordinary environment, social robots could be important tools for education and entertainment (edutainment) in a variety of ways. This paper presents a Natural Programming System (NPS) that is geared to non-expert users. The main goal of such a system is to provide an enjoyable interactive platform for the users to build different programs within their social robot platform. The end-user can build a complex net of actions and conditions (a sequence) in a social robot via mixed-initiative dialogs and multimodal interaction. The system has been implemented and tested in Maggie, a real social robot with multiple skills, conceived as a general HRI researching platform. The robot’s internal features (skills) have been implemented to be verbally accessible to the end-user, who can combine them into others that are more complex following a bottom-up model. The built sequence is internally implemented as a Sequence Function Chart (SFC), which allows parallel execution, modularity and re-use. A multimodal Dialog Manager System (DMS) takes charge of keeping the coherence of the interaction. This work is thought for bringing social robots closer to non-expert users, who can play the game of “teaching how to do things” with the robot.},
  comment  = {Xie2015: Based on dialog system to generate high-level skills},
  doi      = {10.1016/j.robot.2011.07.009},
  file     = {:FILES/2011 - Gorostiza2011 - End-user programming of a social robot by dialog.pdf:PDF},
  groups   = {task understanding},
  keywords = {Sequence function charts, Petri nets, Instruction-based learning, Natural programming, Human–robot dialogs, Dialog manager system, Semantic grammars, Social robotics},
  url      = {https://www.sciencedirect.com/science/article/pii/S092188901100131X},
}

@Article{Paraiso2006,
  author   = {Emerson Cabrera Paraiso and Jean-Paul A. Barthès},
  journal  = {Expert Systems with Applications},
  title    = {An intelligent speech interface for personal assistants in {R\&D} projects},
  year     = {2006},
  issn     = {0957-4174},
  month    = nov,
  note     = {Computer Supported Cooperative Work in Design and Manufacturing},
  number   = {4},
  pages    = {673--683},
  volume   = {31},
  abstract = {Groupware and collaborative tools have been proposed to support cooperative work. However, they suffer from some rather severe limitations. Alternatively, multi-agent systems can be proposed to improve the situation. In the latter case, the user normally interacts with the system through a special agent called a personal assistant. In this paper, we describe the design of an ontology-based speech interface for personal assistants applied in the context of cooperative projects. We believe that this type of interface will improve the quality of assistance and increase collaboration between project members. We present the interface and its insertion into a multi-agent system designed for research and development projects. We describe the design of the interface, highlighting the role of ontologies for semantic interpretation. As a result of this conversational speech interface, we expect an increase in the quality of assistance and a reduction in the time needed to answer user’s requests.},
  doi      = {10.1016/j.eswa.2006.01.018},
  file     = {:FILES/2006 - Paraiso2006 - An intelligent speech interface for personal assistants in R D projects.pdf:PDF},
  groups   = {task understanding},
  keywords = {Speech interface, Ontology, Personal assistants, R&D Projects},
  url      = {https://www.sciencedirect.com/science/article/pii/S0957417406000042},
}

@InProceedings{Zender2009,
  author    = {Zender, Hendrik and Kruijff, {Geert-Jan} M. and {Kruijff-Korbayov\'{a}}, Ivana},
  booktitle = {Proceedings of the 21st International Joint Conference on Artifical Intelligence (IJCAI)},
  title     = {Situated resolution and generation of spatial referring expressions for robotic assistants},
  year      = {2009},
  address   = {San Francisco, CA, USA},
  month     = jul,
  pages     = {1604--1609},
  publisher = {Morgan Kaufmann Publishers Inc.},
  abstract  = {In this paper we present an approach to the task of generating and resolving referring expressions (REs) for conversational mobile robots. It is based on a spatial knowledge base encompassing both robot- and human-centric representations. Existing algorithms for the generation of referring expressions (GRE) try to find a description that uniquely identifies the referent with respect to other entities that are in the current context. Mobile robots, however, act in large-scale space, that is environments that are larger than what can be perceived at a glance, e.g. an office building with different floors, each containing several rooms and objects. One challenge when referring to elsewhere is thus to include enough information so that the interlocutors can extend their context appropriately. We address this challenge with a method for context construction that can be used for both generating and resolving REs - two previously disjoint aspects. Our approach is embedded in a bi-directional framework for natural language processing for robots.},
  comment   = {Boularias2015: generating and resolving referring spatial expression based on KB and rule inference},
  file      = {:FILES/2009 - Zender2009 - Situated resolution and Generation of Spatial Referring Expressions for Robotic Assistants.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.ijcai.org/proceedings/2009/},
}

@InProceedings{Matuszek2012,
  author    = {Matuszek, Cynthia and FitzGerald, Nicholas and Zettlemoyer, Luke and Bo, Liefeng and Fox, Dieter},
  booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning (ICML)},
  title     = {A joint model of language and perception for grounded attribute learning},
  year      = {2012},
  address   = {Madison, WI, USA},
  month     = jun,
  pages     = {1435--1442},
  publisher = {Omnipress},
  abstract  = {As robots become more ubiquitous and capable, it becomes ever more important for untrained users to easily interact with them. Recently, this has led to study of the language grounding problem, where the goal is to extract representations of the meanings of natural language tied to the physical world. We present an approach for joint learning of language and perception models for grounded attribute induction. The perception model includes classifiers for physical characteristics and a language model based on a probabilistic categorial grammar that enables the construction of compositional meaning representations. We evaluate on the task of interpreting sentences that describe sets of objects in a physical workspace, and demonstrate accurate task performance and effective latent-variable concept induction in physical grounded scenes.},
  comment   = {Boularias2015:a joint model of language and perception for grounding.the considered spatial relations were simple
Hemachandra2015: interpret natural language expressions that provide route direction
Hemachandra2014: Mapping NL to the corresponding referents in the robot’s world model
Walter2013:Symbol grounding problem is in the context of following NL commands},
  file      = {:FILES/2012 - Matuszek2012 - A Joint Model of Language and Perception for Grounded Attribute Learning.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781450312851},
  url       = {https://icml.cc/2012/papers/},
}

@InProceedings{Hemachandra2011,
  author    = {Hemachandra, Sachithra and Kollar, Thomas and Roy, Nicholas and Teller, Seth},
  booktitle = {Proceedings of the 2011 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Following and interpreting narrated guided tours},
  year      = {2011},
  address   = {Shanghai, China},
  month     = may,
  pages     = {2574--2579},
  publisher = {IEEE},
  abstract  = {We describe a robotic tour-taking capability enabling a robot to acquire local knowledge of a human-occupied environment. A tour-taking robot autonomously follows a human guide through an environment, interpreting the guide's spoken utterances and the shared spatiotemporal context in order to acquire a spatially segmented and semantically labeled metrical-topological representation of the environment. The described tour-taking capability enables scalable deployment of mobile robots into human-occupied environments, and natural human-robot interaction for commanded mobility. Our primary contributions are an efficient, socially acceptable autonomous tour-following behavior and a tour interpretation algorithm that partitions a map into spaces labeled according to the guide's utterances. The tour-taking behavior is demonstrated in a multi-floor office building and evaluated by assessing the comfort of the tour guides, and by comparing the robot's map partitions to those produced by humans.},
  comment   = {Hemachandra2015:a voice-commandable wheelchair},
  doi       = {10.1109/ICRA.2011.5980209},
  file      = {:FILES/2011 - Hemachandra2011 - Following and interpreting narrated guided tours.pdf:PDF},
  groups    = {task understanding},
  issn      = {1050-4729},
  url       = {https://ieeexplore.ieee.org/abstract/document/5980209},
}

@InProceedings{Howard2014,
  author     = {Howard, Thomas M. and Tellex, Stefanie and Roy, Nicholas},
  booktitle  = {Proceedings of the 2014 IEEE International Conference on Robotics and Automation (ICRA)},
  title      = {A natural language planner interface for mobile manipulators},
  year       = {2014},
  address    = {Hong Kong, China},
  month      = may,
  pages      = {6652--6659},
  publisher  = {IEEE},
  abstract   = {Natural language interfaces for robot control aspire to find the best sequence of actions that reflect the behavior intended by the instruction. This is difficult because of the diversity of language, variety of environments, and heterogeneity of tasks. Previous work has demonstrated that probabilistic graphical models constructed from the parse structure of natural language can be used to identify motions that most closely resemble verb phrases. Such approaches however quickly succumb to computational bottlenecks imposed by construction and search the space of possible actions. Planning constraints, which define goal regions and separate the admissible and inadmissible states in an environment model, provide an interesting alternative to represent the meaning of verb phrases. In this paper we present a new model called the Distributed Correspondence Graph (DCG) to infer the most likely set of planning constraints from natural language instructions. A trajectory planner then uses these planning constraints to find a sequence of actions that resemble the instruction. Separating the problem of identifying the action encoded by the language into individual steps of planning constraint inference and motion planning enables us to avoid computational costs associated with generation and evaluation of many trajectories. We present experimental results from comparative experiments that demonstrate improvements in efficiency in natural language understanding without loss of accuracy.},
  comment    = {Hemachandra2015:interpret natural language expressions that provide command manipulation of objects, 需要prior knowledge
Hemachandra2015:Hierarchical Distributed Correspondence Graph (HDCG) model for NL translation, which is extension of DCG
Howard2014a: DCG model: expand G3 model by assuming conditional independence of grounding constituents to improve the computational efficiency of probabilistic inference. take a brute force approach to constructing the probabilistic graphical models
Duvallet2016: DCG model. Natural language has proven to be effective for commanding robots to follow route directions. Require a complete semantically-labeled environment model that captures the geometry, location, type, and label of objects and regions in the environment.没有利用NL instruction中包含的信息来reason uncertainty and infer environment representation.

本文是Tellex2011的改进版本，提出了G3-DCG和DCG两个模型，分别是增加了更多的假设条件，从而对目标函数进行了新的变换。通过增加变量的个数，来降低计算复杂度。从效果上看，DCG最好。（大致扫了一眼，没有研究具体细节）},
  doi        = {10.1109/ICRA.2014.6907841},
  file       = {:FILES/2014 - Howard2014 - A natural language planner interface for mobile manipulators.pdf:PDF;:FILES/notes/Howard2014.docx:Word 2007+},
  groups     = {task understanding},
  issn       = {1050-4729},
  priority   = {prio1},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/document/6907841},
}

@InCollection{Duvallet2016,
  author     = {Duvallet, Felix and Walter, Matthew R. and Howard, Thomas and Hemachandra, Sachithra and Oh, Jean and Teller, Seth and Roy, Nicholas and Stentz, Anthony},
  booktitle  = {Experimental Robotics: The 14th International Symposium on Experimental Robotics},
  publisher  = {Springer International Publishing},
  title      = {Inferring maps and behaviors from natural language instructions},
  year       = {2016},
  editor     = {Hsieh, M. Ani and Khatib, Oussama and Kumar, Vijay},
  isbn       = {978-3-319-23778-7},
  pages      = {373--388},
  abstract   = {Natural language provides a flexible, intuitive way for people to command robots, which is becoming increasingly important as robots transition to working alongside people in our homes and workplaces. To follow instructions in unknown environments, robots will be expected to reason about parts of the environments that were described in the instruction, but that the robot has no direct knowledge about. However, most existing approaches to natural language understanding require that the robot's environment be known a priori. This paper proposes a probabilistic framework that enables robots to follow commands given in natural language, without any prior knowledge of the environment. The novelty lies in exploiting environment information implicit in the instruction, thereby treating language as a type of sensor that is used to formulate a prior distribution over the unknown parts of the environment. The algorithm then uses this learned distribution to infer a sequence of actions that are most consistent with the command, updating our belief as we gather more metric information. We evaluate our approach through simulation as well as experiments on two mobile robots; our results demonstrate the algorithm's ability to follow navigation commands with performance comparable to that of a fully-known environment.},
  comment    = {Hemachandra2015:前期工作 object-relative navigation within small, open environments
Howard2014a: Apply DCG to control robotic wheelchair based on env maps and robot behavior inferred from NL commands in unknown env

与{Hemachandra2014}的内容基本一致，只是其中对NL instruction进行分析时使用了DCG model而不是G3 model. 可以处理unknown environment. 实验中用了wheelchair. spatial relationships between one or two objects.},
  doi        = {10.1007/978-3-319-23778-7_25},
  file       = {:FILES/2016 - Duvallet2016 - Inferring Maps and Behaviors from Natural Language Instructions.pdf:PDF;:FILES/notes/Duvallet2016.docx:Word 2007+},
  groups     = {task understanding},
  printed    = {Y},
  readstatus = {skimmed},
  url        = {https://link.springer.com/chapter/10.1007/978-3-319-23778-7_25},
}

@Article{Kaess2008,
  author   = {Kaess, Michael and Ranganathan, Ananth and Dellaert, Frank},
  journal  = {IEEE Transactions on Robotics},
  title    = {{iSAM}: {Incremental} smoothing and mapping},
  year     = {2008},
  issn     = {1941-0468},
  month    = dec,
  number   = {6},
  pages    = {1365--1378},
  volume   = {24},
  abstract = {In this paper, we present incremental smoothing and mapping (iSAM), which is a novel approach to the simultaneous localization and mapping problem that is based on fast incremental matrix factorization. iSAM provides an efficient and exact solution by updating a QR factorization of the naturally sparse smoothing information matrix, thereby recalculating only those matrix entries that actually change. iSAM is efficient even for robot trajectories with many loops as it avoids unnecessary fill-in in the factor matrix by periodic variable reordering. Also, to enable data association in real time, we provide efficient algorithms to access the estimation uncertainties of interest based on the factored information matrix. We systematically evaluate the different components of iSAM as well as the overall algorithm using various simulated and real-world datasets for both landmark and pose-only settings.},
  comment  = {Hemachandra2015:Distributed Correspondence Graph (DCG) for NL translation， the metric map and the topology are independent},
  doi      = {10.1109/TRO.2008.2006706},
  file     = {:FILES/2008 - Kaess2008 - {iSAM}- {Incremental} smoothing and mapping.pdf:PDF},
  groups   = {task understanding},
  url      = {https://ieeexplore.ieee.org/document/4682731},
}

@Article{Crammer2001,
  author  = {Koby Crammer and Yoram Singer},
  journal = {Journal of Machine Learning Research},
  title   = {On the algorithmic implementation of multiclass kernel-based vector machines},
  year    = {2001},
  pages   = {265--292},
  volume  = {2},
  comment = {multi-class hinge loss},
  file    = {:FILES/2001 - Crammer2001 - On the algorithmic implementation of multiclass kernel-based vector machines.pdf:PDF},
  groups  = {SVM},
  url     = {https://www.jmlr.org/papers/v2/crammer01a.html},
}

@InProceedings{Howard2014a,
  author     = {Thomas M. Howard and Istvan Chung and Oron Propp and Matthew R. Walter and Nicholas Roy},
  booktitle  = {Proceedings of the 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) Workshop on Rehabilitation and Assistive Robotics},
  title      = {Efficient natural language interfaces for assistive robots},
  year       = {2014},
  address    = {Chicago, IL, USA},
  month      = sep,
  pages      = {1--5},
  publisher  = {IEEE},
  comment    = {Hemachandra2015: HDCG model as extension of DCG


本文主要工作是提出了HDCG，用以提高基于DCG model的计算效率。主要思想是在构建DCG模型以推理phrase与entity之间correspondence之前，首先infer the candidate entities based on a rule inference model.
HDC is a hierarchical model, the higher level of which is used to infer the rules for constructing the space of groundings for the subsequent model, and the lower level of which models the relationships in the physical env that are used to infer from NL instructions. The inference occurs from the top to bottom, i.e., once the rules are successfully inferred, the irrelevant objects can be eliminated from the search space. This is particularly useful when the env contains a lot of such items. (might be explained from the perspective of sparsity mathematically)},
  file       = {:FILES/2014 - Howard2014a - Efficient Natural Language Interfaces for Assistive Robots.pdf:PDF;:FILES/notes/Howard2014a.docx:Word 2007+},
  groups     = {task understanding},
  printed    = {Y},
  readstatus = {read},
  url        = {https://www.ttic.edu/ripl/},
}

@InProceedings{Mooney2008,
  author    = {Mooney, Raymond J.},
  booktitle = {Proceedings of the 23rd National Conference on Artificial Intelligence (AAAI)},
  title     = {Learning to connect language and perception},
  year      = {2008},
  address   = {Chicago, Illinois},
  month     = jul,
  pages     = {1598--1601},
  publisher = {AAAI Press},
  abstract  = {To truly understand language, an intelligent system must be able to connect words, phrases, and sentences to its perception of objects and events in the world. Current natural language processing and computer vision systems make extensive use of machine learning to acquire the probabilistic knowledge needed to comprehend linguistic and visual input. However, to date, there has been relatively little work on learning the relationships between the two modalities. In this talk, I will review some of the existing work on learning to connect language and perception, discuss important directions for future research in this area, and argue that the time is now ripe to make a concerted effort to address this important, integrative AI problem.},
  comment   = {Howard2014a: A key component of natural language interfaces is the model for providing physical meaning for linguistic constituents},
  file      = {:FILES/2008 - Mooney2008 - Learning to Connect Language and Perception.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781577353683},
  url       = {https://www.aaai.org/Library/AAAI/aaai08contents.php},
}

@InProceedings{Bugmann2004,
  author    = {Bugmann, Guido and Klein, Ewan and Lauria, Stanislao and Kyriacou, Theocharis},
  booktitle = {Proceedings of intelligent autonomous systems},
  title     = {Corpus-based robotics: {A} route instruction example},
  year      = {2004},
  pages     = {96--103},
  comment   = {Hemachandra2014: HRI with NL speech
Walter2013:enabling robots to interpret natural language commands
Kollar2010: 提出了formalism similar to SDC to reason about semantics of NL directions. identified a set of 15 primitive procedures associated with clauses in a corpus of spoken natural language directions.侧重于end-2end system. SDC的提出借鉴了该文献。比SDC more expressive,但难以从NL中自动抽取信息},
  file      = {:FILES/2004 - Bugmann2004 - Corpus-based robotics- A route instruction example.pdf:PDF},
  groups    = {task understanding},
}

@InProceedings{Matuszek2010,
  author    = {Matuszek, Cynthia and Fox, Dieter and Koscher, Karl},
  booktitle = {Proceedings of the 2010 5th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  title     = {Following directions using statistical machine translation},
  year      = {2010},
  address   = {Osaka, Japan},
  month     = mar,
  pages     = {251--258},
  publisher = {IEEE},
  abstract  = {Mobile robots that interact with humans in an intuitive way must be able to follow directions provided by humans in unconstrained natural language. In this work we investigate how statistical machine translation techniques can be used to bridge the gap between natural language route instructions and a map of an environment built by a robot. Our approach uses training data to learn to translate from natural language instructions to an automatically-labeled map. The complexity of the translation process is controlled by taking advantage of physical constraints imposed by the map. As a result, our technique can efficiently handle uncertainty in both map labeling and parsing. Our experiments demonstrate the promising capabilities achieved by our approach.},
  comment   = {Hemachandra2014:HRI with NL speech, Mapping NL to the corresponding referents in the robot’s world model
Walter2013:enabling robots to interpret natural language commands, Symbol grounding problem is in the context of following NL commands},
  doi       = {10.1109/HRI.2010.5453189},
  file      = {:FILES/2010 - Matuszek2010 - Following directions using statistical machine translation.pdf:PDF},
  groups    = {task understanding},
  issn      = {2167-2148},
  url       = {https://ieeexplore.ieee.org/abstract/document/5453189},
}

@InProceedings{Pronobis2012,
  author    = {Pronobis, Andrzej and Jensfelt, Patric},
  booktitle = {Proceedings of the 2012 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Large-scale semantic mapping and reasoning with heterogeneous modalities},
  year      = {2012},
  address   = {Saint Paul, MN, USA},
  month     = may,
  pages     = {3515--3522},
  publisher = {IEEE},
  abstract  = {This paper presents a probabilistic framework combining heterogeneous, uncertain, information such as object observations, shape, size, appearance of rooms and human input for semantic mapping. It abstracts multi-modal sensory information and integrates it with conceptual common-sense knowledge in a fully probabilistic fashion. It relies on the concept of spatial properties which make the semantic map more descriptive, and the system more scalable and better adapted for human interaction. A probabilistic graphical model, a chaingraph, is used to represent the conceptual information and perform spatial reasoning. Experimental results from online system tests in a large unstructured office environment highlight the system's ability to infer semantic room categories, predict existence of objects and values of other spatial properties as well as reason about unexplored space.},
  comment   = {Hemachandra2014:Semantic mapping algorithms,考虑了room type, presence of objects based on the appearance model. 利用了multi-modal probabilistic framework including object detection, place appearance, and human provided info.侧重于egocentric descriptions. 基于door detection的topology inference，只适用于特定环境。
Walter2013:augmented lower-level metric maps with higher-level topological and/or semantic information. a multi-modal probabilistic framework incorporating semantic information from a wide variety of modalities including detected objects, place appearance, and human-provided information多模态},
  doi       = {10.1109/ICRA.2012.6224637},
  file      = {:FILES/2012 - Pronobis2012 - Large-scale semantic mapping and reasoning with heterogeneous modalities.pdf:PDF},
  groups    = {task understanding},
  issn      = {1050-4729},
  url       = {https://ieeexplore.ieee.org/document/6224637},
}

@InProceedings{Tellex2012a,
  author    = {Stefanie Tellex and Pratiksha Thaker and Robin Deits and Thomas Kollar and Nicholas Roy},
  booktitle = {Proceedings of Robotics: Science and Systems},
  title     = {Toward information theoretic human-robot dialog},
  year      = {2012},
  address   = {Sydney, Australia},
  month     = jul,
  pages     = {1--8},
  comment   = {Hemachandra2014:Mapping NL to the corresponding referents in the robot’s world model
Walter2013:Symbol grounding problem is in the context of following NL commands},
  doi       = {10.15607/RSS.2012.VIII.052},
  file      = {:FILES/2012 - Tellex2012a - Toward Information Theoretic Human-Robot Dialog.pdf:PDF},
  groups    = {task understanding},
  url       = {http://roboticsproceedings.org/rss08/p52.html},
}

@Article{Harnad1990,
  author     = {Stevan Harnad},
  journal    = {Physica D: Nonlinear Phenomena},
  title      = {The symbol grounding problem},
  year       = {1990},
  issn       = {0167-2789},
  month      = jun,
  number     = {1},
  pages      = {335--346},
  volume     = {42},
  abstract   = {There has been much discussion recently about the scope and limits of purely symbolic models of the mind and about the proper role of connectionism in cognitive modeling. This paper describes the “symbol grounding problem”: How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a Chinese/Chinese dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) iconic representations, which are analogs of the proximal sensory projections of distal objects and events, and (2) categorical representations, which are learned and innate feature detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) symbolic representations, grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g. “An X is a Y that is Z”). Connectionism is one natural candidate for the mechanism that learns the invariant features underlying categorical representations, thereby connecting names to the proximal projections of the distal objects they stand for. In this way connectionism can be seen as a complementary component in a hybrid nonsymbolic/symbolic model of the mind, rather than a rival to purely symbolic modeling. Such a hybrid model would not have an autonomous symbolic “module,” however; the symbolic functions would emerge as an intrinsically “dedicated” symbol system as a consequence of the bottom-up grounding of categories' names in their sensory representations. Symbol manipulation would be governed not just by the arbitrary shapes of the symbol tokens, but by the nonarbitrary shapes of the icons and category invariants in which they are grounded.},
  comment    = {Walter2013:Termed  symbol grounding problem： 概念的提出},
  doi        = {10.1016/0167-2789(90)90087-6},
  file       = {:FILES/1990 - Harnad1990 - The symbol grounding problem.pdf:PDF},
  groups     = {task understanding},
  readstatus = {skimmed},
  url        = {https://www.sciencedirect.com/science/article/pii/0167278990900876},
}

@Article{Levit2007,
  author  = {Levit, Michael and Roy, Deb},
  journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  title   = {Interpretation of spatial language in a map navigation task},
  year    = {2007},
  month   = jun,
  number  = {3},
  pages   = {667--679},
  volume  = {37},
  comment = {Kollar2010: designed navigational informational units that break down instructions into components. 比SDC more expressive,但难以从NL中自动抽取信息},
  doi     = {10.1109/TSMCB.2006.889809},
  file    = {:FILES/2007 - Levit2007 - Interpretation of Spatial Language in a Map Navigation Task.pdf:PDF},
  groups  = {task understanding},
  url     = {https://ieeexplore.ieee.org/abstract/document/4200804},
}

@InProceedings{Wei2009,
  author    = {Wei, Yuan and Brunskill, Emma and Kollar, Thomas and Roy, Nicholas},
  booktitle = {Proceedings of the 2009 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Where to go: {Interpreting} natural directions using global inference},
  year      = {2009},
  address   = {Kobe, Japan},
  month     = jun,
  pages     = {3761--3767},
  publisher = {IEEE},
  comment   = {Kollar2010: 前期工作：built direction understanding systems that model the directions as a sequence of landmarks， baseline method which performs global inference using landmarks visible from any orientation in a region, and no spatial relations or verbs},
  doi       = {10.1109/ROBOT.2009.5152775},
  file      = {:FILES/2009 - Wei2009 - Where to go- Interpreting natural directions using global inference.pdf:PDF},
  groups    = {task understanding},
  url       = {https://ieeexplore.ieee.org/abstract/document/5152775},
}

@InProceedings{Look2005,
  author    = {Look, Gary and Kottahachchi, Buddhika and Laddaga, Robert and Shrobe, Howard},
  booktitle = {Proceedings of the 10th International Conference on Intelligent User Interfaces (IUI)},
  title     = {A location representation for generating descriptive walking directions},
  year      = {2005},
  address   = {New York, NY, USA},
  month     = jan,
  pages     = {122--129},
  publisher = {Association for Computing Machinery},
  abstract  = {An expressive representation for location is an important component in many applications. However, while many location-aware applications can reason about space at the level of coordinates and containment relationships, they have no way to express the semantics that define how a particular space is used. We present Lair, an ontology that addresses this problem by modeling both the geographical relationships between spaces as well as the functional purpose of a given space. We describe how Lair was used to create an application that produces walking directions comparable to those given by a person, and a pilot study that evaluated the quality of these directions. We also describe how Lair can be used to evaluate other intelligent user interfaces.},
  comment   = {Kollar2010: created an ontology for modeling the relationships between spaces, and used it for generating natural language directions. 比SDC more expressive,但难以从NL中自动抽取信息},
  doi       = {10.1145/1040830.1040862},
  file      = {:FILES/2005 - Look2005 - A location representation for generating descriptive walking directions.pdf:PDF},
  groups    = {task understanding},
  isbn      = {1581138946},
  keywords  = {location ontologies, navigation directions},
  location  = {San Diego, California, USA},
  url       = {https://doi.org/10.1145/1040830.1040862},
}

@Article{Hirschberg2015,
  author    = {Hirschberg, Julia and Manning, Christopher D.},
  journal   = {Science},
  title     = {Advances in natural language processing},
  year      = {2015},
  issn      = {0036-8075},
  number    = {6245},
  pages     = {261--266},
  volume    = {349},
  abstract  = {Natural language processing employs computational techniques for the purpose of learning, understanding, and producing human language content. Early computational approaches to language research focused on automating the analysis of the linguistic structure of language and developing basic technologies such as machine translation, speech recognition, and speech synthesis. Today{\textquoteright}s researchers refine and make use of such tools in real-world applications, creating spoken dialogue systems and speech-to-speech translation engines, mining social media for information about health or finance, and identifying sentiment and emotion toward products and services. We describe successes and challenges in this rapidly advancing area.},
  doi       = {10.1126/science.aaa8685},
  file      = {:FILES/2015 - Hirschberg2015 - Advances in natural language processing.pdf:PDF},
  groups    = {nlp},
  publisher = {American Association for the Advancement of Science},
  url       = {https://science.sciencemag.org/content/349/6245/261},
}

@InProceedings{Sap2019,
  author    = {Sap, Maarten and {Le Bras}, Ronan and Allaway, Emily and Bhagavatula, Chandra and Lourie, Nicholas and Rashkin, Hannah and Roof, Brendan and Smith, Noah A. and Choi, Yejin},
  booktitle = {Proceedings of the 33rd AAAI Conference on Artificial Intelligence (AAAI)},
  title     = {{ATOMIC}: {An} atlas of machine commonsense for if-then reasoning},
  year      = {2019},
  month     = jul,
  note      = {Technical Track: Knowledge Representation and Reasoning},
  number    = {1},
  pages     = {3027--3035},
  publisher = {AAAI Press},
  volume    = {33},
  comment   = {将知识表达为if-then的形式，并进行推理},
  doi       = {10.1609/aaai.v33i01.33013027},
  file      = {:FILES/2019 - Sap2019 - {ATOMIC}- {An} atlas of machine commonsense for if-then reasoning.pdf:PDF},
  groups    = {representation},
  priority  = {prio1},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/4160},
}

@Article{Liu2016f,
  author     = {Rui Liu and Xiaoli Zhang},
  journal    = {International Journal of Advanced Robotic Systems},
  title      = {Fuzzy context-specific intention inference for robotic caregiving},
  year       = {2016},
  number     = {5},
  pages      = {1--14},
  volume     = {13},
  abstract   = {To provide timely and appropriate assistance, robots must have the capability of proactively understanding a user’s personal needs, the so-called human intention inference. In human–human interaction, humans have a natural and implicit way to infer others’ intentions by selecting correlated context features and interpreting these features based on their life experience. However, robots do not have this capability and it is not realistic to build an explicit formula to associate human intentions with context. In this article, a novel fuzzy context-specific intention inference method is developed for human-like implicit human intention inference. With a fuzzy manner, context features are converted into discrete context statuses, which are similar to human subjective feelings. An intention-centered common sense database is developed consisting of correlated fuzzy context statuses, object affordances, and their relationship with human intentions. With this database, a Fuzzy Naïve Bayesian Network algorithm is adopted for implicit intention inference. Home scenario results validated the fuzzy context-specific intention inference methods reliability and lab scenario results validated the fuzzy context-specific intention inference methods effectiveness and robustness. This work is expected to develop intuitive and effective human–robot interaction, consequently enhancing the adoption of assistive technologies and improving the independence of the disabled and elderly in activities of daily living.},
  doi        = {10.1177/1729881416662780},
  file       = {:FILES/2016 - Liu2016f - Fuzzy context-specific intention inference for robotic caregiving.pdf:PDF},
  groups     = {task understanding},
  readstatus = {read},
  url        = {https://journals.sagepub.com/doi/full/10.1177/1729881416662780},
}

@InProceedings{Craig2016,
  author    = {Craig, Trevor Lynn and Nelson, Carl A. and Li, Songpo and Zhang, Xiaoli},
  booktitle = {2016 12th IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications (MESA)},
  title     = {Human gaze commands classification: {A} shape based approach to interfacing with robots},
  year      = {2016},
  address   = {Auckland, New Zealand},
  month     = aug,
  pages     = {1--6},
  publisher = {IEEE},
  abstract  = {The sense of sight is one of the main outlets to how we interact with the world around us. Using eye tracking methods, this sensory input channel may also be used as an output channel to provide commands for robots to follow. These gaze-commanded robots could then be used to assist severely mobility-limited individuals in the home or similar environments. This paper explores the use of visually drawn shapes as the input for robot commands. These commands were recorded using low-cost gaze tracking hardware (Gazepoint GP3 Eye Tracker). The data were then processed using a custom algorithm in MATLAB to detect commands to be passed to a small humanoid robot (NAO). Using the techniques and procedures given in this paper, people with limited mobility will be able to input shape commands to have robots like NAO react as personal assistants. This is also extensible to gaze-based human-machine interfaces in general for a variety of applications.},
  doi       = {10.1109/MESA.2016.7587154},
  file      = {:FILES/2016 - Craig2016 - Human gaze commands classification- A shape based approach to interfacing with robots.pdf:PDF},
  groups    = {from gaze},
  url       = {https://ieeexplore.ieee.org/abstract/document/7587154},
}

@InProceedings{Paus2021,
  author    = {Paus, Fabian and Asfour, Tamim},
  booktitle = {Experimental Robotics},
  title     = {Probabilistic representation of objects and their support relations},
  year      = {2021},
  address   = {Cham},
  editor    = {Siciliano, Bruno and Laschi, Cecilia and Khatib, Oussama},
  pages     = {510--519},
  publisher = {Springer International Publishing},
  abstract  = {Understanding uncertainty about objects and their relations in a scene is essential for action selection in robotics. We propose a novel approach for a probabilistic representation of objects and their support relations taking into account pose and shape uncertainty. Starting with a segmented point cloud a probability distribution over the object geometry is estimated, from which samples are drawn to calculate a probability distribution over support relations. To evaluate the approach, we created a new RGB-D dataset, the KIT Support Relation dataset (KIT-SR), consisting of 60 scenes annotated with pixel-wise object labels and ground-truth support relations. Furthermore, we augmented the Object Segmentation Database (OSD) with support relation annotations. We evaluated our proposed probabilistic approach against two state-of-the-art deterministic approaches and show significantly improved precision, recall, F1, and Brier scores.},
  comment   = {识别并表示物体之间的空间关系},
  file      = {:FILES/2021 - Paus2021 - Probabilistic Representation of Objects and Their Support Relations.pdf:PDF},
  groups    = {task understanding, representation},
  isbn      = {978-3-030-71151-1},
  url       = {https://link.springer.com/chapter/10.1007/978-3-030-71151-1_45},
}

@Article{Dreher2020,
  author  = {Christian R. G. Dreher and Mirko W\"{a}chter and Tamim Asfour},
  journal = {IEEE Robotics and Automation Letters},
  title   = {Learning object-action relations from bimanual human demonstration using graph networks},
  year    = {2020},
  month   = jan,
  number  = {1},
  pages   = {187--194},
  volume  = {5},
  comment = {action representation with relation to objects},
  doi     = {10.1109/LRA.2019.2949221},
  file    = {:FILES/2020 - Dreher2020 - Learning Object-Action Relations from Bimanual Human Demonstration Using Graph Networks.pdf:PDF},
  groups  = {task understanding, representation},
  url     = {https://ieeexplore.ieee.org/document/8880484},
}

@InProceedings{Kartmann2020,
  author     = {Kartmann, Rainer and Zhou, You and Liu, Danqing and Paus, Fabian and Asfour, Tamim},
  booktitle  = {Proceedings of the 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title      = {Representing spatial object relations as parametric polar distribution for scene manipulation based on verbal commands},
  year       = {2020},
  address    = {Las Vegas, NV, USA},
  month      = {Oct},
  pages      = {8373--8380},
  publisher  = {IEEE},
  abstract   = {Understanding spatial relations is a key element for natural human-robot interaction. Especially, a robot must be able to manipulate a given scene according to a human verbal command specifying desired spatial relations between objects. To endow robots with this ability, a suitable representation of spatial relations is necessary, which should be derivable from human demonstrations. We claim that polar coordinates can capture the underlying structure of spatial relations better than Cartesian coordinates and propose a parametric probability distribution defined in polar coordinates to represent spatial relations. We consider static spatial relations such as left of, behind, and near, as well as dynamic ones such as closer to and other side of, and take into account verbal modifiers such as roughly and a lot. We show that adequate distributions can be derived for various combinations of spatial relations and modifiers in a sample-efficient way using Maximum Likelihood Estimation, evaluate the effects of modifiers on the distribution parameters, and demonstrate our representation's usefulness in a pick-and-place task on a real robot.},
  comment    = {本文的主要内容是利用极坐标系，来表达spatial relation,从而为理解NL commands并实现物体操作提供基础，其中的指令理解是基于keyword matching，机器人操作过程中所移动的距离是根据指令所对应的距离和角度的概率分布来随机生成的，其中考虑了modifier的影响。
1. 本文目标与【6】相同，基于当前scene，表达spatial relation，并能够used to generate target positions directly，用以complete manipulation actions；
2. a two-dimensional plane for a robot pick-and-place task;
estimate probability distributions separately for each combination of spatial relation and modifier;
3. arranging objects based on a spatial relation between them specified by a verbal command;
4. verbal commands中，位置关系的描述词和modifier是固定的，通过不同组合来测试，object类型也是固定的，不含有未知物体。
5. 用keyword matching来识别verbal commands},
  doi        = {10.1109/IROS45743.2020.9340925},
  file       = {:FILES/2020 - Kartmann2020 - Representing spatial object relations as parametric polar distribution for scene manipulation based on verbal commands.pdf:PDF},
  groups     = {task understanding, spatial relation},
  issn       = {2153-0866},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/document/9340925},
}

@InProceedings{Karrenbauer2018,
  author    = {Karrenbauer, Oliver and Rader, Samuel and Asfour, Tamim},
  booktitle = {Proceedings of the 2018 IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids)},
  title     = {An ontology-based expert system to support the design of humanoid robot components},
  year      = {2018},
  address   = {Beijing, China},
  month     = nov,
  pages     = {1--8},
  publisher = {IEEE},
  abstract  = {The design of humanoid robots is a complex, challenging and time-consuming task. Due to conflicting requirements, such as human-like capabilities within human dimensions, the design of humanoid robots relies highly on the experience and expert knowledge of the engineers. This paper presents an expert system framework that allows to store this knowledge in order to reuse it for the systematic design of humanoid robot components. Based on user requirements, the system executes a multi-stage reasoning on an ontological knowledge base: Partial solutions are generated by integrating existing catalog components into potential concept solutions. After checking logical and physical constraints as well as calculating properties, these partial solutions are either discarded or combined in a bottom-up way to generate valid solutions that are then visualized by a user interface. We evaluate the developed system in terms of its capability to reproduce available solutions for state-of-the-art sensor-actuator units used in several robots as well as its capability to optimize the design of such units.},
  doi       = {10.1109/HUMANOIDS.2018.8625075},
  file      = {:FILES/2018 - Karrenbauer2018 - An ontology-based Expert System to Support the Design of Humanoid Robot Components.pdf:PDF},
  groups    = {representation, 知识生成},
  issn      = {2164-0580},
  url       = {https://ieeexplore.ieee.org/document/8625075},
}

@Article{Plappert2018,
  author     = {Matthias Plappert and Christian Mandery and Tamim Asfour},
  journal    = {Robotics and Autonomous Systems},
  title      = {Learning a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks},
  year       = {2018},
  issn       = {0921-8890},
  month      = nov,
  pages      = {13--26},
  volume     = {109},
  abstract   = {Linking human whole-body motion and natural language is of great interest for the generation of semantic representations of observed human behaviors as well as for the generation of robot behaviors based on natural language input. While there has been a large body of research in this area, most approaches that exist today require a symbolic representation of motions (e.g. in the form of motion primitives), which have to be defined a-priori or require complex segmentation algorithms. In contrast, recent advances in the field of neural networks and especially deep learning have demonstrated that sub-symbolic representations that can be learned end-to-end usually outperform more traditional approaches, for applications such as machine translation. In this paper we propose a generative model that learns a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks (RNNs) and sequence-to-sequence learning. Our approach does not require any segmentation or manual feature engineering and learns a distributed representation, which is shared for all motions and descriptions. We evaluate our approach on 2 846 human whole-body motions and 6 187 natural language descriptions thereof from the KIT Motion-Language Dataset. Our results clearly demonstrate the effectiveness of the proposed model: We show that our model generates a wide variety of realistic motions only from descriptions thereof in form of a single sentence. Conversely, our model is also capable of generating correct and detailed natural language descriptions from human motions.},
  comment    = {proposed to understand natural language commands in terms of robot motions in joint space, using a sequence-to-sequence model based on bidirectional recurrent neural network (RNN) and gated recurrent units (GRUs).},
  doi        = {10.1016/j.robot.2018.07.006},
  file       = {:FILES/2018 - Plappert2018 - Learning a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks.pdf:PDF},
  groups     = {task understanding},
  keywords   = {Human whole-body motion, Natural language, Sequence-to-sequence learning, Recurrent neural network},
  readstatus = {skimmed},
  url        = {https://www.sciencedirect.com/science/article/pii/S0921889017306280},
}

@InProceedings{Mandery2016,
  author    = {Mandery, Christian and Borr\`{a}s, J\'{u}lia and J\"{o}chner, Mirjam and Asfour, Tamim},
  booktitle = {Proceedings of the 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Using language models to generate whole-body multi-contact motions},
  year      = {2016},
  address   = {Daejeon, Korea (South)},
  month     = oct,
  pages     = {5411--5418},
  publisher = {IEEE},
  abstract  = {We present a novel approach for generating sequences of whole-body poses with multi-contacts for humanoid robots, which is inspired by techniques from natural language processing. To this end, we propose a probabilistic n-gram language model learned from observation of human locomotion tasks. Human motion data is automatically segmented according to detected contacts of the body with the environment to provide support, that is, support poses, which are further subdivided with regard to whole-body configuration. These poses are subsequently used to train a language model, whose words are the poses, and whose sentences represent sequences of poses. Then, we propose a planning algorithm that, given the constraints imposed by a task, finds the sequence of transitions with the highest probability according to our language model. We have applied our approach to 140 motion capture recordings of locomotion tasks that involve using one or both hands for support. The evaluation demonstrates that our approach is able to generate complex sets of pose transitions, and shows promising results regarding its application to more complex tasks.},
  comment   = {本文主要内容是提出了一种fuzzy context specific intention inference method，用以将context features转化为discrete context statuses；建立了intention centered commonsense database，提出了fuzzy naive bayesian network algorithm for inference
1.Define fuzzy membership functions based on people’s daily life experience.
2.每个context feature可能有多种取值，即context statuses,每种status用fuzzy membership function描述，而每种status都对intention recognition具有不同的贡献。
3.Commonsense knowledge分为object-intention correlation and context status-intention correlation，前者是f(object | intention)，后者是f(context status | intention)
4.Commonsense knowledge database的组织形式是图结构，其中节点是context feature status, intention, object，而边是第三点中的概率，
5.在利用context information进行human intention inference时，首先进行特征选择，即根据membership function value(定义阈值),筛选出strongly correlated feature，然后再利用这些特征值计算概率，选择其中概率最大的作为intention},
  doi       = {10.1109/IROS.2016.7759796},
  file      = {:FILES/2016 - Mandery2016 - Using language models to generate whole-body multi-contact motions.pdf:PDF},
  groups    = {task understanding},
  issn      = {2153-0866},
  url       = {https://ieeexplore.ieee.org/document/7759796},
}

@Article{Liu2020b,
  author   = {Kang Liu and Yubo Chen and Jian Liu and Xinyu Zuo and Jun Zhao},
  journal  = {AI Open},
  title    = {Extracting events and their relations from texts: {A} survey on recent research progress and challenges},
  year     = {2020},
  issn     = {2666-6510},
  pages    = {22--39},
  volume   = {1},
  abstract = {Event is a common but non-negligible knowledge type. How to identify events from texts, extract their arguments, even analyze the relations between different events are important for many applications. This paper summaries some constructed event-centric knowledge graphs and the recent typical approaches for event and event relation extraction, besides task description, widely used evaluation datasets, and challenges. Specifically, in the event extraction task, we mainly focus on three recent important research problems: 1) how to learn the textual semantic representations for events in sentence-level event extraction; 2) how to extract relations across sentences or in a document level; 3) how to acquire or augment labeled instances for model training. In event relation extraction, we focus on the extraction approaches for three typical event relation types, including coreference, causal and temporal relations, respectively. Finally, we give out our conclusion and potential research issues in the future.},
  comment  = {事件及事件关系抽取：其他领域数据的利用，document-level, data augmentation. temporal/causal/coreference events extraction,},
  doi      = {10.1016/j.aiopen.2021.02.004},
  file     = {:FILES/2020 - Liu2020b - Extracting Events and Their Relations from Texts- A Survey on Recent Research Progress and Challenges.pdf:PDF},
  groups   = {knowledge extractions},
  keywords = {Event extraction, Event relation extraction, Knowledge graph},
  url      = {https://www.sciencedirect.com/science/article/pii/S266665102100005X},
}

@InProceedings{Bastianelli2013,
  author    = {Bastianelli, Emanuele and Castellucci, Giuseppe and Croce, Danilo and Basili, Roberto},
  booktitle = {Proceedings of the Joint Symposium on Semantic Processing. Textual Inference and Structures in Corpora},
  title     = {Textual inference and meaning representation in human robot interaction},
  year      = {2013},
  address   = {Trento, Italy},
  month     = nov,
  pages     = {65--69},
  comment   = {VillamarGomez2021: combines existing inference technologies to identify a command’s semantic information and improve the design of human–robot interaction
architectures.},
  file      = {:FILES/2013 - Bastianelli2013 - Textual Inference and Meaning Representation in Human Robot Interaction.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.aclweb.org/anthology/W13-3820},
}

@InProceedings{Thomason2019,
  author     = {Thomason, Jesse and Padmakumar, Aishwarya and Sinapov, Jivko and Walker, Nick and Jiang, Yuqian and Yedidsion, Harel and Hart, Justin and Stone, Peter and Mooney, Raymond J.},
  booktitle  = {Proceedings of the 2019 International Conference on Robotics and Automation (ICRA)},
  title      = {Improving grounded natural language understanding through human-robot dialog},
  year       = {2019},
  address    = {Montreal, QC, Canada},
  month      = may,
  pages      = {6934--6941},
  publisher  = {IEEE},
  comment    = {VillamarGomez2021 : A study expanded a robot’s language understanding and grounded physical objects through conversations with humans.  It incorporates the description of objects, including visual, audio, and haptic properties. the system can learn new concepts referring to object properties.but  it still requires a considerable number of clarification questions, even after training perception and parsing modules, to understand before executing a command. overusing of questions

本文提出了一种pipeline来实现TU,其中包括:
1.  semantic parsing,将word sequence识别为task and roles,基于CCG,其中unknown task通过word embedding来实现.应该是基于关键词来进行匹配.
2. grounding:基于多模态信息,包括visual, haptic, audio等,利用classifier判定word所属feature,
3. clarification dialog:在grounding过程中,可能出现同一role对应了多个可能的实体,这时利用dialog system来不断更新各grounding 的 belief state,从而实现准确的grounding,其中在不同情况下完成不同的action(即问题类型)

此外,本文方法能够记录过程中的utterance-denotation pair,从而从小样本开始训练,并利用新样本来更新模型,属于弱监督模型.利用了opportunistic active learning来对未知概念进行处理,也是基于对话系统的concept establishment过程.},
  doi        = {10.1109/ICRA.2019.8794287},
  file       = {:FILES/2019 - Thomason2019 - Improving Grounded Natural Language Understanding through Human-Robot Dialog.pdf:PDF},
  groups     = {task understanding},
  keywords   = {read},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/8794287},
}

@InProceedings{Woelfel2018,
  author    = {W\"{o}lfel, Kim and Henrich, Dominik},
  booktitle = {2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},
  title     = {Grounding verbs for tool-dependent, sensor-based robot tasks},
  year      = {2018},
  address   = {Nanjing, China},
  month     = aug,
  pages     = {378--383},
  publisher = {IEEE},
  abstract  = {Speech-based robot instruction is a promising field in private households and in small and medium-sized enterprises. It facilitates the use of robot systems for experts as well as non-experts, even while the user executes other tasks. The common approach is to map action verbs to robot tasks represented by well-defined interfaces. While this method works well for a wide variety of robot motions, it contains the necessity for defining additional robot tasks for each change in the physical properties of the manipulated objects. To overcome this drawback, we contribute a novel approach for defining complex and sensor-based robot tasks called Combined Verbalized Effects. It allows to systematically ground action verbs to sensor-based robot motions, while considering accessible tools and highlighting the motion primitive combinations complex motions are made of. Furthermore, real-world examples and a user study show the applicability of our approach.},
  comment   = {VillamarGomez2021: A robot requires techniques to connect verbs to their associated tasks intuitively and the tools or sensors needed to execute such tasks

motion level grounding to verbs in a command},
  doi       = {10.1109/ROMAN.2018.8525827},
  file      = {:FILES/2018 - Woelfel2018 - Grounding Verbs for Tool-Dependent, Sensor-Based Robot Tasks.pdf:PDF},
  groups    = {task understanding},
  issn      = {1944-9437},
  priority  = {prio1},
  url       = {https://ieeexplore.ieee.org/document/8525827},
}

@InProceedings{Patki2019,
  author     = {Patki, Siddharth and Daniele, Andrea F. and Walter, Matthew R. and Howard, Thomas M.},
  booktitle  = {Proceedings of the 2019 International Conference on Robotics and Automation (ICRA)},
  title      = {Inferring compact representations for efficient natural language understanding of robot instructions},
  year       = {2019},
  address    = {Montreal, QC, Canada},
  month      = may,
  pages      = {6926--6933},
  publisher  = {IEEE},
  abstract   = {The speed and accuracy with which robots are able to interpret natural language is fundamental to realizing effective human-robot interaction. A great deal of attention has been paid to developing models and approximate inference algorithms that improve the efficiency of language understanding. However, existing methods still attempt to reason over a representation of the environment that is flat and unnecessarily detailed, which limits scalability. An open problem is then to develop methods capable of producing the most compact environment model sufficient for accurate and efficient natural language understanding. We propose a model that leverages environment-related information encoded within instructions to identify the subset of observations and perceptual classifiers necessary to perceive a succinct, instruction-specific environment representation. The framework uses three probabilistic graphical models trained from a corpus of annotated instructions to infer salient scene semantics, perceptual classifiers, and grounded symbols. Experimental results on two robots operating in different environments demonstrate that by exploiting the content and the structure of the instructions, our method learns compact environment representations that significantly improve the efficiency of natural language symbol grounding.},
  comment    = {Reasoning based on acquired knowledge before taking action is a skill be pursued in robots. probabilistic graphical models are trained by associating language to scene semantics and perceptual classifiers to map natural language instructions correctly.  However, these models do not consider techniques of solving ambiguous instructions, such as verbal interaction

主要思路是将grounding过程中需要的world model进行预处理，忽略其中与utterance无关的entity，从而降低计算复杂度。其中用到了三个模型，用于perception classification, semance scene labeling, and NL grounding,分别需要training corpora。所基于的模型均是DCG},
  doi        = {10.1109/ICRA.2019.8793667},
  file       = {:FILES/2019 - Patki2019 - Inferring Compact Representations for Efficient Natural Language Understanding of Robot Instructions.pdf:PDF},
  groups     = {task understanding},
  issn       = {2577-087X},
  printed    = {Y},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/8793667},
}

@InProceedings{Stenmark2015,
  author    = {Stenmark, Maj and Malec, Jacek},
  booktitle = {Proceedings of the 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems: Workshop on Multimedia Semantics for Robotic Systems},
  title     = {Connecting natural language to task demonstrations and low-level control of industrial robots},
  year      = {2015},
  pages     = {25--29},
  publisher = {IEEE},
  comment   = {Cui2021:combine descriptions of robot tasks using natural language together with their realizations using robot hardware to representing knowledge about industrial processes.},
  file      = {:FILES/2015 - Stenmark2015 - Connecting natural language to task demonstrations and low-level control of industrial robots.pdf:PDF},
  groups    = {task understanding},
  url       = {https://lup.lub.lu.se/search/publication/1173e008-13f8-4fae-a420-e9304bd26a5d},
}

@Article{Puigbo2015,
  author    = {{Jordi-Ysard} Puigbo and Albert Pumarola and Cecilio Angulo and Ricardo Tellez},
  journal   = {Connection Science},
  title     = {Using a cognitive architecture for general purpose service robot control},
  year      = {2015},
  number    = {2},
  pages     = {105--117},
  volume    = {27},
  abstract  = {A humanoid service robot equipped with a set of simple action skills including navigating, grasping, recognising objects or people, among others, is considered in this paper. By using those skills the robot should complete a voice command expressed in natural language encoding a complex task (defined as the concatenation of a number of those basic skills). As a main feature, no traditional planner has been used to decide skills to be activated, as well as in which sequence. Instead, the SOAR cognitive architecture acts as the reasoner by selecting which action the robot should complete, addressing it towards the goal. Our proposal allows to include new goals for the robot just by adding new skills (without the need to encode new plans). The proposed architecture has been tested on a human-sized humanoid robot, REEM, acting as a general purpose service robot.},
  comment   = {Cui2021: adopt Soar cognitive architecture [16] to support understanding and executing human-specified commands. collects information from user during natural language processing (NLP) representing HRI actions using
planning actions.},
  doi       = {10.1080/09540091.2014.968093},
  file      = {:FILES/2015 - Puigbo2015 - Using a cognitive architecture for general purpose service robot control.pdf:PDF},
  groups    = {task understanding},
  publisher = {Taylor \& Francis},
  url       = {https://www.tandfonline.com/doi/abs/10.1080/09540091.2014.968093?journalCode=ccos20},
}

@Article{ReforgiatoRecupero2020,
  author     = {Diego {Reforgiato Recupero} and Federico Spiga},
  journal    = {Information Processing \& Management},
  title      = {Knowledge acquisition from parsing natural language expressions for humanoid robot action commands},
  year       = {2020},
  issn       = {0306-4573},
  month      = nov,
  number     = {6},
  pages      = {102094},
  volume     = {57},
  abstract   = {In this paper we propose an approach that allows the NAO humanoid robot to execute natural language commands spoken by the user. To provide the robot with knowledge, we have defined an action robot ontology. The ontology is fed to an NLP engine that performs a machine reading of the input text (in natural language) given by a user and tries to identify action commands for the robot to execute. The system can work in two modes: STATELESS and STATEFUL. In STATELESS mode, each human expression correctly interpreted by the robot as an action command is performed by NAO which returns in its default posture afterwards. When in STATEFUL mode, the robot has knowledge of its current posture and performs the command only if it is compatible with its current state. In this mode, the robot does not return to its default posture. For example, if the user had told the robot to stand on its right leg in a first command, the robot cannot perform a following command stating to stand on its left leg as the two actions (raise left leg and raise right leg are incompatible). For each action that the robot can perform we modeled a corresponding element in the ontology that also includes a list of associated compatible and non-compatible actions. Our system also handles compound expressions (e.g., move your arms up) and multiple expressions (different commands within one sentence) that the robot understands and performs.},
  comment    = {本文介绍了一款人形机器人，基于Kobayashi2011中的方法。其中包括NLP engine, ontology based knowledge, pepper robot, etc. 其中任务理解过程的主要原理是：
1. 利用Nuance提供的SR服务，将语音信号转化文NLP text （云端）
2. 利用Stanford CoreNLP来进行处理，包括tokenization、POS、syntactic parser等
3. 将处理结果中的动词与ontology中与action相关的keyword and synonym进行匹配，将物体（机器人本体相关）的词语ontology中关键字匹配，将方向词（up down等）匹配，
4. 利用上述信息在ontology中进行查询SPARQL，得到满足条件的action。
总结：
1. 该方法只涉及与机器人本体相关动作，无法实现与环境物体的交互
2. 该方法利用关键词进行匹配，OOV无法处理
3. 该方法在无法识别动作、有多种结果时，利用语音交互进行确认，有进一步改进空间
4. NLP engine依赖于SR处理结果，若存在文本识别错误，或arms识别成arm等情况，则后续无法处理
5. 仅限英语。
6. 未建立知识库，只是建立了本体库。动作或任务的类型和数量有局限，不具备自学习能力},
  doi        = {https://doi.org/10.1016/j.ipm.2019.102094},
  file       = {:FILES/2020 - ReforgiatoRecupero2020 -Knowledge acquisition from parsing natural language expressions.pdf:PDF},
  groups     = {task understanding, ontology based},
  keywords   = {Humanoid robot, Robot action ontology, Language understanding, Human-Robot dialogue, Ontology design, read},
  printed    = {Y},
  readstatus = {read},
  url        = {https://www.sciencedirect.com/science/article/pii/S0306457319303322},
}

@InProceedings{Huo2014,
  author    = {Huo, Zhiyu and Alexenko, Tatiana and Skubic, Marjorie},
  booktitle = {Proceedings of the 2014 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {Using spatial language to drive a robot for an indoor environment fetch task},
  year      = {2014},
  address   = {Chicago, IL, USA},
  month     = sep,
  pages     = {1361--1366},
  publisher = {IEEE},
  abstract  = {This paper proposes a system that allows the use of natural spatial language to control a robot performing a fetch task in an indoor environment. The system processes spatial referencing language and extracts a tree structure of language chunks. The spatial language system is then grounded to a robot navigation instruction in the form of a sequence of actions based on spatial references to furniture and room structure; the best navigation instruction is selected by scoring. In addition, the Reference-Direction-Target (RDT) model is proposed to represent indoor robot actions. To control the robot for the fetch task, a behavior model is designed based on the RDT model. An assistive robot has been designed and programmed based on this system. The proposed spatial language grounding model and robot behavior model are tested experimentally in three sets of experiments. Results show that the system enables a robot to follow spatial language commands in a physical indoor environment even if the referenced furniture items are re-positioned.},
  comment   = {Zhang2019a: indoor or outdoor navigation},
  doi       = {10.1109/IROS.2014.6942734},
  file      = {:FILES/2014 - Huo2014 - Using spatial language to drive a robot for an indoor environment fetch task.pdf:PDF},
  groups    = {task understanding},
  issn      = {2153-0866},
  url       = {https://ieeexplore.ieee.org/abstract/document/6942734},
}

@Article{Tao2017a,
  author   = {Tao, Yang and Ding, Linlin and Ganz, Aura},
  journal  = {IEEE Access},
  title    = {Indoor navigation validation framework for visually impaired users},
  year     = {2017},
  issn     = {2169-3536},
  month    = oct,
  pages    = {21763--21773},
  volume   = {5},
  abstract = {In this paper, we introduce the first validation framework of an indoor navigation system for blind and visually impaired (BVI) users, which is a significant step toward the development of cost effective indoor way-finding solutions for BVI users. The BVI users require detailed landmark-based navigation instructions that will help them arrive at the chosen destination independently. These users will interact with the navigation instructions on a smartphone using an accessible user interface. The validation framework includes the following three main components: 1) virtual reality-based simulation that simulates a BVI user traversing and interacting with the physical environment, developed using Unity game engine; 2) generation of action codes that emulate the avatar movement in the virtual environment, developed using a natural language processing parser of the navigation instructions; and 3) accessible user interface, which enables the user to access the navigation instructions, developed using Sikuli script library. We introduce a case study that illustrates the use of the validation tool using PERCEPT system. It is our strong belief that the validation framework we provide in this paper will encourage other developers to invent indoor navigation systems for BVI users. In addition, we would like to mention that this tool is the first step of validating an indoor navigation system and should be followed by trials with human subjects.},
  comment  = {Zhang2019a: indoor or outdoor navigation},
  doi      = {10.1109/ACCESS.2017.2761698},
  file     = {:FILES/2017 - Tao2017a - Indoor Navigation Validation Framework for Visually Impaired Users.pdf:PDF},
  groups   = {task understanding},
  url      = {https://ieeexplore.ieee.org/document/8063454},
}

@InProceedings{Tan2014,
  author    = {Tan, Jiacheng and Ju, Zhaojie and Liu, Honghai},
  booktitle = {Proceedings of the 2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)},
  title     = {Grounding spatial relations in natural language by fuzzy representation for human-robot interaction},
  year      = {2014},
  address   = {Beijing, China},
  month     = jul,
  pages     = {1743--1750},
  publisher = {IEEE},
  abstract  = {This paper addresses the issue of grounding spatial relations in natural language for human-robot interaction and robot control. The problem is approached by identifying two set of spatial relations, the image space-based and object-centered, and expressing them as fuzzy sets to capture the ambiguity inherent to the linguistic expressions for the relations. The sizes and shades of the scene objects have also been modeled as fuzzy sets for conditioning the spatial relations. To verify the validity of our approach and test its feasibility in a natural language-based interface, we have considered the typical scenarios of using the spatial relations in simple declarative and imperative sentences and designed simple grammars for parsing such sentences. Our experiment has shown that fuzzy spatial relation analysis provides a useful way for modeling the ambiguity or imprecision of the natural language in describing spatial relations and that it is possible to use the spatial relation models to support robot control and human-robot interaction in a natural language-based interface.},
  comment   = {Zhang2019a"task instructions are usually expressed in natural language that encompasses abstract concepts"
{Kartmann2020}:spatial relations are represented as fuzzy memberships to nine image regions around an object to identify an object referred to in a command.no actions were executed on a robot. use fuzzy membership of locations to defined regions around the object},
  doi       = {10.1109/FUZZ-IEEE.2014.6891797},
  file      = {:FILES/2014 - Tan2014 - Grounding spatial relations in natural language by fuzzy representation for human-robot interaction.pdf:PDF},
  groups    = {task understanding, spatial relation},
  issn      = {1098-7584},
  url       = {https://ieeexplore.ieee.org/document/6891797},
}

@InProceedings{Lu2017b,
  author    = {Dongcai Lu and Yi Zhou and Feng Wu and Zhao Zhang and Xiaoping Chen},
  booktitle = {Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI)},
  title     = {Integrating answer set programming with semantic dictionaries for robot task planning},
  year      = {2017},
  address   = {Melbourne, Australia},
  month     = aug,
  pages     = {4361--4367},
  publisher = {International Joint Conferences on Artificial Intelligence},
  comment   = {Zhang2019a: Accuracy is often low given the ambiguity of verbs and incomplete natural language description scenarios. user instructions or high-level tasks are parsed into a series of frame elements based on predefined knowledge. These frame templates come from open resources},
  doi       = {10.24963/ijcai.2017/609},
  file      = {:FILES/2017 - Lu2017b - Integrating Answer Set Programming with Semantic Dictionaries for Robot Task Planning.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.ijcai.org/proceedings/2017/609},
}

@Article{Magassouba2018,
  author     = {Magassouba, Aly and Sugiura, Komei and Kawai, Hisashi},
  journal    = {IEEE Robotics and Automation Letters},
  title      = {A multimodal classifier generative adversarial network for carry and place tasks from ambiguous language instructions},
  year       = {2018},
  issn       = {2377-3766},
  month      = oct,
  number     = {4},
  pages      = {3113--3120},
  volume     = {3},
  abstract   = {This letter focuses on a multimodal language understanding method for carry-and-place tasks with domestic service robots. We address the case of ambiguous instructions, that is, when the target area is not specified. For instance “put away the milk and cereal” is a natural instruction where there is ambiguity regarding the target area, considering environments in daily life. Conventionally, this instruction can be disambiguated from a dialogue system, but at the cost of time and cumbersome interaction. Instead, we propose a multimodal approach, in which the instructions are disambiguated using the robot's state and environment context. We develop the Multi-Modal Classifier Generative Adversarial Network (MMC-GAN) to predict the likelihood of different target areas considering the robot's physical limitation and the target clutter. Our approach, MMC-GAN, significantly improves accuracy compared with baseline methods that use instructions only or simple deep neural networks.},
  comment    = {MMC-GAN to disambiguate target areas for the specified carry-and-place task triggered by natural language commands.

takes in the textual commands and perceived image of the environment as the input simultaneously. Due to the different modality of the inputs, the authors utilized different parsing techniques. On the one hand, the textual command sentences are vectorized using the one-hot representation, and then vectorized using the paragraph vector distributed memory (PV-DM) model \cite{Le2014}. On the other hand, the images of the environment are parsed into latent feature vectors based on the convolutional neural network.  \cite{Magassouba2018} proposed the disambiguation method called multi-modal classifier generative adversarial network (MMC-GAN) to automatically imply the target areas for the carry-and-place tasks. The method takes the linguistic commands and the perceived images of the environment as the inputs and outputs the probabilities of the recognized candidate target areas. The method is an extension of the LAtent classifier GAN (LAC-GAN) proposed in \cite{Sugiura2017}, which only takes the natural language commands as inputs.},
  doi        = {10.1109/LRA.2018.2849607},
  file       = {:FILES/2018 - Magassouba2018 - A Multimodal Classifier Generative Adversarial Network for Carry and Place Tasks From Ambiguous Language Instructions.pdf:PDF},
  groups     = {task understanding},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/document/8392364},
}

@Article{Katsuki2006,
  author    = {Rie Katsuki and Roland Siegwart and Jun Ota and Tamio Arai},
  journal   = {Advanced Robotics},
  title     = {Reasoning of abstract motion of a target object through task order with natural language -- pre-knowledge of object-handling-task programming for a service robot},
  year      = {2006},
  number    = {4},
  pages     = {391--412},
  volume    = {20},
  abstract  = {In this paper, an attempt is made to reason an abstract motion of a target object when the object is manipulated through a task order. The reasoning algorithm is used as a function in the system that navigates layman's robot programming. The task order consists of two words: Task and Target (e.g., 'switch on' and 'light'). There are three kinds of motions: Linear, Circular and Point-To-Point motion. The system chooses a suitable motion. In the reasoning, it is important to be able to reason from various input words using a limited knowledge base. Therefore, a knowledge base is proposed that consists of a thesaurus and minimum knowledge. The knowledge defines only words that directly stand for the motions (e.g., 'turn' means Circular motion). The knowledge is propagated through hypernyms and hyponyms in the thesaurus. A motion is reasoned using the propagated knowledge in Task and Target. Moreover, learning, which results from on-site updating of the knowledge from the user, achieves reinforcement/customization of the knowledge base. The system successfully reasoned motions from various task orders. Moreover, for the robot programming of a door-opening task, a robot with the reasoning system reasoned a motion of the door and realized the task.},
  comment   = {Zhang2019a: introduce a synonym dictionary， wordnet, but there are still a large number of action instructions that cannot be matched correctly},
  doi       = {10.1163/156855306776562251},
  file      = {:FILES/2016 - Katsuki2006 - Reasoning of abstract motion of a target object through task order with natural language — pre-knowledge of object-handling-task programming for a service robot.pdf:PDF},
  groups    = {task understanding},
  publisher = {Taylor & Francis},
  url       = {https://www.tandfonline.com/doi/abs/10.1163/156855306776562251},
}

@InProceedings{Zhang2016a,
  author    = {Xiaodong Zhang and Houfeng Wang},
  booktitle = {Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI)},
  title     = {A joint model of intent determination and slot filling for spoken language understanding},
  year      = {2016},
  address   = {New York, New York, USA},
  month     = jul,
  pages     = {2993--2999},
  publisher = {AAAI Press},
  comment   = {Zhang2019a:joint model for ID and SF},
  file      = {:FILES/2016 - Zhang2016a - A Joint Model of Intent Determination and Slot Filling for Spoken Language Understanding.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.ijcai.org/Abstract/16/425},
}

@InProceedings{Yao2014,
  author    = {Yao, Kaisheng and Peng, Baolin and Zweig, Geoffrey and Yu, Dong and Li, Xiaolong and Gao, Feng},
  booktitle = {Proceedings of the 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title     = {Recurrent conditional random field for language understanding},
  year      = {2014},
  address   = {Florence, Italy},
  month     = may,
  pages     = {4077--4081},
  publisher = {IEEE},
  abstract  = {Recurrent neural networks (RNNs) have recently produced record setting performance in language modeling and word-labeling tasks. In the word-labeling task, the RNN is used analogously to the more traditional conditional random field (CRF) to assign a label to each word in an input sequence, and has been shown to significantly outperform CRFs. In contrast to CRFs, RNNs operate in an online fashion to assign labels as soon as a word is seen, rather than after seeing the whole word sequence. In this paper, we show that the performance of an RNN tagger can be significantly improved by incorporating elements of the CRF model; specifically, the explicit modeling of output-label dependencies with transition features, its global sequence-level objective function, and offline decoding. We term the resulting model a “recurrent conditional random field” and demonstrate its effectiveness on the ATIS travel domain dataset and a variety of web-search language understanding datasets.},
  comment   = {Zhang2019a: recurrent neural network (RNN)

 解决的是word labeling的问题，没有包括intent determination},
  doi       = {10.1109/ICASSP.2014.6854368},
  file      = {:FILES/2016 - Yao2014 - Recurrent conditional random field for language understanding.pdf:PDF},
  groups    = {task understanding},
  issn      = {2379-190X},
  url       = {https://ieeexplore.ieee.org/abstract/document/6854368},
}

@InProceedings{Liu2016g,
  author    = {Bing Liu and Ian Lane},
  booktitle = {Proceedings of Interspeech 2016},
  title     = {Attention-based recurrent neural network models for joint intent detection and slot filling},
  year      = {2016},
  pages     = {685--689},
  comment   = {{Zhang2019a}:对比方法：attention-based model},
  doi       = {10.21437/Interspeech.2016-1352},
  file      = {:FILES/2016 - Liu2016g - Attention-based recurrent neural network models for joint intent detection and slot filling.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.isca-speech.org/archive/Interspeech_2016/abstracts/1352.html},
}

@Article{Qiu2018,
  author   = {Qiu, Lirong and Chen, Yida and Jia, Haoran and Zhang, Zhen},
  journal  = {IEEE Access},
  title    = {Query intent recognition based on multi-class features},
  year     = {2018},
  issn     = {2169-3536},
  month    = sep,
  pages    = {52195--52204},
  volume   = {6},
  abstract = {In order to enhance the user search experience of the search engine, an intent recognition search based on natural language input is proposed. By using reality mining technology to obtain the potential consciousness information from the query expression, search engines can better predict the query results that meet users' requirements. With the development of conventional machine learning and deep learning, it is possible to further improve the accuracy of prediction results. This paper adopts a similarity calculation method based on long short-term memory (LSTM) and a traditional machine learning method based on multi-feature extraction. It is found that entity features can significantly improve the accuracy of intention classification. Second, the accuracy of intention classification based on the feature sequence constructed by key entities is up to 94.16% in the field of manual labeling by using the BiLSTM classification model.},
  comment  = {{Zhang2019a}:"Most of the DNN based studies focus on simple query statements, but the performance improvement in task understanding for service
robots is not significant"

本文和robot没有关系},
  doi      = {10.1109/ACCESS.2018.2869585},
  file     = {:FILES/2018 - Qiu2018 - Query intent recognition based on multi-class features.pdf:PDF},
  url      = {https://ieeexplore.ieee.org/abstract/document/8458426},
}

@InProceedings{Goo2018,
  author    = {Goo, Chih-Wen and Gao, Guang and Hsu, Yun-Kai and Huo, Chih-Li and Chen, Tsung-Chieh and Hsu, Keng-Wei and Chen, Yun-Nung},
  booktitle = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},
  title     = {Slot-gated modeling for joint slot filling and intent prediction},
  year      = {2018},
  address   = {New Orleans, Louisiana},
  month     = jun,
  pages     = {753--757},
  publisher = {Association for Computational Linguistics},
  abstract  = {Attention-based recurrent neural network models for joint intent detection and slot filling have achieved the state-of-the-art performance, while they have independent attention weights. Considering that slot and intent have the strong relationship, this paper proposes a slot gate that focuses on learning the relationship between intent and slot attention vectors in order to obtain better semantic frame results by the global optimization. The experiments show that our proposed model significantly improves sentence-level semantic frame accuracy with 4.2{\%} and 1.9{\%} relative improvement compared to the attentional model on benchmark ATIS and Snips datasets respectively},
  comment   = {{Zhang2019a}:本文相似方法：对比方法slot-gated model with a single gate,the slotgated mechanism has been proposed to guide joint optimization by simply modeling the overall proportional relationship between the two tasks. h uses only a single gate to model the global contribution ratio of ID task to SF task


intention and slot recognition methods, but not for robots.},
  doi       = {10.18653/v1/N18-2118},
  file      = {:FILES/2018 - Goo2018 - Slot-Gated Modeling for Joint Slot Filling and Intent Prediction.pdf:PDF},
  url       = {https://www.aclweb.org/anthology/N18-2118},
}

@InProceedings{Zhou2015a,
  author    = {Zhou, Jie and Xu, Wei},
  booktitle = {Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing},
  title     = {End-to-end learning of semantic role labeling using recurrent neural networks},
  year      = {2015},
  address   = {Beijing, China},
  month     = jul,
  pages     = {1127--1137},
  publisher = {Association for Computational Linguistics},
  comment   = {{Zhang2019a}:本文相似的方法：adding hand-crafted features to the input of neural networks can improve prediction performance

跟机器人无关。},
  doi       = {10.3115/v1/P15-1109},
  file      = {:FILES/2015 - Zhou2015a - End-to-end learning of semantic role labeling using recurrent neural networks.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.aclweb.org/anthology/P15-1109},
}

@InProceedings{Mees2020,
  author    = {Mees, Oier and Emek, Alp and Vertens, Johan and Burgard, Wolfram},
  booktitle = {Proceedings of the 2020 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Learning object placements for relational instructions by hallucinating scene representations},
  year      = {2020},
  address   = {Paris, France},
  month     = may,
  pages     = {94--100},
  publisher = {IEEE},
  abstract  = {Robots coexisting with humans in their environment and performing services for them need the ability to interact with them. One particular requirement for such robots is that they are able to understand spatial relations and can place objects in accordance with the spatial relations expressed by their user. In this work, we present a convolutional neural network for estimating pixelwise object placement probabilities for a set of spatial relations from a single input image. During training, our network receives the learning signal by classifying hallucinated high-level scene representations as an auxiliary task. Unlike previous approaches, our method does not require ground truth data for the pixelwise relational probabilities or 3D models of the objects, which significantly expands the applicability in practical applications. Our results obtained using real-world data and human-robot experiments demonstrate the effectiveness of our method in reasoning about the best way to place objects to reproduce a spatial relation. Videos of our experiments can be found at https://youtu.be/zaZkHTWFMKM.},
  comment   = {{Kartmann2020}:"基于图像。realization of a given spatial relation by manipulating the current scene. predicting these distributions over pixels of an image.  train a neural network to predict pixel-wise probability maps of placement positions for different spatial relations given an input image of the scene to place an object according to a
verbal command."},
  doi       = {10.1109/ICRA40945.2020.9197472},
  file      = {:FILES/2020 - Mees2020 - Learning Object Placements For Relational Instructions by Hallucinating Scene Representations.pdf:PDF},
  groups    = {spatial relation},
  issn      = {2577-087X},
  url       = {https://ieeexplore.ieee.org/abstract/document/9197472},
}

@InProceedings{Stopp1994,
  author    = {Stopp, Eva and Gapp, Klaus-Peter and Herzog, Gerd and Laengle, Thomas and Lueth, Tim C.},
  booktitle = {KI-94: Advances in Artificial Intelligence},
  title     = {Utilizing spatial relations for natural language access to an autonomous mobile robot},
  year      = {1994},
  address   = {Berlin, Heidelberg},
  editor    = {Nebel, Bernhard and Dreschler-Fischer, Leonie},
  pages     = {39--50},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Natural language, a primary communication medium for humans, facilitates better human-machine interaction and could be an efficient means to use intelligent robots in a more flexible manner. In this paper, we report on our joint efforts at providing natural language access to the autonomous mobile two-arm robot Kamro. The robot is able to perform complex assembly tasks. To achieve autonomous behaviour, several camera systems are used for the perception of the environment during task execution. Since natural language utterances must be interpreted with respect to the robot's current environment the processing must be based on a referential semantics that is perceptually anchored. Considering localization expressions, we demonstrate how, on the one hand, verbal descriptions, and on the other hand, knowledge about the physical environment, i.e., visual and geometric information, can be connected to each other.},
  comment   = {{Kartmann2020}:introduce the applicability of different spatial relations as potential fields around an object based on user-defined cubic splines.no actions were executed on a robot.To cope with uncertainties in spatial relations, a continuous measure of applicability based on user-defined cubic splines is used},
  file      = {:FILES/1994 - Stopp1994 - Utilizing spatial relations for natural language access to an autonomous mobile robot.pdf:PDF},
  groups    = {spatial relation},
  isbn      = {978-3-540-48979-5},
  url       = {https://link.springer.com/chapter/10.1007/3-540-58467-6_4},
}

@InProceedings{Nicolescu2019,
  author       = {Nicolescu, Monica and Arnold, Natalie and Blankenburg, Janelle and Feil-Seifer, David and Banisetty, Santosh and Nicolescu, Mircea and Palmer, Andrew and Monteverde, Thor},
  booktitle    = {2019 IEEE-RAS 19th International Conference on Humanoid Robots (Humanoids)},
  title        = {Learning of complex-structured tasks from verbal instruction},
  year         = {2019},
  organization = {IEEE},
  pages        = {747--754},
  comment      = {{Kartmann2020}:Prepositions from natural language commands are incorporated as action parameters in a task representation},
  file         = {:FILES/2019 - Nicolescu2019 - Learning of complex-structured tasks from verbal instruction.pdf:PDF},
  groups       = {spatial relation},
}

@Article{Loeliger2004,
  author  = {Loeliger, {Hans-Andrea}},
  journal = {IEEE Signal Processing Magazine},
  title   = {An introduction to factor graphs},
  year    = {2004},
  number  = {1},
  pages   = {28--41},
  volume  = {21},
  doi     = {10.1109/MSP.2004.1267047},
  file    = {:FILES/2004 - Loeliger2004 - An introduction to factor graphs.pdf:PDF},
  groups  = {mathematical basis},
  url     = {https://ieeexplore.ieee.org/abstract/document/1267047/},
}

@InProceedings{Savage2009,
  author    = {Savage, Jesus and Weitzenfeld, Alfredo and Ayala, Francisco and Cuellar, Sergio},
  booktitle = {RoboCup 2008: Robot Soccer World Cup XII},
  title     = {The use of scripts based on conceptual dependency primitives for the operation of service mobile robots},
  year      = {2009},
  address   = {Berlin, Heidelberg},
  editor    = {Iocchi, Luca and Matsubara, Hitoshi and Weitzenfeld, Alfredo and Zhou, Changjiu},
  pages     = {284--295},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {This paper describes a Human-Robot interaction subsystem that is part of a robotics architecture, the ViRbot, used to control the operation of service mobile robots. The Human/Robot Interface subsystem consists of tree modules: Natural Language Understanding, Speech Generation and Robot's Facial Expressions. To demonstrate the utility of this Human-Robot interaction subsystem it is presented a set of applications that allows a user to command a mobile robot through spoken commands. The mobile robot accomplish the required commands using an actions planner and reactive behaviors. In the ViRbot architecture the actions planner module uses Conceptual Dependency (CD) primitives as the base for representing the problem domain. After a command is spoken a CD representation of it is generated, a rule base system takes this CD representation, and using the state of the environment generates other subtasks represented by CDs to accomplish the command. In this paper is also presented how to represent context through scripts. Using scripts it is easy to make inferences about events for which there are incomplete information or are ambiguous. Scripts serve to encode common sense knowledge. Scripts are also used to fill the gaps between seemingly unrelated events.},
  file      = {:FILES/2009 - Savage2009 - The use of scripts based on conceptual dependency primitives for the operation of service mobile robots.pdf:PDF},
  groups    = {task understanding},
  isbn      = {978-3-642-02921-9},
  url       = {https://link.springer.com/chapter/10.1007/978-3-642-02921-9_25},
}

@InProceedings{Fried2018,
  author    = {Fried, Daniel and Andreas, Jacob and Klein, Dan},
  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  title     = {Unified pragmatic models for generating and following instructions},
  year      = {2018},
  address   = {New Orleans, Louisiana},
  month     = jun,
  pages     = {1951--1963},
  publisher = {Association for Computational Linguistics},
  abstract  = {We show that explicit pragmatic inference aids in correctly generating and following natural language instructions for complex, sequential tasks. Our pragmatics-enabled models reason about why speakers produce certain instructions, and about how listeners will react upon hearing them. Like previous pragmatic models, we use learned base listener and speaker models to build a pragmatic speaker that uses the base listener to simulate the interpretation of candidate descriptions, and a pragmatic listener that reasons counterfactually about alternative descriptions. We extend these models to tasks with sequential structure. Evaluation of language generation and interpretation shows that pragmatic inference improves state-of-the-art listener models (at correctly interpreting human instructions) and speaker models (at producing instructions correctly interpreted by humans) in diverse settings.},
  doi       = {10.18653/v1/N18-1177},
  file      = {:FILES/2018 - Fried2018 - Unified Pragmatic Models for Generating and Following Instructions.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.aclweb.org/anthology/N18-1177},
}

@InProceedings{Schermerhorn2007,
  author    = {P. Schermerhorn and J. Kramer and T. Brick and D. Anderson and A. Dingler and M. Scheutz},
  booktitle = {Mobile Robot Competition and Exhibition - Papers from the 2006 AAAI Workshop, Technical Report},
  title     = {{DIARC}: {A} testbed for natural human-robot interaction},
  year      = {2007},
  month     = dec,
  pages     = {45--52},
  series    = {AAAI Workshop - Technical Report},
  abstract  = {DIARC, a distributed integrated affect, reflection, cognition architecture for robots, provides many features that are critical to successful natural human-robot interaction. As such, DIARC is an ideal platform for experimentation in HRI. In this paper we describe the architecture and and its implementation in ADE, paying particular attention to its interaction capabilities and features that allow robust operation. These features are evaluated in the context of the 2006 AAAI Robot Competition.},
  comment   = {Savage2019:DIARC:  emphasizes (1) natural language understanding and action execution, and (2) perceptual learning through human teaching.},
  file      = {:FILES/2007 - Schermerhorn2007 - DIARC- A testbed for natural human-robot interaction.pdf:PDF},
  groups    = {task understanding},
  isbn      = {9781577353201},
}

@TechReport{Mueller1993,
  author      = {J\"{o}rg P. M\"{u}ller and Markus Pischel},
  institution = {German Research Center for Artificial Intelligence},
  title       = {The agent architecture {inteRRaP}: {Concept} and application},
  year        = {1993},
  note        = {RR 93-26},
  abstract    = {One of the basic questions of research in
                  Distributed Articial Intelligence DAI is how agents
                  have to be structured and organized and what
                  functionalities they need in order to be able to act
                  and to interact in a dynamic environment To cope
                  with this question is the purpose of models and
                  architectures for autonomous and intelligent agents
                  In the rst part of this report InteRRaP an agent
                  architecture for multiagent systems is presented The
                  basic idea is to combine the use of patterns of
                  behaviour with planning facilities in order to be
                  able to exploit the advantages both of the reactive
                  behaviourbased and of the deliberate planbased
                  paradigm Patterns of behaviour allow an agent to
                  react exibly to changes in its environment What is
                  considered necessary for the performance of more
                  sophisticated tasks is the ability of devising plans
                  deliberately A further important feature of the
                  model is that it explicitly represents knowledge and
                  strategies for coopera tion This makes the model
                  suitable for describing highlevel interaction among
                  autonomous agents In the second part the loadingdock
                  domain is presented which has been the rst
                  application the InteRRaP agent model has been tested
                  with An automated loadingdock is described where the
                  agent society consists of forklifts which have to
                  load and unload trucks in a shared environment},
  comment     = {不涉及任务理解。

提出了一种agent model, i.e., INTERRAP, which consists of knowledge base and multi-stage control unit. 适用于多机协同，但是不涉及人机交互。
1 将pattern of behavior (action)定义为rule-based programming language OPS-5【For82】, (name attr val attr val...) (multi-agent extension MAGSY 【FW92】)， 需要知道behavior的activation condition, outcome of execution, termination and failure condition等。更一般的，包括name of pattern, static priority, participants, situational contex (需要与current context匹配才可以执行), mental context (goal by executing pattern), postconditions, termination condition, failure condition
2. KB与RATMAN agent【BM91】的方法相同，包括world model （如robot's capability and capacities, represented as KRIS【BH90】）, behavioral knowledge（pattern of behavior, + primitive action表示为precondition-action-postcondition三元组）, planning knowledge (tree structure), cooperation knowledge,层次结构。},
  file        = {:FILES/1993 - Mueller1993 - The agent architecture inte{RR}a{P}- Concept and application.pdf:PDF},
  groups      = {representation},
  keywords    = {multiagent application planning},
  readstatus  = {skimmed},
  url         = {http://jmvidal.cse.sc.edu/library/muller93a.pdf},
}

@InProceedings{Neo2008,
  author    = {Ee Sian Neo and Takeshi Sakaguchi and Kazuhito Yokoi},
  booktitle = {Proceedings of the 2008 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)},
  title     = {A natural language instruction system for humanoid robots integrating situated speech recognition, visual recognition and on-line whole-body motion generation},
  year      = {2008},
  address   = {i'an, China},
  month     = jul,
  pages     = {1176--1182},
  publisher = {IEEE},
  abstract  = {This paper presents an integrated on-line operation system that enables a human user to operate humanoid robots by using natural language instructions. This paper has two major contributions. First, we present an integrated behavior system that is able to trigger behaviors according to speech commands, by recognizing objects, triggering actions and generating whole body motions on-line. Second, we present a situated natural language instruction system that is able not only to act according to speech commands, but also response to the direction of the sound source. A system that is able to understand natural language instructions and act accordingly will need the integration of knowledge representation, perception, decision making and on-line motion generation technologies. This paper tackles this integration problem by addressing the issues of representing knowledge of objects and actions which facilitates natural language instructions for tasks in indoor human environments. We propose a taxonomy of objects in indoor human environments and a lexicon of actions in this preliminary attempt to construct a reliable and flexible natural language instruction system. We report on the implementation of the proposed system on humanoid robot HRP-2, which is able to locate auditory sources and receive natural language instructions from a user within 2 meters using a 8-channel microphone array connected to a speech recognition embedded system on-board the robot.},
  doi       = {10.1109/AIM.2008.4601829},
  file      = {:FILES/2008 - Neo2008 - A natural language instruction system for humanoid robots integrating situated speech recognition, visual recognition and on-line whole-body motion generation.pdf:PDF},
  groups    = {task understanding},
  issn      = {2159-6255},
  url       = {https://ieeexplore.ieee.org/abstract/document/4601829},
}

@PhdThesis{Nyga2017,
  author   = {Daniel Nyga},
  school   = {University of Bremen},
  title    = {Interpretation of natural-language robot instructions: {Probabilistic} kowledge representation, learning, and reasoning},
  year     = {2017},
  abstract = {A robot that can be simply told in natural language what to do -- this has been one of the ultimate long-standing goals in both Artificial Intelligence and Robotics research. In near-future applications, robotic assistants and companions will have to understand and perform commands such as set the table for dinner'', make pancakes for breakfast'', or cut the pizza into 8 pieces.'' Although such instructions are only vaguely formulated, complex sequences of sophisticated and accurate manipulation activities need to be carried out in order to accomplish the respective tasks. The acquisition of knowledge about how to perform these activities from huge collections of natural-language instructions from the Internet has garnered a lot of attention within the last decade. However, natural language is typically massively unspecific, incomplete, ambiguous and vague and thus requires powerful means for interpretation. This work presents PRAC -- Probabilistic Action Cores -- an interpreter for natural-language instructions which is able to resolve vagueness and ambiguity in natural language and infer missing information pieces that are required to render an instruction executable by a robot. To this end, PRAC formulates the problem of instruction interpretation as a reasoning problem in first-order probabilistic knowledge bases. In particular, the system uses Markov logic networks as a carrier formalism for encoding uncertain knowledge. A novel framework for reasoning about unmodeled symbolic concepts is introduced, which incorporates ontological knowledge from taxonomies and exploits semantically similar relational structures in a domain of discourse. The resulting reasoning framework thus enables more compact representations of knowledge and exhibits strong generalization performance when being learnt from very sparse data. Furthermore, a novel approach for completing directives is presented, which applies semantic analogical reasoning to transfer knowledge collected from thousands of natural-language instruction sheets to new situations. In addition, a cohesive processing pipeline is described that transforms vague and incomplete task formulations into sequences of formally specified robot plans. The system is connected to a plan executive that is able to execute the computed plans in a simulator. Experiments conducted in a publicly accessible, browser-based web interface showcase that PRAC is capable of closing the loop from natural-language instructions to their execution by a robot.},
  comment  = {Savage2019: encode knowledge differently. He explores how to deal with ambiguity in NL and how to make inferences from missing information to create instructions that a robot can execute, using Markov logic networks for encoding uncertain knowledge},
  file     = {:FILES/2017 - Nyga2017 - Interpretation of natural-language robot instructions- {Probabilistic} kowledge representation, learning, and reasoning.pdf:PDF},
  groups   = {task understanding},
  keywords = {Natural-language Understanding, Robotics, Probabilistic Models, Knowledge Representation, Statistical Relational Learning, Markov logic networks},
  url      = {https://media.suub.uni-bremen.de/handle/elib/1215},
}

@Article{GuerraFilho2007,
  author   = {{Guerra-Filho}, Gutemberg and Aloimonos, Yiannis},
  journal  = {Computer},
  title    = {A language for human action},
  year     = {2007},
  issn     = {1558-0814},
  month    = may,
  number   = {5},
  pages    = {42--51},
  volume   = {40},
  abstract = {Human-centered computing (HCC) involves conforming computer technology to humans while naturally achieving human-machine interaction. In a human-centered system, the interaction focuses on human requirements, capabilities, and limitations. These anthropocentric systems also focus on the consideration of human sensory-motor skills in a wide range of activities. This ensures that the interface between artificial agents and human users accounts for perception and action in a novel interaction paradigm. In turn, this leads to behavior understanding through cognitive models that allow content description and, ultimately, the integration of real and virtual worlds. Our work focuses on building a language that maps to the lower-level sensory and motor languages and to the higher-level natural language. An empirically demonstrated human activity language provides sensory-motor-grounded representations for understanding human actions. A linguistic framework allows the analysis and synthesis of these actions.},
  comment  = {{SuarezBonilla2019}: robot control  language},
  doi      = {10.1109/MC.2007.154},
  file     = {:FILES/2007 -  GuerraFilho2007 - A language for human action.pdf:PDF},
  groups   = {task understanding},
  url      = {https://ieeexplore.ieee.org/abstract/document/4198245},
}

@InProceedings{Ferrein2016,
  author    = {Ferrein, Alexander and Maier, Christopher and M{\"u}hlbacher, Clemens and Niemueller, Tim and Steinbauer, Gerald and Vassos, Stavros},
  booktitle = {Intelligent Robotics and Applications},
  title     = {Controlling logistics robots with the action-based language {YAGI}},
  year      = {2016},
  address   = {Cham},
  editor    = {Kubota, Naoyuki and Kiguchi, Kazuo and Liu, Honghai and Obo, Takenori},
  pages     = {525--537},
  publisher = {Springer International Publishing},
  abstract  = {To achieve any meaningful tasks, a robot needs some form of task-level executive which acquires knowledge, reasons or plans, and performs and monitors actions. A formal approach for such agent programming is the Golog agent programming language. Golog is based on a first-order logic representation, and a drawback of common implementations is that in order to program agents, also knowledge of Prolog functionality is typically needed. In this paper, we present a prototype implementation of YAGI, a language rooted in Golog that offers a practical subset of the rich Golog framework in a more familiar syntax. Bridging imperative-style programming with an action-based specification, YAGI is more accessible to developers and provides a better ground for robot task-level executives. Moreover, we developed bindings for popular robotics frameworks such as ROS and Fawkes. As a proof of concept we present a YAGI-based agent for the RoboCup Logistics League which shows the expressiveness and the possibility to easily embed YAGI into robot applications.},
  comment   = {robot control language},
  file      = {:FILES/2016 - Ferrein2016 - Controlling Logistics Robots with the Action-Based Language YAGI.pdf:PDF},
  groups    = {task understanding},
  isbn      = {978-3-319-43506-0},
  url       = {https://link.springer.com/chapter/10.1007/978-3-319-43506-0_46},
}

@InProceedings{Zhang2015a,
  author    = {Zhang, Shiqi and Yang, Fangkai and Khandelwal, Piyush and Stone, Peter},
  booktitle = {Logic Programming and Nonmonotonic Reasoning},
  title     = {Mobile robot planning using action language {BC} with an abstraction hierarchy},
  year      = {2015},
  address   = {Cham},
  editor    = {Calimeri, Francesco and Ianni, Giovambattista and Truszczynski, Miroslaw},
  pages     = {502--516},
  publisher = {Springer International Publishing},
  abstract  = {Planning in real-world environments can be challenging for intelligent robots due to incomplete domain knowledge that results from unpredictable domain dynamism, and due to lack of global observability. Action language {\$}{\$}{\backslash}mathcal{\{}BC{\}}{\$}{\$}can be used for planning by formalizing the preconditions and (direct and indirect) effects of actions, and is especially suited for planning in robotic domains by incorporating defaults with the incomplete domain knowledge. However, planning with {\$}{\$}{\backslash}mathcal{\{}BC{\}}{\$}{\$}is very computationally expensive, especially when action costs are considered. We introduce algorithm PlanHG for formalizing {\$}{\$}{\backslash}mathcal{\{}BC{\}}{\$}{\$}domains at different abstraction levels in order to trade optimality for significant efficiency improvement when aiming to minimize overall plan cost. We observe orders of magnitude improvement in efficiency compared to a standard ``flat'' planning approach.},
  comment   = {robot control language

提出一种action language，或者说是action representation，以及相应的规划方法},
  file      = {:FILES/2015 - Zhang2015a - Mobile Robot Planning Using Action Language  BC with an Abstraction Hierarchy.pdf:PDF},
  groups    = {task understanding},
  isbn      = {978-3-319-23264-5},
  url       = {https://link.springer.com/chapter/10.1007/978-3-319-23264-5_42},
}

@InProceedings{Elmaghraby1988,
  author     = {Elmaghraby, A. S.},
  booktitle  = {Conference Proceedings '88., IEEE Southeastcon},
  title      = {A robot control language},
  year       = {1988},
  address    = {Knoxville, TN, USA},
  month      = apr,
  pages      = {413--416},
  publisher  = {IEEE},
  comment    = {robot control language},
  doi        = {10.1109/SECON.1988.194888},
  file       = {:FILES/1988 - Elmaghraby1988 - A robot control language.pdf:PDF},
  groups     = {task understanding},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/abstract/document/194888},
}

@InProceedings{Chen1988,
  author     = {Baokang Chen and Vuliang Xu},
  booktitle  = {Proceedings of the 1988 IEEE International Conference on Systems, Man, and Cybernetics},
  title      = {{ZDRL}: {A} motion-oriented robot programming language},
  year       = {1988},
  address    = {Beijing, China},
  month      = aug,
  pages      = {1226--1229},
  publisher  = {IEEE},
  volume     = {2},
  comment    = {robot control language


1.本文提出了一种motion-oriented robot language, ZDRL (Zhe Da Robot Language). 优点是lower computer requirement, abundant language control structure and diverse debugging facilities.
(1)其中包含system command (32,如定义未知、program editing, program and location data listing等) and program instruction (37， such as motion, hand control, integer variable processing, system status and control等)
(2)使用了二元关系（比较）logical operation command
(3)Motion type 包括jointinterpolated, straight- line interpolated. and geometry circle interpolated motion
2.已有的robot language, including WAVE (first, 1973【2】), VAL, MCL， JAR, RPL, AML, HELP 【1,3】.
(1)Motion-oriented: It s kernel is various motion statements with respect to a robot h and or gripper
(2)Task-oriented
(3)Object-oriented},
  doi        = {10.1109/ICSMC.1988.712918},
  file       = {:FILES/1988 - Chen1988 - ZDRL- A Motion-Oriented Robot Programming Language.pdf:PDF},
  groups     = {task understanding},
  readstatus = {skimmed},
  url        = {https://ieeexplore.ieee.org/abstract/document/712918},
}

@InProceedings{Thomason2017,
  author    = {Jesse Thomason and Aishwarya Padmakumar and Jivko Sinapov and Justin Hart and Peter Stone and Raymond J. Mooney},
  booktitle = {Proceedings of the 1st Annual Conference on Robot Learning},
  title     = {Opportunistic active learning for grounding natural language descriptions},
  year      = {2017},
  editor    = {Sergey Levine and Vincent Vanhoucke and Ken Goldberg},
  month     = nov,
  pages     = {67--76},
  publisher = {PMLR},
  series    = {Proceedings of Machine Learning Research},
  volume    = {78},
  abstract  = {Active learning identifies data points from a pool of unlabeled examples whose labels, if made available, are most likely to improve the predictions of a supervised model. Most research on active learning assumes that an agent has access to the entire pool of unlabeled data and can ask for labels of any data points during an initial training phase. However, when incorporated in a larger task, an agent may only be able to query some subset of the unlabeled pool. An agent can also opportunistically query for labels that may be useful in the future, even if they are not immediately relevant. In this paper, we demonstrate that this type of opportunistic active learning can improve performance in grounding natural language descriptions of everyday objects—an important skill for home and office robots. We find, with a real robot in an object identification setting, that inquisitive behavior—asking users important questions about the meanings of words that may be off-topic for the current dialog—leads to identifying the correct object more often over time.},
  comment   = {Thomasan2019: active learning for acquiring concepts of objects},
  file      = {:FILES/2017 - Thomason2017 - Opportunistic Active Learning for Grounding Natural Language Descriptions.pdf:PDF},
  groups    = {task understanding},
  url       = {http://proceedings.mlr.press/v78/thomason17a.html},
}

@InProceedings{Anderson2018,
  author     = {Anderson, Peter and Wu, Qi and Teney, Damien and Bruce, Jake and Johnson, Mark and S\"{u}nderhauf, Niko and Reid, Ian and Gould, Stephen and van den Hengel, Anton},
  booktitle  = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title      = {Vision-and-language navigation: {Interpreting} visually-grounded navigation instructions in real environments},
  year       = {2018},
  address    = {Salt Lake City, UT, USA},
  month      = jun,
  pages      = {3674--3683},
  publisher  = {IEEE},
  comment    = {Thomason2019: naviage in unknown environment based on semantic parsing

本文讨论的是设计一种虚拟仿真环境，以及相应的数据集，用以实现利用visual perception and natural language instruction navigation.同时，提出了一种baseline，基于的是end-2-end model，i.e. LSTM and attention based seq-2-seq model (for language and image, respectively). 数据的获取是在AMT上，得到path description from the start location to the goal location. the instruction vocabulary is relatively constrained, consisting of around 3.1k words (approximately 1.2k with five or more mentions).文中给出了常见句式的distribution， Fig 6.},
  doi        = {10.1109/CVPR.2018.00387},
  file       = {:FILES/2018 - Anderson2018 - Vision-and-Language Navigation- Interpreting Visually-Grounded Navigation Instructions in Real Environments.pdf:PDF;:FILES/notes/Anderson2018.xlsx:Excel 2007+},
  groups     = {task understanding, navigation},
  printed    = {Y},
  priority   = {prio1},
  readstatus = {read},
  url        = {https://ieeexplore.ieee.org/document/8578485},
}

@InProceedings{Wang2018a,
  author     = {Wang, Xin and Xiong, Wenhan and Wang, Hongmin and Wang, William Yang},
  booktitle  = {Computer Vision -- European Conference on Computer Vision (ECCV) 2018},
  title      = {Look before you leap: {Bridging} model-free and model-based reinforcement learning for planned-ahead vision-and-language navigation},
  year       = {2018},
  address    = {Cham},
  editor     = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
  pages      = {38--55},
  publisher  = {Springer International Publishing},
  abstract   = {Existing research studies on vision and language grounding for robot navigation focus on improving model-free deep reinforcement learning (DRL) models in synthetic environments. However, model-free DRL models do not consider the dynamics in the real-world environments, and they often fail to generalize to new scenes. In this paper, we take a radical approach to bridge the gap between synthetic studies and real-world practices---We propose a novel, planned-ahead hybrid reinforcement learning model that combines model-free and model-based reinforcement learning to solve a real-world vision-language navigation task. Our look-ahead module tightly integrates a look-ahead policy model with an environment model that predicts the next state and the reward. Experimental results suggest that our proposed method significantly outperforms the baselines and achieves the best on the real-world Room-to-Room dataset. Moreover, our scalable method is more generalizable when transferring to unseen environments.},
  comment    = {Thomason2019: navigate in unknown environment based on semantic parsing},
  doi        = {10.1007/978-3-030-01270-0_3},
  file       = {:FILES/2018 - Wang2018a - Look before You Leap- Bridging Model-Free and Model-Based Reinforcement Learning for Planned-Ahead Vision-and-Language Navigation.pdf:PDF},
  groups     = {task understanding},
  isbn       = {978-3-030-01270-0},
  readstatus = {skimmed},
  url        = {https://link.springer.com/chapter/10.1007/978-3-030-01270-0_3},
}

@InProceedings{Shah2018,
  author        = {Pararth Shah and Marek Fiser and Aleksandra Faust and J. Chase Kew and Dilek Hakkani-Tur},
  booktitle     = {Proceedings of International Conference onRobotics and Automation (ICRA) 3rd Workshop in Machine Learning in the Planning and Control of Robot Motion},
  title         = {{FollowNet}: {Robot} navigation by following natural language directions with deep reinforcement learning},
  year          = {2018},
  pages         = {1--6},
  abstract      = {Understanding and following directions provided
by humans can enable robots to navigate effectively in unknown
situations. We present FollowNet, an end-to-end differentiable
neural architecture for learning multi-modal navigation policies. FollowNet maps natural language instructions as well
as visual and depth inputs to locomotion primitives. FollowNet processes instructions using an attention mechanism
conditioned on its visual and depth input to focus on the
relevant parts of the command while performing the navigation
task. Deep reinforcement learning (RL) a sparse reward learns
simultaneously the state representation, the attention function,
and control policies. We evaluate our agent on a dataset
of complex natural language directions that guide the agent
through a rich and realistic dataset of simulated homes. We
show that the FollowNet agent learns to execute previously
unseen instructions described with a similar vocabulary, and
successfully navigates along paths not encountered during
training. The agent shows 30\% improvement over a baseline
model without the attention mechanism, with 52\% success rate
at novel instructions.},
  archiveprefix = {arXiv},
  comment       = {Thomason2019: navigate in unknown environment based on semantic parsing

proposed the , an end-to-end architecture of task understanding based on natural language commands and perceived images of the environments, for navigation in unknown environments. The images are parsed so that each pixel is assigned a semantic label. The natural language commands are encoded using the single layer bidirectional GRU network and the feed-forward attention layer. The multi-modal inputs are fused together using a feed-forward attention layer to predict the Q value of the DQN, so that the action can be predicted.},
  file          = {:FILES/2018 - Shah2018 - {FollowNet}- {Robot} navigation by following natural language directions with deep reinforcement learning.pdf:PDF},
  groups        = {task understanding},
  primaryclass  = {cs.RO},
  readstatus    = {skimmed},
  url           = {https://arxiv.org/abs/1805.06150},
}

@InProceedings{Williams2018,
  author    = {Williams, Edward C. and Gopalan, Nakul and Rhee, Mine and Tellex, Stefanie},
  booktitle = {2018 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Learning to parse natural language to grounded reward functions with weak supervision},
  year      = {2018},
  address   = {Brisbane, QLD, Australia},
  month     = may,
  pages     = {4430--4436},
  publisher = {IEEE},
  abstract  = {In order to intuitively and efficiently collaborate with humans, robots must learn to complete tasks specified using natural language. We represent natural language instructions as goal-state reward functions specified using lambda calculus. Using reward functions as language representations allows robots to plan efficiently in stochastic environments. To map sentences to such reward functions, we learn a weighted linear Combinatory Categorial Grammar (CCG) semantic parser. The parser, including both parameters and the CCG lexicon, is learned from a validation procedure that does not require execution of a planner, annotating reward functions, or labeling parse trees, unlike prior approaches. To learn a CCG lexicon and parse weights, we use coarse lexical generation and validation-driven perceptron weight updates using the approach of Artzi and Zettlemoyer [4]. We present results on the Cleanup World domain [18] to demonstrate the potential of our approach. We report an F1 score of 0.82 on a collected corpus of 23 tasks containing combinations of nested referential expressions, comparators and object properties with 2037 corresponding sentences. Our goal-condition learning approach enables an improvement of orders of magnitude in computation time over a baseline that performs planning during learning, while achieving comparable results. Further, we conduct an experiment with just 6 labeled demonstrations to show the ease of teaching a robot behaviors using our method. We show that parsing models learned from small data sets can generalize to commands not seen during training.},
  comment   = {Thomason2019: language for planning},
  doi       = {10.1109/ICRA.2018.8460937},
  file      = {:FILES/2018 - Williams2018 - Learning to Parse Natural Language to Grounded Reward Functions with Weak Supervision.pdf:PDF},
  groups    = {task understanding},
  issn      = {2577-087X},
  url       = {https://ieeexplore.ieee.org/document/8460937},
}

@InProceedings{Chai2018,
  author    = {Chai, Joyce Y.},
  booktitle = {Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI)},
  title     = {Language to action: {Towards} interactive task learning with physical agents},
  year      = {2018},
  address   = {Richland, SC},
  pages     = {1--6},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  abstract  = {Language communication plays an important role in human learning and skill acquisition. With the emergence of a new generation of cognitive robots, empowering these physical agents to learn directly from human partners about the world and joint tasks becomes increasingly important. In this talk, I will share some recent work on interactive task learning where humans can teach physical agents new tasks through natural language communication and demonstration. I will give examples of language use in interactive task learning and discuss multiple levels of grounding that are critical in this process. I will demonstrate the importance of common-sense knowledge, particularly the acquisition of very basic physical causality knowledge, in grounding human language to actions not only perceived but also performed by the agent. As humans and agents often have mismatched capabilities and knowledge, I will highlight the role of collaboration in communicative grounding to mediate differences and strive for a common ground of joint representations.},
  comment   = {Thomason2019: learnin actions from dialog system},
  file      = {:FILES/2018 - Chai2018 - Language to Action- Towards Interactive Task Learning with Physical Agents.pdf:PDF},
  groups    = {task understanding},
  keywords  = {interactive task learning, natural language processing, human-robot communication},
  location  = {Stockholm, Sweden},
  url       = {https://dl.acm.org/doi/abs/10.5555/3237383.3237390},
}

@InProceedings{Nyga2018,
  author       = {Nyga, Daniel and Roy, Subhro and Paul, Rohan and Park, Daehyung and Pomarlan, Mihai and Beetz, Michael and Roy, Nicholas},
  booktitle    = {Proceedings of the 2018 Conference on Robot Learning (CoRL)},
  title        = {Grounding robot plans from natural language instructions with incomplete world knowledge},
  year         = {2018},
  organization = {PMLR},
  pages        = {714--723},
  comment      = {Thomason2019: language for planning},
  file         = {:FILES/2018 - Nyga2018 - Grounding robot plans from natural language instructions with incomplete world knowledge.pdf:PDF},
  groups       = {task understanding},
  url          = {https://koasas.kaist.ac.kr/handle/10203/277548},
}

@InProceedings{Paul2017,
  author    = {Rohan Paul and Andrei Barbu and Sue Felshin and Boris Katz and Nicholas Roy},
  booktitle = {Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI)},
  title     = {Temporal grounding graphs for language understanding with accrued visual-linguistic context},
  year      = {2017},
  address   = {Melbourne, Australia},
  month     = aug,
  pages     = {4506--4514},
  publisher = {International Joint Conferences on Artificial Intelligence},
  comment   = {Thomason2019: memorize semantic reference in a dialog},
  doi       = {10.24963/ijcai.2017/629},
  file      = {:FILES/2017 - Paul2017 - Temporal Grounding Graphs for Language Understanding with Accrued Visual-Linguistic Context.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.ijcai.org/Proceedings/2017/629},
}

@InProceedings{Parde2015,
  author    = {Natalie Parde and Adam Hair and Michalis Papakostas and Konstantinos Tsiakas and Maria Dagioglou and Vangelis Karkaletsis and Rodney D. Nielsen},
  booktitle = {Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)},
  title     = {Grounding the meaning of words through vision and interactive gameplay},
  year      = {2015},
  address   = {Buenos Aires, Argentina},
  month     = jul,
  pages     = {1895--1901},
  publisher = {AAAI Press},
  comment   = {Thomason2019: grounding object attributes and namses through dialog},
  file      = {:FILES/2015 - Parde2015 - Grounding the meaning of words through vision and interactive gameplay.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.ijcai.org/Abstract/15/269},
}

@InProceedings{Thomason2016,
  author    = {Jesse Thomason and Jivko Sinapov and Maxwell Svetlik and Peter Stone and Raymond J. Mooney},
  booktitle = {Proceedings of the 25th International Joint Conference on Artificial Intelligence (IJCAI)},
  title     = {Learning multi-modal grounded linguistic semantics by playing {``I Spy''}},
  year      = {2016},
  address   = {New York, New York, USA},
  month     = jul,
  pages     = {3477--3483},
  publisher = {AAAI Press},
  comment   = {Thomason2019: grounding object attributes and names through dialog},
  file      = {:FILES/2016 - Thomason2016 - Learning multi-modal grounded linguistic semantics by playing {``I Spy''}.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.ijcai.org/Abstract/16/491},
}

@InBook{Steedman2011,
  author    = {Steedman, Mark and Baldridge, Jason},
  chapter   = {5},
  pages     = {181--224},
  publisher = {John Wiley \& Sons, Ltd},
  title     = {Combinatory categorial grammar},
  year      = {2011},
  isbn      = {9781444395037},
  abstract  = {Summary This chapter contains sections titled: Introduction The Crisis in Syntactic Theory Combinatory Categorial Grammar The Combinatory Projection Principle The Bounded Constructions The Unbounded Constructions Scrambling Gapping and the Order of Constituents Intonation Structure and Parentheticals Implications for Performance: The Strict Competence Hypothesis Computational Applications Conclusion References},
  booktitle = {Non‐transformational syntax},
  comment   = {CCG},
  doi       = {10.1002/9781444395037.ch5},
  file      = {:FILES/2011 - Steedman2011 - Combinatory categorial grammar.pdf:PDF},
  groups    = {mathematical basis, task understanding},
  keywords  = {combinatory categorial grammar, Categorial Grammar (CG), one of the oldest - lexicalized grammar formalisms, earliest forms of CG, context-free - weakly equivalent, to context-free phrase-structure grammars, early extensions to CG, “combinatory” in nature - core CG with functional operations on “wrap”, combinatory and type-logical approach distinction - fairly sharp, crisis in syntactic theory - constraints on rules, Combinatory Categorial Grammar (CCG) - form of lexicalized grammar, unbounded constructions - lexicon and application, function argument relations, gapping and order of constituents - gapping and SOV (Dutch, traditionally), word order, computational applications - statistical optimization, differences in algorithmic complexity},
  url       = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781444395037.ch5},
}

@InProceedings{Sinapov2014,
  author    = {Sinapov, Jivko and Schenck, Connor and Stoytchev, Alexander},
  booktitle = {Proceedings of the 2014 IEEE International Conference on Robotics and Automation (ICRA)},
  title     = {Learning relational object categories using behavioral exploration and multimodal perception},
  year      = {2014},
  address   = {Hong Kong, China},
  month     = may,
  pages     = {5691--5698},
  publisher = {IEEE},
  abstract  = {This paper proposes a framework for learning human-provided category labels that describe individual objects, pairwise object relationships, as well as groups of objects. The framework was evaluated using an experiment in which the robot interactively explored 36 objects that varied by color, weight, and contents. The proposed method allowed the robot not only to learn categories describing individual objects, but also to learn categories describing pairs and groups of objects with high recognition accuracy. Furthermore, by grounding the category representations in its own sensorimotor repertoire, the robot was able to estimate how similar two categories are in terms of the behaviors and sensory modalities that are used to recognize them. Finally, this grounded measure of similarity enabled the robot to boost its recognition performance when learning a new category by relating it to a set of familiar categories.},
  comment   = {Thomason2019:分类问题},
  doi       = {10.1109/ICRA.2014.6907696},
  file      = {:FILES/2014 - Sinapov2014 - Learning relational object categories using behavioral exploration and multimodal perception.pdf:PDF},
  groups    = {task understanding},
  issn      = {1050-4729},
  url       = {https://ieeexplore.ieee.org/abstract/document/6907696},
}

@InProceedings{Thomason2018,
  author    = {Jesse Thomason and Jivko Sinapov and Raymond Mooney and Peter Stone},
  booktitle = {Proceedings of the 32nd AAAI Conference on Artificial Intelligence},
  title     = {Guiding exploratory behaviors for multi-modal grounding of linguistic descriptions},
  year      = {2018},
  address   = {New Orleans, Louisiana, USA},
  month     = apr,
  number    = {1},
  pages     = {5520--5527},
  publisher = {AAAI Press},
  volume    = {32},
  comment   = {Thomason2019: 基于感知到的信息进行grounding,而不是全部物体,降低计算量},
  groups    = {task understanding},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/11966},
}

@InProceedings{Chung2015,
  author    = {Chung, Istvan and Propp, Oron and Walter, Matthew R. and Howard, Thomas M.},
  booktitle = {Proceedings of the 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  title     = {On the performance of hierarchical distributed correspondence graphs for efficient symbol grounding of robot instructions},
  year      = {2015},
  address   = {Hamburg, Germany},
  month     = sep,
  pages     = {5247--5252},
  publisher = {IEEE},
  abstract  = {Natural language interfaces are powerful tools that enables humans and robots to convey information without the need for extensive training or complex graphical interfaces. Statistical techniques that employ probabilistic graphical models have proven effective at interpreting symbols that represent commands and observations for robot direction-following and object manipulation. A limitation of these approaches is their inefficiency in dealing with larger and more complex symbolic representations. Herein, we present a model for language understanding that uses parse trees and environment models both to learn the structure of probabilistic graphical models and to perform inference over this learned structure for symbol grounding. This model, called the Hierarchical Distributed Correspondence Graph (HDCG), exploits information about symbols that are expressed in the corpus to construct minimalist graphical models that are more efficient to search. In a series of comparative experiments, we demonstrate a significant improvement in efficiency without loss in accuracy over contemporary approaches for human-robot interaction.},
  comment   = {HDCG},
  doi       = {10.1109/IROS.2015.7354117},
  file      = {:FILES/2015 - Chung2015 - On the performance of hierarchical distributed correspondence graphs for efficient symbol grounding of robot instructions.pdf:PDF},
  groups    = {task understanding},
  url       = {https://ieeexplore.ieee.org/abstract/document/7354117},
}

@InProceedings{Patki2018,
  author    = {Patki, Siddharth and Howard, Thomas},
  booktitle = {Proceedings of the 19th Annual {SIGdial} Meeting on Discourse and Dialogue},
  title     = {Language-guided adaptive perception for efficient grounded communication with robotic manipulators in cluttered environments},
  year      = {2018},
  address   = {Melbourne, Australia},
  month     = jul,
  pages     = {151--160},
  publisher = {Association for Computational Linguistics},
  abstract  = {The utility of collaborative manipulators for shared tasks is highly dependent on the speed and accuracy of communication between the human and the robot. The run-time of recently developed probabilistic inference models for situated symbol grounding of natural language instructions depends on the complexity of the representation of the environment in which they reason. As we move towards more complex bi-directional interactions, tasks, and environments, we need intelligent perception models that can selectively infer precise pose, semantics, and affordances of the objects when inferring exhaustively detailed world models is inefficient and prohibits real-time interaction with these robots. In this paper we propose a model of language and perception for the problem of adapting the configuration of the robot perception pipeline for tasks where constructing exhaustively detailed models of the environment is inefficient and inconsequential for symbol grounding. We present experimental results from a synthetic corpus of natural language instructions for robot manipulation in example environments. The results demonstrate that by adapting perception we get significant gains in terms of run-time for perception and situated symbol grounding of the language instructions without a loss in the accuracy of the latter.},
  comment   = {Patki2019: grounding with dynamic rep of env is faster than static model},
  doi       = {10.18653/v1/W18-5016},
  file      = {:FILES/2018 - Patki2018 - Language-Guided Adaptive Perception for Efficient Grounded Communication with Robotic Manipulators in Cluttered Environments.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.aclweb.org/anthology/W18-5016},
}

@InProceedings{She2017,
  author    = {She, Lanbo and Chai, Joyce},
  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics},
  title     = {Interactive learning of grounded verb semantics towards human-robot communication},
  year      = {2017},
  address   = {Vancouver, Canada},
  month     = jul,
  pages     = {1634--1644},
  publisher = {Association for Computational Linguistics},
  abstract  = {To enable human-robot communication and collaboration, previous works represent grounded verb semantics as the potential change of state to the physical world caused by these verbs. Grounded verb semantics are acquired mainly based on the parallel data of the use of a verb phrase and its corresponding sequences of primitive actions demonstrated by humans. The rich interaction between teachers and students that is considered important in learning new skills has not yet been explored. To address this limitation, this paper presents a new interactive learning approach that allows robots to proactively engage in interaction with human partners by asking good questions to learn models for grounded verb semantics. The proposed approach uses reinforcement learning to allow the robot to acquire an optimal policy for its question-asking behaviors by maximizing the long-term reward. Our empirical results have shown that the interactive learning approach leads to more reliable models for grounded verb semantics, especially in the noisy environment which is full of uncertainties. Compared to previous work, the models acquired from interactive learning result in a 48{\%} to 145{\%} performance gain when applied in new situations.},
  comment   = {通过人机交互来learn model},
  doi       = {10.18653/v1/P17-1150},
  file      = {:FILES/2017 - She2017 - Interactive Learning of Grounded Verb Semantics towards Human-Robot Communication.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.aclweb.org/anthology/P17-1150},
}

@InBook{Bollini2013,
  author    = {Bollini, Mario and Tellex, Stefanie and Thompson, Tyler and Roy, Nicholas and Rus, Daniela},
  editor    = {Desai, Jaydev P. and Dudek, Gregory and Khatib, Oussama and Kumar, Vijay},
  pages     = {481--495},
  publisher = {Springer International Publishing},
  title     = {Interpreting and executing recipes with a cooking robot},
  year      = {2013},
  address   = {Heidelberg},
  isbn      = {978-3-319-00065-7},
  abstract  = {The creation of a robot chef represents a grand challenge for the field of robotics. Cooking is one of the most important activities that takes place in the home, and a robotic chef capable of following arbitrary recipes would have many applications in both household and industrial environments. The kitchen environment is a semi-structured proving ground for algorithms in robotics. It provides many computational challenges, such as accurately perceiving ingredients in cluttered environments, manipulating objects, and engaging in complex activities such as mixing and chopping.},
  booktitle = {Experimental Robotics: The 13th International Symposium on Experimental Robotics},
  comment   = {probabilistic model for grounding is effective in interpreting cooking recipes},
  doi       = {10.1007/978-3-319-00065-7_33},
  file      = {:FILES/2013 - Bollini2013 - Interpreting and executing recipes with a cooking robot.pdf:PDF},
  groups    = {task understanding},
  url       = {https://link.springer.com/chapter/10.1007/978-3-319-00065-7_33},
}

@Article{Walter2015,
  author   = {Walter, Matthew R. and Antone, Matthew and Chuangsuwanich, Ekapol and Correa, Andrew and Davis, Randall and Fletcher, Luke and Frazzoli, Emilio and Friedman, Yuli and Glass, James and How, Jonathan P. and Jeon, Jeong hwan and Karaman, Sertac and Luders, Brandon and Roy, Nicholas and Tellex, Stefanie and Teller, Seth},
  journal  = {Journal of Field Robotics},
  title    = {A situationally aware voice-commandable robotic forklift working alongside people in unstructured outdoor environments},
  year     = {2015},
  number   = {4},
  pages    = {590--628},
  volume   = {32},
  abstract = {One long-standing challenge in robotics is the realization of mobile autonomous robots able to operate safely in human workplaces, and be accepted by the human occupants. We describe the development of a multiton robotic forklift intended to operate alongside people and vehicles, handling palletized materials within existing, active outdoor storage facilities. The system has four novel characteristics. The first is a multimodal interface that allows users to efficiently convey task-level commands to the robot using a combination of pen-based gestures and natural language speech. These tasks include the manipulation, transport, and placement of palletized cargo within dynamic, human-occupied warehouses. The second is the robot's ability to learn the visual identity of an object from a single user-provided example and use the learned model to reliably and persistently detect objects despite significant spatial and temporal excursions. The third is a reliance on local sensing that allows the robot to handle variable palletized cargo and navigate within dynamic, minimally prepared environments without a global positioning system. The fourth concerns the robot's operation in close proximity to people, including its human supervisor, pedestrians who may cross or block its path, moving vehicles, and forklift operators who may climb inside the robot and operate it manually. This is made possible by interaction mechanisms that facilitate safe, effective operation around people. This paper provides a comprehensive description of the system's architecture and implementation, indicating how real-world operational requirements motivated key design choices. We offer qualitative and quantitative analyses of the robot operating in real settings and discuss the lessons learned from our effort.},
  comment  = {probabilistic grounding is effective for directing robot manipulators},
  doi      = {10.1002/rob.21539},
  file     = {:FILES/2015 - Walter2015 - A situationally aware voice-commandable robotic forklift working alongside people in unstructured outdoor environments.pdf:PDF},
  groups   = {task understanding},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21539},
}

@InProceedings{Chaplot2018,
  author    = {Devendra Singh Chaplot and Kanthashree Mysore Sathyendra and Rama Kumar Pasumarthi and Dheeraj Rajagopal and Ruslan Salakhutdinov},
  booktitle = {Proceedings of the 32nd AAAI Conference on Artificial Intelligence},
  title     = {Gated-attention architectures for task-oriented language grounding},
  year      = {2018},
  address   = {New Orleans, Louisiana, USA},
  month     = feb,
  number    = {1},
  pages     = {2819--2826},
  publisher = {AAAI Press},
  volume    = {32},
  comment   = {{Anderson2018}：use reinforcement learning (RL) to train navigational agents, with template based NL instruction, navigation in Doom env。operating in visually restricted environments requiring limited perception},
  file      = {:FILES/2018 - Chaplot2018 - Gated-attention architectures for task-oriented language grounding.pdf:PDF},
  groups    = {task understanding},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/11832},
}

@InProceedings{Mei2016,
  author    = {Hongyuan Mei and Mohit Bansal and Matthew Walter},
  booktitle = {Proceedings of the 30th AAAI Conference on Artificial Intelligence},
  title     = {Listen, attend, and walk: {Neural} mapping of navigational instructions to action sequences},
  year      = {2016},
  address   = {Phoenix, Arizona, USA},
  month     = feb,
  pages     = {2772--2778},
  publisher = {AAAI Press},
  volume    = {30},
  comment   = {{Anderson2018}：simulator, House3D, natural language navigation，operating in visually restricted environments requiring limited perception. 

{Wang2018a}: a sequence-to-sequence model to map the language to navigation actions.},
  file      = {:FILES/2016 - Mei2016 - Listen, Attend, and Walk- Neural Mapping of Navigational Instructions to Action Sequences.pdf:PDF},
  groups    = {task understanding, navigation},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/10364},
}

@InProceedings{Misra2017,
  author    = {Misra, Dipendra and Langford, John and Artzi, Yoav},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  title     = {Mapping instructions and visual observations to actions with reinforcement learning},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  month     = sep,
  pages     = {1004--1015},
  publisher = {Association for Computational Linguistics},
  abstract  = {We propose to directly map raw visual observations and text input to actions for instruction execution. While existing approaches assume access to structured environment representations or use a pipeline of separately trained models, we learn a single model to jointly reason about linguistic and visual input. We use reinforcement learning in a contextual bandit setting to train a neural network agent. To guide the agent{'}s exploration, we use reward shaping with different forms of supervision. Our approach does not require intermediate representations, planning procedures, or training different models. We evaluate in a simulated environment, and show significant improvements over supervised learning and common reinforcement learning variants.},
  comment   = {{Anderson2018}：use reinforcement learning (RL) to train navigational agents, with complex NL instruction ub fully observable blocks world},
  doi       = {10.18653/v1/D17-1106},
  file      = {:FILES/2017 - Misra2017 - Mapping Instructions and Visual Observations to Actions with Reinforcement Learning.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.aclweb.org/anthology/D17-1106},
}

@InProceedings{Vogel2010,
  author    = {Vogel, Adam and Jurafsky, Daniel},
  booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics},
  title     = {Learning to follow navigational directions},
  year      = {2010},
  address   = {Uppsala, Sweden},
  month     = jul,
  pages     = {806--814},
  publisher = {Association for Computational Linguistics},
  comment   = {{Anderson2018}：operating in visually restricted environments requiring limited perception},
  file      = {:FILES/2010 - Vogel2010 - Learning to Follow Navigational Directions.pdf:PDF},
  groups    = {task understanding, navigation},
  url       = {https://www.aclweb.org/anthology/P10-1083},
}

@TechReport{Winograd1971,
  author      = {Winograd, Terry},
  institution = {Massachusetts Institute of Technology},
  title       = {Procedures as a representation for data in a computer program for understanding natural language},
  year        = {1971},
  month       = jan,
  number      = {AITR-235},
  comment     = {{Anderson2018}：Natural language command of robots in unstructured environments},
  file        = {:FILES/1971 - Winograd1971 - Procedures as a Representation for Data in a Computer Program for Understanding Natural Language.pdf:PDF},
  groups      = {task understanding},
  url         = {http://oastats.mit.edu/handle/1721.1/7095},
}

@TechReport{Forgy1981,
  author      = {Forgy, Charles L.},
  institution = {Carnegie Mellon University},
  title       = {{OPS5} user's manual},
  year        = {1981},
  number      = {CMU-CS-81-135},
  comment     = {representation of actions (pattern of behavior).},
  file        = {:FILES/1981 - Forgy1981 - OPS5 user's manual.pdf:PDF},
  groups      = {representation},
}

@InProceedings{Asoh1997,
  author    = {Asoh, Hideki and Hayamizu, Satoru and Hara, Isao and Motomura, Yoichi and Akaho, Shotaro and Matsui, Toshihiro},
  booktitle = {Proceedings of the 15th International Joint Conference on Artifical Intelligence (IJCAI)},
  title     = {Socially embedded learning of the office-conversant mobile robot {Jijo-2}},
  year      = {1997},
  address   = {San Francisco, CA, USA},
  pages     = {880--85},
  publisher = {Morgan Kaufmann Publishers Inc.},
  abstract  = {This paper explores a newly developing direction of machine learning called "socially embedded learning". In this research we have been building an office-conversant mobile robot which autonomously moves around in an office environment, actively gathers information through close interaction with this environment including sensing multi-modal data and making dialog with people in the office, and acquires knowledge about the environment with which it ultimately becomes conversant. Here our major concerns are in how the close interaction between the learning system and its social environment can help or accelerate the systems learning process, and what kinds of prepared mechanisms are necessary for the emergence of such interactions. The office-conversant robot is a platform on which we implement our ideas and test their feasibility in a real-world setting. An overview of the system is given and two examples of implemented ideas, i.e. dialog-based map acquisition and route acquisition by following, are described in detail.},
  comment   = {{Burgard1999}:phrase based NL interaction interface for navigate in offices},
  file      = {:FILES/1997 - Asoh1997 - Socially Embedded Learning of the Office-Conversant Mobile Robot Jijo-2.pdf:PDF},
  groups    = {task understanding},
  isbn      = {15558604804},
  location  = {Nagoya, Japan},
  url       = {https://www.ijcai.org/Proceedings/97-2/Papers/013.pdf},
}

@InProceedings{Bischoff1999,
  author    = {Bischoff, Rainer and Jain, Tamhant},
  booktitle = {Proceedings of the 2nd International Symposium on Humanoid Robots (HURO)},
  title     = {Natural communication and interaction with humanoid robots},
  year      = {1999},
  address   = {Tokyo, Japan},
  month     = dec,
  pages     = {1--9},
  comment   = {{Ghidary2001}: HERMES, the humanoid robot combines visual, kinesthetic and tactile sensing for enabling a natural communication and interaction with humans.},
  file      = {:FILES/1999 - Bischoff1999 - Natural Communication and Interaction with Humanoid Robots.pdf:PDF},
  groups    = {task understanding},
}

@MastersThesis{Torrance1994,
  author  = {Torrance, Mark Charles},
  school  = {Massachusetts Institute of Technology},
  title   = {Natural communication with robots},
  year    = {1994},
  month   = feb,
  comment = {{Ghidary2000}: developed a natural language interface for teaching mobile robots name of places in an indoor environment. for navigation
{Burgard1999}: NL to teach robots names of places in indoor env with NL input by keyboard},
  file    = {:FILES/1994 - Torrance1994 - Natural communication with robots.pdf:PDF},
  groups  = {task understanding},
  url     = {https://dspace.mit.edu/handle/1721.1/88300},
}

@InProceedings{Ghidary2000,
  author     = {Ghidary, Saeed Shiry and Nakata, Yasushi and Takamori, Toshi and Hattori, Motofumi},
  booktitle  = {Proceedings of the ICEE 2000},
  title      = {Head and face detection at indoor environment by home robot},
  year       = {2000},
  address    = {Isfahan, Iran},
  month      = may,
  pages      = {1--6},
  comment    = {{Ghidary2001}: 前期工作：we proposed a multi cue approach consisting of three feature modules sensitive to skin color, motion information and the circular model of the head for human head detection.

we describe a method for the detection and tracking of human’s head and face inside indoor environment by a home robot},
  file       = {:FILES/2000 - Ghidary2000 - Head and face detection at indoor environment by home robot.pdf:PDF},
  groups     = {from visual},
  keywords   = {skimmed},
  readstatus = {skimmed},
}

@InProceedings{BrandtPook1999,
  author    = {Brandt-Pook, Hans and Fink, Gernot A. and Wachsmuth, Sven and Sagerer, Gerhard},
  booktitle = {Proceedings of the 8th International Conference on Human-Computer Interaction (HCI)},
  title     = {Integrated recognition and interpretation of speech for a construction task domain},
  year      = {1999},
  address   = {USA},
  month     = aug,
  pages     = {550--554},
  publisher = {L. Erlbaum Associates Inc.},
  comment   = {{McGuire2002}: 单模态HRI， horizontal architecture of spoken language understanding.},
  file      = {:FILES/1999 - BrandtPook1999 - Integrated Recognition and Interpretation of Speech for a Construction Task Domain.pdf:PDF},
  groups    = {task understanding},
  isbn      = {0805833919},
  url       = {https://dl.acm.org/doi/abs/10.5555/647943.743437},
}

@InProceedings{Wachsmuth1999,
  author    = {Wachsmuth, Sven and Brandt-Pook, Hans and Socher, Gudrun and Kummert, Franz and Sagerer, Gerhard},
  booktitle = {Computer Vision Systems},
  title     = {Multilevel integration of vision and speech understanding using {Bayesian} networks},
  year      = {1999},
  address   = {Berlin, Heidelberg},
  pages     = {231--254},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {The interaction of image and speech processing is a crucial property of multimedia systems. Classical systems using inferences on pure qualitative high level descriptions miss a lot of information when concerned with erroneous, vague, or incomplete data. We propose a new architecture that integrates various levels of processing by using multiple representations of the visually observed scene. They are vertically connected by Bayesian networks in order to find the most plausible interpretation of the scene.},
  comment   = {{McGuire2002}:  Bayesian netivork approach that robustly combines verbal and visual information through different abstraction levels。 数据experimental data},
  file      = {:FILES/1999 - Wachsmuth1999 - Multilevel Integration of Vision and Speech Understanding Using Bayesian Networks.pdf:PDF},
  groups    = {task understanding},
  isbn      = {978-3-540-49256-6},
  url       = {https://link.springer.com/chapter/10.1007/3-540-49256-9_15},
}

@InCollection{Schank1996,
  author    = {Roger C. Schank and Andrew Fano},
  booktitle = {Integration of natural language and vision processing: {Theory} and grounding representations volume {III}},
  publisher = {Springer Netherlands},
  title     = {Memory and expectations in learning, language, and visual understanding},
  year      = {1996},
  edition   = {1st},
  editor    = {Paul Mc Kevitt},
  isbn      = {978-0-7923-3944-1,978-94-009-1639-5},
  pages     = {19--29},
  comment   = {{McGuire2002}: learning in cognitive architectures (speech and image integration)},
  groups    = {task understanding},
  url       = {https://www.springer.com/gp/book/9780792339441},
}

@InProceedings{Gorniak2005,
  author    = {Peter Gorniak and Deb Roy},
  booktitle = {Proceedings of the 1st Artificial Intelligence and Iteractive Digital Entertainment Conference},
  title     = {Speaking with your sidekick: {Understanding} situated speech in computer role playing games},
  year      = {2005},
  address   = {Marina del Rey, California, USA},
  month     = jun,
  pages     = {1--6},
  publisher = {AAAI Press},
  comment   = {{Tellex2006}: Gorniak and Roy’s speech understanding system},
  file      = {:FILES/2005 - Gorniak2005 - Speaking with Your Sidekick- Understanding Situated Speech in Computer Role Playing Games.pdf:PDF},
  groups    = {task understanding},
  url       = {https://www.aaai.org/Library/AIIDE/aiide05contents.php},
}

@Article{Levine1999,
  author   = {Levine, Simon P. and Bell, David A. and Jaros, Lincoln A. and Simpson, Richard C. and Koren, Yoram and Borenstein, Johann},
  journal  = {IEEE Transactions on Rehabilitation Engineering},
  title    = {The {NavChair} assistive wheelchair navigation system},
  year     = {1999},
  issn     = {1558-0024},
  month    = dec,
  number   = {4},
  pages    = {443--451},
  volume   = {7},
  abstract = {The NavChair Assistive Wheelchair Navigation System is being developed to reduce the cognitive and physical requirements of operating a power wheelchair for people with wide ranging impairments that limit their access to powered mobility. The NavChair is based on a commercial wheelchair system with the addition of a DOS-based computer system, ultrasonic sensors, and an interface module interposed between the joystick and power module of the wheelchair. The obstacle avoidance routines used by the NavChair in conjunction with the ultrasonic sensors are modifications of methods originally used in mobile robotics research. The NavChair currently employs three operating modes: general obstacle avoidance, door passage, and automatic wall following. Results from performance testing of these three operating modes demonstrate their functionality. In additional to advancing the technology of smart wheelchairs, the NavChair has application to the development and testing of "shared control" systems where a human and machine share control of a system and the machine can automatically adapt to human behaviors.},
  comment  = {Tellex2006: navChair System is a wheelchair designed to reduce the cognitive and physical load required of the user. left or right command turn a fixed amount regardless of env.  包括speed command。  基于当前位置以及Bayes net来决定所应采用的mode，i.e. general obstacle avoidance, door passage, and automatic wall following},
  doi      = {10.1109/86.808948},
  file     = {:FILES/1999 - Levine1999 - The NavChair Assistive Wheelchair Navigation System.pdf:PDF},
  groups   = {task understanding},
  url      = {https://ieeexplore.ieee.org/document/808948},
}

@Article{Pires2002,
  author   = {Pires, Gabriel and Nunes, Urbano},
  journal  = {Journal of Intelligent and Robotic Systems},
  title    = {A wheelchair steered through voice commands and assisted by a reactive fuzzy-logic controller},
  year     = {2002},
  issn     = {1573-0409},
  month    = jul,
  number   = {3},
  pages    = {301--314},
  volume   = {34},
  abstract = {This paper describes new results with a Reactive Shared-Control system that enables a semi-autonomous navigation of a wheelchair in unknown and dynamic environments. The purpose of the reactive shared controller is to assist wheelchair users providing an easier and safer navigation. It is designed as a fuzzy-logic controller and follows a behaviour-based architecture. The implemented behaviours are three: intelligent obstacle avoidance, collision detection and contour following. Intelligent obstacle avoidance blends user commands, from voice or joystick, with an obstacle avoidance behaviour. Therefore, the user and the vehicle share the control of the wheelchair. The reactive shared control was tested on the RobChair powered wheelchair prototype [6] equipped with a set of ranging sensors. Experimental results are presented demonstrating the effectiveness of the controller.},
  comment  = {Tellex2006: RobChair  uses fuzzy logic to blend user speech and joystick commands with obstacle avoidance goals.  imode: ntelligent obstacle avoidance, collision detection, and contour following},
  doi      = {10.1023/A:1016363605613},
  file     = {:FILES/2002 - Pires2002 - A Wheelchair Steered through Voice Commands and Assisted by a Reactive Fuzzy-Logic Controller.pdf:PDF},
  groups   = {task understanding},
  refid    = {Pires2002},
  url      = {https://link.springer.com/article/10.1023/A:1016363605613},
}

@Article{Regier2001,
  author  = {Regier, Terry and Carlson, Laura A.},
  journal = {Journal of experimental psychology: General},
  title   = {Grounding spatial language in perception: {An} empirical and computational investigation},
  year    = {2001},
  number  = {2},
  pages   = {273--298},
  volume  = {130},
  comment = {Tellex2006:  attention vector sum used to quantify left or right of an object},
  doi     = {10.1037/0096-3445.130.2.273},
  file    = {:FILES/2001 - Regier2001 - Grounding spatial language in perception- an empirical and computational investigation.pdf:PDF},
  groups  = {task understanding},
  url     = {https://pubmed.ncbi.nlm.nih.gov/11409104/},
}

@InProceedings{Simpson1997,
  author    = {Simpson, Richard C. and Levine, Simon P.},
  booktitle = {Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications (IROS)},
  title     = {Adaptive shared control of a smart wheelchair operated by voice control},
  year      = {1997},
  address   = {Grenoble, France},
  month     = sep,
  pages     = {622--626},
  publisher = {IEEE},
  volume    = {2},
  abstract  = {The NavChair Assistive Wheelchair Navigation System is being developed to reduce the cognitive and physical requirements of operating a power wheelchair. The NavChair is an adaptive shared control system, shared in that control is divided between the wheelchair and the wheelchair operator and adaptive in that how control is divided between the wheelchair and the wheelchair operator varies based on current task requirements. This paper describes the NavChair's method for automatically allocating control between the wheelchair and its operator and presents results evaluating the performance of the NavChair's automatic adaptation mechanism from an experiment in which able-bodied subjects used voice control to steer the NavChair through a navigation task requiring several transitions between operating modes.},
  comment   = {Tellex2006: navChair System is a wheelchair designed to reduce the cognitive and physical load required of the user. left or right command turn a fixed amount regardless of env.  包括speed command。  基于当前位置以及Bayes net来决定所应采用的mode，i.e. general obstacle avoidance, door passage, and automatic wall following},
  doi       = {10.1109/IROS.1997.655076},
  file      = {:FILES/1997 - Simpson1997 - Adaptive shared control of a smart wheelchair operated by voice control.pdf:PDF},
  groups    = {task understanding},
  url       = {https://ieeexplore.ieee.org/document/655076},
}

@InBook{Yanco1998,
  author    = {Holly A. Yanco},
  editor    = {Mittal, Vibhu O. and Yanco, Holly A. and Aronis, John and Simpson, Richard},
  pages     = {256--268},
  publisher = {Springer Berlin Heidelberg},
  title     = {A robotic wheelchair system: {Indoor} navigation and user interface},
  year      = {1998},
  isbn      = {978-3-540-64790-4},
  month     = may,
  booktitle = {Assistive Technology and Artificial Intelligence: Applications in Robotics, User Interfaces and Natural Language Processing},
  comment   = {Tellex2006: Yanco [17] built a robotic wheelchair named Wheelesley which understands high level commands.},
  doi       = {10.1007/BFb0055983},
  file      = {:FILES/1998 - Yanco1998 - A Robotic Wheelchair System- Indoor Navigation and User Interface.pdf:PDF},
  groups    = {task understanding},
  url       = {https://link.springer.com/chapter/10.1007/BFb0055983},
}

@InProceedings{Aliannejadi2014,
  author     = {Aliannejadi, Mohammad and Kiaeeha, Masoud and Khadivi, Shahram and Ghidary, Saeed Shiry},
  booktitle  = {Proceedings of the Australasian Language Technology Association Workshop 2014},
  title      = {Graph-based semi-supervised conditional random fields for spoken language understanding using unaligned data},
  year       = {2014},
  address    = {Melbourne, Australia},
  month      = nov,
  pages      = {98--103},
  comment    = {1. 本文是将如何利用semi-supervised CRF来实现utterance to structured concept mapping过程。其中command表示为concept with attributes的形式，（类似json。。只是给打了标签，CRF的方法也是对每个phrase打标签，而没有考虑标签之间的关系）
2. 假设 hypothesis that data is aligned to labels in a monotone manner, and words appearing in similar contexts tend to have same labels
3. 模型输入是semantic tree (结构如He and Young 2005所示).模型本身基于（Subramanya et al., 2010），模型训练过程：
3.1 首先利用labeled data训练CRF模型，
3.2 构造k-NN similarity graph
3.3 计算labeled data上的 label distribution
3.4 利用CRF模型参数，以及unlabeled data + forward backward algorihtm，计算unlabeled data上的marginal probability of labels.
3.5 all marginal label probabilities of eac trigram are averaged over its occurrence
3.6 在similarity graph上 propagate label，利用Pointwise Mutual Information (PMI)计算trigram相似性.用Modified Adsorption (MAD) algorithm for label propagation. 
4. 在训练过程中，构造similarity graph所需要的feature包括context， left/right context, center word in trigram, isPreposition, etc. feature window is reduced to [0,2]
5. CRF 在CRFSuite上改进},
  file       = {:FILES/2014 - Aliannejadi2014 - Graph-Based Semi-Supervised Conditional Random Fields For Spoken Language Understanding Using Unaligned Data.pdf:PDF},
  groups     = {NLU},
  readstatus = {read},
  url        = {https://www.aclweb.org/anthology/U14-1012},
}

@Article{Mettler2017,
  author   = {Mettler, Tobias and Sprenger, Michaela and Winter, Robert},
  journal  = {European Journal of Information Systems},
  title    = {Service robots in hospitals: {New} perspectives on niche evolution and technology affordances},
  year     = {2017},
  issn     = {1476-9344},
  number   = {5},
  pages    = {451--468},
  volume   = {26},
  abstract = {Changing demands in society and the limited capabilities of health systems have paved the way for robots to move out of industrial contexts and enter more human-centered environments such as health care. We explore the shared beliefs and concerns of health workers on the introduction of autonomously operating service robots in hospitals or professional care facilities. By means of Q-methodology, a mixed research approach specifically designed for studying subjective thought patterns, we identify five potential end-user niches, each of which perceives different affordances and outcomes from using service robots in their working environment. Our findings allow for better understanding resistance and susceptibility of different users in a hospital and encourage managerial awareness of varying demands, needs, and surrounding conditions that a service robot must contend with. We also discuss general insights into presenting the Q-methodology results and how an affordance-based view could inform the adoption, appropriation, and adaptation of emerging technologies.},
  doi      = {10.1057/s41303-017-0046-1},
  file     = {:FILES/2017 - Mettler2017 - Service robots in hospitals- new perspectives on niche evolution and technology affordances.pdf:PDF},
  groups   = {robot},
  url      = {https://link.springer.com/article/10.1057/s41303-017-0046-1},
}

@Article{Ceccarelli2011,
  author   = {Ceccarelli, Marco},
  journal  = {International Journal of Social Robotics},
  title    = {Problems and issues for service robots in new applications},
  year     = {2011},
  issn     = {1875-4805},
  number   = {3},
  pages    = {299--312},
  volume   = {3},
  abstract = {Service robots give the possibility of new fields of applications for Robotics by wide spreading robots also into no technical areas. But requirements and goals need to be carefully revised both in designing and operating specific solutions. In this paper, main aspects and challenges are discussed both as problems and advantages in using robots in service operations for new areas of applications, by taking particular attention to non engineering aspects that are deduced from new service areas. In particular, two novel applications, with direct experience of the author and his team, are discussed as referring to robots for restoration activity of historical goods, and robots for physiotherapy rehabilitation and training, as examples with many very different aspects and backgrounds, but even with common issues. Key problems for developing service robots for a successful acceptance and use by even no technical users can be considered in terms of specific technical problems for low-cost user-oriented operation systems, but mainly in terms of implications for human-machine interactions.},
  doi      = {10.1007/s12369-011-0097-8},
  file     = {:FILES/2011 - Ceccarelli2011 - Problems and Issues for Service Robots in New Applications.pdf:PDF},
  groups   = {robot},
  url      = {https://link.springer.com/article/10.1007/s12369-011-0097-8},
}

@Article{Wirtz2018,
  author    = {Wirtz, Jochen and Patterson, Paul G. and Kunz, Werner H. and Gruber, Thorsten and Lu, Vinh Nhat and Paluch, Stefanie and Martins, Antje},
  journal   = {Journal of Service Management},
  title     = {Brave new world: {Service} robots in the frontline},
  year      = {2018},
  issn      = {1757-5818},
  month     = jan,
  number    = {5},
  pages     = {907--931},
  volume    = {29},
  abstract  = {Purpose The service sector is at an inflection point with regard to productivity gains and service industrialization similar to the industrial revolution in manufacturing that started in the eighteenth century. Robotics in combination with rapidly improving technologies like artificial intelligence (AI), mobile, cloud, big data and biometrics will bring opportunities for a wide range of innovations that have the potential to dramatically change service industries. The purpose of this paper is to explore the potential role service robots will play in the future and to advance a research agenda for service researchers. Design/methodology/approach This paper uses a conceptual approach that is rooted in the service, robotics and AI literature. Findings The contribution of this paper is threefold. First, it provides a definition of service robots, describes their key attributes, contrasts their features and capabilities with those of frontline employees, and provides an understanding for which types of service tasks robots will dominate and where humans will dominate. Second, this paper examines consumer perceptions, beliefs and behaviors as related to service robots, and advances the service robot acceptance model. Third, it provides an overview of the ethical questions surrounding robot-delivered services at the individual, market and societal level. Practical implications This paper helps service organizations and their management, service robot innovators, programmers and developers, and policymakers better understand the implications of a ubiquitous deployment of service robots. Originality/value This is the first conceptual paper that systematically examines key dimensions of robot-delivered frontline service and explores how these will differ in the future.},
  doi       = {10.1108/JOSM-04-2018-0119},
  file      = {:FILES/2018 - Wirtz2018 - Brave new world- service robots in the frontline.pdf:PDF},
  groups    = {robot},
  publisher = {Emerald Publishing Limited},
  url       = {https://www.emerald.com/insight/content/doi/10.1108/JOSM-04-2018-0119/full/html},
}

@Article{Kim2013a,
  author   = {Yunkyung Kim and Sonya S. Kwak and Myung-suk Kim},
  journal  = {Computers in Human Behavior},
  title    = {Am {I} acceptable to you? {Effect} of a robot’s verbal language forms on people’s social distance from robots},
  year     = {2013},
  issn     = {0747-5632},
  number   = {3},
  pages    = {1091--1101},
  volume   = {29},
  abstract = {This study is to examine the effect of robots’ language forms on people’s acceptance of robots. We applied a concept of social distance to measure people’s acceptance of robots. In an experiment, calling participants by name vs. not calling by name as well as the robot’s speech styles (familiar vs. honorific), were used to impose a verticality and horizontality of social relationships between participants and robots. After the conversation with a robot, participants rated the robot’s interpersonal traits and their comfortable approach distance to the robot, and their response to the robot during the experiment were analyzed. As a result, participants whom the robot called by their name perceived the robot as friendlier. They introduced themselves more actively, and were more intently focused on what the robot said. They asked the robot questions more frequently. Participants called by their names consequently approached the robot more closely than participants who were not called. An interaction effect was found between speech styles and whether names were used in regard to the perceived friendliness of robots, negative response to robots, and comfortable approach distance to robots. We discuss verbal interaction design for increasing people’s acceptance of robots.},
  doi      = {10.1016/j.chb.2012.10.001},
  file     = {:FILES/2013 - Kim2013a - Am I acceptable to you- Effect of a robot’s verbal language forms on people’s social distance from robots.pdf:PDF},
  groups   = {robot},
  keywords = {Social distance, Human–robot interaction, Robots’ verbal language, User acceptance},
  url      = {https://www.sciencedirect.com/science/article/pii/S0747563212002695},
}

@Article{Joerling2019,
  author   = {Moritz J\"{o}rling and Robert B\"{o}hm and Stefanie Paluch},
  journal  = {Journal of Service Research},
  title    = {Service robots: {Drivers} of perceived responsibility for service outcomes},
  year     = {2019},
  number   = {4},
  pages    = {404--420},
  volume   = {22},
  abstract = {The use of service robots is on the rise. Characterized by technology autonomy with a physical embodiment, service robots have a higher level of social presence than other service technologies. This research focuses on one specific phenomenon of such social encounters: attribution of responsibility. Study 1 explores potential antecedents driving the attribution of responsibility in encounters with service robots. We derive a research model, which is tested and expanded in three subsequent scenario-based experiments. In Study 2, we find that technology’s autonomy decreases perceived behavioral control over the service robot, which in turn decreases perceived responsibility for positive outcomes but not for negative outcomes. Study 3 indicates that perceived ownership of the service robot accounts for the high responsibility for negative outcomes irrespective of perceived behavioral control. In Study 4, we show that the potential to interrupt the service robots’ autonomy increases perceived behavioral control and perceived responsibility for positive outcomes. Our results propose theoretical implications for responsibility perceptions and practical implications for customer satisfaction with service robots.},
  comment  = {给出了service robot 的定义},
  doi      = {10.1177/1094670519842334},
  file     = {:FILES/2019 - Joerling2019 - Service Robots- Drivers of Perceived Responsibility for Service Outcomes.pdf:PDF},
  groups   = {robot},
  url      = {https://journals.sagepub.com/doi/abs/10.1177/1094670519842334},
}

@TechReport{ISO8373:2012,
  author      = {ISO},
  institution = {International Organization for Standardization},
  title       = {{ISO} 8373:2012 Robots and robotic devices -- {Vocabulary}},
  year        = {2012},
  month       = mar,
  comment     = {给出了service robot 的定义},
  groups      = {robot},
  url         = {https://www.iso.org/standard/55890.html},
}

@InProceedings{Kim2010,
  author    = {Kim, {KangGeon} and Lee, {Ji-Yong} and Choi, Dongkyu and Park, {Jung-Min} and You, {Bum-Jae}},
  booktitle = {Proceedings of the 2010 IEEE International Conference on Robotics and Biomimetics (ROBIO)},
  title     = {Autonomous task execution of a humanoid robot using a cognitive model},
  year      = {2010},
  address   = {Tianjin, China},
  month     = dec,
  pages     = {405--410},
  publisher = {IEEE},
  abstract  = {Cognitive architectures provide infrastructure for modeling human cognition. Recent studies reveal that these architectures are useful control mechanisms for a variety of robots. Previously, we showed one such architecture, ICARUS, can successfully control a humanoid robot for Blocks World tasks in a simulated environment. In the current work, we extend the application to the real world and use the architecture to perform similar tasks with Mahru-Z platform. As commonly expected, we encountered many challenges in system integration, vision-based information updates, and manipulation tasks. This paper reports the result of our initial work to address some of these issues. The successful completion of a color sorting task indicates the system is capable to adapt to such challenges and we expect similar results in more complicated tasks in this domain.},
  doi       = {10.1109/ROBIO.2010.5723361},
  file      = {:FILES/2010 - Kim2010 - Autonomous task execution of a humanoid robot using a cognitive model.pdf:PDF},
  groups    = {knowledge extractions},
  url       = {https://ieeexplore.ieee.org/document/5723361},
}

@Article{Afouras2018,
  author   = {Afouras, Triantafyllos and Chung, Joon Son and Senior, Andrew and Vinyals, Oriol and Zisserman, Andrew},
  journal  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title    = {Deep audio-visual speech recognition},
  year     = {2018},
  issn     = {1939-3539},
  pages    = {1-11},
  abstract = {The goal of this work is to recognise phrases and sentences being spoken by a talking face, with or without the audio. Unlike previous works that have focussed on recognising a limited number of words or phrases, we tackle lip reading as an open-world problem -- unconstrained natural language sentences, and in the wild videos. Our key contributions are: (1) we compare two models for lip reading, one using a CTC loss, and the other using a sequence-to-sequence loss. Both models are built on top of the transformer self-attention architecture; (2) we investigate to what extent lip reading is complementary to audio speech recognition, especially when the audio signal is noisy; (3) we introduce and publicly release two new datasets for audio-visual speech recognition: LRS2-BBC, consisting of thousands of natural sentences from British television; and LRS3-TED, consisting of hundreds of hours of TED and TEDx talks obtained from YouTube. The models that we train surpass the performance of all previous work on lip reading benchmark datasets by a significant margin.},
  doi      = {10.1109/TPAMI.2018.2889052},
  file     = {:FILES/2018 - Afouras2018 - Deep Audio-visual Speech Recognition.pdf:PDF},
  groups   = {lipreading},
  url      = {https://ieeexplore.ieee.org/abstract/document/8585066},
}

@InProceedings{Camgoz2020,
  author     = {Camgoz, Necati Cihan and Koller, Oscar and Hadfield, Simon and Bowden, Richard},
  booktitle  = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title      = {Sign language transformers: {Joint} end-to-end sign language recognition and translation},
  year       = {2020},
  month      = jun,
  pages      = {10023--10033},
  publisher  = {Computer Vision Foundation},
  comment    = {sign language recognition
利用了transformer based architecture，以spatial embedding of video frames作为输入，以word embedding 作为输出，同时训练除video到token和NL的模型。},
  file       = {:FILES/2020 - Camgoz2020 - Sign Language Transformers- Joint End-to-End Sign Language Recognition and Translation.pdf:PDF},
  groups     = {sign language},
  readstatus = {read},
  url        = {https://openaccess.thecvf.com/content_CVPR_2020/html/Camgoz_Sign_Language_Transformers_Joint_End-to-End_Sign_Language_Recognition_and_Translation_CVPR_2020_paper.html},
}

@Article{Zhang2020b,
  author   = {Hepeng Zhang and Bin Huang and Guohui Tian},
  journal  = {Pattern Recognition Letters},
  title    = {Facial expression recognition based on deep convolution long short-term memory networks of double-channel weighted mixture},
  year     = {2020},
  issn     = {0167-8655},
  pages    = {128--134},
  volume   = {131},
  abstract = {With the aging population and the increasing number of empty nest elderly, more and more researches focus on home service robots. Autonomous analysis of human emotions by robots is helpful to provide better services for human beings. Facial expression, as an important modality in emotional recognition, is helpful to improve emotional recognition. In order to explore a new method that can effectively improve the recognition rate of expression two facial expression recognition(FER) methods are proposed in this paper. They are double-channel weighted mixture deep convolution neural networks (WMDCNN) based on static images and deep cnn long short-term memory networks of double-channel weighted mixture(WMCNN-LSTM) based on image sequences. WMDCNN network can quickly recognize facial expressions and provide static image features for WMCNN-LSTM network. WMCNN-LSTM network utilizes the static image features to further acquire the temporal features of image sequence, which can realize the accurate recognition of facial expressions. The experimental results show that the average recognition rate of the WMDCNN network on the four datasets of CK+, JAFFE, Oulu-CASIA and MMI are 0.985, 0.923,0.86,0.78 respectively. The WMCNN-LSTM method has an average recognition rate of 0.975, 0.88, and 0.87 on the three datasets CK+, Oulu-CASIA and MMI respectively. By comparing with the existing FER method, our method further improves the recognition rate in the above four expression data sets.},
  doi      = {10.1016/j.patrec.2019.12.013},
  file     = {:FILES/2020 - Zhang2020b - Facial expression recognition based on deep convolution long short-term memory networks of double-channel weighted mixture.pdf:PDF},
  groups   = {face expression},
  keywords = {Facial expression recognition, Computer applications, CNN, LSTM},
  url      = {https://www.sciencedirect.com/science/article/pii/S0167865519303769},
}

@Article{Ding2018,
  author     = {{Ing-Jr} Ding and {Rui-Zhi} Lin and {Zong-Yi} Lin},
  journal    = {Computers \& Electrical Engineering},
  title      = {Service robot system with integration of wearable {Myo} armband for specialized hand gesture human–computer interfaces for people with disabilities with mobility problems},
  year       = {2018},
  issn       = {0045-7906},
  month      = jul,
  pages      = {815--827},
  volume     = {69},
  abstract   = {Hand gestures will become a mainstream method of manipulating human computer interfaces (HCIs). For disabled people with mobility problems, hand gesture-based HCIs should be specifically designed. To achieve effective hand gesture HCIs, this study integrated a mobile service robot platform, three-dimensional (3D) imaging sensors, and wearable Myo armband device. Four kernel techniques are presented: (1) Myo armband software development kit hand gesture recognition using a two-layer hierarchy scheme to significantly increase hand gesture command numbers, (2) identity recognition of users using clustering-based support vector machine classifiers with a designed root mean square surface electromyography (RMS-sEMG) feature, (3) robot vehicle navigation with effective obstacle avoidance using a conceptually simple and computationally fast approach, and (4) efficient vehicle positioning based on the face-detection information of the user provided from the 3D imaging sensor to receive the hand gestures commands of the user with disabilities.},
  comment    = {hand gesture

为残疾人提供hand gesture based HRI. 实现的功能包括：1）two layer hierarchy scheme of hand gesture recognition, 2) user identity recognition based on SVM classification, 3) (moving or static) obstacle avoidance during robot vehicle navigation, 4) vehicle positioning based on user face detection. 具体的：
1. 所利用的信息：visual information of 3D imaging sensors, Myo armband device (sEMG sensor and 9-axis internal measurement units).
2. hand gesture的识别是基于Myo信号，而不是视觉信号. 设计了两层结构，可以进行命令选择，增加了可是别的命令内容
3. user identification也是基于Myo信号，基于SVM classification with labels authenticated or un-
4. navigation是基于SLAM
5. image sensor的作用是识别人脸，从而保证机器人与人之间的视角最优，并实现face tracking,识别算法是opencv development kits, 。},
  doi        = {10.1016/j.compeleceng.2018.02.041},
  file       = {:FILES/2018 - Ding2018 - Service robot system with integration of wearable {Myo} armband for specialized hand gesture human–computer interfaces for people with disabilities with mobility problems.pdf:PDF},
  groups     = {visual understanding, hand gesture},
  keywords   = {Myo armband, Service robot vehicle, Hand gesture HCIs, Disabled people with mobility problems, Identity recognition, Support vector machine, read},
  readstatus = {read},
  url        = {https://www.sciencedirect.com/science/article/pii/S0045790617329920},
}

@Article{Xu2018a,
  author     = {Xu, Wang and Chen, Naijian and Han, Xiangdong and Sun, Jianbo},
  journal    = {AIP Conference Proceedings},
  title      = {Research on wheelchair robot control system based on {EOG}},
  year       = {2018},
  number     = {1},
  pages      = {040151},
  volume     = {1955},
  comment    = {eye movement

利用EOG信号来实现对wheelchair的控制，可执行的指令数目有限，通过pattern recognition,没有什么复杂方法，就是识别波形特征。},
  doi        = {10.1063/1.5033815},
  file       = {:FILES/2018 - Xu2018a - Research on wheelchair robot control system based on EOG.pdf:PDF},
  groups     = {from gaze},
  readstatus = {read},
  url        = {https://aip.scitation.org/doi/abs/10.1063/1.5033815},
}

@Article{Liu2021,
  author   = {Yizhi Liu and Mahmoud Habibnezhad and Houtan Jebelli},
  journal  = {Automation in Construction},
  title    = {Brainwave-driven human-robot collaboration in construction},
  year     = {2021},
  issn     = {0926-5805},
  month    = apr,
  pages    = {103556},
  volume   = {124},
  abstract = {Due to the unstructured, fast-changing environment of construction sites, robots require human assistance to perform various tasks, especially those involving high dexterity and nuanced human judgment. However, in shared physical spaces, human-robot collaboration (HRC) can raise new safety concerns as workers' mental health can be adversely affected by poor communication between the two peers. To create a harmonized, safe HRC, this study proposes a worker-centered collaborative framework that enables robots to capture workers' brainwaves from wearable electroencephalograph, evaluate their task-related cognitive load, and adjust the robotic performance accordingly. The framework was examined by asking 14 subjects to execute a collaborative construction task with a terrestrial robot under various levels of cognitive loads. The results showed the robot could regulate its working pace with 81.91% accuracy. This level of communication can instill trust in HRC and facilitate future endeavors in safety design of collaborative robotics.},
  doi      = {10.1016/j.autcon.2021.103556},
  file     = {:FILES/2021 - Liu2021 - Brainwave-driven human-robot collaboration in construction.pdf:PDF},
  groups   = {from brainwave},
  keywords = {Human-robot collaboration (HRC), Electroencephalogram (EEG), Construction robots, Workers' cognitive load, Workplace safety and productivity},
  url      = {https://www.sciencedirect.com/science/article/pii/S0926580521000078},
}

@Article{Wei2019a,
  author    = {Wei, Jiaqi and Liu, Huaping and Wang, Bowen and Sun, Fuchun},
  journal   = {Interaction Studies},
  title     = {Lifelong learning for tactile emotion recognition},
  year      = {2019},
  issn      = {1572-0373},
  number    = {1},
  pages     = {25-41},
  volume    = {20},
  abstract  = {<span class=} # tl-main-part #{>Abstract</span>
<p id=} # abstract-p1 #{>Tactile emotion recognition provides a lot of valuable information in human-computer interaction, and it has
                    strong application prospects in many aspects such as smart home and medical treatment. So this situation raises a question: How to
                    quickly and efficiently let the robot perform the correct emotion recognition? In this work, we develop a lifelong learning
                    algorithm which is based on the efficient dictionary learning technology, to tackle the tactile emotion recognition across
                    different tasks. To verify the efficiency of the proposed method, we applied it to two data sets for experimentation: Corpus of
                    Social Touch (CoST) and our dataset(We built it with a 12X12 array sensor). The results show that the proposed lifelong learning
                    algorithm achieves satisfactory results.},
  comment   = {tactile emotion recognition},
  doi       = {10.1075/is.18041.wei},
  groups    = {from tactile},
  keywords  = {Lifelong Learning, tactile interaction, emotion recognition},
  publisher = {John Benjamins},
  type      = {Journal Article},
  url       = {https://www.jbe-platform.com/content/journals/10.1075/is.18041.wei},
}

@InProceedings{Leng2007,
  author    = {Leng, H. and Lin, Y. and Zanzi, L. A.},
  booktitle = {Ergonomics and Health Aspects of Work with Computers},
  title     = {An experimental study on physiological parameters toward driver emotion recognition},
  year      = {2007},
  address   = {Berlin, Heidelberg},
  editor    = {Dainoff, Marvin J.},
  pages     = {237--246},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Although many emotion recognition methods have been developed, monitoring a driver's emotions during driving is still a challenge because some special requirements must be met. This study begins with the classification of emotion, and then proceeds to emotion recognition. In particular, this study presents the applications of blood volume pressure, skin conductance, skin temperature, gripping force, respiration rate, and facial expression in emotion recognition. Experiments are designed and carried out to find the mapping relation among heart rate, skin conductance, and skin temperature to two kinds of emotions: fear and amusement. The experimental results demonstrate the feasibility of using the selected physiological parameters to monitor drivers' emotions.},
  file      = {:FILES/2007 - Leng2007 - An Experimental Study on Physiological Parameters Toward Driver Emotion Recognition.pdf:PDF},
  groups    = {from others},
  isbn      = {978-3-540-73333-1},
  url       = {https://link.springer.com/chapter/10.1007/978-3-540-73333-1_30},
}

@InCollection{Siebert2011,
  author    = {Siebert, Felix W. and Oehl, Michael and Pfister, {Hans-Ruediger}},
  booktitle = {Advances in Human Factors, Ergonomics, and Safety in Manufacturing and Service Industries},
  publisher = {CRC Press},
  title     = {The measurement of grip-strength in automobiles: {A} new approach to detect driver's emotions},
  year      = {2011},
  edition   = {1st},
  editor    = {Waldemar Karwowski and Gavriel Salvendy},
  isbn      = {9780429151736},
  pages     = {775--783},
  abstract  = {This experimental study investigated grip-strength as a new non-invasive method to detect emotion, A positive emotion (happiness) and a negative emotion (anger) were examined regarding their influence on grip-strength applied to the steering wheel. Results confirmed and extended preliminary findings of LaMont (2000): Subjects showed increased grip-strength while driving a car when strong emotions like anger or happiness were induced. Implications for further research as well as for praxis will be outlined.},
  comment   = {driver's emotion recognition},
  file      = {:FILES/2011 - Siebert2011 - The measurement of grip-strength in automobiles A new approach to detect driver's emotions.pdf:PDF},
  groups    = {from others},
  url       = {https://www.taylorfrancis.com/chapters/mono/10.1201/EBK1439834992-83/measurement-grip-strength-automobiles-new-approach-detect-driver-emotions-waldemar-karwowski-gavriel-salvendy},
}

@Article{Zepf2020,
  author    = {Zepf, Sebastian and Hernandez, Javier and Schmitt, Alexander and Minker, Wolfgang and Picard, Rosalind W.},
  journal   = {ACM Computing Surveys},
  title     = {Driver emotion recognition for intelligent vehicles: {A} survey},
  year      = {2020},
  issn      = {0360-0300},
  month     = jun,
  number    = {3},
  pages     = {64},
  volume    = {53},
  abstract  = {Driving can occupy a large portion of daily life and often can elicit negative emotional states like anger or stress, which can significantly impact road safety and long-term human health. In recent decades, the arrival of new tools to help recognize human affect has inspired increasing interest in how to develop emotion-aware systems for cars. To help researchers make needed advances in this area, this article provides a comprehensive literature survey of work addressing the problem of human emotion recognition in an automotive context. We systematically review the literature back to 2002 and identify 63 peer-review published articles on this topic. We overview each study’s methodology to measure and recognize emotions in the context of driving. Across the literature, we find a strong preference toward studying emotional states associated with high arousal and negative valence, monitoring the different states with cardiac, electrodermal activity, and speech signals, and using supervised machine learning to automatically infer the underlying human affective states. This article summarizes the existing work together with publicly available resources (e.g.,&nbsp;datasets and tools) to help new researchers get started in this field. We also identify new research opportunities to help advance progress for improving driver emotion recognition.},
  comment   = {survey of driver's emotion recognition techniques},
  doi       = {10.1145/3388790},
  file      = {:FILES/2020 - Zepf2020 - Driver Emotion Recognition for Intelligent Vehicles- A Survey.pdf:PDF},
  groups    = {from others},
  keywords  = {Affective computing, literature survey, emotion measurement, machine learning, road safety, intelligent user sensing},
  publisher = {Association for Computing Machinery},
  url       = {https://dl.acm.org/doi/10.1145/3388790},
}

@Article{Levesque1997,
  author   = {Hector J. Levesque and Raymond Reiter and Yves Lesp\'{e}rance and Fangzhen Lin and Richard B. Scherl},
  journal  = {The Journal of Logic Programming},
  title    = {{GOLOG}: {A} logic programming language for dynamic domains},
  year     = {1997},
  issn     = {0743-1066},
  note     = {Reasoning about Action and Change},
  number   = {1},
  pages    = {59--83},
  volume   = {31},
  abstract = {This paper proposes a new logic programming language called GOLOG whose interpreter automatically maintains an explicit representation of the dynamic world being modeled, on the basis of user supplied axioms about the preconditions and effects of actions and the initial state of the world. This allows programs to reason about the state of the world and consider the effects of various possible courses of action before committing to a particular behavior. The net effect is that programs may be written at a much higher level of abstraction than is usually possible. The language appears well suited for applications in high level control of robots and industrial processes, intelligent software agents, discrete event simulation, etc. It is based on a formal theory of action specified in an extended version of the situation calculus. A prototype implementation in Prolog has been developed.},
  comment  = {logic programming language as command representation},
  doi      = {10.1016/S0743-1066(96)00121-5},
  file     = {:FILES/1997 - Levesque1997 - GOLOG- A logic programming language for dynamic domains.pdf:PDF},
  groups   = {task understanding},
  url      = {https://www.sciencedirect.com/science/article/pii/S0743106696001215},
}

@Article{Randall2019,
  author    = {Randall, Natasha},
  journal   = {ACM Transactions on Human-Robot Interaction},
  title     = {A survey of robot-assisted language learning {(RALL)}},
  year      = {2019},
  month     = dec,
  number    = {1},
  pages     = {7},
  volume    = {9},
  abstract  = {Robot-assisted language learning (RALL) is becoming a more commonly studied area of human-robot interaction (HRI). This research draws on theories and methods from many different fields, with researchers utilizing different instructional methods, robots, and populations to evaluate the effectiveness of RALL. This survey details the characteristics of robots used—form, voice, immediacy, non-verbal cues, and personalization—along with study implementations, discussing research findings. It also analyzes robot effectiveness. While research clearly shows that robots can support native and foreign language acquisition, it has been unclear what benefits robots provide over computer-assisted language learning. This survey examines the results of relevant studies from 2004 (RALL's inception) to 2017. Results suggest that robots may be uniquely suited to aid in language production, with apparent benefits in comparison to other technology. As well, research consistently indicates that robots provide unique advantages in increasing learning motivation and in-task engagement, and decreasing anxiety, though long-term benefits are uncertain. Throughout this survey, future areas of exploration are suggested, with the hope that answers to these questions will allow for more robust design and implementation guidelines in RALL.},
  address   = {New York, NY, USA},
  comment   = {robot control language},
  doi       = {10.1145/3345506},
  file      = {:FILES/2019 - Randall2019 - A survey of robot-assisted language learning {(RALL)}.pdf:PDF},
  groups    = {representation},
  keywords  = {robot-assisted learning, RALL, human-robot interaction, social robotics, intelligent tutoring system, educational service robots, r-learning, Robot-assisted language learning, RAL},
  publisher = {Association for Computing Machinery},
  url       = {https://doi.org/10.1145/3345506},
}

@InProceedings{Vaswani2017,
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, undefinedukasz and Polosukhin, Illia},
  booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems (NIPS)},
  title     = {Attention is all you need},
  year      = {2017},
  address   = {Red Hook, NY, USA},
  pages     = {6000--6010},
  publisher = {Curran Associates Inc.},
  abstract  = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
  file      = {:FILES/2017 - Vaswani2017 - Attention is all you need.pdf:PDF},
  groups    = {machine learning},
  isbn      = {9781510860964},
  location  = {Long Beach, California, USA},
  url       = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
}

@Book{Kamp1993,
  author    = {Kamp, Hans and Reyle, Uwe},
  publisher = {Springer Netherlands},
  title     = {From discourse to logic: {Introduction} to modeltheoretic semantics of natural language, formal logic and discourse representation theory},
  year      = {1993},
  isbn      = {0792310284},
  comment   = {proposal of discourse representation theory},
  file      = {:FILES/1993 - Kamp1993 - From discourse to logic- {Introduction} to modeltheoretic semantics of natural language, formal logic and discourse representation theory.djvu:Djvu},
  groups    = {task understanding},
  url       = {http://gen.lib.rus.ec/book/index.php?md5=96a908c431b511a782109e5e2844c432},
}

@InProceedings{Kollar2009,
  author    = {Kollar, Thomas and Roy, Nicholas},
  booktitle = {2009 IEEE International Conference on Robotics and Automation},
  title     = {Utilizing object-object and object-scene context when planning to find things},
  year      = {2009},
  month     = {May},
  pages     = {2168-2173},
  abstract  = {In this paper, our goal is to search for a novel object, where we have a prior map of the environment and knowledge of some of the objects in it, but no information about the location of the specific novel object. We develop a probabilistic model over possible object locations that utilizes object-object and object-scene context. This model can be queried for any of over 25,000 naturally occurring objects in the world and is trained from labeled data acquired from the captions of photos on the Flickr Website. We show that these simple models based on object co-occurrences perform surprisingly well at localizing arbitrary objects in an office setting. In addition, we show how to compute paths that minimize the expected distance to the query object and show that this approach performs better than a greedy approach. Finally, we give preliminary results for grounding our approach in object classifiers.},
  comment   = {grounding of landmarks based on concurrence of objects and landmarks},
  doi       = {10.1109/ROBOT.2009.5152831},
  groups    = {task understanding},
  issn      = {1050-4729},
}

@Book{Jackendoff1983,
  author    = {Jackendoff, Ray},
  publisher = {MIT Press},
  title     = {Semantics and cognition},
  year      = {1983},
  volume    = {8},
  groups    = {task understanding},
}

@InProceedings{Tellex2009,
  author    = {Tellex, Stefanie and Roy, Deb},
  booktitle = {Proceedings of the 2009 International Conference on Multimodal Interfaces},
  title     = {Grounding spatial prepositions for video search},
  year      = {2009},
  address   = {New York, NY, USA},
  pages     = {253--260},
  publisher = {Association for Computing Machinery},
  abstract  = {Spatial language video retrieval is an important real-world problem that forms a test bed for evaluating semantic structures for natural language descriptions of motion on naturalistic data. Video search by natural language query requires that linguistic input be converted into structures that operate on video in order to find clips that match a query. This paper describes a framework for grounding the meaning of spatial prepositions in video. We present a library of features that can be used to automatically classify a video clip based on whether it matches a natural language query. To evaluate these features, we collected a corpus of natural language descriptions about the motion of people in video clips. We characterize the language used in the corpus, and use it to train and test models for the meanings of the spatial prepositions "to," "across," "through," "out," "along," "towards," and "around." The classifiers can be used to build a spatial language video retrieval system that finds clips matching queries such as "across the kitchen."},
  comment   = {features used for grounding in {Tellex2011}},
  doi       = {10.1145/1647314.1647369},
  groups    = {task understanding},
  isbn      = {9781605587721},
  keywords  = {video retrieval, spatial language},
  location  = {Cambridge, Massachusetts, USA},
  url       = {https://dl.acm.org/doi/10.1145/1647314.1647369},
}

@PhdThesis{Munoz2013,
  author  = {Mu\~{n}oz, Daniel},
  school  = {Carnegie Mellon University},
  title   = {Inference machines: {Parsing} scenes via iterated predictions},
  year    = {2013},
  address = {Pittsburgh, Pennsylvania, USA},
  month   = jun,
  comment = {object recognition in {Boularias2015}},
  file    = {:FILES/2013 - Munoz2013 - Inference machines- {Parsing} scenes via iterated predictions.pdf:PDF},
  groups  = {task understanding},
}

@Article{Chen2011,
  author   = {Chen, {Chih-Rung} and Wong, {Wei-Su} and Chiu, {Ching-Te}},
  journal  = {IEEE Transactions on Very Large Scale Integration (VLSI) Systems},
  title    = {A 0.64 mm$^{2}$ real-time cascade face detection design based on reduced two-field extraction},
  year     = {2011},
  issn     = {1557-9999},
  month    = {Nov},
  number   = {11},
  pages    = {1937-1948},
  volume   = {19},
  abstract = {Face detection is widely used in portable consumer handheld devices aimed at low area, low power, and high performance applications. The boosted cascade algorithm is one of the fastest face detection algorithms in use, but its hardware implementation requires a huge amount of SRAM to store the input data, integral image, and classifiers. This paper proposes a novel cascade face detection architecture based on a reduced two-field feature extraction scheme for faster integral image calculation and feature extraction. This scheme reduces the required memory for storing integral images by 75%, and employs multiple register files instead of a single SRAM to speed up the integral image updating and feature extraction processes. The reduced integral images have only 5% of the features of original images. Although this approach requires more weak classifiers, the proposed parallel cascade detection architecture reduces the average detection time for one feature to 63% that of the original. A 0.64 mm2 15 mw (@390 fps) boosted cascade face detection is implemented under the UMC 90-nm CMOS technology. Experimental results show that this face detection system can achieve a high face detection rate in processing 160 × 120 grayscale images at a speed of 390 fps.},
  comment  = {face recognition in {Zhang2020b}},
  doi      = {10.1109/TVLSI.2010.2069575},
  file     = {:FILES/2011 - Chen2011 - A 0.64 mm2 Real-Time Cascade Face Detection Design Based on Reduced Two-Field Extraction.pdf:PDF},
  groups   = {task understanding},
  url      = {https://ieeexplore.ieee.org/document/5580132},
}

@Article{Wang2014,
  author  = {Wang, {Yi-Qing}},
  journal = {Image Processing On Line},
  title   = {An analysis of the {Viola-Jones} face detection algorithm},
  year    = {2014},
  pages   = {128--148},
  volume  = {4},
  comment = {face recognition in {Zhang2020b}},
  groups  = {task understanding},
  url     = {http://www.ipol.im/pub/art/2014/104/},
}

@Article{Yang2018,
  author   = {Yang, Biao and Cao, Jinmeng and Ni, Rongrong and Zhang, Yuyu},
  journal  = {IEEE Access},
  title    = {Facial expression recognition using weighted mixture deep neural network based on double-channel facial images},
  year     = {2018},
  issn     = {2169-3536},
  pages    = {4630--4640},
  volume   = {6},
  abstract = {Facial expression recognition (FER) is a significant task for the machines to understand the emotional changes in human beings. However, accurate hand-crafted features that are highly related to changes in expression are difficult to extract because of the influences of individual difference and variations in emotional intensity. Therefore, features that can accurately describe the changes in facial expressions are urgently required. Method: A weighted mixture deep neural network (WMDNN) is proposed to automatically extract the features that are effective for FER tasks. Several pre-processing approaches, such as face detection, rotation rectification, and data augmentation, are implemented to restrict the regions for FER. Two channels of facial images, including facial grayscale images and their corresponding local binary pattern (LBP) facial images, are processed by WMDNN. Expression-related features of facial grayscale images are extracted by fine-tuning a partial VGG16 network, the parameters of which are initialized using VGG16 model trained on ImageNet database. Features of LBP facial images are extracted by a shallow convolutional neural network (CNN) built based on DeepID. The outputs of both channels are fused in a weighted manner. The result of final recognition is calculated using softmax classification. Results: Experimental results indicate that the proposed algorithm can recognize six basic facial expressions (happiness, sadness, anger, disgust, fear, and surprise) with high accuracy. The average recognition accuracies for benchmarking data sets “CK+,”“JAFFE,”and “Oulu-CASIA”are 0.970, 0.922, and 0.923, respectively. Conclusions: The proposed FER method outperforms the state-of-the-art FER methods based on the hand-crafted features or deep networks using one channel. Compared with the deep networks that use multiple channels, our proposed network can achieve comparable performance with easier procedures. Fine-tuning is effective to FER tasks with a well pre-trained model if sufficient samples cannot be collected.},
  comment  = {rotation rectification in {Zhang2020b}},
  doi      = {10.1109/ACCESS.2017.2784096},
  groups   = {task understanding},
  url      = {https://ieeexplore.ieee.org/document/8214102},
}

@Article{Ranganathan2011,
  author   = {Ananth Ranganathan and Frank Dellaert},
  journal  = {The International Journal of Robotics Research},
  title    = {Online probabilistic topological mapping},
  year     = {2011},
  month    = jan,
  number   = {6},
  pages    = {755--771},
  volume   = {30},
  abstract = {We present a novel algorithm for topological mapping, which is the problem of finding the graph structure of an environment from a sequence of measurements. Our algorithm, called Online Probabilistic Topological Mapping (OPTM), systematically addresses the problem by constructing the posterior on the space of all possible topologies given measurements. With each successive measurement, the posterior is updated incrementally using a Rao—Blackwellized particle filter. We present efficient sampling mechanisms using data-driven proposals and prior distributions on topologies that further enable OPTM’s operation in an online manner. OPTM can incorporate various sensors seamlessly, as is demonstrated by our use of appearance, laser, and odometry measurements. OPTM is the first topological mapping algorithm that is theoretically accurate, systematic, sensor independent, and online, and thus advances the state of the art significantly. We evaluate the algorithm on a robot in diverse environments.},
  comment  = {Rao-Blackwellization method used in {Walter2013}},
  doi      = {10.1177/0278364910393287},
  groups   = {task understanding},
  url      = {https://journals.sagepub.com/doi/abs/10.1177/0278364910393287},
}

@Misc{Zhang2017SR,
  author       = {Zhang, Anthony},
  howpublished = {Software},
  title        = {Speech recognition},
  year         = {2017},
  groups       = {softwares},
  url          = {https://github.com/Uberi/speech_recognition},
}

@InProceedings{Sugiura2017,
  author    = {Sugiura, Komei and Kawai, Hisashi},
  booktitle = {Proceedings of the 2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  title     = {Grounded language understanding for manipulation instructions using {GAN}-based classification},
  year      = {2017},
  address   = {Okinawa, Japan},
  month     = dec,
  pages     = {519--524},
  publisher = {IEEE},
  abstract  = {The target task of this study is grounded language understanding for domestic service robots (DSRs). In particular, we focus on instruction understanding for short sentences where verbs are missing. This task is of critical importance to build communicative DSRs because manipulation is essential for DSRs. Existing instruction understanding methods usually estimate missing information only from non-grounded knowledge; therefore, whether the predicted action is physically executable or not was unclear. In this paper, we present a grounded instruction understanding method to estimate appropriate objects given an instruction and situation. We extend the Generative Adversarial Nets (GAN) and build a GAN-based classifier using latent representations. To quantitatively evaluate the proposed method, we have developed a data set based on the standard data set used for visual question answering (VQA). Experimental results have shown that the proposed method gives the better result than baseline methods.},
  comment   = {la-gan for finding target area in carry and place task},
  doi       = {10.1109/ASRU.2017.8268980},
  groups    = {task understanding},
  url       = {https://ieeexplore.ieee.org/document/8268980},
}

@InProceedings{Le2014,
  author    = {Quoc Le and Tomas Mikolov},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning (ICML)},
  title     = {Distributed representations of sentences and documents},
  year      = {2014},
  address   = {Bejing, China},
  editor    = {Eric P. Xing and Tony Jebara},
  month     = jun,
  pages     = {1188--1196},
  publisher = {PMLR},
  volume    = {32},
  abstract  = {Many machine learning algorithms require the input to be represented as a fixed length feature vector. When it comes to texts, one of the most common representations is bag-of-words. Despite their popularity, bag-of-words models have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, "powerful," "strong" and "Paris" are equally distant. In this paper, we propose an unsupervised algorithm that learns vector representations of sentences and text documents. This algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that our technique outperforms bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.},
  file      = {:FILES/2014 - Le2014 - Distributed Representations of Sentences and Documents.pdf:PDF},
  groups    = {task understanding},
  url       = {http://proceedings.mlr.press/v32/le14.html},
}

@InProceedings{Golland2010,
  author    = {Golland, Dave and Liang, Percy and Klein, Dan},
  booktitle = {Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  title     = {A game-theoretic approach to generating spatial descriptions},
  year      = {2010},
  address   = {USA},
  pages     = {410--419},
  publisher = {Association for Computational Linguistics},
  abstract  = {Language is sensitive to both semantic and pragmatic effects. To capture both effects, we model language use as a cooperative game between two players: a speaker, who generates an utterance, and a listener, who responds with an action. Specifically, we consider the task of generating spatial references to objects, wherein the listener must accurately identify an object described by the speaker. We show that a speaker model that acts optimally with respect to an explicit, embedded listener model substantially outperforms one that is trained to directly generate spatial descriptions.},
  comment   = {\cite{Guadarrama2013} utilized the probabilistic compositional semantics},
  file      = {:FILES/2013 - Golland2010 - A Game-Theoretic Approach to Generating Spatial Descriptions.pdf:PDF},
  groups    = {task understanding},
  location  = {Cambridge, Massachusetts},
  url       = {https://dl.acm.org/doi/abs/10.5555/1870658.1870698},
}

@InProceedings{He2016,
  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {Deep residual learning for image recognition},
  year      = {2016},
  month     = {June},
  comment   = {ResNet-152 in {Anderson2018}},
  file      = {:FILES/2016 - He2016 - Deep Residual Learning for Image Recognition.pdf:PDF},
  groups    = {task understanding},
  url       = {https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html},
}

@Misc{Artzi2013,
  author  = {Yoav Artzi and Luke Zettlemoyer},
  title   = {{UW SPF}: {The} {University} of {Washington} semantic parsing framework},
  year    = {2013},
  comment = {semantic parser},
  file    = {:FILES/2013 - Artzi2013 - {UW SPF}- {The} {University} of {Washington} semantic parsing framework.pdf:PDF},
  groups  = {task understanding},
}

@Article{McKeague2000,
  author   = {Ian W. {McKeague} and Wolfgang Wefelmeyer},
  journal  = {Journal of Statistical Planning and Inference},
  title    = {{Markov} chain {Monte Carlo} and {Rao–Blackwellization}},
  year     = {2000},
  issn     = {0378-3758},
  month    = apr,
  number   = {1},
  pages    = {171--182},
  volume   = {85},
  abstract = {We introduce a form of Rao–Blackwellization for Markov chains which uses the transition distribution for conditioning. We show that for reversible Markov chains, this form of Rao–Blackwellization always reduces the asymptotic variance, and derive two explicit forms of the variance reduction obtained through repeated Rao–Blackwellization. The result applies to many Markov chain Monte Carlo methods used in practice. In particular, we discuss an application to data augmentation and give some simulation results for Ising model samplers.},
  doi      = {10.1016/S0378-3758(99)00079-8},
  file     = {:FILES/2000 - McKeague2000 - Markov chain Monte Carlo and Rao–Blackwellization.pdf:PDF},
  groups   = {mathematical basis},
  keywords = {Empirical estimator, Conditioning, Data augmentation, Ising model, Gibbs sampler, Metropolis algorithm},
  url      = {https://www.sciencedirect.com/science/article/pii/S0378375899000798},
}

@Article{Devlin2018,
  author        = {Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  journal       = {CoRR},
  title         = {{BERT}: Pre-training of deep bidirectional transformers for language understanding},
  year          = {2018},
  volume        = {abs/1810.04805},
  archiveprefix = {arXiv},
  eprint        = {1810.04805},
  file          = {:FILES/2018 - Devlin2018 - {BERT} Pre-training of deep bidirectional transformers for language understanding.pdf:PDF},
  groups        = {structure},
  timestamp     = {Tue, 30 Oct 2018 20:39:56 +0100},
  url           = {http://arxiv.org/abs/1810.04805},
}

@Book{Knight2010,
  author    = {Knight, Kevin and Rich, Elaine and Nair, B.},
  publisher = {Tata McGraw-Hill Education Pvt. Ltd.},
  title     = {Artificial intelligence},
  year      = {2010},
  edition   = {3rd},
  isbn      = {978-0070087705},
  groups    = {task understanding},
}

@Article{Forcada2011,
  author   = {Forcada, Mikel L. and Ginestí-Rosell, Mireia and Nordfalk, Jacob and {O’Regan}, Jim and Ortiz-Rojas, Sergio and P\'{e}rez-Ortiz, Juan Antonio and S\'{a}nchez-Martínez, Felipe and Ramírez-Sánchez, Gema and Tyers, Francis M.},
  journal  = {Machine Translation},
  title    = {Apertium: {A} free/open-source platform for rule-based machine translation},
  year     = {2011},
  issn     = {1573-0573},
  number   = {2},
  pages    = {127--144},
  volume   = {25},
  abstract = {Apertium is a free/open-source platform for rule-based machine translation. It is being widely used to build machine translation systems for a variety of language pairs, especially in those cases (mainly with related-language pairs) where shallow transfer suffices to produce good quality translations, although it has also proven useful in assimilation scenarios with more distant pairs involved. This article summarises the Apertium platform: the translation engine, the encoding of linguistic data, and the tools developed around the platform. The present limitations of the platform and the challenges posed for the coming years are also discussed. Finally, evaluation results for some of the most active language pairs are presented. An appendix describes Apertium as a free/open-source project.},
  doi      = {10.1007/s10590-011-9090-0},
  file     = {:FILES/2011 - Forcada2011 - Apertium- a free-open-source platform for rule-based machine translation.pdf:PDF},
  groups   = {machine translation},
  url      = {https://link.springer.com/article/10.1007/s10590-011-9090-0},
}

@Article{Lopez2008,
  author    = {Lopez, Adam},
  journal   = {ACM Computing Surveys},
  title     = {Statistical machine translation},
  year      = {2008},
  issn      = {0360-0300},
  month     = aug,
  number    = {3},
  pages     = {8},
  volume    = {40},
  abstract  = {Statistical machine translation (SMT) treats the translation of natural language as a machine learning problem. By examining many samples of human-produced translation, SMT algorithms automatically learn how to translate. SMT has made tremendous strides in less than two decades, and new ideas are constantly introduced. This survey presents a tutorial overview of the state of the art. We describe the context of the current research and then move to a formal problem description and an overview of the main subproblems: translation modeling, parameter estimation, and decoding. Along the way, we present a taxonomy of some different approaches within these areas. We conclude with an overview of evaluation and a discussion of future directions.},
  address   = {New York, NY, USA},
  doi       = {10.1145/1380584.1380586},
  file      = {:FILES/2008 - Lopez2008 - Statistical machine translation.pdf:PDF},
  groups    = {machine translation},
  keywords  = {machine translation, Natural language processing},
  publisher = {Association for Computing Machinery},
  url       = {https://dl.acm.org/doi/abs/10.1145/1380584.1380586},
}

@Article{Gaspari2015,
  author    = {Federico Gaspari and Hala Almaghout and Stephen Doherty},
  journal   = {Perspectives},
  title     = {A survey of machine translation competences: {Insights} for translation technology educators and practitioners},
  year      = {2015},
  number    = {3},
  pages     = {333--358},
  volume    = {23},
  doi       = {10.1080/0907676X.2014.979842},
  file      = {:FILES/2015 - Gaspari2015 - A survey of machine translation competences- {Insights} for translation technology educators and practitioners.pdf:PDF},
  groups    = {machine translation},
  publisher = {Routledge},
  url       = {https://www.tandfonline.com/doi/abs/10.1080/0907676X.2014.979842},
}

@InProceedings{Kazemi2014,
  author    = {Kazemi, Vahid and Sullivan, Josephine},
  booktitle = {Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title     = {One millisecond face alignment with an ensemble of regression trees},
  year      = {2014},
  address   = {Columbus, OH, USA},
  month     = jun,
  pages     = {1867--1874},
  publisher = {IEEE},
  abstract  = {This paper addresses the problem of Face Alignment for a single image. We show how an ensemble of regression trees can be used to estimate the face's landmark positions directly from a sparse subset of pixel intensities, achieving super-realtime performance with high quality predictions. We present a general framework based on gradient boosting for learning an ensemble of regression trees that optimizes the sum of square error loss and naturally handles missing or partially labelled data. We show how using appropriate priors exploiting the structure of image data helps with efficient feature selection. Different regularization strategies and its importance to combat overfitting are also investigated. In addition, we analyse the effect of the quantity of training data on the accuracy of the predictions and explore the effect of data augmentation using synthesized data.},
  doi       = {10.1109/CVPR.2014.241},
  file      = {:FILES/2014 - Kazemi2014 - One millisecond face alignment with an ensemble of regression trees.pdf:PDF},
  groups    = {emotion recognition},
  issn      = {1063-6919},
  url       = {https://ieeexplore.ieee.org/document/6909637},
}

@TechReport{Yanco2002,
  author      = {Holly A. Yanco and Jill L. Drury},
  institution = {University of Massachusetts Lowell},
  title       = {A taxonomy for human-robot interaction},
  year        = {2002},
  number      = {FS-02-03},
  type        = {AAAI 2002 FALL SYMPOSIA},
  file        = {:FILES/2002 - Yanco2002 - A taxonomy for human-robot interaction.pdf:PDF},
  groups      = {human robot interaction},
  url         = {https://www.aaai.org/Papers/Symposia/Fall/2002/FS-02-03/FS02-03-015.pdf},
}

@InProceedings{Kosuge2004,
  author    = {Kosuge, K. and Hirata, Y.},
  booktitle = {Proceedings of the 2004 IEEE International Conference on Robotics and Biomimetics (ROBIO)},
  title     = {Human-robot interaction},
  year      = {2004},
  address   = {Shenyang, China},
  month     = aug,
  pages     = {8--11},
  publisher = {IEEE},
  abstract  = {This article introduces several types of robots having physical interactions among a human/humans and a robot/robots, which we have developed so far. MR Helper (mobile robot helper) is a mobile robot with dual manipulators, which could manipulate an object in cooperation with a human. DR Helpers (distributed robot helpers) are multiple small mobile robots which transport an object in cooperation with a human/humans. MS DanceR (mobile smart dance robot) could dance the waltz as a female dance partner with a male dancer. These examples inspire possible applications of the human-robot interaction in near future},
  doi       = {10.1109/ROBIO.2004.1521743},
  file      = {:FILES/2004 - Kosuge2004 - Human-robot interaction.pdf:PDF},
  groups    = {human robot interaction},
  url       = {https://ieeexplore.ieee.org/abstract/document/1521743},
}

@Article{Peternel2018,
  author   = {Peternel, Luka and Tsagarakis, Nikos and Caldwell, Darwin and Ajoudani, Arash},
  journal  = {Autonomous Robots},
  title    = {Robot adaptation to human physical fatigue in human-robot co-manipulation},
  year     = {2018},
  issn     = {1573-7527},
  number   = {5},
  pages    = {1011--1021},
  volume   = {42},
  abstract = {In this paper, we propose a novel method for human-robot collaboration, where the robot physical behaviour is adapted online to the human motor fatigue. The robot starts as a follower and imitates the human. As the collaborative task is performed under the human lead, the robot gradually learns the parameters and trajectories related to the task execution. In the meantime, the robot monitors the human fatigue during the task production. When a predefined level of fatigue is indicated, the robot uses the learnt skill to take over physically demanding aspects of the task and lets the human recover some of the strength. The human remains present to perform aspects of collaborative task that the robot cannot fully take over and maintains the overall supervision. The robot adaptation system is based on the Dynamical Movement Primitives, Locally Weighted Regression and Adaptive Frequency Oscillators. The estimation of the human motor fatigue is carried out using a proposed online model, which is based on the human muscle activity measured by the electromyography. We demonstrate the proposed approach with experiments on real-world co-manipulation tasks: material sawing and surface polishing.},
  doi      = {10.1007/s10514-017-9678-1},
  file     = {:FILES/2018 - Peternel2018 - Robot adaptation to human physical fatigue in human-robot co-manipulation.pdf:PDF},
  groups   = {human robot interaction},
  url      = {https://link.springer.com/article/10.1007/s10514-017-9678-1},
}

@Article{Peterson2021,
  author    = {Peterson, Joshua C. and Bourgin, David D. and Agrawal, Mayank and Reichman, Daniel and Griffiths, Thomas L.},
  journal   = {Science},
  title     = {Using large-scale experiments and machine learning to discover theories of human decision-making},
  year      = {2021},
  issn      = {0036-8075},
  number    = {6547},
  pages     = {1209--1214},
  volume    = {372},
  abstract  = {Theories of human decision-making have proliferated in recent years. However, these theories are often difficult to distinguish from each other and offer limited improvement in accounting for patterns in decision-making over earlier theories. Peterson et al. leverage machine learning to evaluate classical decision theories, increase their predictive power, and generate new theories of decision-making (see the Perspective by Bhatia and He). This method has implications for theory generation in other domains.Science, abe2629, this issue p. 1209; see also abi7668, p. 1150Predicting and understanding how people make decisions has been a long-standing goal in many fields, with quantitative models of human decision-making informing research in both the social sciences and engineering. We show how progress toward this goal can be accelerated by using large datasets to power machine-learning algorithms that are constrained to produce interpretable psychological theories. Conducting the largest experiment on risky choice to date and analyzing the results using gradient-based optimization of differentiable decision theories implemented through artificial neural networks, we were able to recapitulate historical discoveries, establish that there is room to improve on existing theories, and discover a new, more accurate model of human decision-making in a form that preserves the insights from centuries of research.},
  doi       = {10.1126/science.abe2629},
  groups    = {Portfolio Selection},
  publisher = {American Association for the Advancement of Science},
  url       = {https://science.sciencemag.org/content/372/6547/1209},
}

@Misc{Field2013,
  author  = {Tim Field},
  month   = mar,
  title   = {{OpenNI} {Tracker}},
  year    = {2013},
  comment = {gesture identification based on skeleton frames},
  groups  = {softwares},
  url     = {http://wiki.ros.org/openni_tracker},
}

@InProceedings{Linde2004,
  author    = {Linde, Oskar and Lindeberg, Tony},
  booktitle = {Proceedings of the 17th International Conference on Pattern Recognition (ICPR)},
  title     = {Object recognition using composed receptive field histograms of higher dimensionality},
  year      = {2004},
  address   = {USA},
  pages     = {1--6},
  publisher = {IEEE Computer Society},
  abstract  = {Recent work has shown that effective methods for recognising objects or spatio-temporal
events can be constructed based on receptive field responses summarised into histograms
or other histogram-like image descriptors. This paper presents a set of composed histogram
features of higher dimensionality, which give significantly better recognition performance
compared to the histogram descriptors of lower dimensionality that were used in the
original papers by Swain &amp; Ballard (1991) or Schiele &amp; Crowley (2000). The use of
histograms of higher dimensionality is made possible by a sparse representation for
efficient computation and handling of higher-dimensional histograms. Results of extensive
experiments are reported, showing how the performance of histogram-based recognition
schemes depend upon different combinations of cues, in terms of Gaussian derivatives
or differential invariants applied to either intensity information, chromatic information
or both. It is shown that there exist composed higher-dimensional histogram descriptors
with much better performance for recognising known objects than previously used histogram
features. Experiments are also reported of classifying unknown objects into visual
categories.},
  groups    = {interesting articles},
  isbn      = {0769521282},
  url       = {https://dl.acm.org/doi/abs/10.5555/1018428.1020637},
}

@InProceedings{Xu2005,
  author    = {Xu, Linli and Schuurmans, Dale},
  booktitle = {Proceedings of the 20th National Conference on Artificial Intelligence (AAAI)},
  title     = {Unsupervised and semi-supervised multi-class support vector nachines},
  year      = {2005},
  address   = {Pittsburgh, Pennsylvania},
  pages     = {904--910},
  publisher = {AAAI Press},
  abstract  = {We present new unsupervised and semi-supervised training algorithms for multi-class
support vector machines based on semidefinite programming. Although support vector
machines (SVMs) have been a dominant machine learning technique for the past decade,
they have generally been applied to supervised learning problems. Developing unsupervised
extensions to SVMs has in fact proved to be difficult. In this paper, we present a
principled approach to unsupervised SVM training by formulating convex relaxations
of the natural training criterion: find a labeling that would yield an optimal SVM
classifier on the resulting training data. The problem is hard, but semidefinite relaxations
can approximate this objective surprisingly well. While previous work has concentrated
on the two-class case, we present a general, multi-class formulation that can be applied
to a wider range of natural data sets. The resulting training procedures are computationally
intensive, but produce high quality generalization results.},
  groups    = {SVM},
  isbn      = {157735236x},
  url       = {https://dl.acm.org/doi/10.5555/1619410.1619478},
}

@InProceedings{Schank1969,
  author    = {Schank, Roger C. and Tesler, Larry},
  booktitle = {Proceedings of the 1969 Conference on Computational Linguistics (COLING)},
  title     = {A conceptual dependency parser for natural language},
  year      = {1969},
  address   = {USA},
  pages     = {1--3},
  publisher = {Association for Computational Linguistics},
  abstract  = {This paper describes an operable automatic parser for natural language. The parser
is not concerned with producing the syntactic structure of an input sentence. Instead,
it is a conceptual parser, concerned with determining the underlying meaning of the
input. Given a natural language input, the parser identifies and disambiguates the
concepts derivable from that input and places them into a network that explicates
their inter-relations with respect to the unambiguous meaning of the input.The parser
utilizes a conceptually-oriented dependency grammar that has as its highest level
the network which represents the underlying conceptual structure of a linguistic input.
The parser also incorporates a language-free semantics that checks all possible conceptual
dependencies with its own knowledge of the world.The parser is capable of learning
new words and new constructions. It presently has a vocabulary of a few hundred words
which enables it to operate in a psychiatric interviewing program without placing
any restriction on the linguistic input.The theory behind the conceptual dependency
is outlined in this paper and the parsing algorithm is explained in some detail.},
  doi       = {10.3115/990403.990405},
  file      = {:FILES/1969 - Schank1969 - A conceptual dependency parser for natural language.pdf:PDF},
  groups    = {nlp},
  location  = {S\r{a}ng-S\"{a}by, Sweden},
  url       = {https://dl.acm.org/doi/10.3115/990403.990405},
}

@InProceedings{Milward2000,
  author    = {Milward, David},
  booktitle = {Proceedings of the 38th Annual Meeting on Association for Computational Linguistics (ACL)},
  title     = {Distributing representation for robust interpretation of dialogue utterances},
  year      = {2000},
  address   = {USA},
  pages     = {133--141},
  publisher = {Association for Computational Linguistics},
  abstract  = {A syntax tree or standard semantic representation can be represented as a set of indexed
constraints. This paper describes how this idea can be used in task oriented dialogue
systems to provide interpretation rules which incorporate structural and contextual
constraints where available, and degrade gracefully on ungrammatical input.},
  doi       = {10.3115/1075218.1075236},
  file      = {:FILES/2000 - Milward2000 - Distributing representation for robust interpretation of dialogue utterances.pdf:PDF},
  groups    = {nlp},
  location  = {Hong Kong},
  url       = {https://dl.acm.org/doi/10.3115/1075218.1075236},
}

@Article{Gelfond1991,
  author  = {Michael Gelfond and Vladimir Lifschitz},
  journal = {New Generation Computing},
  title   = {Classical negation in logic programs and disjunctive databases},
  year    = {1991},
  pages   = {365--385},
  volume  = {9},
  comment = {ASP},
  groups  = {task understanding},
  url     = {http://www.cs.utexas.edu/users/ai-lab?gel91b},
}

@Article{Widayani2020,
  author  = {Heni Widayani and Nuning Nuraini and Anita Triska},
  journal = {CAUCHY - Jurnal Matematika Murni dan Aplikasi},
  title   = {Pyramid population prediction using age structure model},
  year    = {2020},
  issn    = {2086-0382},
  number  = {2},
  pages   = {66--76},
  volume  = {6},
  doi     = {10.18860/ca.v6i2.8859},
  file    = {:FILES/2020 - Widayani2020 - Pyramid population prediction using age structure model.pdf:PDF},
  groups  = {interesting articles},
  url     = {http://ejournal.uin-malang.ac.id/index.php/Math/article/view/8859#:~:text=The population pyramid prediction of the five countries,in a country in the next few years.},
}

@InBook{BenAri2018,
  author    = {{Ben-Ari}, Mordechai and Mondada, Francesco},
  pages     = {1--20},
  publisher = {Springer International Publishing},
  title     = {Robots and their applications},
  year      = {2018},
  address   = {Cham},
  isbn      = {978-3-319-62533-1},
  abstract  = {This chapter starts with an overview and classification of robots: industrial robots, autonomous mobile robots, humanoid robots and educational robots. A specification is given of a generic educational robot used throughout the book: a small mobile robot with differential drive and horizontal and ground proximity sensors. A pseudocode is defined so that algorithms can be presented in a platform-independent manner. The chapter concludes with a detailed overview of the contents of the book.},
  booktitle = {Elements of Robotics},
  doi       = {10.1007/978-3-319-62533-1_1},
  groups    = {robots},
  url       = {https://link.springer.com/chapter/10.1007/978-3-319-62533-1_1},
}

@InProceedings{Huang2007,
  author    = {Huang, Hui-Min},
  booktitle = {Proceedings of the 2007 Workshop on Performance Metrics for Intelligent Systems (PerMIS)},
  title     = {Autonomy levels for unmanned systems {(ALFUS)} framework: {Safety} and application issues},
  year      = {2007},
  address   = {New York, NY, USA},
  pages     = {48--53},
  publisher = {Association for Computing Machinery},
  abstract  = {The Autonomy Levels for Unmanned Systems (ALFUS) framework is generic and applicable
to multiple unmanned system (UMS) domains. The key component of the Framework is metrics
along the three established axes or aspects. This paper attempts to examine how the
metrics might be applied to selected domains that include homeland security, manufacturing,
and defense. In particular, the paper attempts to lay out how the critical UMS concerns,
including requirements specification, performance measures, safety, and risks might
be established from the Framework.},
  comment   = {definition of autonomy},
  doi       = {10.1145/1660877.1660883},
  file      = {:FILES/2007 - Huang2007 - Autonomy levels for unmanned systems {(ALFUS)} framework- {Safety} and application issues.pdf:PDF},
  groups    = {robots},
  isbn      = {9781595938541},
  keywords  = {metrics, environment, contextual autonomous capability (CAC), human robot interaction (HRI), autonomy, task, human independence (HI), mission, unmanned system (UMS)},
  location  = {Washington, D.C.},
  url       = {https://dl.acm.org/doi/abs/10.1145/1660877.1660883},
}

@InProceedings{Park2020,
  author    = {Park, Jae Sung and Bhagavatula, Chandra and Mottaghi, Roozbeh and Farhadi, Ali and Choi, Yejin},
  booktitle = {Computer Vision -- ECCV 2020},
  title     = {{VisualCOMET}: {Reasoning} about the dynamic context of a still image},
  year      = {2020},
  address   = {Cham},
  editor    = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, {Jan-Michael}},
  pages     = {508--524},
  publisher = {Springer International Publishing},
  abstract  = {Even from a single frame of a still image, people can reason about the dynamic story of the image before, after, and beyond the frame. For example, given an image of a man struggling to stay afloat in water, we can reason that the man fell into the water sometime in the past, the intent of that man at the moment is to stay alive, and he will need help in the near future or else he will get washed away. We propose  VisualCOMET, (Visual Commonsense Reasoning in Time.) the novel framework of visual commonsense reasoning tasks to predict events that might have happened before, events that might happen next, and the intents of the people at present. To support research toward visual commonsense reasoning, we introduce the first large-scale repository of Visual Commonsense Graphs that consists of over 1.4 million textual descriptions of visual commonsense inferences carefully annotated over a diverse set of 59,000 images, each paired with short video summaries of before and after. In addition, we provide person-grounding (i.e., co-reference links) between people appearing in the image and people mentioned in the textual commonsense descriptions, allowing for tighter integration between images and text. We establish strong baseline performances on this task and demonstrate that integration between visual and textual commonsense reasoning is the key and wins over non-integrative alternatives.},
  doi       = {10.1007/978-3-030-58558-7_30},
  file      = {:FILES/2020 - Park2020 - {VisualCOMET}- {Reasoning} about the dynamic context of a still image.pdf:PDF},
  groups    = {visual understanding},
  isbn      = {978-3-030-58558-7},
  url       = {https://link.springer.com/chapter/10.1007/978-3-030-58558-7_30},
}

@Book{Karwowski2011,
  editor    = {Karwowski, Waldemar and Salvendy, Gavriel},
  publisher = {CRC Press, Taylor \& Framcis Group},
  title     = {Advances in human factors, ergonomics, and safety in manudacturing and service industries},
  year      = {2011},
  isbn      = {978-1-4398-3500-5},
  file      = {:FILES/2011 - Karwowski2011 - Advances in human factors, ergonomics, and safety in manudacturing and service industries.pdf:PDF},
  groups    = {from others},
}

@Article{Li2021b,
  author     = {Li, Zhihao and Mu, Yishan and Sun, Zhenglong and Song, Sifan and Su, Jionglong and Zhang, Jiaming},
  journal    = {Frontiers in Neurorobotics},
  title      = {Intention understanding in human–robot interaction based on visual-{NLP} semantics},
  year       = {2021},
  issn       = {1662-5218},
  pages      = {121},
  volume     = {14},
  abstract   = {With the rapid development of robotic and AI technology in recent years, human–robot interaction has made great advancement, making practical social impact. Verbal commands are one of the most direct and frequently used means for human–robot interaction. Currently, such technology can enable robots to execute pre-defined tasks based on simple and direct and explicit language instructions, e.g., certain keywords must be used and detected. However, that is not the natural way for human to communicate. In this paper, we propose a novel task-based framework to enable the robot to comprehend human intentions using visual semantics information, such that the robot is able to satisfy human intentions based on natural language instructions (total three types, namely clear, vague, and feeling, are defined and tested). The proposed framework includes a language semantics module to extract the keywords despite the explicitly of the command instruction, a visual object recognition module to identify the objects in front of the robot, and a similarity computation algorithm to infer the intention based on the given task. The task is then translated into the commands for the robot accordingly. Experiments are performed and validated on a humanoid robot with a defined task: to pick the desired item out of multiple objects on the table, and hand over to one desired user out of multiple human participants. The results show that our algorithm can interact with different types of instructions, even with unseen sentence structures.},
  doi        = {10.3389/fnbot.2020.610139},
  file       = {:FILES/2021 - Li2021b - Intention Understanding in Human–Robot Interaction Based on Visual-NLP Semantics.pdf:PDF},
  groups     = {visual understanding, task understanding},
  keywords   = {skimmed},
  readstatus = {skimmed},
  url        = {https://www.frontiersin.org/article/10.3389/fnbot.2020.610139},
}

@Article{Diez2013,
  author     = {Pablo F. Diez and Sandra M. Torres M\"{u}ller and Vicente A. Mut and Eric Laciar and Enrique Avila and Teodiano Freire {Bastos-Filho} and M\'{a}rio {Sarcinelli-Filho}},
  journal    = {Journal of Medical Engineering \& Physics},
  title      = {Commanding a robotic wheelchair with a high-frequency steady-state visual evoked potential based brain-computer interface},
  year       = {2013},
  month      = aug,
  number     = {8},
  pages      = {1155--1164},
  volume     = {35},
  comment    = {利用EEG signal实现对wheelchair的控制，只有5中pattern},
  doi        = {10.1016/j.medengphy.2012.12.005},
  file       = {:FILES/2013 - Diez2013 - Commanding a robotic wheelchair with a high-frequency steady-state visual evoked potential based brain-computer interface.pdf:PDF},
  groups     = {from brainwave},
  readstatus = {read},
  url        = {https://www.sciencedirect.com/science/article/pii/S1350453312003335?via=ihub},
}

@Article{Ko2019,
  author         = {Ko, Sang-Ki and Kim, Chang Jo and Jung, Hyedong and Cho, Choongsang},
  journal        = {Applied Sciences},
  title          = {Neural sign language translation based on human keypoint estimation},
  year           = {2019},
  issn           = {2076-3417},
  number         = {13},
  volume         = {9},
  abstract       = {We propose a sign language translation system based on human keypoint estimation. It is well-known that many problems in the field of computer vision require a massive dataset to train deep neural network models. The situation is even worse when it comes to the sign language translation problem as it is far more difficult to collect high-quality training data. In this paper, we introduce the KETI (Korea Electronics Technology Institute) sign language dataset, which consists of 14,672 videos of high resolution and quality. Considering the fact that each country has a different and unique sign language, the KETI sign language dataset can be the starting point for further research on the Korean sign language translation. Using the KETI sign language dataset, we develop a neural network model for translating sign videos into natural language sentences by utilizing the human keypoints extracted from the face, hands, and body parts. The obtained human keypoint vector is normalized by the mean and standard deviation of the keypoints and used as input to our translation model based on the sequence-to-sequence architecture. As a result, we show that our approach is robust even when the size of the training data is not sufficient. Our translation model achieved 93.28% (55.28%, respectively) translation accuracy on the validation set (test set, respectively) for 105 sentences that can be used in emergency situations. We compared several types of our neural sign translation models based on different attention mechanisms in terms of classical metrics for measuring the translation performance.},
  article-number = {2683},
  comment        = {sign language recognition using neural networks, where input is video and the estimated human keypoints and output is natural sentences. 所用的模型是RNN（LSTM或GRU） with attention，需要对keypoints进行normalization，从而保证human-independent,同时对背景不敏感。},
  doi            = {10.3390/app9132683},
  file           = {:FILES/2019 - Ko2019 - Neural Sign Language Translation Based on Human Keypoint Estimation.pdf:PDF},
  groups         = {sign language},
  readstatus     = {skimmed},
  url            = {https://www.mdpi.com/2076-3417/9/13/2683},
}

@InProceedings{Camgoz2018,
  author     = {Camgoz, Necati Cihan and Hadfield, Simon and Koller, Oscar and Ney, Hermann and Bowden, Richard},
  booktitle  = {Proceedings of the 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  title      = {Neural sign language translation},
  year       = {2018},
  month      = {June},
  pages      = {7784--7793},
  comment    = {Camgoz2020: 先将sign language 转换成token，再做text to text translation},
  file       = {:FILES/2018 - Camgoz2018 - Neural Sign Language Translation.pdf:PDF},
  groups     = {sign language},
  readstatus = {skimmed},
  url        = {https://openaccess.thecvf.com/content_cvpr_2018/html/Camgoz_Neural_Sign_Language_CVPR_2018_paper.html},
}

@InProceedings{Strubell2020,
  author    = {Emma Strubell and Ananya Ganesh and Andrew McCallum},
  booktitle = {Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI)},
  title     = {Energy and policy considerations for modern deep learning research},
  year      = {2020},
  month     = feb,
  pages     = {13693--13696},
  publisher = {AAAI Press},
  volume    = {34},
  doi       = {10.1609/aaai.v34i09.7123},
  file      = {:FILES/2020 - Strubell2020 - Energy and Policy Considerations for Modern Deep Learning Research.pdf:PDF},
  groups    = {energy},
  url       = {https://ojs.aaai.org/index.php/AAAI/article/view/7123},
}

@InProceedings{Gupta2004a,
  author       = {Surendra M. Gupta and Evren Erbis and Seamus M. {McGovern}},
  booktitle    = {Environmentally Conscious Manufacturing IV},
  title        = {Disassembly sequencing problem: {A} case study of a cell phone},
  year         = {2004},
  editor       = {Surendra M. Gupta},
  organization = {International Society for Optics and Photonics},
  pages        = {43--52},
  publisher    = {SPIE},
  volume       = {5583},
  abstract     = {Selection of an optimal disassembly sequence is essential for the efficient processing of a product at the end of its life. Disassembly sequences are listings of disassembly actions (such as the separation of an assembly into two or more subassemblies, or removing one or more connections between components). Disassembly takes place in remanufacturing, recycling, and disposal with a disassembly line being the best choice for automation. In this paper, the disassembly sequencing problem is solved for a cell phone case on a disassembly line, seeking a sequence which is feasible, minimizes the number of workstations (and hence idle times), provides for early removal of high demand/value parts, provides the removal of parts that lead to the access of greatest number of still-installed parts, and early removal of hazardous parts as well as for the grouping of parts for removal having identical part removal directions. Since finding the optimal sequence is computationally intensive due to factorial growth, a heuristic method is used taking into account various disassembly-specific matters. Using the experimentally determined precedence relationships and task times of a real-world cell phone, a MATLAB program is designed and a sequencing solution is generated. Finally, Design for Disassembly (DFD) improvements are recommended with respect to environmentally conscious manufacturing.},
  doi          = {10.1117/12.577196},
  groups       = {robots},
  keywords     = {Disassembly Line, Cell Phone, Balancing Problem},
  url          = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5583/1/Disassembly-sequencing-problem--a-case-study-of-a-cell/10.1117/12.577196.short},
}

@Article{Beer2014a,
  author  = {Jenay M. Beer and Arthur D. Fisk and Wendy A. Rogers},
  journal = {Journal of Human Robot Interaction},
  title   = {Toward a framework for levels of robot autonomy in human-robot interaction},
  year    = {2014},
  month   = jul,
  number  = {2},
  pages   = {74--99},
  volume  = {3},
  doi     = {10.5898/JHRI.3.2.Beer},
  groups  = {robots},
  url     = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5656240/},
}

@InProceedings{Ehsani2021,
  author     = {Ehsani, Kiana and Han, Winson and Herrasti, Alvaro and VanderBilt, Eli and Weihs, Luca and Kolve, Eric and Kembhavi, Aniruddha and Mottaghi, Roozbeh},
  booktitle  = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  title      = {{ManipulaTHOR}: {A} framework for visual object manipulation},
  year       = {2021},
  address    = {Virtual},
  month      = jun,
  pages      = {4497--4506},
  comment    = {这个是利用视觉感知信息来获得机械臂的运动轨迹,应该属于task planning的过程,且只能处理将一个物体从当前位置移动到新位置.},
  file       = {:FILES/2021 - Ehsani2021 - {ManipulaTHOR}- {A} framework for visual object manipulation.pdf:PDF},
  groups     = {visual understanding},
  keywords   = {skimmed},
  readstatus = {skimmed},
  url        = {https://openaccess.thecvf.com/content/CVPR2021/html/Ehsani_ManipulaTHOR_A_Framework_for_Visual_Object_Manipulation_CVPR_2021_paper.html},
}

@Article{Buetepage2019,
  author   = {B\"{u}tepage, Judith and Cruciani, Silvia and Kokic, Mia and Welle, Michael and Kragic, Danica},
  journal  = {Annual Review of Control, Robotics, and Autonomous Systems},
  title    = {From visual understanding to complex object manipulation},
  year     = {2019},
  number   = {1},
  pages    = {161--179},
  volume   = {2},
  abstract = {Planning and executing object manipulation requires integrating multiple sensory and motor channels while acting under uncertainty and complying with task constraints. As the modern environment is tuned for human hands, designing robotic systems with similar manipulative capabilities is crucial. Research on robotic object manipulation is divided into smaller communities interested in, e.g., motion planning, grasp planning, sensorimotor learning, and tool use. However, few attempts have been made to combine these areas into holistic systems. In this review, we aim to unify the underlying mechanics of grasping and in-hand manipulation by focusing on the temporal aspects of manipulation, including visual perception, grasp planning and execution, and goal-directed manipulation. Inspired by human manipulation, we envision that an emphasis on the temporal integration of these processes opens the way for human-like object use by robots.},
  comment  = {tas e planning},
  doi      = {10.1146/annurev-control-053018-023735},
  file     = {:FILES/2019 - Buetepage2019 - From Visual Understanding to Complex Object Manipulation.pdf:PDF},
  groups   = {visual understanding},
  url      = {https://www.annualreviews.org/doi/abs/10.1146/annurev-control-053018-023735},
}

@Misc{Bommasani2021,
  author   = {Rishi Bommasani and Drew A. Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S. Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dorottya Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Fei-Fei Li and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E. Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D. Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher R\'{e} and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W. Thomas and Florian Tram\`{e}r and Rose E. Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang},
  title    = {On the opportunities and risks of foundation models},
  year     = {2021},
  comment  = {about pre-trained model},
  groups   = {machine learning},
  priority = {prio1},
  url      = {https://fsi.stanford.edu/publication/opportunities-and-risks-foundation-models},
}

@InProceedings{Wang2018b,
  author     = {Wang, Yu and Shen, Yilin and Jin, Hongxia},
  booktitle  = {Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  title      = {A bi-model based {RNN} semantic frame parsing model for intent detection and slot filling},
  year       = {2018},
  address    = {New Orleans, Louisiana},
  month      = jun,
  pages      = {309--314},
  publisher  = {Association for Computational Linguistics},
  abstract   = {Intent detection and slot filling are two main tasks for building a spoken language understanding(SLU) system. Multiple deep learning based models have demonstrated good results on these tasks . The most effective algorithms are based on the structures of sequence to sequence models (or {``}encoder-decoder{''} models), and generate the intents and semantic tags either using separate models. Most of the previous studies, however, either treat the intent detection and slot filling as two separate parallel tasks, or use a sequence to sequence model to generate both semantic tags and intent. None of the approaches consider the cross-impact between the intent detection task and the slot filling task. In this paper, new Bi-model based RNN semantic frame parsing network structures are designed to perform the intent detection and slot filling tasks jointly, by considering their cross-impact to each other using two correlated bidirectional LSTMs (BLSTM). Our Bi-model structure with a decoder achieves state-of-art result on the benchmark ATIS data, with about 0.5{\%} intent accuracy improvement and 0.9 {\%} slot filling improvement.},
  comment    = {提出了一种bi-model based RNN with Bi-LSTM encoder and LSTM decoder to jointly detect intent and fill slots. the training is asynchronous, i.e., first train intent detection network and then slot filling network.

using ATIS dataset},
  doi        = {10.18653/v1/N18-2050},
  file       = {:FILES/2018 - Wang2018b - A Bi-Model Based {RNN} Semantic Frame Parsing Model for Intent Detection and Slot Filling.pdf:PDF},
  groups     = {task understanding},
  readstatus = {read},
  url        = {https://aclanthology.org/N18-2050},
}

@PhdThesis{王2020,
  author = {{学军} 王},
  school = {山西大学},
  title  = {鲁棒的稀疏表示方法研究},
  year   = {2020},
  file   = {:FILES/2020 - 王2020 - 鲁棒的稀疏表示方法研究.caj:caj},
  groups = {Compressive sensing},
}

@InProceedings{Qi2020,
  author    = {Qi, Yuankai and Pan, Zizheng and Zhang, Shengping and van den Hengel, Anton and Wu, Qi},
  booktitle = {Computer Vision -- ECCV 2020},
  title     = {Object-and-action aware model for visual language navigation},
  year      = {2020},
  address   = {Cham},
  editor    = {Vedaldi, Andrea and Bischof, Horst and Brox, Thomas and Frahm, Jan-Michael},
  pages     = {303--317},
  publisher = {Springer International Publishing},
  abstract  = {Vision-and-Language Navigation (VLN) is unique in that it requires turning relatively general natural-language instructions into robot agent actions, on the basis of visible environments. This requires to extract value from two very different types of natural-language information. The first is object description (e.g., `table', `door'), each presenting as a tip for the agent to determine the next action by finding the item visible in the environment, and the second is action specification (e.g., `go straight', `turn left') which allows the robot to directly predict the next movements without relying on visual perceptions. However, most existing methods pay few attention to distinguish these information from each other during instruction encoding and mix together the matching between textual object/action encoding and visual perception/orientation features of candidate viewpoints. In this paper, we propose an Object-and-Action Aware Model (OAAM) that processes these two different forms of natural language based instruction separately. This enables each process to match object-centered/action-centered instruction to their own counterpart visual perception/action orientation flexibly. However, one side-issue caused by above solution is that an object mentioned in instructions may be observed in the direction of two or more candidate viewpoints, thus the OAAM may not predict the viewpoint on the shortest path as the next action. To handle this problem, we design a simple but effective path loss to penalize trajectories deviating from the ground truth path. Experimental results demonstrate the effectiveness of the proposed model and path loss, and the superiority of their combination with a {\$}{\$}50{\backslash}{\%}{\$}{\$}50{\%}SPL score on the R2R dataset and a {\$}{\$}40{\backslash}{\%}{\$}{\$}40{\%}CLS score on the R4R dataset in unseen environments, outperforming the previous state-of-the-art.},
  file      = {:FILES/2020 - Qi2020 - Object-and-Action Aware Model for Visual Language Navigation.pdf:PDF},
  groups    = {navigation},
  isbn      = {978-3-030-58607-2},
  url       = {https://link.springer.com/chapter/10.1007/978-3-030-58607-2_18},
}

@Misc{Hinton2021,
  author        = {Geoffrey Hinton},
  title         = {How to represent part-whole hierarchies in a neural network},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2102.12627},
  file          = {:FILES/2021 - Hinton2021 - How to represent part-whole hierarchies in a neural network.pdf:PDF},
  groups        = {Neural Network},
  primaryclass  = {cs.CV},
  priority      = {prio1},
  url           = {https://arxiv.org/abs/2102.12627},
}

@Article{Tivatansakul2016,
  author  = {Somchanok Tivatansakul and Michiko Ohkura},
  journal = {International Journal of Affective Engineering},
  title   = {Emotion recognition using {ECG} signals with local pattern description methods},
  year    = {2016},
  number  = {2},
  pages   = {51--61},
  volume  = {15},
  doi     = {10.5057/ijae.IJAE-D-15-00036},
  file    = {:FILES/2016 - Tivatansakul2016 - Emotion recognition using {ECG} signals with local pattern description methods.pdf:PDF},
  groups  = {from bio signal},
  url     = {https://www.jstage.jst.go.jp/article/ijae/15/2/15_IJAE-D-15-00036/_article},
}

@InProceedings{Mithbavkar2021,
  author    = {Mithbavkar, Shraddha A. and Shah, Milind S.},
  booktitle = {Proceedings of 2021 IEEE 3rd Eurasia Conference on Biomedical Engineering, Healthcare and Sustainability (ECBIOS)},
  title     = {Analysis of {EMG} based emotion recognition for multiple people and emotions},
  year      = {2021},
  address   = {Tainan, Taiwan},
  month     = may,
  pages     = {1--4},
  publisher = {IEEE},
  abstract  = {The human-machine interaction has limitations in recognizing emotions. Electromyogram (EMG) based emotion recognition is prominent. The lack of online availability of people’s EMG signal databank constraints in research works. This research generates an EMG signal databank of nine emotions for eleven people. Long and Short Term Memory classifier (LSTM) is used for EMG-based emotion recognition. LSTM classifier achieved a 51.77% improvement in classification accuracy than Least-Square Support Vector Machine (LSSVM) classifier.},
  doi       = {10.1109/ECBIOS51820.2021.9510858},
  file      = {:FILES/2021 - Mithbavkar2021 - Analysis of {EMG} based emotion recognition for multiple people and emotions.pdf:PDF},
  groups    = {from bio signal},
  url       = {https://ieeexplore.ieee.org/abstract/document/9510858},
}

@Article{Liu2018a,
  author   = {Hongyi Liu and Tongtong Fang and Tianyu Zhou and Yuquan Wang and Lihui Wang},
  journal  = {Procedia CIRP},
  title    = {Deep learning-based multimodal control interface for human-robot collaboration},
  year     = {2018},
  issn     = {2212-8271},
  note     = {51st CIRP Conference on Manufacturing Systems},
  pages    = {3--8},
  volume   = {72},
  abstract = {In human-robot collaborative manufacturing, industrial robot is required to dynamically change its pre-programmed tasks and collaborate with human operators at the same workstation. However, traditional industrial robot is controlled by pre-programmed control codes, which cannot support the emerging needs of human-robot collaboration. In response to the request, this research explored a deep learning-based multimodal robot control interface for human-robot collaboration. Three methods were integrated into the multimodal interface, including voice recognition, hand motion recognition, and body posture recognition. Deep learning was adopted as the algorithm for classification and recognition. Human-robot collaboration specific datasets were collected to support the deep learning algorithm. The result presented at the end of the paper shows the potential to adopt deep learning in human-robot collaboration systems.},
  doi      = {10.1016/j.procir.2018.03.224},
  file     = {:FILES/2018 - Liu2018a - Deep Learning-based Multimodal Control Interface for Human-Robot Collaboration.pdf:PDF},
  groups   = {multimodal},
  keywords = {Human-robot collaboration, Deep learning, Robot control},
  url      = {https://www.sciencedirect.com/science/article/pii/S2212827118303846},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:knowledge graph\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:robot\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:representation\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:reasoning\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:dynamic KG\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:query\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:知识库调研报告\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:unsorted\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:task understanding\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:explanation\;0\;0\;0x8a8a8aff\;\;\;;
3 StaticGroup:dialog system\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:self-motivated\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:spatial relation\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:ontology based\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:classification based\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:navigation\;0\;0\;0x8a8a8aff\;\;\;;
3 StaticGroup:知识生成\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:NLU\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:visual understanding\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:multimodal\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:ontology\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:knowledge extractions\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Appendix\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:benchmark\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:data\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:industry report\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:my paper\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:projects\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:softwares\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:for aire\;0\;1\;0xff0000ff\;\;\;;
3 StaticGroup:ASR\;0\;1\;0x8a8a8aff\;\;\;;
4 StaticGroup:multi-modal\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:lipreading\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:from visual\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:from tactile\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:from kinematics\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:from bio signal\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:from gaze\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:from brainwave\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:from others\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:hand gesture\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:body gesture\;0\;0\;0x8a8a8aff\;\;\;;
3 StaticGroup:sign language\;0\;0\;0x8a8a8aff\;\;\;;
3 StaticGroup:face expression\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:action classification\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:approximation\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Compressive sensing\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:cloudpoint\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:DSP\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:global optimization\;0\;0\;0x8066ccff\;\;\;;
2 StaticGroup:concave\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:convergence\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Heuristics\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:Evolutionary Algorithms\;0\;1\;0x8a8a8aff\;\;\;;
4 StaticGroup:Biological Basis\;0\;1\;0x8a8a8aff\;\;\;;
4 StaticGroup:differential evolution\;0\;1\;0x8a8a8aff\;\;\;;
4 StaticGroup:Evolution Strategy\;0\;1\;0x8a8a8aff\;\;\;;
4 StaticGroup:genetic algorithms\;0\;0\;0x8a8a8aff\;\;history and development in GA\;;
3 StaticGroup:Simulated Annealing\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:Swarm algorithms\;0\;1\;0x8a8a8aff\;\;\;;
4 StaticGroup:ABC\;0\;1\;0x8a8a8aff\;\;\;;
4 StaticGroup:PSO\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:MIP\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:MILP\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:MINLP\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:multi-objective\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:nonsmooth optimization\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:proximal bundle method\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:stochastic programming\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:interesting articles\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:discrete\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:intelligent\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:svm\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:nonconvex\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:portfolio\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:quantum filtering\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:quantum network\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:robust statistics\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:to_read\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:identification-toread\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:control\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Kmax\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Clustering\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:FIR filter design\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:complementary problem\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:discrete\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:FRM\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:matrix decomposition\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:pattern match\;0\;0\;0x8a8a8aff\;\;\;;
3 StaticGroup:sparse\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:SPT\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:subexpression\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:two-dimensional FIR\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:window design\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:LMS\;0\;0\;0x8a8a8aff\;\;least median of squares\;;
2 StaticGroup:quantile optimization\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:SGP\;0\;1\;0xcc8099ff\;\;\;;
3 StaticGroup:bilevel\;0\;0\;0x8a8a8aff\;\;\;;
3 StaticGroup:bilinear\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:LSEO\;0\;0\;0x4d8080ff\;\;\;;
2 StaticGroup:VaR\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:algorithms\;0\;0\;0x8a8a8aff\;\;\;;
3 StaticGroup:Monte Carlo\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:nonparametric\;0\;0\;0x8a8a8aff\;\;\;;
3 StaticGroup:others\;0\;0\;0x8a8a8aff\;\;\;;
3 StaticGroup:parametric approach\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:time series\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:machine learning\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Feature Selection\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Neural Network\;0\;1\;0xe6994dff\;\;\;;
3 StaticGroup:Application\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:structure\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:theory\;0\;1\;0x8a8a8aff\;\;\;;
4 StaticGroup:expressive capacity\;0\;1\;0x8a8a8aff\;\;\;;
4 StaticGroup:approximability\;0\;1\;0x8a8a8aff\;\;\;;
4 StaticGroup:robustness\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:training algorithm\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:energy\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:regression\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:RL\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:sparsity\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:SVM\;0\;1\;0x00ff00ff\;\;\;;
2 StaticGroup:imitation learning\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:applications\;0\;0\;0x8a8a8aff\;\;\;;
3 StaticGroup:nlp\;0\;1\;0x8a8a8aff\;\;\;;
4 StaticGroup:dependency parsing\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:emotion recognition\;0\;0\;0x8a8a8aff\;\;\;;
3 StaticGroup:speech enhancement\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:speaker detection\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:fake news detection\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:question answering\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:learn from video\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:speech translation\;0\;0\;0x8a8a8aff\;\;\;;
3 StaticGroup:machine translation\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:mathematical basis\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:sampling by distribution\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:semi-infinite programming\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Portfolio Selection\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:asset allocation\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:concepts\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:cvar\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:expected shortfall\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:mean variance\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:prospect theory\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:utility theory\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:PWL\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:application\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Approximation\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:identification\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:optimization\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:robots\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:parallel manipulator\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:path planning\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:motion planning\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:task planning\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:human robot interaction\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:tour guide robot\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:sensing system\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:TEC\;0\;0\;0xff0000ff\;\;\;;
1 StaticGroup:Wang's Work\;0\;1\;0x8a8a8aff\;\;\;;
}
